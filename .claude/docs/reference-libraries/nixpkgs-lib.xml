This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    update.yml
lib/
  deprecated/
    misc.nix
    README.md
  fileset/
    benchmark.sh
    default.nix
    internal.nix
    mock-splitRoot.nix
    README.md
    tests.sh
  network/
    default.nix
    internal.nix
  path/
    tests/
      default.nix
      generate.awk
      prop.nix
      prop.sh
      unit.nix
    default.nix
    README.md
  systems/
    architectures.nix
    default.nix
    doubles.nix
    examples.nix
    flake-systems.nix
    inspect.nix
    parse.nix
    platforms.nix
    supported.nix
  tests/
    flakes/
      subflakeTest/
        subflake/
          flake.nix
        flake.nix
    modules/
      disable-recursive/
        bar.nix
        disable-bar.nix
        disable-foo.nix
        foo.nix
        main.nix
      functionTo/
        list-order.nix
        merging-attrs.nix
        merging-list.nix
        submodule-options.nix
        trivial.nix
        wrong-type.nix
      graph/
        a.nix
        b.nix
        test.nix
      types-anything/
        attrs-coercible.nix
        equal-atoms.nix
        functions.nix
        lists.nix
        mk-mods.nix
        nested-attrs.nix
      adhoc-freeformType-survives-type-merge.nix
      alias-with-priority-can-override.nix
      alias-with-priority.nix
      assert-module-class-is-nixos.nix
      attrsOf-conditional-check.nix
      attrsOf-lazy-check.nix
      boolByOr.nix
      class-check.nix
      declaration-positions.nix
      declare-attrsOf.nix
      declare-attrsOfSub-any-enable.nix
      declare-bare-submodule-deep-option-duplicate.nix
      declare-bare-submodule-deep-option.nix
      declare-bare-submodule-nested-option.nix
      declare-bare-submodule.nix
      declare-coerced-value-no-default.nix
      declare-coerced-value-unsound.nix
      declare-coerced-value.nix
      declare-either.nix
      declare-enable-nested.nix
      declare-enable.nix
      declare-int-between-value.nix
      declare-int-positive-value-nested.nix
      declare-int-positive-value.nix
      declare-int-unsigned-value.nix
      declare-lazyAttrsOf.nix
      declare-mkPackageOption.nix
      declare-oneOf.nix
      declare-set.nix
      declare-submodule-via-evalModules.nix
      declare-submoduleWith-modules.nix
      declare-submoduleWith-noshorthand.nix
      declare-submoduleWith-path.nix
      declare-submoduleWith-shorthand.nix
      declare-submoduleWith-special.nix
      declare-variants.nix
      default-type-merge-both.nix
      default.nix
      deferred-module-error.nix
      deferred-module.nix
      define-_module-args-custom.nix
      define-attrsOfSub-bar-enable.nix
      define-attrsOfSub-bar.nix
      define-attrsOfSub-foo-enable-force.nix
      define-attrsOfSub-foo-enable-if.nix
      define-attrsOfSub-foo-enable.nix
      define-attrsOfSub-foo-force-enable.nix
      define-attrsOfSub-foo-if-enable.nix
      define-attrsOfSub-foo.nix
      define-attrsOfSub-force-foo-enable.nix
      define-attrsOfSub-if-foo-enable.nix
      define-bare-submodule-values.nix
      define-enable-abort.nix
      define-enable-force.nix
      define-enable-throw.nix
      define-enable-with-custom-arg.nix
      define-enable-with-top-level-mkIf.nix
      define-enable.nix
      define-force-attrsOfSub-foo-enable.nix
      define-force-enable.nix
      define-freeform-keywords-shorthand.nix
      define-if-attrsOfSub-foo-enable.nix
      define-module-check.nix
      define-option-dependently-nested.nix
      define-option-dependently.nix
      define-settingsDict-a-is-b.nix
      define-shorthandOnlyDefinesConfig-true.nix
      define-submoduleWith-noshorthand.nix
      define-submoduleWith-shorthand.nix
      define-value-int-negative.nix
      define-value-int-positive.nix
      define-value-int-zero.nix
      define-value-list.nix
      define-value-string-arbitrary.nix
      define-value-string-bigint.nix
      define-value-string-properties.nix
      define-value-string.nix
      define-variant.nix
      deprecated-wrapped.nix
      disable-declare-enable.nix
      disable-define-enable-string-path.nix
      disable-define-enable.nix
      disable-enable-modules.nix
      disable-module-bad-key.nix
      disable-module-with-key.nix
      disable-module-with-toString-key.nix
      docs.nix
      doRename-basic.nix
      doRename-condition-enable.nix
      doRename-condition-migrated.nix
      doRename-condition-no-enable.nix
      doRename-condition.nix
      doRename-warnings.nix
      emptyValues.nix
      error-mkOption-in-config.nix
      error-mkOption-in-submodule-config.nix
      error-nonEmptyListOf-submodule.nix
      expose-module-class.nix
      extendModules-168767-imports.nix
      freeform-attrsOf.nix
      freeform-lazyAttrsOf.nix
      freeform-nested.nix
      freeform-str-dep-unstr.nix
      freeform-submodules.nix
      freeform-unstr-dep-str.nix
      gvariant.nix
      import-configuration.nix
      import-custom-arg.nix
      import-error-submodule.nix
      import-from-store.nix
      importApply-disabling.nix
      importApply-function.nix
      importApply.nix
      lazy-attrsWith.nix
      merge-module-with-key.nix
      merge-typeless-option.nix
      mkDefinition.nix
      module-argument-default.nix
      module-class-is-darwin.nix
      module-class-is-nixos.nix
      module-imports-_type-check.nix
      name-merge-attrsWith-1.nix
      name-merge-attrsWith-2.nix
      options-type-error-configuration.nix
      options-type-error-typical-nested.nix
      options-type-error-typical.nix
      optionTypeFile.nix
      optionTypeMerging.nix
      pathWith.nix
      polymorphic-module.nix
      prefix-module-argument.nix
      raw.nix
      shorthand-meta.nix
      specialArgs-class.nix
      specialArgs-lib.nix
      strMatching-merge.nix
      submoduleFiles.nix
      test-mergeAttrDefinitionsWithPrio.nix
      types-attrTag-wrong-decl.nix
      types-attrTag.nix
      types-unique.nix
      types.nix
    packages-from-directory/
      c/
        not-a-namespace/
          not-a-package.nix
        my-extra-feature.patch
        package.nix
        support-definitions.nix
      my-namespace/
        f/
          package.nix
        my-sub-namespace/
          g.nix
          h.nix
        d.nix
        e.nix
      plain/
        c/
          not-a-namespace/
            not-a-package.nix
          my-extra-feature.patch
          package.nix
          support-definitions.nix
        my-namespace/
          f/
            package.nix
          my-sub-namespace/
            g.nix
            h.nix
          d.nix
          e.nix
        a.nix
        b.nix
      scope/
        c/
          not-a-namespace/
            not-a-package.nix
          my-extra-feature.patch
          package.nix
          support-definitions.nix
        my-namespace/
          f/
            package.nix
          my-sub-namespace/
            g.nix
            h.nix
          d.nix
          e.nix
        a.nix
        b.nix
      a.nix
      b.nix
    .editorconfig
    check-eval.nix
    fetchers.nix
    filesystem.sh
    maintainer-module.nix
    maintainers.nix
    misc.nix
    modules.sh
    network.sh
    nix-for-tests.nix
    release.nix
    sources.sh
    systems.nix
    teams.nix
    test-to-plist-escaped-expected.plist
    test-to-plist-expected.plist
    test-to-plist-unescaped-expected.plist
    test-with-nix.nix
  .version
  ascii-table.nix
  asserts.nix
  attrsets.nix
  cli.nix
  customisation.nix
  debug.nix
  default.nix
  deprecated.nix
  derivations.nix
  fetchers.nix
  filesystem.nix
  fixed-points.nix
  flake-version-info.nix
  flake.nix
  flakes.nix
  generators.nix
  gvariant.nix
  kernel.nix
  licenses.nix
  lists.nix
  meta.nix
  minver.nix
  modules.nix
  options.nix
  README.md
  source-types.nix
  sources.nix
  strings-with-deps.nix
  strings.nix
  trivial.nix
  types.nix
  versions.nix
  zip-int-bits.nix
flake.nix
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/update.yml">
name: Update

on:
  workflow_dispatch:
  schedule:
    - cron:  '0 0 * * SUN' # every sunday

jobs:
  update:
    name: Pull in latest lib from Nixpkgs
    runs-on: ubuntu-latest
    steps:

    - name: Procure Nix
      uses: cachix/install-nix-action@v21

    - name: Checkout
      uses: actions/checkout@v2
      with:
        ref: master
        path: nixpkgs-lib

    - name: Checkout nixpkgs repo
      uses: actions/checkout@v2
      with:
        ref: master
        repository: NixOS/nixpkgs
        path: nixpkgs
        fetch-depth: 0 # complete history

    - name: Procure git-filter-repo from nixpkgs
      run: "nix profile install nixpkgs#git-filter-repo"


    - name: Filter nixpkgs on ./lib
      run: |
        cd ./nixpkgs
        git filter-repo --path lib --force

    - name: Update nixpkgs.lib
      run: |
        cd ./nixpkgs-lib
        git remote add other ../nixpkgs/
        git fetch other master
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        git merge -X theirs --allow-unrelated-histories other/master

    - name: Push changes
      uses: ad-m/github-push-action@master
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        directory: nixpkgs-lib
        branch: master
</file>

<file path="lib/deprecated/misc.nix">
{ lib }:

let
  inherit (lib)
    and
    any
    attrByPath
    attrNames
    compare
    concat
    concatMap
    elem
    filter
    foldl
    foldr
    genericClosure
    head
    imap1
    init
    isAttrs
    isFunction
    isInt
    isList
    lists
    listToAttrs
    mapAttrs
    mergeAttrs
    meta
    nameValuePair
    tail
    toList
    warn
    ;

  inherit (lib.attrsets) removeAttrs mapAttrsToList;

  # returns default if env var is not set
  maybeEnv =
    name: default:
    let
      value = builtins.getEnv name;
    in
    if value == "" then default else value;

  defaultMergeArg = x: y: if builtins.isAttrs y then y else (y x);
  defaultMerge = x: y: x // (defaultMergeArg x y);
  foldArgs =
    merger: f: init: x:
    let
      arg = (merger init (defaultMergeArg init x));
      # now add the function with composed args already applied to the final attrs
      base = (
        setAttrMerge "passthru" { } (f arg) (
          z:
          z
          // {
            function = foldArgs merger f arg;
            args = (attrByPath [ "passthru" "args" ] { } z) // x;
          }
        )
      );
      withStdOverrides = base // {
        override = base.passthru.function;
      };
    in
    withStdOverrides;

  # shortcut for attrByPath ["name"] default attrs
  maybeAttrNullable = maybeAttr;

  # shortcut for attrByPath ["name"] default attrs
  maybeAttr =
    name: default: attrs:
    attrs.${name} or default;

  # Return the second argument if the first one is true or the empty version
  # of the second argument.
  ifEnable =
    cond: val:
    if cond then
      val
    else if builtins.isList val then
      [ ]
    else if builtins.isAttrs val then
      { }
    # else if builtins.isString val then ""
    else if val == true || val == false then
      false
    else
      null;

  # Return true only if there is an attribute and it is true.
  checkFlag =
    attrSet: name:
    if name == "true" then
      true
    else if name == "false" then
      false
    else if (elem name (attrByPath [ "flags" ] [ ] attrSet)) then
      true
    else
      attrByPath [ name ] false attrSet;

  # Input : attrSet, [ [name default] ... ], name
  # Output : its value or default.
  getValue =
    attrSet: argList: name:
    (attrByPath [ name ] (
      if checkFlag attrSet name then
        true
      else if argList == [ ] then
        null
      else
        let
          x = builtins.head argList;
        in
        if (head x) == name then (head (tail x)) else (getValue attrSet (tail argList) name)
    ) attrSet);

  # Input : attrSet, [[name default] ...], [ [flagname reqs..] ... ]
  # Output : are reqs satisfied? It's asserted.
  checkReqs =
    attrSet: argList: condList:
    (foldr and true (
      map (
        x:
        let
          name = (head x);
        in

        (
          (checkFlag attrSet name)
          -> (foldr and true (
            map (
              y:
              let
                val = (getValue attrSet argList y);
              in
              (val != null) && (val != false)
            ) (tail x)
          ))
        )
      ) condList
    ));

  # This function has O(n^2) performance.
  uniqList =
    {
      inputList,
      acc ? [ ],
    }:
    let
      go =
        xs: acc:
        if xs == [ ] then
          [ ]
        else
          let
            x = head xs;
            y = if elem x acc then [ ] else [ x ];
          in
          y ++ go (tail xs) (y ++ acc);
    in
    go inputList acc;

  uniqListExt =
    {
      inputList,
      outputList ? [ ],
      getter ? (x: x),
      compare ? (x: y: x == y),
    }:
    if inputList == [ ] then
      outputList
    else
      let
        x = head inputList;
        isX = y: (compare (getter y) (getter x));
        newOutputList = outputList ++ (if any isX outputList then [ ] else [ x ]);
      in
      uniqListExt {
        outputList = newOutputList;
        inputList = (tail inputList);
        inherit getter compare;
      };

  condConcat =
    name: list: checker:
    if list == [ ] then
      name
    else if checker (head list) then
      condConcat (name + (head (tail list))) (tail (tail list)) checker
    else
      condConcat name (tail (tail list)) checker;

  lazyGenericClosure =
    { startSet, operator }:
    let
      work =
        list: doneKeys: result:
        if list == [ ] then
          result
        else
          let
            x = head list;
            key = x.key;
          in
          if elem key doneKeys then
            work (tail list) doneKeys result
          else
            work (tail list ++ operator x) ([ key ] ++ doneKeys) ([ x ] ++ result);
    in
    work startSet [ ] [ ];

  innerModifySumArgs =
    f: x: a: b:
    if b == null then (f a b) // x else innerModifySumArgs f x (a // b);
  modifySumArgs = f: x: innerModifySumArgs f x { };

  innerClosePropagation =
    acc: xs:
    if xs == [ ] then
      acc
    else
      let
        y = head xs;
        ys = tail xs;
      in
      if !isAttrs y then
        innerClosePropagation acc ys
      else
        let
          acc' = [ y ] ++ acc;
        in
        innerClosePropagation acc' (uniqList {
          inputList =
            (maybeAttrNullable "propagatedBuildInputs" [ ] y)
            ++ (maybeAttrNullable "propagatedNativeBuildInputs" [ ] y)
            ++ ys;
          acc = acc';
        });

  closePropagationSlow = list: (uniqList { inputList = (innerClosePropagation [ ] list); });

  # This is an optimisation of closePropagation which avoids the O(n^2) behavior
  # Using a list of derivations, it generates the full closure of the propagatedXXXBuildInputs
  # The ordering / sorting / comparison is done based on the `outPath`
  # attribute of each derivation.
  # On some benchmarks, it performs up to 15 times faster than closePropagation.
  # See https://github.com/NixOS/nixpkgs/pull/194391 for details.
  closePropagationFast =
    list:
    builtins.map (x: x.val) (
      builtins.genericClosure {
        startSet = builtins.map (x: {
          key = x.outPath;
          val = x;
        }) (builtins.filter (x: x != null) list);
        operator =
          item:
          if !builtins.isAttrs item.val then
            [ ]
          else
            builtins.concatMap (
              x:
              if x != null then
                [
                  {
                    key = x.outPath;
                    val = x;
                  }
                ]
              else
                [ ]
            ) ((item.val.propagatedBuildInputs or [ ]) ++ (item.val.propagatedNativeBuildInputs or [ ]));
      }
    );

  closePropagation = if builtins ? genericClosure then closePropagationFast else closePropagationSlow;

  # calls a function (f attr value ) for each record item. returns a list
  mapAttrsFlatten = warn "lib.misc.mapAttrsFlatten is deprecated, please use lib.attrsets.mapAttrsToList instead." mapAttrsToList;

  # attribute set containing one attribute
  nvs = name: value: listToAttrs [ (nameValuePair name value) ];
  # adds / replaces an attribute of an attribute set
  setAttr =
    set: name: v:
    set // (nvs name v);

  # setAttrMerge (similar to mergeAttrsWithFunc but only merges the values of a particular name)
  # setAttrMerge "a" [] { a = [2];} (x: x ++ [3]) -> { a = [2 3]; }
  # setAttrMerge "a" [] {         } (x: x ++ [3]) -> { a = [  3]; }
  setAttrMerge =
    name: default: attrs: f:
    setAttr attrs name (f (maybeAttr name default attrs));

  # Using f = a: b = b the result is similar to //
  # merge attributes with custom function handling the case that the attribute
  # exists in both sets
  mergeAttrsWithFunc =
    f: set1: set2:
    foldr (n: set: if set ? ${n} then setAttr set n (f set.${n} set2.${n}) else set) (set2 // set1) (
      attrNames set2
    );

  # merging two attribute set concatenating the values of same attribute names
  # eg { a = 7; } {  a = [ 2 3 ]; } becomes { a = [ 7 2 3 ]; }
  mergeAttrsConcatenateValues = mergeAttrsWithFunc (a: b: (toList a) ++ (toList b));

  # merges attributes using //, if a name exists in both attributes
  # an error will be triggered unless its listed in mergeLists
  # so you can mergeAttrsNoOverride { buildInputs = [a]; } { buildInputs = [a]; } {} to get
  # { buildInputs = [a b]; }
  # merging buildPhase doesn't really make sense. The cases will be rare where appending /prefixing will fit your needs?
  # in these cases the first buildPhase will override the second one
  # ! deprecated, use mergeAttrByFunc instead
  mergeAttrsNoOverride =
    {
      mergeLists ? [
        "buildInputs"
        "propagatedBuildInputs"
      ],
      overrideSnd ? [ "buildPhase" ],
    }:
    attrs1: attrs2:
    foldr (
      n: set:
      setAttr set n (
        if set ? ${n} then # merge
          if
            elem n mergeLists # attribute contains list, merge them by concatenating
          then
            attrs2.${n} ++ attrs1.${n}
          else if elem n overrideSnd then
            attrs1.${n}
          else
            throw "error mergeAttrsNoOverride, attribute ${n} given in both attributes - no merge func defined"
        else
          attrs2.${n} # add attribute not existing in attr1
      )
    ) attrs1 (attrNames attrs2);

  # example usage:
  # mergeAttrByFunc  {
  #   inherit mergeAttrBy; # defined below
  #   buildInputs = [ a b ];
  # } {
  #  buildInputs = [ c d ];
  # };
  # will result in
  # { mergeAttrsBy = [...]; buildInputs = [ a b c d ]; }
  # is used by defaultOverridableDelayableArgs and can be used when composing using
  # foldArgs, composedArgsAndFun or applyAndFun. Example: composableDerivation in all-packages.nix
  mergeAttrByFunc =
    x: y:
    let
      mergeAttrBy2 = {
        mergeAttrBy = mergeAttrs;
      }
      // (maybeAttr "mergeAttrBy" { } x)
      // (maybeAttr "mergeAttrBy" { } y);
    in
    foldr mergeAttrs { } [
      x
      y
      (mapAttrs
        (
          a: v: # merge special names using given functions
          if x ? ${a} then
            if y ? ${a} then
              v x.${a} y.${a} # both have attr, use merge func
            else
              x.${a} # only x has attr
          else
            y.${a} # only y has attr)
        )
        (
          removeAttrs mergeAttrBy2
            # don't merge attrs which are neither in x nor y
            (filter (a: !x ? ${a} && !y ? ${a}) (attrNames mergeAttrBy2))
        )
      )
    ];
  mergeAttrsByFuncDefaults = foldl mergeAttrByFunc { inherit mergeAttrBy; };
  mergeAttrsByFuncDefaultsClean = list: removeAttrs (mergeAttrsByFuncDefaults list) [ "mergeAttrBy" ];

  # sane defaults (same name as attr name so that inherit can be used)
  mergeAttrBy = # { buildInputs = concatList; [...]; passthru = mergeAttr; [..]; }
    listToAttrs (
      map (n: nameValuePair n concat) [
        "nativeBuildInputs"
        "buildInputs"
        "propagatedBuildInputs"
        "configureFlags"
        "prePhases"
        "postAll"
        "patches"
      ]
    )
    // listToAttrs (
      map (n: nameValuePair n mergeAttrs) [
        "passthru"
        "meta"
        "cfg"
        "flags"
      ]
    )
    // listToAttrs (
      map (n: nameValuePair n (a: b: "${a}\n${b}")) [
        "preConfigure"
        "postInstall"
      ]
    );

  nixType =
    x:
    if isAttrs x then
      if x ? outPath then "derivation" else "attrs"
    else if isFunction x then
      "function"
    else if isList x then
      "list"
    else if x == true then
      "bool"
    else if x == false then
      "bool"
    else if x == null then
      "null"
    else if isInt x then
      "int"
    else
      "string";

  /**
    # Deprecated

    For historical reasons, imap has an index starting at 1.

    But for consistency with the rest of the library we want an index
    starting at zero.
  */
  imap = imap1;

  # Fake hashes. Can be used as hash placeholders, when computing hash ahead isn't trivial
  fakeHash = "sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=";
  fakeSha256 = "0000000000000000000000000000000000000000000000000000000000000000";
  fakeSha512 = "00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000";

in

# Everything in this attrset is the public interface of the file.
{
  inherit
    checkFlag
    checkReqs
    closePropagation
    closePropagationFast
    closePropagationSlow
    condConcat
    defaultMerge
    defaultMergeArg
    fakeHash
    fakeSha256
    fakeSha512
    foldArgs
    getValue
    ifEnable
    imap
    innerClosePropagation
    innerModifySumArgs
    lazyGenericClosure
    mapAttrsFlatten
    maybeAttr
    maybeAttrNullable
    maybeEnv
    mergeAttrBy
    mergeAttrByFunc
    mergeAttrsByFuncDefaults
    mergeAttrsByFuncDefaultsClean
    mergeAttrsConcatenateValues
    mergeAttrsNoOverride
    mergeAttrsWithFunc
    modifySumArgs
    nixType
    nvs
    setAttr
    setAttrMerge
    uniqList
    uniqListExt
    ;
}
</file>

<file path="lib/deprecated/README.md">
# lib/deprecated

Do not add any new functions to this directory.

This directory contains the `lib.misc` sublibrary, which - as a location - is deprecated.
Furthermore, some of the functions inside are of *dubious* utility, and should perhaps be avoided, while some functions *may still be needed*.

This directory does not play a role in the deprecation process for library functions.
They should be deprecated in place, by putting a `lib.warn` or `lib.warnIf` call around the function.
</file>

<file path="lib/fileset/benchmark.sh">
#!/usr/bin/env nix-shell
#!nix-shell -i bash -p sta jq bc nix -I nixpkgs=../..
# shellcheck disable=SC2016

# Benchmarks lib.fileset
# Run:
# [nixpkgs]$ lib/fileset/benchmark.sh HEAD

set -euo pipefail
shopt -s inherit_errexit dotglob

if (( $# == 0 )); then
    echo "Usage: $0 HEAD"
    echo "Benchmarks the current tree against the HEAD commit. Any git ref will work."
    exit 1
fi
compareTo=$1

SCRIPT_FILE=$(readlink -f "${BASH_SOURCE[0]}")
SCRIPT_DIR=$(dirname "$SCRIPT_FILE")

nixpkgs=$(cd "$SCRIPT_DIR/../.."; pwd)

tmp="$(mktemp -d)"
clean_up() {
    rm -rf "$tmp"
}
trap clean_up EXIT SIGINT SIGTERM
work="$tmp/work"
mkdir "$work"
cd "$work"

declare -a stats=(
    ".envs.elements"
    ".envs.number"
    ".gc.totalBytes"
    ".list.concats"
    ".list.elements"
    ".nrFunctionCalls"
    ".nrLookups"
    ".nrOpUpdates"
    ".nrPrimOpCalls"
    ".nrThunks"
    ".sets.elements"
    ".sets.number"
    ".symbols.number"
    ".values.number"
)

runs=10

run() {
    # Empty the file
    : > cpuTimes

    for i in $(seq 0 "$runs"); do
        NIX_PATH=nixpkgs=$1 NIX_SHOW_STATS=1 NIX_SHOW_STATS_PATH=$tmp/stats.json \
            nix-instantiate --eval --strict --show-trace >/dev/null \
            --expr 'with import <nixpkgs/lib>; with fileset; '"$2"

        # Only measure the time after the first run, one is warmup
        if (( i > 0 )); then
            jq '.cpuTime' "$tmp/stats.json" >> cpuTimes
        fi
    done

    # Compute mean and standard deviation
    read -r mean sd < <(sta --mean --sd --brief <cpuTimes)

    jq --argjson mean "$mean" --argjson sd "$sd" \
        '.cpuTimeMean = $mean | .cpuTimeSd = $sd' \
        "$tmp/stats.json"
}

bench() {
    echo "Benchmarking expression $1" >&2
    #echo "Running benchmark on index" >&2
    run "$nixpkgs" "$1" > "$tmp/new.json"
    (
        #echo "Checking out $compareTo" >&2
        git -C "$nixpkgs" worktree add --quiet "$tmp/worktree" "$compareTo"
        trap 'git -C "$nixpkgs" worktree remove "$tmp/worktree"' EXIT
        #echo "Running benchmark on $compareTo" >&2
        run "$tmp/worktree" "$1" > "$tmp/old.json"
    )

    read -r oldMean oldSd newMean newSd percentageMean percentageSd < \
        <(jq -rn --slurpfile old "$tmp/old.json" --slurpfile new "$tmp/new.json" \
        ' $old[0].cpuTimeMean as $om
        | $old[0].cpuTimeSd as $os
        | $new[0].cpuTimeMean as $nm
        | $new[0].cpuTimeSd as $ns
        | (100 / $om * $nm) as $pm
        # Copied from https://github.com/sharkdp/hyperfine/blob/b38d550b89b1dab85139eada01c91a60798db9cc/src/benchmark/relative_speed.rs#L46-L53
        | ($pm * pow(pow($ns / $nm; 2) + pow($os / $om; 2); 0.5)) as $ps
        | [ $om, $os, $nm, $ns, $pm, $ps ]
        | @sh')

    echo -e "Mean CPU time $newMean (σ = $newSd) for $runs runs is \e[0;33m$percentageMean% (σ = $percentageSd%)\e[0m of the old value $oldMean (σ = $oldSd)" >&2

    different=0
    for stat in "${stats[@]}"; do
        oldValue=$(jq "$stat" "$tmp/old.json")
        newValue=$(jq "$stat" "$tmp/new.json")
        if (( oldValue != newValue )); then
            percent=$(bc <<< "scale=100; result = 100/$oldValue*$newValue; scale=4; result / 1")
            if (( oldValue < newValue )); then
                echo -e "Statistic $stat ($newValue) is \e[0;31m$percent% (+$(( newValue - oldValue )))\e[0m of the old value $oldValue" >&2
            else
                echo -e "Statistic $stat ($newValue) is \e[0;32m$percent% (-$(( oldValue - newValue )))\e[0m of the old value $oldValue" >&2
            fi
            (( different++ )) || true
        fi
    done
    echo "$different stats differ between the current tree and $compareTo"
    echo ""
}

# Create a fairly populated tree
touch f{0..5}
mkdir d{0..5}
mkdir e{0..5}
touch d{0..5}/f{0..5}
mkdir -p d{0..5}/d{0..5}
mkdir -p e{0..5}/e{0..5}
touch d{0..5}/d{0..5}/f{0..5}
mkdir -p d{0..5}/d{0..5}/d{0..5}
mkdir -p e{0..5}/e{0..5}/e{0..5}
touch d{0..5}/d{0..5}/d{0..5}/f{0..5}
mkdir -p d{0..5}/d{0..5}/d{0..5}/d{0..5}
mkdir -p e{0..5}/e{0..5}/e{0..5}/e{0..5}
touch d{0..5}/d{0..5}/d{0..5}/d{0..5}/f{0..5}

bench 'toSource { root = ./.; fileset = ./.; }'

rm -rf -- *

touch {0..1000}
bench 'toSource { root = ./.; fileset = unions (mapAttrsToList (name: value: ./. + "/${name}") (builtins.readDir ./.)); }'
rm -rf -- *
</file>

<file path="lib/fileset/default.nix">
/**
  <!-- This anchor is here for backwards compatibility -->
  []{#sec-fileset}

  The [`lib.fileset`](#sec-functions-library-fileset) library allows you to work with _file sets_.
  A file set is a (mathematical) set of local files that can be added to the Nix store for use in Nix derivations.
  File sets are easy and safe to use, providing obvious and composable semantics with good error messages to prevent mistakes.

  # Overview {#sec-fileset-overview}

  Basics:
  - [Implicit coercion from paths to file sets](#sec-fileset-path-coercion)

  - [`lib.fileset.maybeMissing`](#function-library-lib.fileset.maybeMissing):

    Create a file set from a path that may be missing.

  - [`lib.fileset.trace`](#function-library-lib.fileset.trace)/[`lib.fileset.traceVal`](#function-library-lib.fileset.trace):

    Pretty-print file sets for debugging.

  - [`lib.fileset.toSource`](#function-library-lib.fileset.toSource):

    Add files in file sets to the store to use as derivation sources.

  - [`lib.fileset.toList`](#function-library-lib.fileset.toList):

    The list of files contained in a file set.

  Combinators:
  - [`lib.fileset.union`](#function-library-lib.fileset.union)/[`lib.fileset.unions`](#function-library-lib.fileset.unions):

    Create a larger file set from all the files in multiple file sets.

  - [`lib.fileset.intersection`](#function-library-lib.fileset.intersection):

    Create a smaller file set from only the files in both file sets.

  - [`lib.fileset.difference`](#function-library-lib.fileset.difference):

    Create a smaller file set containing all files that are in one file set, but not another one.

  Filtering:
  - [`lib.fileset.fileFilter`](#function-library-lib.fileset.fileFilter):

    Create a file set from all files that satisisfy a predicate in a directory.

  Utilities:
  - [`lib.fileset.fromSource`](#function-library-lib.fileset.fromSource):

    Create a file set from a `lib.sources`-based value.

  - [`lib.fileset.gitTracked`](#function-library-lib.fileset.gitTracked)/[`lib.fileset.gitTrackedWith`](#function-library-lib.fileset.gitTrackedWith):

    Create a file set from all tracked files in a local Git repository.

  If you need more file set functions,
  see [this issue](https://github.com/NixOS/nixpkgs/issues/266356) to request it.

  # Implicit coercion from paths to file sets {#sec-fileset-path-coercion}

  All functions accepting file sets as arguments can also accept [paths](https://nixos.org/manual/nix/stable/language/values.html#type-path) as arguments.
  Such path arguments are implicitly coerced to file sets containing all files under that path:
  - A path to a file turns into a file set containing that single file.
  - A path to a directory turns into a file set containing all files _recursively_ in that directory.

  If the path points to a non-existent location, an error is thrown.

  ::: {.note}
  Just like in Git, file sets cannot represent empty directories.
  Because of this, a path to a directory that contains no files (recursively) will turn into a file set containing no files.
  :::

  :::{.note}
  File set coercion does _not_ add any of the files under the coerced paths to the store.
  Only the [`toSource`](#function-library-lib.fileset.toSource) function adds files to the Nix store, and only those files contained in the `fileset` argument.
  This is in contrast to using [paths in string interpolation](https://nixos.org/manual/nix/stable/language/values.html#type-path), which does add the entire referenced path to the store.
  :::

  ## Example {#sec-fileset-path-coercion-example}

  Assume we are in a local directory with a file hierarchy like this:
  ```
  ├─ a/
  │  ├─ x (file)
  │  └─ b/
  │     └─ y (file)
  └─ c/
     └─ d/
  ```

  Here's a listing of which files get included when different path expressions get coerced to file sets:
  - `./.` as a file set contains both `a/x` and `a/b/y` (`c/` does not contain any files and is therefore omitted).
  - `./a` as a file set contains both `a/x` and `a/b/y`.
  - `./a/x` as a file set contains only `a/x`.
  - `./a/b` as a file set contains only `a/b/y`.
  - `./c` as a file set is empty, since neither `c` nor `c/d` contain any files.
*/
{ lib }:
let

  inherit (import ./internal.nix { inherit lib; })
    _coerce
    _singleton
    _coerceMany
    _toSourceFilter
    _fromSourceFilter
    _toList
    _unionMany
    _fileFilter
    _printFileset
    _intersection
    _difference
    _fromFetchGit
    _fetchGitSubmodulesMinver
    _emptyWithoutBase
    ;

  inherit (builtins)
    isBool
    isList
    isPath
    pathExists
    seq
    typeOf
    nixVersion
    ;

  inherit (lib.lists)
    elemAt
    imap0
    ;

  inherit (lib.path)
    hasPrefix
    splitRoot
    ;

  inherit (lib.strings)
    isStringLike
    versionOlder
    ;

  inherit (lib.filesystem)
    pathType
    ;

  inherit (lib.sources)
    cleanSourceWith
    ;

  inherit (lib.trivial)
    isFunction
    pipe
    ;

in
{

  /**
    Create a file set from a path that may or may not exist:
    - If the path does exist, the path is [coerced to a file set](#sec-fileset-path-coercion).
    - If the path does not exist, a file set containing no files is returned.

    # Inputs

    `path`

    : 1\. Function argument

    # Type

    ```
    maybeMissing :: Path -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.maybeMissing` usage example

    ```nix
    # All files in the current directory, but excluding main.o if it exists
    difference ./. (maybeMissing ./main.o)
    ```

    :::
  */
  maybeMissing =
    path:
    if !isPath path then
      if isStringLike path then
        throw ''lib.fileset.maybeMissing: Argument ("${toString path}") is a string-like value, but it should be a path instead.''
      else
        throw ''lib.fileset.maybeMissing: Argument is of type ${typeOf path}, but it should be a path instead.''
    else if !pathExists path then
      _emptyWithoutBase
    else
      _singleton path;

  /**
    Incrementally evaluate and trace a file set in a pretty way.
    This function is only intended for debugging purposes.
    The exact tracing format is unspecified and may change.

    This function takes a final argument to return.
    In comparison, [`traceVal`](#function-library-lib.fileset.traceVal) returns
    the given file set argument.

    This variant is useful for tracing file sets in the Nix repl.

    # Inputs

    `fileset`

    : The file set to trace.

      This argument can also be a path,
      which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    `val`

    : The value to return.

    # Type

    ```
    trace :: FileSet -> Any -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.trace` usage example

    ```nix
    trace (unions [ ./Makefile ./src ./tests/run.sh ]) null
    =>
    trace: /home/user/src/myProject
    trace: - Makefile (regular)
    trace: - src (all files in directory)
    trace: - tests
    trace:   - run.sh (regular)
    null
    ```

    :::
  */
  trace =
    fileset:
    let
      # "fileset" would be a better name, but that would clash with the argument name,
      # and we cannot change that because of https://github.com/nix-community/nixdoc/issues/76
      actualFileset = _coerce "lib.fileset.trace: Argument" fileset;
    in
    seq (_printFileset actualFileset) (x: x);

  /**
    Incrementally evaluate and trace a file set in a pretty way.
    This function is only intended for debugging purposes.
    The exact tracing format is unspecified and may change.

    This function returns the given file set.
    In comparison, [`trace`](#function-library-lib.fileset.trace) takes another argument to return.

    This variant is useful for tracing file sets passed as arguments to other functions.

    # Inputs

    `fileset`

    : The file set to trace and return.

      This argument can also be a path,
      which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    # Type

    ```
    traceVal :: FileSet -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.traceVal` usage example

    ```nix
    toSource {
      root = ./.;
      fileset = traceVal (unions [
        ./Makefile
        ./src
        ./tests/run.sh
      ]);
    }
    =>
    trace: /home/user/src/myProject
    trace: - Makefile (regular)
    trace: - src (all files in directory)
    trace: - tests
    trace:   - run.sh (regular)
    "/nix/store/...-source"
    ```

    :::
  */
  traceVal =
    fileset:
    let
      # "fileset" would be a better name, but that would clash with the argument name,
      # and we cannot change that because of https://github.com/nix-community/nixdoc/issues/76
      actualFileset = _coerce "lib.fileset.traceVal: Argument" fileset;
    in
    seq (_printFileset actualFileset)
      # We could also return the original fileset argument here,
      # but that would then duplicate work for consumers of the fileset, because then they have to coerce it again
      actualFileset;

  /**
    Add the local files contained in `fileset` to the store as a single [store path](https://nixos.org/manual/nix/stable/glossary#gloss-store-path) rooted at `root`.

    The result is the store path as a string-like value, making it usable e.g. as the `src` of a derivation, or in string interpolation:
    ```nix
    stdenv.mkDerivation {
      src = lib.fileset.toSource { ... };
      # ...
    }
    ```

    The name of the store path is always `source`.

    # Inputs

    Takes an attribute set with the following attributes

    `root` (Path; _required_)

    : The local directory [path](https://nixos.org/manual/nix/stable/language/values.html#type-path) that will correspond to the root of the resulting store path.
      Paths in [strings](https://nixos.org/manual/nix/stable/language/values.html#type-string), including Nix store paths, cannot be passed as `root`.
      `root` has to be a directory.

      :::{.note}
      Changing `root` only affects the directory structure of the resulting store path, it does not change which files are added to the store.
      The only way to change which files get added to the store is by changing the `fileset` attribute.
      :::

    `fileset` (FileSet; _required_)

    : The file set whose files to import into the store.
      File sets can be created using other functions in this library.
      This argument can also be a path,
      which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

      :::{.note}
      If a directory does not recursively contain any file, it is omitted from the store path contents.
      :::

    # Type

    ```
    toSource :: {
      root :: Path,
      fileset :: FileSet,
    } -> SourceLike
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.toSource` usage example

    ```nix
    # Import the current directory into the store
    # but only include files under ./src
    toSource {
      root = ./.;
      fileset = ./src;
    }
    => "/nix/store/...-source"

    # Import the current directory into the store
    # but only include ./Makefile and all files under ./src
    toSource {
      root = ./.;
      fileset = union
        ./Makefile
        ./src;
    }
    => "/nix/store/...-source"

    # Trying to include a file outside the root will fail
    toSource {
      root = ./.;
      fileset = unions [
        ./Makefile
        ./src
        ../LICENSE
      ];
    }
    => <error>

    # The root needs to point to a directory that contains all the files
    toSource {
      root = ../.;
      fileset = unions [
        ./Makefile
        ./src
        ../LICENSE
      ];
    }
    => "/nix/store/...-source"

    # The root has to be a local filesystem path
    toSource {
      root = "/nix/store/...-source";
      fileset = ./.;
    }
    => <error>
    ```

    :::
  */
  toSource =
    {
      root,
      fileset,
    }:
    let
      # We cannot rename matched attribute arguments, so let's work around it with an extra `let in` statement
      filesetArg = fileset;
    in
    let
      fileset = _coerce "lib.fileset.toSource: `fileset`" filesetArg;
      rootFilesystemRoot = (splitRoot root).root;
      filesetFilesystemRoot = (splitRoot fileset._internalBase).root;
      sourceFilter = _toSourceFilter fileset;
    in
    if !isPath root then
      if root ? _isLibCleanSourceWith then
        throw ''
          lib.fileset.toSource: `root` is a `lib.sources`-based value, but it should be a path instead.
              To use a `lib.sources`-based value, convert it to a file set using `lib.fileset.fromSource` and pass it as `fileset`.
              Note that this only works for sources created from paths.''
      else if isStringLike root then
        throw ''
          lib.fileset.toSource: `root` (${toString root}) is a string-like value, but it should be a path instead.
              Paths in strings are not supported by `lib.fileset`, use `lib.sources` or derivations instead.''
      else
        throw ''lib.fileset.toSource: `root` is of type ${typeOf root}, but it should be a path instead.''
    # Currently all Nix paths have the same filesystem root, but this could change in the future.
    # See also ../path/README.md
    else if !fileset._internalIsEmptyWithoutBase && rootFilesystemRoot != filesetFilesystemRoot then
      throw ''
        lib.fileset.toSource: Filesystem roots are not the same for `fileset` and `root` (${toString root}):
            `root`: Filesystem root is "${toString rootFilesystemRoot}"
            `fileset`: Filesystem root is "${toString filesetFilesystemRoot}"
            Different filesystem roots are not supported.''
    else if !pathExists root then
      throw ''lib.fileset.toSource: `root` (${toString root}) is a path that does not exist.''
    else if pathType root != "directory" then
      throw ''
        lib.fileset.toSource: `root` (${toString root}) is a file, but it should be a directory instead. Potential solutions:
            - If you want to import the file into the store _without_ a containing directory, use string interpolation or `builtins.path` instead of this function.
            - If you want to import the file into the store _with_ a containing directory, set `root` to the containing directory, such as ${toString (dirOf root)}, and set `fileset` to the file path.''
    else if !fileset._internalIsEmptyWithoutBase && !hasPrefix root fileset._internalBase then
      throw ''
        lib.fileset.toSource: `fileset` could contain files in ${toString fileset._internalBase}, which is not under the `root` (${toString root}). Potential solutions:
            - Set `root` to ${toString fileset._internalBase} or any directory higher up. This changes the layout of the resulting store path.
            - Set `fileset` to a file set that cannot contain files outside the `root` (${toString root}). This could change the files included in the result.''
    else
      seq sourceFilter cleanSourceWith {
        name = "source";
        src = root;
        filter = sourceFilter;
      };

  /**
    The list of file paths contained in the given file set.

    :::{.note}
    This function is strict in the entire file set.
    This is in contrast with combinators [`lib.fileset.union`](#function-library-lib.fileset.union),
    [`lib.fileset.intersection`](#function-library-lib.fileset.intersection) and [`lib.fileset.difference`](#function-library-lib.fileset.difference).

    Thus it is recommended to call `toList` on file sets created using the combinators,
    instead of doing list processing on the result of `toList`.
    :::

    The resulting list of files can be turned back into a file set using [`lib.fileset.unions`](#function-library-lib.fileset.unions).

    # Inputs

    `fileset`

    : The file set whose file paths to return. This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    # Type

    ```
    toList :: FileSet -> [ Path ]
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.toList` usage example

    ```nix
    toList ./.
    [ ./README.md ./Makefile ./src/main.c ./src/main.h ]

    toList (difference ./. ./src)
    [ ./README.md ./Makefile ]
    ```

    :::
  */
  toList = fileset: _toList (_coerce "lib.fileset.toList: Argument" fileset);

  /**
    The file set containing all files that are in either of two given file sets.
    This is the same as [`unions`](#function-library-lib.fileset.unions),
    but takes just two file sets instead of a list.
    See also [Union (set theory)](https://en.wikipedia.org/wiki/Union_(set_theory)).

    The given file sets are evaluated as lazily as possible,
    with the first argument being evaluated first if needed.

    # Inputs

    `fileset1`

    : The first file set. This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    `fileset2`

    : The second file set. This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    # Type

    ```
    union :: FileSet -> FileSet -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.union` usage example

    ```nix
    # Create a file set containing the file `Makefile`
    # and all files recursively in the `src` directory
    union ./Makefile ./src

    # Create a file set containing the file `Makefile`
    # and the LICENSE file from the parent directory
    union ./Makefile ../LICENSE
    ```

    :::
  */
  union =
    fileset1: fileset2:
    _unionMany (
      _coerceMany "lib.fileset.union" [
        {
          context = "First argument";
          value = fileset1;
        }
        {
          context = "Second argument";
          value = fileset2;
        }
      ]
    );

  /**
    The file set containing all files that are in any of the given file sets.
    This is the same as [`union`](#function-library-lib.fileset.unions),
    but takes a list of file sets instead of just two.
    See also [Union (set theory)](https://en.wikipedia.org/wiki/Union_(set_theory)).

    The given file sets are evaluated as lazily as possible,
    with earlier elements being evaluated first if needed.

    # Inputs

    `filesets`

    : A list of file sets. The elements can also be paths, which get [implicitly coerced to file sets](#sec-fileset-path-coercion).

    # Type

    ```
    unions :: [ FileSet ] -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.unions` usage example

    ```nix
    # Create a file set containing selected files
    unions [
      # Include the single file `Makefile` in the current directory
      # This errors if the file doesn't exist
      ./Makefile

      # Recursively include all files in the `src/code` directory
      # If this directory is empty this has no effect
      ./src/code

      # Include the files `run.sh` and `unit.c` from the `tests` directory
      ./tests/run.sh
      ./tests/unit.c

      # Include the `LICENSE` file from the parent directory
      ../LICENSE
    ]
    ```

    :::
  */
  unions =
    filesets:
    if !isList filesets then
      throw ''lib.fileset.unions: Argument is of type ${typeOf filesets}, but it should be a list instead.''
    else
      pipe filesets [
        # Annotate the elements with context, used by _coerceMany for better errors
        (imap0 (
          i: el: {
            context = "Element ${toString i}";
            value = el;
          }
        ))
        (_coerceMany "lib.fileset.unions")
        _unionMany
      ];

  /**
    The file set containing all files that are in both of two given file sets.
    See also [Intersection (set theory)](https://en.wikipedia.org/wiki/Intersection_(set_theory)).

    The given file sets are evaluated as lazily as possible,
    with the first argument being evaluated first if needed.

    # Inputs

    `fileset1`

    : The first file set. This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    `fileset2`

    : The second file set. This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    # Type

    ```
    intersection :: FileSet -> FileSet -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.intersection` usage example

    ```nix
    # Limit the selected files to the ones in ./., so only ./src and ./Makefile
    intersection ./. (unions [ ../LICENSE ./src ./Makefile ])
    ```

    :::
  */
  intersection =
    fileset1: fileset2:
    let
      filesets = _coerceMany "lib.fileset.intersection" [
        {
          context = "First argument";
          value = fileset1;
        }
        {
          context = "Second argument";
          value = fileset2;
        }
      ];
    in
    _intersection (elemAt filesets 0) (elemAt filesets 1);

  /**
    The file set containing all files from the first file set that are not in the second file set.
    See also [Difference (set theory)](https://en.wikipedia.org/wiki/Complement_(set_theory)#Relative_complement).

    The given file sets are evaluated as lazily as possible,
    with the first argument being evaluated first if needed.

    # Inputs

    `positive`

    : The positive file set. The result can only contain files that are also in this file set.  This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    `negative`

    : The negative file set. The result will never contain files that are also in this file set.  This argument can also be a path, which gets [implicitly coerced to a file set](#sec-fileset-path-coercion).

    # Type

    ```
    difference :: FileSet -> FileSet -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.difference` usage example

    ```nix
    # Create a file set containing all files from the current directory,
    # except ones under ./tests
    difference ./. ./tests

    let
      # A set of Nix-related files
      nixFiles = unions [ ./default.nix ./nix ./tests/default.nix ];
    in
    # Create a file set containing all files under ./tests, except ones in `nixFiles`,
    # meaning only without ./tests/default.nix
    difference ./tests nixFiles
    ```

    :::
  */
  difference =
    positive: negative:
    let
      filesets = _coerceMany "lib.fileset.difference" [
        {
          context = "First argument (positive set)";
          value = positive;
        }
        {
          context = "Second argument (negative set)";
          value = negative;
        }
      ];
    in
    _difference (elemAt filesets 0) (elemAt filesets 1);

  /**
    Filter a file set to only contain files matching some predicate.

    # Inputs

    `predicate`

    : The predicate function to call on all files contained in given file set.
      A file is included in the resulting file set if this function returns true for it.

      This function is called with an attribute set containing these attributes:

      - `name` (String): The name of the file

      - `type` (String, one of `"regular"`, `"symlink"` or `"unknown"`): The type of the file.
        This matches result of calling [`builtins.readFileType`](https://nixos.org/manual/nix/stable/language/builtins.html#builtins-readFileType) on the file's path.

      - `hasExt` (String -> Bool): Whether the file has a certain file extension.
        `hasExt ext` is true only if `hasSuffix ".${ext}" name`.

        This also means that e.g. for a file with name `.gitignore`,
        `hasExt "gitignore"` is true.

      Other attributes may be added in the future.

    `path`

    : The path whose files to filter

    # Type

    ```
    fileFilter ::
      ({
        name :: String,
        type :: String,
        hasExt :: String -> Bool,
        ...
      } -> Bool)
      -> Path
      -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.fileFilter` usage example

    ```nix
    # Include all regular `default.nix` files in the current directory
    fileFilter (file: file.name == "default.nix") ./.

    # Include all non-Nix files from the current directory
    fileFilter (file: ! file.hasExt "nix") ./.

    # Include all files that start with a "." in the current directory
    fileFilter (file: hasPrefix "." file.name) ./.

    # Include all regular files (not symlinks or others) in the current directory
    fileFilter (file: file.type == "regular") ./.
    ```

    :::
  */
  fileFilter =
    predicate: path:
    if !isFunction predicate then
      throw ''lib.fileset.fileFilter: First argument is of type ${typeOf predicate}, but it should be a function instead.''
    else if !isPath path then
      if path._type or "" == "fileset" then
        throw ''
          lib.fileset.fileFilter: Second argument is a file set, but it should be a path instead.
              If you need to filter files in a file set, use `intersection fileset (fileFilter pred ./.)` instead.''
      else
        throw ''lib.fileset.fileFilter: Second argument is of type ${typeOf path}, but it should be a path instead.''
    else if !pathExists path then
      throw ''lib.fileset.fileFilter: Second argument (${toString path}) is a path that does not exist.''
    else
      _fileFilter predicate path;

  /**
    Create a file set with the same files as a `lib.sources`-based value.
    This does not import any of the files into the store.

    This can be used to gradually migrate from `lib.sources`-based filtering to `lib.fileset`.

    A file set can be turned back into a source using [`toSource`](#function-library-lib.fileset.toSource).

    :::{.note}
    File sets cannot represent empty directories.
    Turning the result of this function back into a source using `toSource` will therefore not preserve empty directories.
    :::

    # Inputs

    `source`

    : 1\. Function argument

    # Type

    ```
    fromSource :: SourceLike -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.fromSource` usage example

    ```nix
    # There's no cleanSource-like function for file sets yet,
    # but we can just convert cleanSource to a file set and use it that way
    toSource {
      root = ./.;
      fileset = fromSource (lib.sources.cleanSource ./.);
    }

    # Keeping a previous sourceByRegex (which could be migrated to `lib.fileset.unions`),
    # but removing a subdirectory using file set functions
    difference
      (fromSource (lib.sources.sourceByRegex ./. [
        "^README\.md$"
        # This regex includes everything in ./doc
        "^doc(/.*)?$"
      ])
      ./doc/generated

    # Use cleanSource, but limit it to only include ./Makefile and files under ./src
    intersection
      (fromSource (lib.sources.cleanSource ./.))
      (unions [
        ./Makefile
        ./src
      ]);
    ```

    :::
  */
  fromSource =
    source:
    let
      # This function uses `._isLibCleanSourceWith`, `.origSrc` and `.filter`,
      # which are technically internal to lib.sources,
      # but we'll allow this since both libraries are in the same code base
      # and this function is a bridge between them.
      isFiltered = source ? _isLibCleanSourceWith;
      path = if isFiltered then source.origSrc else source;
    in
    # We can only support sources created from paths
    if !isPath path then
      if isStringLike path then
        throw ''
          lib.fileset.fromSource: The source origin of the argument is a string-like value ("${toString path}"), but it should be a path instead.
              Sources created from paths in strings cannot be turned into file sets, use `lib.sources` or derivations instead.''
      else
        throw ''lib.fileset.fromSource: The source origin of the argument is of type ${typeOf path}, but it should be a path instead.''
    else if !pathExists path then
      throw ''lib.fileset.fromSource: The source origin (${toString path}) of the argument is a path that does not exist.''
    else if isFiltered then
      _fromSourceFilter path source.filter
    else
      # If there's no filter, no need to run the expensive conversion, all subpaths will be included
      _singleton path;

  /**
    Create a file set containing all [Git-tracked files](https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository) in a repository.

    This function behaves like [`gitTrackedWith { }`](#function-library-lib.fileset.gitTrackedWith) - using the defaults.

    # Inputs

    `path`

    : The [path](https://nixos.org/manual/nix/stable/language/values#type-path) to the working directory of a local Git repository.
      This directory must contain a `.git` file or subdirectory.

    # Type

    ```
    gitTracked :: Path -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.gitTracked` usage example

    ```nix
    # Include all files tracked by the Git repository in the current directory
    gitTracked ./.

    # Include only files tracked by the Git repository in the parent directory
    # that are also in the current directory
    intersection ./. (gitTracked ../.)
    ```

    :::
  */
  gitTracked = path: _fromFetchGit "gitTracked" "argument" path { };

  /**
    Create a file set containing all [Git-tracked files](https://git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository) in a repository.
    The first argument allows configuration with an attribute set,
    while the second argument is the path to the Git working tree.

    `gitTrackedWith` does not perform any filtering when the path is a [Nix store path](https://nixos.org/manual/nix/stable/store/store-path.html#store-path) and not a repository.
    In this way, it accommodates the use case where the expression that makes the `gitTracked` call does not reside in an actual git repository anymore,
    and has presumably already been fetched in a way that excludes untracked files.
    Fetchers with such equivalent behavior include `builtins.fetchGit`, `builtins.fetchTree` (experimental), and `pkgs.fetchgit` when used without `leaveDotGit`.

    If you don't need the configuration,
    you can use [`gitTracked`](#function-library-lib.fileset.gitTracked) instead.

    This is equivalent to the result of [`unions`](#function-library-lib.fileset.unions) on all files returned by [`git ls-files`](https://git-scm.com/docs/git-ls-files)
    (which uses [`--cached`](https://git-scm.com/docs/git-ls-files#Documentation/git-ls-files.txt--c) by default).

    :::{.warning}
    Currently this function is based on [`builtins.fetchGit`](https://nixos.org/manual/nix/stable/language/builtins.html#builtins-fetchGit)
    As such, this function causes all Git-tracked files to be unnecessarily added to the Nix store,
    without being re-usable by [`toSource`](#function-library-lib.fileset.toSource).

    This may change in the future.
    :::

    # Inputs

    `options` (attribute set)
    : `recurseSubmodules` (optional, default: `false`)
      : Whether to recurse into [Git submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules) to also include their tracked files.
        If `true`, this is equivalent to passing the [--recurse-submodules](https://git-scm.com/docs/git-ls-files#Documentation/git-ls-files.txt---recurse-submodules) flag to `git ls-files`.

      `path`
      : The [path](https://nixos.org/manual/nix/stable/language/values#type-path) to the working directory of a local Git repository.
        This directory must contain a `.git` file or subdirectory.

    # Type

    ```
    gitTrackedWith :: { recurseSubmodules :: Bool ? false } -> Path -> FileSet
    ```

    # Examples
    :::{.example}
    ## `lib.fileset.gitTrackedWith` usage example

    ```nix
    # Include all files tracked by the Git repository in the current directory
    # and any submodules under it
    gitTracked { recurseSubmodules = true; } ./.
    ```

    :::
  */
  gitTrackedWith =
    {
      recurseSubmodules ? false,
    }:
    path:
    if !isBool recurseSubmodules then
      throw "lib.fileset.gitTrackedWith: Expected the attribute `recurseSubmodules` of the first argument to be a boolean, but it's a ${typeOf recurseSubmodules} instead."
    else if recurseSubmodules && versionOlder nixVersion _fetchGitSubmodulesMinver then
      throw "lib.fileset.gitTrackedWith: Setting the attribute `recurseSubmodules` to `true` is only supported for Nix version ${_fetchGitSubmodulesMinver} and after, but Nix version ${nixVersion} is used."
    else
      _fromFetchGit "gitTrackedWith" "second argument" path
        # This is the only `fetchGit` parameter that makes sense in this context.
        # We can't just pass `submodules = recurseSubmodules` here because
        # this would fail for Nix versions that don't support `submodules`.
        (
          lib.optionalAttrs recurseSubmodules {
            submodules = true;
          }
        );
}
</file>

<file path="lib/fileset/internal.nix">
{
  lib ? import ../.,
}:
let

  inherit (builtins)
    isAttrs
    isPath
    isString
    nixVersion
    pathExists
    readDir
    split
    trace
    typeOf
    fetchGit
    ;

  inherit (lib.attrsets)
    attrNames
    attrValues
    mapAttrs
    mapAttrsToList
    optionalAttrs
    zipAttrsWith
    ;

  inherit (lib.filesystem)
    pathType
    ;

  inherit (lib.lists)
    all
    commonPrefix
    concatLists
    elemAt
    filter
    findFirst
    findFirstIndex
    foldl'
    head
    length
    sublist
    tail
    ;

  inherit (lib.path)
    append
    splitRoot
    hasStorePathPrefix
    splitStorePath
    ;

  inherit (lib.path.subpath)
    components
    join
    ;

  inherit (lib.strings)
    isStringLike
    concatStringsSep
    substring
    stringLength
    hasSuffix
    versionAtLeast
    ;

  inherit (lib.trivial)
    inPureEvalMode
    ;
in
# Rare case of justified usage of rec:
# - This file is internal, so the return value doesn't matter, no need to make things overridable
# - The functions depend on each other
# - We want to expose all of these functions for easy testing
rec {

  # If you change the internal representation, make sure to:
  # - Increment this version
  # - Add an additional migration function below
  # - Update the description of the internal representation in ./README.md
  _currentVersion = 3;

  # Migrations between versions. The 0th element converts from v0 to v1, and so on
  migrations = [
    # Convert v0 into v1: Add the _internalBase{Root,Components} attributes
    (
      filesetV0:
      let
        parts = splitRoot filesetV0._internalBase;
      in
      filesetV0
      // {
        _internalVersion = 1;
        _internalBaseRoot = parts.root;
        _internalBaseComponents = components parts.subpath;
      }
    )

    # Convert v1 into v2: filesetTree's can now also omit attributes to signal paths not being included
    (
      filesetV1:
      # This change is backwards compatible (but not forwards compatible, so we still need a new version)
      filesetV1
      // {
        _internalVersion = 2;
      }
    )

    # Convert v2 into v3: filesetTree's now have a representation for an empty file set without a base path
    (
      filesetV2:
      filesetV2
      // {
        # All v1 file sets are not the new empty file set
        _internalIsEmptyWithoutBase = false;
        _internalVersion = 3;
      }
    )
  ];

  _noEvalMessage = ''
    lib.fileset: Directly evaluating a file set is not supported.
      To turn it into a usable source, use `lib.fileset.toSource`.
      To pretty-print the contents, use `lib.fileset.trace` or `lib.fileset.traceVal`.'';

  # The empty file set without a base path
  _emptyWithoutBase = {
    _type = "fileset";

    _internalVersion = _currentVersion;

    # The one and only!
    _internalIsEmptyWithoutBase = true;

    # Due to alphabetical ordering, this is evaluated last,
    # which makes the nix repl output nicer than if it would be ordered first.
    # It also allows evaluating it strictly up to this error, which could be useful
    _noEval = throw _noEvalMessage;
  };

  # Create a fileset, see ./README.md#fileset
  # Type: path -> filesetTree -> fileset
  _create =
    base: tree:
    let
      # Decompose the base into its components
      # See ../path/README.md for why we're not just using `toString`
      parts = splitRoot base;
    in
    {
      _type = "fileset";

      _internalVersion = _currentVersion;

      _internalIsEmptyWithoutBase = false;
      _internalBase = base;
      _internalBaseRoot = parts.root;
      _internalBaseComponents = components parts.subpath;
      _internalTree = tree;

      # Due to alphabetical ordering, this is evaluated last,
      # which makes the nix repl output nicer than if it would be ordered first.
      # It also allows evaluating it strictly up to this error, which could be useful
      _noEval = throw _noEvalMessage;
    };

  # Coerce a value to a fileset, erroring when the value cannot be coerced.
  # The string gives the context for error messages.
  # Type: String -> (fileset | Path) -> fileset
  _coerce =
    context: value:
    if value._type or "" == "fileset" then
      if value._internalVersion > _currentVersion then
        throw ''
          ${context} is a file set created from a future version of the file set library with a different internal representation:
              - Internal version of the file set: ${toString value._internalVersion}
              - Internal version of the library: ${toString _currentVersion}
              Make sure to update your Nixpkgs to have a newer version of `lib.fileset`.''
      else if value._internalVersion < _currentVersion then
        let
          # Get all the migration functions necessary to convert from the old to the current version
          migrationsToApply = sublist value._internalVersion (
            _currentVersion - value._internalVersion
          ) migrations;
        in
        foldl' (value: migration: migration value) value migrationsToApply
      else
        value
    else if !isPath value then
      if value ? _isLibCleanSourceWith then
        throw ''
          ${context} is a `lib.sources`-based value, but it should be a file set or a path instead.
              To convert a `lib.sources`-based value to a file set you can use `lib.fileset.fromSource`.
              Note that this only works for sources created from paths.''
      else if isStringLike value then
        throw ''
          ${context} ("${toString value}") is a string-like value, but it should be a file set or a path instead.
              Paths represented as strings are not supported by `lib.fileset`, use `lib.sources` or derivations instead.''
      else
        throw ''${context} is of type ${typeOf value}, but it should be a file set or a path instead.''
    else if !pathExists value then
      throw ''
        ${context} (${toString value}) is a path that does not exist.
            To create a file set from a path that may not exist, use `lib.fileset.maybeMissing`.''
    else
      _singleton value;

  # Coerce many values to filesets, erroring when any value cannot be coerced,
  # or if the filesystem root of the values doesn't match.
  # Type: String -> [ { context :: String, value :: fileset | Path } ] -> [ fileset ]
  _coerceMany =
    functionContext: list:
    let
      filesets = map ({ context, value }: _coerce "${functionContext}: ${context}" value) list;

      # Find the first value with a base, there may be none!
      firstWithBase = findFirst (fileset: !fileset._internalIsEmptyWithoutBase) null filesets;
      # This value is only accessed if first != null
      firstBaseRoot = firstWithBase._internalBaseRoot;

      # Finds the first element with a filesystem root different than the first element, if any
      differentIndex = findFirstIndex (
        fileset:
        # The empty value without a base doesn't have a base path
        !fileset._internalIsEmptyWithoutBase && firstBaseRoot != fileset._internalBaseRoot
      ) null filesets;
    in
    # Only evaluates `differentIndex` if there are any elements with a base
    if firstWithBase != null && differentIndex != null then
      throw ''
        ${functionContext}: Filesystem roots are not the same:
            ${(head list).context}: Filesystem root is "${toString firstBaseRoot}"
            ${(elemAt list differentIndex).context}: Filesystem root is "${toString (elemAt filesets differentIndex)._internalBaseRoot}"
            Different filesystem roots are not supported.''
    else
      filesets;

  # Create a file set from a path.
  # Type: Path -> fileset
  _singleton =
    path:
    let
      type = pathType path;
    in
    if type == "directory" then
      _create path type
    else
      # This turns a file path ./default.nix into a fileset with
      # - _internalBase: ./.
      # - _internalTree: {
      #     "default.nix" = <type>;
      #   }
      # See ./README.md#single-files
      _create (dirOf path) {
        ${baseNameOf path} = type;
      };

  # Expand a directory representation to an equivalent one in attribute set form.
  # All directory entries are included in the result.
  # Type: Path -> filesetTree -> { <name> = filesetTree; }
  _directoryEntries =
    path: value:
    if value == "directory" then
      readDir path
    else
      # Set all entries not present to null
      mapAttrs (name: value: null) (readDir path) // value;

  /**
    A normalisation of a filesetTree suitable filtering with `builtins.path`:
    - Replace all directories that have no files with `null`.
      This removes directories that would be empty
    - Replace all directories with all files with `"directory"`.
      This speeds up the source filter function

    Note that this function is strict, it evaluates the entire tree

    # Inputs

    `path`

    : 1\. Function argument

    `tree`

    : 2\. Function argument

    # Type

    ```
    Path -> filesetTree -> filesetTree
    ```
  */
  _normaliseTreeFilter =
    path: tree:
    if tree == "directory" || isAttrs tree then
      let
        entries = _directoryEntries path tree;
        normalisedSubtrees = mapAttrs (name: _normaliseTreeFilter (path + "/${name}")) entries;
        subtreeValues = attrValues normalisedSubtrees;
      in
      # This triggers either when all files in a directory are filtered out
      # Or when the directory doesn't contain any files at all
      if all isNull subtreeValues then
        null
      # Triggers when we have the same as a `readDir path`, so we can turn it back into an equivalent "directory".
      else if all isString subtreeValues then
        "directory"
      else
        normalisedSubtrees
    else
      tree;

  /**
    A minimal normalisation of a filesetTree, intended for pretty-printing:
    - If all children of a path are recursively included or empty directories, the path itself is also recursively included
    - If all children of a path are fully excluded or empty directories, the path itself is an empty directory
    - Other empty directories are represented with the special "emptyDir" string
      While these could be replaced with `null`, that would take another mapAttrs

    Note that this function is partially lazy.

    # Inputs

    `path`

    : 1\. Function argument

    `tree`

    : 2\. Function argument

    # Type

    ```
    Path -> filesetTree -> filesetTree (with "emptyDir"'s)
    ```
  */
  _normaliseTreeMinimal =
    path: tree:
    if tree == "directory" || isAttrs tree then
      let
        entries = _directoryEntries path tree;
        normalisedSubtrees = mapAttrs (name: _normaliseTreeMinimal (path + "/${name}")) entries;
        subtreeValues = attrValues normalisedSubtrees;
      in
      # If there are no entries, or all entries are empty directories, return "emptyDir".
      # After this branch we know that there's at least one file
      if all (value: value == "emptyDir") subtreeValues then
        "emptyDir"

      # If all subtrees are fully included or empty directories
      # (both of which are coincidentally represented as strings), return "directory".
      # This takes advantage of the fact that empty directories can be represented as included directories.
      # Note that the tree == "directory" check allows avoiding recursion
      else if tree == "directory" || all (value: isString value) subtreeValues then
        "directory"

      # If all subtrees are fully excluded or empty directories, return null.
      # This takes advantage of the fact that empty directories can be represented as excluded directories
      else if all (value: isNull value || value == "emptyDir") subtreeValues then
        null

      # Mix of included and excluded entries
      else
        normalisedSubtrees
    else
      tree;

  # Trace a filesetTree in a pretty way when the resulting value is evaluated.
  # This can handle both normal filesetTree's, and ones returned from _normaliseTreeMinimal
  # Type: Path -> filesetTree (with "emptyDir"'s) -> Null
  _printMinimalTree =
    base: tree:
    let
      treeSuffix =
        tree:
        if isAttrs tree then
          ""
        else if tree == "directory" then
          " (all files in directory)"
        else
          # This does "leak" the file type strings of the internal representation,
          # but this is the main reason these file type strings even are in the representation!
          # TODO: Consider removing that information from the internal representation for performance.
          # The file types can still be printed by querying them only during tracing
          " (${tree})";

      # Only for attribute set trees
      traceTreeAttrs =
        prevLine: indent: tree:
        foldl' (
          prevLine: name:
          let
            subtree = tree.${name};

            # Evaluating this prints the line for this subtree
            thisLine = trace "${indent}- ${name}${treeSuffix subtree}" prevLine;
          in
          if subtree == null || subtree == "emptyDir" then
            # Don't print anything at all if this subtree is empty
            prevLine
          else if isAttrs subtree then
            # A directory with explicit entries
            # Do print this node, but also recurse
            traceTreeAttrs thisLine "${indent}  " subtree
          else
            # Either a file, or a recursively included directory
            # Do print this node but no further recursion needed
            thisLine
        ) prevLine (attrNames tree);

      # Evaluating this will print the first line
      firstLine =
        if tree == null || tree == "emptyDir" then
          trace "(empty)" null
        else
          trace "${toString base}${treeSuffix tree}" null;
    in
    if isAttrs tree then traceTreeAttrs firstLine "" tree else firstLine;

  # Pretty-print a file set in a pretty way when the resulting value is evaluated
  # Type: fileset -> Null
  _printFileset =
    fileset:
    if fileset._internalIsEmptyWithoutBase then
      trace "(empty)" null
    else
      _printMinimalTree fileset._internalBase (
        _normaliseTreeMinimal fileset._internalBase fileset._internalTree
      );

  # Turn a fileset into a source filter function suitable for `builtins.path`
  # Only directories recursively containing at least one files are recursed into
  # Type: fileset -> (String -> String -> Bool)
  _toSourceFilter =
    fileset:
    let
      # Simplify the tree, necessary to make sure all empty directories are null
      # which has the effect that they aren't included in the result
      tree = _normaliseTreeFilter fileset._internalBase fileset._internalTree;

      # The base path as a string with a single trailing slash
      baseString =
        if fileset._internalBaseComponents == [ ] then
          # Need to handle the filesystem root specially
          "/"
        else
          "/" + concatStringsSep "/" fileset._internalBaseComponents + "/";

      baseLength = stringLength baseString;

      # Check whether a list of path components under the base path exists in the tree.
      # This function is called often, so it should be fast.
      # Type: [ String ] -> Bool
      inTree =
        components:
        let
          recurse =
            index: localTree:
            if isAttrs localTree then
              # We have an attribute set, meaning this is a directory with at least one file
              if index >= length components then
                # The path may have no more components though, meaning the filter is running on the directory itself,
                # so we always include it, again because there's at least one file in it.
                true
              else
                # If we do have more components, the filter runs on some entry inside this directory, so we need to recurse
                # We do +2 because builtins.split is an interleaved list of the inbetweens and the matches
                recurse (index + 2) localTree.${elemAt components index}
            else
              # If it's not an attribute set it can only be either null (in which case it's not included)
              # or a string ("directory" or "regular", etc.) in which case it's included
              localTree != null;
        in
        recurse 0 tree;

      # Filter suited when there's no files
      empty = _: _: false;

      # Filter suited when there's some files
      # This can't be used for when there's no files, because the base directory is always included
      nonEmpty =
        path: type:
        let
          # Add a slash to the path string, turning "/foo" to "/foo/",
          # making sure to not have any false prefix matches below.
          # Note that this would produce "//" for "/",
          # but builtins.path doesn't call the filter function on the `path` argument itself,
          # meaning this function can never receive "/" as an argument
          pathSlash = path + "/";
        in
        (
          # Same as `hasPrefix pathSlash baseString`, but more efficient.
          # With base /foo/bar we need to include /foo:
          # hasPrefix "/foo/" "/foo/bar/"
          if substring 0 (stringLength pathSlash) baseString == pathSlash then
            true
          # Same as `! hasPrefix baseString pathSlash`, but more efficient.
          # With base /foo/bar we need to exclude /baz
          # ! hasPrefix "/baz/" "/foo/bar/"
          else if substring 0 baseLength pathSlash != baseString then
            false
          else
            # Same as `removePrefix baseString path`, but more efficient.
            # From the above code we know that hasPrefix baseString pathSlash holds, so this is safe.
            # We don't use pathSlash here because we only needed the trailing slash for the prefix matching.
            # With base /foo and path /foo/bar/baz this gives
            # inTree (split "/" (removePrefix "/foo/" "/foo/bar/baz"))
            # == inTree (split "/" "bar/baz")
            # == inTree [ "bar" "baz" ]
            inTree (split "/" (substring baseLength (-1) path))
        )
        # This is a way have an additional check in case the above is true without any significant performance cost
        && (
          # This relies on the fact that Nix only distinguishes path types "directory", "regular", "symlink" and "unknown",
          # so everything except "unknown" is allowed, seems reasonable to rely on that
          type != "unknown"
          || throw ''
            lib.fileset.toSource: `fileset` contains a file that cannot be added to the store: ${path}
                This file is neither a regular file nor a symlink, the only file types supported by the Nix store.
                Therefore the file set cannot be added to the Nix store as is. Make sure to not include that file to avoid this error.''
        );
    in
    # Special case because the code below assumes that the _internalBase is always included in the result
    # which shouldn't be done when we have no files at all in the base
    # This also forces the tree before returning the filter, leads to earlier error messages
    if fileset._internalIsEmptyWithoutBase || tree == null then empty else nonEmpty;

  # Turn a builtins.filterSource-based source filter on a root path into a file set
  # containing only files included by the filter.
  # The filter is lazily called as necessary to determine whether paths are included
  # Type: Path -> (String -> String -> Bool) -> fileset
  _fromSourceFilter =
    root: sourceFilter:
    let
      # During the recursion we need to track both:
      # - The path value such that we can safely call `readDir` on it
      # - The path string value such that we can correctly call the `filter` with it
      #
      # While we could just recurse with the path value,
      # this would then require converting it to a path string for every path,
      # which is a fairly expensive operation

      # Create a file set from a directory entry
      fromDirEntry =
        path: pathString: type:
        # The filter needs to run on the path as a string
        if !sourceFilter pathString type then
          null
        else if type == "directory" then
          fromDir path pathString
        else
          type;

      # Create a file set from a directory
      fromDir =
        path: pathString:
        mapAttrs
          # This looks a bit funny, but we need both the path-based and the path string-based values
          (name: fromDirEntry (path + "/${name}") (pathString + "/${name}"))
          # We need to readDir on the path value, because reading on a path string
          # would be unspecified if there are multiple filesystem roots
          (readDir path);

      rootPathType = pathType root;

      # We need to convert the path to a string to imitate what builtins.path calls the filter function with.
      # We don't want to rely on `toString` for this though because it's not very well defined, see ../path/README.md
      # So instead we use `lib.path.splitRoot` to safely deconstruct the path into its filesystem root and subpath
      # We don't need the filesystem root though, builtins.path doesn't expose that in any way to the filter.
      # So we only need the components, which we then turn into a string as one would expect.
      rootString = "/" + concatStringsSep "/" (components (splitRoot root).subpath);
    in
    if rootPathType == "directory" then
      # We imitate builtins.path not calling the filter on the root path
      _create root (fromDir root rootString)
    else
      # Direct files are always included by builtins.path without calling the filter
      # But we need to lift up the base path to its parent to satisfy the base path invariant
      _create (dirOf root) {
        ${baseNameOf root} = rootPathType;
      };

  # Turns a file set into the list of file paths it includes.
  # Type: fileset -> [ Path ]
  _toList =
    fileset:
    let
      recurse =
        path: tree:
        if isAttrs tree then
          concatLists (mapAttrsToList (name: value: recurse (path + "/${name}") value) tree)
        else if tree == "directory" then
          recurse path (readDir path)
        else if tree == null then
          [ ]
        else
          [ path ];
    in
    if fileset._internalIsEmptyWithoutBase then
      [ ]
    else
      recurse fileset._internalBase fileset._internalTree;

  # Transforms the filesetTree of a file set to a shorter base path, e.g.
  # _shortenTreeBase [ "foo" ] (_create /foo/bar null)
  # => { bar = null; }
  _shortenTreeBase =
    targetBaseComponents: fileset:
    let
      recurse =
        index:
        # If we haven't reached the required depth yet
        if index < length fileset._internalBaseComponents then
          # Create an attribute set and recurse as the value, this can be lazily evaluated this way
          { ${elemAt fileset._internalBaseComponents index} = recurse (index + 1); }
        else
          # Otherwise we reached the appropriate depth, here's the original tree
          fileset._internalTree;
    in
    recurse (length targetBaseComponents);

  # Transforms the filesetTree of a file set to a longer base path, e.g.
  # _lengthenTreeBase [ "foo" "bar" ] (_create /foo { bar.baz = "regular"; })
  # => { baz = "regular"; }
  _lengthenTreeBase =
    targetBaseComponents: fileset:
    let
      recurse =
        index: tree:
        # If the filesetTree is an attribute set and we haven't reached the required depth yet
        if isAttrs tree && index < length targetBaseComponents then
          # Recurse with the tree under the right component (which might not exist)
          recurse (index + 1) (tree.${elemAt targetBaseComponents index} or null)
        else
          # For all values here we can just return the tree itself:
          # tree == null -> the result is also null, everything is excluded
          # tree == "directory" -> the result is also "directory",
          #   because the base path is always a directory and everything is included
          # isAttrs tree -> the result is `tree`
          #   because we don't need to recurse any more since `index == length longestBaseComponents`
          tree;
    in
    recurse (length fileset._internalBaseComponents) fileset._internalTree;

  # Computes the union of a list of filesets.
  # The filesets must already be coerced and validated to be in the same filesystem root
  # Type: [ Fileset ] -> Fileset
  _unionMany =
    filesets:
    let
      # All filesets that have a base, aka not the ones that are the empty value without a base
      filesetsWithBase = filter (fileset: !fileset._internalIsEmptyWithoutBase) filesets;

      # The first fileset that has a base.
      # This value is only accessed if there are at all.
      firstWithBase = head filesetsWithBase;

      # To be able to union filesetTree's together, they need to have the same base path.
      # Base paths can be unioned by taking their common prefix,
      # e.g. such that `union /foo/bar /foo/baz` has the base path `/foo`

      # A list of path components common to all base paths.
      # Note that commonPrefix can only be fully evaluated,
      # so this cannot cause a stack overflow due to a build-up of unevaluated thunks.
      commonBaseComponents =
        foldl' (components: el: commonPrefix components el._internalBaseComponents)
          firstWithBase._internalBaseComponents
          # We could also not do the `tail` here to avoid a list allocation,
          # but then we'd have to pay for a potentially expensive
          # but unnecessary `commonPrefix` call
          (tail filesetsWithBase);

      # The common base path assembled from a filesystem root and the common components
      commonBase = append firstWithBase._internalBaseRoot (join commonBaseComponents);

      # A list of filesetTree's that all have the same base path
      # This is achieved by nesting the trees into the components they have over the common base path
      # E.g. `union /foo/bar /foo/baz` has the base path /foo
      # So the tree under `/foo/bar` gets nested under `{ bar = ...; ... }`,
      # while the tree under `/foo/baz` gets nested under `{ baz = ...; ... }`
      # Therefore allowing combined operations over them.
      trees = map (_shortenTreeBase commonBaseComponents) filesetsWithBase;

      # Folds all trees together into a single one using _unionTree
      # We do not use a fold here because it would cause a thunk build-up
      # which could cause a stack overflow for a large number of trees
      resultTree = _unionTrees trees;
    in
    # If there's no values with a base, we have no files
    if filesetsWithBase == [ ] then _emptyWithoutBase else _create commonBase resultTree;

  # The union of multiple filesetTree's with the same base path.
  # Later elements are only evaluated if necessary.
  # Type: [ filesetTree ] -> filesetTree
  _unionTrees =
    trees:
    let
      stringIndex = findFirstIndex isString null trees;
      withoutNull = filter (tree: tree != null) trees;
    in
    if stringIndex != null then
      # If there's a string, it's always a fully included tree (dir or file),
      # no need to look at other elements
      elemAt trees stringIndex
    else if withoutNull == [ ] then
      # If all trees are null, then the resulting tree is also null
      null
    else
      # The non-null elements have to be attribute sets representing partial trees
      # We need to recurse into those
      zipAttrsWith (name: _unionTrees) withoutNull;

  # Computes the intersection of a list of filesets.
  # The filesets must already be coerced and validated to be in the same filesystem root
  # Type: Fileset -> Fileset -> Fileset
  _intersection =
    fileset1: fileset2:
    let
      # The common base components prefix, e.g.
      # (/foo/bar, /foo/bar/baz) -> /foo/bar
      # (/foo/bar, /foo/baz) -> /foo
      commonBaseComponentsLength =
        # TODO: Have a `lib.lists.commonPrefixLength` function such that we don't need the list allocation from commonPrefix here
        length (commonPrefix fileset1._internalBaseComponents fileset2._internalBaseComponents);

      # To be able to intersect filesetTree's together, they need to have the same base path.
      # Base paths can be intersected by taking the longest one (if any)

      # The fileset with the longest base, if any, e.g.
      # (/foo/bar, /foo/bar/baz) -> /foo/bar/baz
      # (/foo/bar, /foo/baz) -> null
      longestBaseFileset =
        if commonBaseComponentsLength == length fileset1._internalBaseComponents then
          # The common prefix is the same as the first path, so the second path is equal or longer
          fileset2
        else if commonBaseComponentsLength == length fileset2._internalBaseComponents then
          # The common prefix is the same as the second path, so the first path is longer
          fileset1
        else
          # The common prefix is neither the first nor the second path
          # This means there's no overlap between the two sets
          null;

      # Whether the result should be the empty value without a base
      resultIsEmptyWithoutBase =
        # If either fileset is the empty fileset without a base, the intersection is too
        fileset1._internalIsEmptyWithoutBase
        || fileset2._internalIsEmptyWithoutBase
        # If there is no overlap between the base paths
        || longestBaseFileset == null;

      # Lengthen each fileset's tree to the longest base prefix
      tree1 = _lengthenTreeBase longestBaseFileset._internalBaseComponents fileset1;
      tree2 = _lengthenTreeBase longestBaseFileset._internalBaseComponents fileset2;

      # With two filesetTree's with the same base, we can compute their intersection
      resultTree = _intersectTree tree1 tree2;
    in
    if resultIsEmptyWithoutBase then
      _emptyWithoutBase
    else
      _create longestBaseFileset._internalBase resultTree;

  # The intersection of two filesetTree's with the same base path
  # The second element is only evaluated as much as necessary.
  # Type: filesetTree -> filesetTree -> filesetTree
  _intersectTree =
    lhs: rhs:
    if isAttrs lhs && isAttrs rhs then
      # Both sides are attribute sets, we can recurse for the attributes existing on both sides
      mapAttrs (name: _intersectTree lhs.${name}) (builtins.intersectAttrs lhs rhs)
    else if lhs == null || isString rhs then
      # If the lhs is null, the result should also be null
      # And if the rhs is the identity element
      # (a string, aka it includes everything), then it's also the lhs
      lhs
    else
      # In all other cases it's the rhs
      rhs;

  # Compute the set difference between two file sets.
  # The filesets must already be coerced and validated to be in the same filesystem root.
  # Type: Fileset -> Fileset -> Fileset
  _difference =
    positive: negative:
    let
      # The common base components prefix, e.g.
      # (/foo/bar, /foo/bar/baz) -> /foo/bar
      # (/foo/bar, /foo/baz) -> /foo
      commonBaseComponentsLength =
        # TODO: Have a `lib.lists.commonPrefixLength` function such that we don't need the list allocation from commonPrefix here
        length (commonPrefix positive._internalBaseComponents negative._internalBaseComponents);

      # We need filesetTree's with the same base to be able to compute the difference between them
      # This here is the filesetTree from the negative file set, but for a base path that matches the positive file set.
      # Examples:
      # For `difference /foo /foo/bar`, `negativeTreeWithPositiveBase = { bar = "directory"; }`
      #   because under the base path of `/foo`, only `bar` from the negative file set is included
      # For `difference /foo/bar /foo`, `negativeTreeWithPositiveBase = "directory"`
      #   because under the base path of `/foo/bar`, everything from the negative file set is included
      # For `difference /foo /bar`, `negativeTreeWithPositiveBase = null`
      #   because under the base path of `/foo`, nothing from the negative file set is included
      negativeTreeWithPositiveBase =
        if commonBaseComponentsLength == length positive._internalBaseComponents then
          # The common prefix is the same as the positive base path, so the second path is equal or longer.
          # We need to _shorten_ the negative filesetTree to the same base path as the positive one
          # E.g. for `difference /foo /foo/bar` the common prefix is /foo, equal to the positive file set's base
          # So we need to shorten the base of the tree for the negative argument from /foo/bar to just /foo
          _shortenTreeBase positive._internalBaseComponents negative
        else if commonBaseComponentsLength == length negative._internalBaseComponents then
          # The common prefix is the same as the negative base path, so the first path is longer.
          # We need to lengthen the negative filesetTree to the same base path as the positive one.
          # E.g. for `difference /foo/bar /foo` the common prefix is /foo, equal to the negative file set's base
          # So we need to lengthen the base of the tree for the negative argument from /foo to /foo/bar
          _lengthenTreeBase positive._internalBaseComponents negative
        else
          # The common prefix is neither the first nor the second path.
          # This means there's no overlap between the two file sets,
          # and nothing from the negative argument should get removed from the positive one
          # E.g for `difference /foo /bar`, we remove nothing to get the same as `/foo`
          null;

      resultingTree =
        _differenceTree positive._internalBase positive._internalTree
          negativeTreeWithPositiveBase;
    in
    # If the first file set is empty, we can never have any files in the result
    if positive._internalIsEmptyWithoutBase then
      _emptyWithoutBase
    # If the second file set is empty, nothing gets removed, so the result is just the first file set
    else if negative._internalIsEmptyWithoutBase then
      positive
    else
      # We use the positive file set base for the result,
      # because only files from the positive side may be included,
      # which is what base path is for
      _create positive._internalBase resultingTree;

  # Computes the set difference of two filesetTree's
  # Type: Path -> filesetTree -> filesetTree
  _differenceTree =
    path: lhs: rhs:
    # If the lhs doesn't have any files, or the right hand side includes all files
    if lhs == null || isString rhs then
      # The result will always be empty
      null
    # If the right hand side has no files
    else if rhs == null then
      # The result is always the left hand side, because nothing gets removed
      lhs
    else
      # Otherwise we always have two attribute sets to recurse into
      mapAttrs (name: lhsValue: _differenceTree (path + "/${name}") lhsValue (rhs.${name} or null)) (
        _directoryEntries path lhs
      );

  # Filters all files in a path based on a predicate
  # Type: ({ name, type, ... } -> Bool) -> Path -> FileSet
  _fileFilter =
    predicate: root:
    let
      # Check the predicate for a single file
      # Type: String -> String -> filesetTree
      fromFile =
        name: type:
        if
          predicate {
            inherit name type;
            hasExt = ext: hasSuffix ".${ext}" name;

            # To ensure forwards compatibility with more arguments being added in the future,
            # adding an attribute which can't be deconstructed :)
            "lib.fileset.fileFilter: The predicate function passed as the first argument must be able to handle extra attributes for future compatibility. If you're using `{ name, file, hasExt }:`, use `{ name, file, hasExt, ... }:` instead." =
              null;
          }
        then
          type
        else
          null;

      # Check the predicate for all files in a directory
      # Type: Path -> filesetTree
      fromDir =
        path:
        mapAttrs (
          name: type: if type == "directory" then fromDir (path + "/${name}") else fromFile name type
        ) (readDir path);

      rootType = pathType root;
    in
    if rootType == "directory" then
      _create root (fromDir root)
    else
      # Single files are turned into a directory containing that file or nothing.
      _create (dirOf root) {
        ${baseNameOf root} = fromFile (baseNameOf root) rootType;
      };

  # Support for `builtins.fetchGit` with `submodules = true` was introduced in 2.4
  # https://github.com/NixOS/nix/commit/55cefd41d63368d4286568e2956afd535cb44018
  _fetchGitSubmodulesMinver = "2.4";

  # Support for `builtins.fetchGit` with `shallow = true` was introduced in 2.4
  # https://github.com/NixOS/nix/commit/d1165d8791f559352ff6aa7348e1293b2873db1c
  _fetchGitShallowMinver = "2.4";

  # Mirrors the contents of a Nix store path relative to a local path as a file set.
  # Some notes:
  # - The store path is read at evaluation time.
  # - The store path must not include files that don't exist in the respective local path.
  #
  # Type: Path -> String -> FileSet
  _mirrorStorePath =
    localPath: storePath:
    let
      recurse =
        focusedStorePath:
        mapAttrs (
          name: type: if type == "directory" then recurse (focusedStorePath + "/${name}") else type
        ) (builtins.readDir focusedStorePath);
    in
    _create localPath (recurse storePath);

  # Create a file set from the files included in the result of a fetchGit call
  # Type: String -> String -> Path -> Attrs -> FileSet
  _fromFetchGit =
    function: argument: path: extraFetchGitAttrs:
    let
      # The code path for when isStorePath is true
      tryStorePath =
        if pathExists (path + "/.git") then
          # If there is a `.git` directory in the path,
          # it means that the path was imported unfiltered into the Nix store.
          # This function should throw in such a case, because
          # - `fetchGit` doesn't generally work with `.git` directories in store paths
          # - Importing the entire path could include Git-tracked files
          throw ''
            lib.fileset.${function}: The ${argument} (${toString path}) is a store path within a working tree of a Git repository.
                This indicates that a source directory was imported into the store using a method such as `import "''${./.}"` or `path:.`.
                This function currently does not support such a use case, since it currently relies on `builtins.fetchGit`.
                You could make this work by using a fetcher such as `fetchGit` instead of copying the whole repository.
                If you can't avoid copying the repo to the store, see https://github.com/NixOS/nix/issues/9292.''
        else
          # Otherwise we're going to assume that the path was a Git directory originally,
          # but it was fetched using a method that already removed files not tracked by Git,
          # such as `builtins.fetchGit`, `pkgs.fetchgit` or others.
          # So we can just import the path in its entirety.
          _singleton path;

      # The code path for when isStorePath is false
      tryFetchGit =
        let
          # This imports the files unnecessarily, which currently can't be avoided
          # because `builtins.fetchGit` is the only function exposing which files are tracked by Git.
          # With the [lazy trees PR](https://github.com/NixOS/nix/pull/6530),
          # the unnecessarily import could be avoided.
          # However a simpler alternative still would be [a builtins.gitLsFiles](https://github.com/NixOS/nix/issues/2944).
          fetchResult = fetchGit (
            {
              url = path;
            }
            # In older Nix versions, repositories were always assumed to be deep clones, which made `fetchGit` fail for shallow clones
            # For newer versions this was fixed, but the `shallow` flag is required.
            # The only behavioral difference is that for shallow clones, `fetchGit` doesn't return a `revCount`,
            # which we don't need here, so it's fine to always pass it.

            # Unfortunately this means older Nix versions get a poor error message for shallow repositories, and there's no good way to improve that.
            # Checking for `.git/shallow` doesn't seem worth it, especially since that's more of an implementation detail,
            # and would also require more code to handle worktrees where `.git` is a file.
            // optionalAttrs (versionAtLeast nixVersion _fetchGitShallowMinver) { shallow = true; }
            // extraFetchGitAttrs
          );
        in
        # We can identify local working directories by checking for .git,
        # see https://git-scm.com/docs/gitrepository-layout#_description.
        # Note that `builtins.fetchGit` _does_ work for bare repositories (where there's no `.git`),
        # even though `git ls-files` wouldn't return any files in that case.
        if !pathExists (path + "/.git") then
          throw "lib.fileset.${function}: Expected the ${argument} (${toString path}) to point to a local working tree of a Git repository, but it's not."
        else
          _mirrorStorePath path fetchResult.outPath;

    in
    if !isPath path then
      throw "lib.fileset.${function}: Expected the ${argument} to be a path, but it's a ${typeOf path} instead."
    else if pathType path != "directory" then
      throw "lib.fileset.${function}: Expected the ${argument} (${toString path}) to be a directory, but it's a file instead."
    else if hasStorePathPrefix path then
      tryStorePath
    else
      tryFetchGit;

}
</file>

<file path="lib/fileset/mock-splitRoot.nix">
# This overlay implements mocking of the lib.path.splitRoot function
# It pretends that the last component named "mock-root" is the root:
#
# splitRoot /foo/mock-root/bar/mock-root/baz
# => {
#      root = /foo/mock-root/bar/mock-root;
#      subpath = "./baz";
#    }
self: super: {
  path = super.path // {
    splitRoot =
      path:
      let
        parts = super.path.splitRoot path;
        components = self.path.subpath.components parts.subpath;
        count = self.length components;
        rootIndex =
          count
          - self.lists.findFirstIndex (component: component == "mock-root") (self.length components) (
            self.reverseList components
          );
        root = self.path.append parts.root (self.path.subpath.join (self.take rootIndex components));
        subpath = self.path.subpath.join (self.drop rootIndex components);
      in
      {
        inherit root subpath;
      };
  };
}
</file>

<file path="lib/fileset/README.md">
# File set library

This is the internal contributor documentation.
The user documentation is [in the Nixpkgs manual](https://nixos.org/manual/nixpkgs/unstable/#sec-fileset).

## Goals

The main goal of the file set library is to be able to select local files that should be added to the Nix store.
It should have the following properties:
- Easy:
  The functions should have obvious semantics, be low in number and be composable.
- Safe:
  Throw early and helpful errors when mistakes are detected.
- Lazy:
  Only compute values when necessary.

Non-goals are:
- Efficient:
  If the abstraction proves itself worthwhile but too slow, it can be still be optimized further.

## Tests

Tests are declared in [`tests.sh`](./tests.sh) and can be run using
```
./tests.sh
```

## Benchmark

A simple benchmark against the HEAD commit can be run using
```
./benchmark.sh HEAD
```

This is intended to be run manually and is not checked by CI.

## Internal representation

The internal representation is versioned in order to allow file sets from different Nixpkgs versions to be composed with each other, see [`internal.nix`](./internal.nix) for the versions and conversions between them.
This section describes only the current representation, but past versions will have to be supported by the code.

### `fileset`

An attribute set with these values:

- `_type` (constant string `"fileset"`):
  Tag to indicate this value is a file set.

- `_internalVersion` (constant `3`, the current version):
  Version of the representation.

- `_internalIsEmptyWithoutBase` (bool):
  Whether this file set is the empty file set without a base path.
  If `true`, `_internalBase*` and `_internalTree` are not set.
  This is the only way to represent an empty file set without needing a base path.

  Such a value can be used as the identity element for `union` and the return value of `unions []` and co.

- `_internalBase` (path):
  Any files outside of this path cannot influence the set of files.
  This is always a directory and should be as long as possible.
  This is used by `lib.fileset.toSource` to check that all files are under the `root` argument

- `_internalBaseRoot` (path):
  The filesystem root of `_internalBase`, same as `(lib.path.splitRoot _internalBase).root`.
  This is here because this needs to be computed anyway, and this computation shouldn't be duplicated.

- `_internalBaseComponents` (list of strings):
  The path components of `_internalBase`, same as `lib.path.subpath.components (lib.path.splitRoot _internalBase).subpath`.
  This is here because this needs to be computed anyway, and this computation shouldn't be duplicated.

- `_internalTree` ([filesetTree](#filesettree)):
  A tree representation of all included files under `_internalBase`.

- `__noEval` (error):
  An error indicating that directly evaluating file sets is not supported.

## `filesetTree`

One of the following:

- `{ <name> = filesetTree; }`:
  A directory with a nested `filesetTree` value for directory entries.
  Entries not included may either be omitted or set to `null`, as necessary to improve efficiency or laziness.

- `"directory"`:
  A directory with all its files included recursively, allowing early cutoff for some operations.
  This specific string is chosen to be compatible with `builtins.readDir` for a simpler implementation.

- `"regular"`, `"symlink"`, `"unknown"` or any other non-`"directory"` string:
  A nested file with its file type.
  These specific strings are chosen to be compatible with `builtins.readDir` for a simpler implementation.
  Distinguishing between different file types is not strictly necessary for the functionality this library,
  but it does allow nicer printing of file sets.

- `null`:
  A file or directory that is excluded from the tree.
  It may still exist on the file system.

## API design decisions

This section justifies API design decisions.

### Internal structure

The representation of the file set data type is internal and can be changed over time.

Arguments:
- (+) The point of this library is to provide high-level functions, users don't need to be concerned with how it's implemented
- (+) It allows adjustments to the representation, which is especially useful in the early days of the library.
- (+) It still allows the representation to be stabilized later if necessary and if it has proven itself

### Influence tracking

File set operations internally track the top-most directory that could influence the exact contents of a file set.
Specifically, `toSource` requires that the given `fileset` is completely determined by files within the directory specified by the `root` argument.
For example, even with `dir/file.txt` being the only file in `./.`, `toSource { root = ./dir; fileset = ./.; }` gives an error.
This is because `fileset` may as well be the result of filtering `./.` in a way that excludes `dir`.

Arguments:
- (+) This gives us the guarantee that adding new files to a project never breaks a file set expression.
  This is also true in a lesser form for removed files:
  only removing files explicitly referenced by paths can break a file set expression.
- (+) This can be removed later, if we discover it's too restrictive
- (-) It leads to errors when a sensible result could sometimes be returned, such as in the above example.

### Empty file set without a base

There is a special representation for an empty file set without a base path.
This is used for return values that should be empty but when there's no base path that would makes sense.

Arguments:
- Alternative: This could also be represented using `_internalBase = /.` and `_internalTree = null`.
  - (+) Removes the need for a special representation.
  - (-) Due to [influence tracking](#influence-tracking),
    `union empty ./.` would have `/.` as the base path,
    which would then prevent `toSource { root = ./.; fileset = union empty ./.; }` from working,
    which is not as one would expect.
  - (-) With the assumption that there can be multiple filesystem roots (as established with the [path library](../path/README.md)),
    this would have to cause an error with `union empty pathWithAnotherFilesystemRoot`,
    which is not as one would expect.
- Alternative: Do not have such a value and error when it would be needed as a return value
  - (+) Removes the need for a special representation.
  - (-) Leaves us with no identity element for `union` and no reasonable return value for `unions []`.
    From a set theory perspective, which has a well-known notion of empty sets, this is unintuitive.

### No intersection for lists

While there is `intersection a b`, there is no function `intersections [ a b c ]`.

Arguments:
- (+) There is no known use case for such a function, it can be added later if a use case arises
- (+) There is no suitable return value for `intersections [ ]`, see also "Nullary intersections" [here](https://en.wikipedia.org/w/index.php?title=List_of_set_identities_and_relations&oldid=1177174035#Definitions)
  - (-) Could throw an error for that case
  - (-) Create a special value to represent "all the files" and return that
    - (+) Such a value could then not be used with `fileFilter` unless the internal representation is changed considerably
  - (-) Could return the empty file set
    - (+) This would be wrong in set theory
- (-) Inconsistent with `union` and `unions`

### Intersection base path

The base path of the result of an `intersection` is the longest base path of the arguments.
E.g. the base path of `intersection ./foo ./foo/bar` is `./foo/bar`.
Meanwhile `intersection ./foo ./bar` returns the empty file set without a base path.

Arguments:
- Alternative: Use the common prefix of all base paths as the resulting base path
  - (-) This is unnecessarily strict, because the purpose of the base path is to track the directory under which files _could_ be in the file set.
    It should be as long as possible.
    All files contained in `intersection ./foo ./foo/bar` will be under `./foo/bar` (never just under `./foo`), and `intersection ./foo ./bar` will never contain any files (never under `./.`).
    This would lead to `toSource` having to unexpectedly throw errors for cases such as `toSource { root = ./foo; fileset = intersect ./foo base; }`, where `base` may be `./bar` or `./.`.
  - (-) There is no benefit to the user, since base path is not directly exposed in the interface

### Empty directories

File sets can only represent a _set_ of local files.
Directories on their own are not representable.

Arguments:
- (+) There does not seem to be a sensible set of combinators when directories can be represented on their own.
  Here's some possibilities:
  - `./.` represents the files in `./.` _and_ the directory itself including its subdirectories, meaning that even if there's no files, the entire structure of `./.` is preserved

    In that case, what should `fileFilter (file: false) ./.` return?
    It could return the entire directory structure unchanged, but with all files removed, which would not be what one would expect.

    Trying to have a filter function that also supports directories will lead to the question of:
    What should the behavior be if `./foo` itself is excluded but all of its contents are included?
    It leads to having to define when directories are recursed into, but then we're effectively back at how the `builtins.path`-based filters work.

  - `./.` represents all files in `./.` _and_ the directory itself, but not its subdirectories, meaning that at least `./.` will be preserved even if it's empty.

    In that case, `intersection ./. ./foo` should only include files and no directories themselves, since `./.` includes only `./.` as a directory, and same for `./foo`, so there's no overlap in directories.
    But intuitively this operation should result in the same as `./foo` – everything else is just confusing.
- (+) This matches how Git only supports files, so developers should already be used to it.
- (-) Empty directories (even if they contain nested directories) are neither representable nor preserved when coercing from paths.
  - (+) It is very rare that empty directories are necessary.
  - (+) We can implement a workaround, allowing `toSource` to take an extra argument for ensuring certain extra directories exist in the result.
- (-) It slows down store imports, since the evaluator needs to traverse the entire tree to remove any empty directories
  - (+) This can still be optimized by introducing more Nix builtins if necessary

### String paths

File sets do not support Nix store paths in strings such as `"/nix/store/...-source"`.

Arguments:
- (+) Such paths are usually produced by derivations, which means `toSource` would either:
  - Require [Import From Derivation](https://nixos.org/manual/nix/unstable/language/import-from-derivation) (IFD) if `builtins.path` is used as the underlying primitive
  - Require importing the entire `root` into the store such that derivations can be used to do the filtering
- (+) The convenient path coercion like `union ./foo ./bar` wouldn't work for absolute paths, requiring more verbose alternate interfaces:
  - `let root = "/nix/store/...-source"; in union "${root}/foo" "${root}/bar"`

    Verbose and dangerous because if `root` was a path, the entire path would get imported into the store.

  - `toSource { root = "/nix/store/...-source"; fileset = union "./foo" "./bar"; }`

    Does not allow debug printing intermediate file set contents, since we don't know the paths contents before having a `root`.

  - `let fs = lib.fileset.withRoot "/nix/store/...-source"; in fs.union "./foo" "./bar"`

    Makes library functions impure since they depend on the contextual root path, questionable composability.

- (+) The point of the file set abstraction is to specify which files should get imported into the store.

  This use case makes little sense for files that are already in the store.
  This should be a separate abstraction as e.g. `pkgs.drvLayout` instead, which could have a similar interface but be specific to derivations.
  Additional capabilities could be supported that can't be done at evaluation time, such as renaming files, creating new directories, setting executable bits, etc.
- (+) An API for filtering/transforming Nix store paths could be much more powerful,
  because it's not limited to just what is possible at evaluation time with `builtins.path`.
  Operations such as moving and adding files would be supported.

### Single files

File sets cannot add single files to the store, they can only import files under directories.

Arguments:
- (+) There's no point in using this library for a single file, since you can't do anything other than add it to the store or not.
  And it would be unclear how the library should behave if the one file wouldn't be added to the store:
  `toSource { root = ./file.nix; fileset = <empty>; }` has no reasonable result because returning an empty store path wouldn't match the file type, and there's no way to have an empty file store path, whatever that would mean.

### `fileFilter` takes a path

The `fileFilter` function takes a path, and not a file set, as its second argument.

- (-) Makes it harder to compose functions, since the file set type, the return value, can't be passed to the function itself like `fileFilter predicate fileset`
  - (+) It's still possible to use `intersection` to filter on file sets: `intersection fileset (fileFilter predicate ./.)`
    - (-) This does need an extra `./.` argument that's not obvious
      - (+) This could always be `/.` or the project directory, `intersection` will make it lazy
- (+) In the future this will allow `fileFilter` to support a predicate property like `subpath` and/or `components` in a reproducible way.
  This wouldn't be possible if it took a file set, because file sets don't have a predictable absolute path.
  - (-) What about the base path?
    - (+) That can change depending on which files are included, so if it's used for `fileFilter`
      it would change the `subpath`/`components` value depending on which files are included.
- (+) If necessary, this restriction can be relaxed later, the opposite wouldn't be possible

### Strict path existence checking

Coercing paths that don't exist to file sets always gives an error.

- (-) Sometimes you want to remove a file that may not always exist using `difference ./. ./does-not-exist`,
  but this does not work because coercion of `./does-not-exist` fails,
  even though its existence would have no influence on the result.
  - (+) This is dangerous, because you wouldn't be protected against typos anymore.
    E.g. when trying to prevent `./secret` from being imported, a typo like `difference ./. ./sercet` would import it regardless.
  - (+) `difference ./. (maybeMissing ./does-not-exist)` can be used to do this more explicitly.
  - (+) `difference ./. (difference ./foo ./foo/bar)` should report an error when `./foo/bar` does not exist ("double negation").
    Unfortunately, the current internal representation does not lend itself to a behavior where both `difference x ./does-not-exists` and double negation are handled and checked correctly.
    This could be fixed, but would require significant changes to the internal representation that are not worth the effort and the risk of introducing implicit behavior.
</file>

<file path="lib/fileset/tests.sh">
#!/usr/bin/env bash
# shellcheck disable=SC2016
# shellcheck disable=SC2317
# shellcheck disable=SC2192

# Tests lib.fileset
# Run:
# [nixpkgs]$ lib/fileset/tests.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -euo pipefail
shopt -s inherit_errexit dotglob

die() {
    # The second to last entry contains the line number of the top-level caller
    lineIndex=$(( ${#BASH_LINENO[@]} - 2 ))
    echo >&2 -e "test case at ${BASH_SOURCE[0]}:${BASH_LINENO[$lineIndex]} failed:" "$@"
    exit 1
}

if test -n "${TEST_LIB:-}"; then
  NIX_PATH=nixpkgs="$(dirname "$TEST_LIB")"
else
  NIX_PATH=nixpkgs="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.."; pwd)"
fi
export NIX_PATH

tmp="$(mktemp -d)"
clean_up() {
    rm -rf "$tmp"
}
trap clean_up EXIT SIGINT SIGTERM
work="$tmp/work"
mkdir "$work"
cd "$work"

# Crudely unquotes a JSON string by just taking everything between the first and the second quote.
# We're only using this for resulting /nix/store paths, which can't contain " anyways,
# nor can they contain any other characters that would need to be escaped specially in JSON
# This way we don't need to add a dependency on e.g. jq
crudeUnquoteJSON() {
    cut -d \" -f2
}

prefixExpression='
  let
    lib = import <nixpkgs/lib>;
    internal = import <nixpkgs/lib/fileset/internal.nix> {
      inherit lib;
    };
  in
  with lib;
  with internal;
  with lib.fileset;
'

# Check that two nix expression successfully evaluate to the same value.
# The expressions have `lib.fileset` in scope.
# Usage: expectEqual NIX NIX
expectEqual() {
    local actualExpr=$1
    local expectedExpr=$2
    if actualResult=$(nix-instantiate --eval --strict --show-trace 2>"$tmp"/actualStderr \
        --expr "$prefixExpression ($actualExpr)"); then
        actualExitCode=$?
    else
        actualExitCode=$?
    fi
    actualStderr=$(< "$tmp"/actualStderr)

    if expectedResult=$(nix-instantiate --eval --strict --show-trace 2>"$tmp"/expectedStderr \
        --expr "$prefixExpression ($expectedExpr)"); then
        expectedExitCode=$?
    else
        expectedExitCode=$?
    fi
    expectedStderr=$(< "$tmp"/expectedStderr)

    if [[ "$actualExitCode" != "$expectedExitCode" ]]; then
        echo "$actualStderr" >&2
        echo "$actualResult" >&2
        die "$actualExpr should have exited with $expectedExitCode, but it exited with $actualExitCode"
    fi

    if [[ "$actualResult" != "$expectedResult" ]]; then
        die "$actualExpr should have evaluated to $expectedExpr:\n$expectedResult\n\nbut it evaluated to\n$actualResult"
    fi

    if [[ "$actualStderr" != "$expectedStderr" ]]; then
        die "$actualExpr should have had this on stderr:\n$expectedStderr\n\nbut it was\n$actualStderr"
    fi
}

# Check that a nix expression evaluates successfully to a store path and returns it (without quotes).
# The expression has `lib.fileset` in scope.
# Usage: expectStorePath NIX
expectStorePath() {
    local expr=$1
    if ! result=$(nix-instantiate --eval --strict --json --read-write-mode --show-trace 2>"$tmp"/stderr \
        --expr "$prefixExpression ($expr)"); then
        cat "$tmp/stderr" >&2
        die "$expr failed to evaluate, but it was expected to succeed"
    fi
    # This is safe because we assume to get back a store path in a string
    crudeUnquoteJSON <<< "$result"
}

# Check that a nix expression fails to evaluate (strictly, read-write-mode).
# And check the received stderr against a regex
# The expression has `lib.fileset` in scope.
# Usage: expectFailure NIX REGEX
expectFailure() {
    local expr=$1
    local expectedErrorRegex=$2
    if result=$(nix-instantiate --eval --strict --read-write-mode --show-trace 2>"$tmp/stderr" \
        --expr "$prefixExpression $expr"); then
        die "$expr evaluated successfully to $result, but it was expected to fail"
    fi
    stderr=$(<"$tmp/stderr")
    if [[ ! "$stderr" =~ $expectedErrorRegex ]]; then
        die "$expr should have errored with this regex pattern:\n\n$expectedErrorRegex\n\nbut this was the actual error:\n\n$stderr"
    fi
}

# Check that the traces of a Nix expression are as expected when evaluated.
# The expression has `lib.fileset` in scope.
# Usage: expectTrace NIX STR
expectTrace() {
    local expr=$1
    local expectedTrace=$2

    nix-instantiate --eval --show-trace >/dev/null 2>"$tmp"/stderrTrace \
        --expr "$prefixExpression trace ($expr)" || true

    actualTrace=$(sed -n 's/^trace: //p' "$tmp/stderrTrace")

    nix-instantiate --eval --show-trace >/dev/null 2>"$tmp"/stderrTraceVal \
        --expr "$prefixExpression traceVal ($expr)" || true

    actualTraceVal=$(sed -n 's/^trace: //p' "$tmp/stderrTraceVal")

    # Test that traceVal returns the same trace as trace
    if [[ "$actualTrace" != "$actualTraceVal" ]]; then
        cat "$tmp"/stderrTrace >&2
        die "$expr traced this for lib.fileset.trace:\n\n$actualTrace\n\nand something different for lib.fileset.traceVal:\n\n$actualTraceVal"
    fi

    if [[ "$actualTrace" != "$expectedTrace" ]]; then
        cat "$tmp"/stderrTrace >&2
        die "$expr should have traced this:\n\n$expectedTrace\n\nbut this was actually traced:\n\n$actualTrace"
    fi
}

# We conditionally use inotifywait in withFileMonitor.
# Check early whether it's available
# TODO: Darwin support, though not crucial since we have Linux CI
if type inotifywait 2>/dev/null >/dev/null; then
    canMonitor=1
else
    echo "Warning: Cannot check for paths not getting read since the inotifywait command (from the inotify-tools package) is not available" >&2
    canMonitor=
fi

# Run a function while monitoring that it doesn't read certain paths
# Usage: withFileMonitor FUNNAME PATH...
# - FUNNAME should be a bash function that:
#   - Performs some operation that should not read some paths
#   - Delete the paths it shouldn't read without triggering any open events
# - PATH... are the paths that should not get read
#
# This function outputs the same as FUNNAME
withFileMonitor() {
    local funName=$1
    shift

    # If we can't monitor files or have none to monitor, just run the function directly
    if [[ -z "$canMonitor" ]] || (( "$#" == 0 )); then
        "$funName"
    else

        # Use a subshell to start the coprocess in and use a trap to kill it when exiting the subshell
        (
            # Assigned by coproc, makes shellcheck happy
            local watcher watcher_PID

            # Start inotifywait in the background to monitor all excluded paths
            coproc watcher {
                # inotifywait outputs a string on stderr when ready
                # Redirect it to stdout so we can access it from the coproc's stdout fd
                # exec so that the coprocess is inotify itself, making the kill below work correctly
                # See below why we listen to both open and delete_self events
                exec inotifywait --format='%e %w' --event open,delete_self --monitor "$@" 2>&1
            }

            # This will trigger when this subshell exits, no matter if successful or not
            # After exiting the subshell, the parent shell will continue executing
            trap 'kill "${watcher_PID}"' exit

            # Synchronously wait until inotifywait is ready
            while read -r -u "${watcher[0]}" line && [[ "$line" != "Watches established." ]]; do
                :
            done

            # Call the function that should not read the given paths and delete them afterwards
            "$funName"

            # Get the first event
            read -r -u "${watcher[0]}" event file

            # With funName potentially reading files first before deleting them,
            # there's only these two possible event timelines:
            # - open*, ..., open*, delete_self, ..., delete_self: If some excluded paths were read
            # - delete_self, ..., delete_self: If no excluded paths were read
            # So by looking at the first event we can figure out which one it is!
            # This also means we don't have to wait to collect all events.
            case "$event" in
                OPEN*)
                    die "$funName opened excluded file $file when it shouldn't have"
                    ;;
                DELETE_SELF)
                    # Expected events
                    ;;
                *)
                    die "During $funName, Unexpected event type '$event' on file $file that should be excluded"
                    ;;
            esac
        )
    fi
}


# Create the tree structure declared in the tree variable, usage:
#
# tree=(
#   [a/b] =   # Declare that file       a/b should exist
#   [c/a] =   # Declare that file       c/a should exist
#   [c/d/]=   # Declare that directory c/d/ should exist
# )
# createTree
declare -A tree
createTree() {
    # Track which paths need to be created
    local -a dirsToCreate=()
    local -a filesToCreate=()
    for p in "${!tree[@]}"; do
        # If keys end with a `/` we treat them as directories, otherwise files
        if [[ "$p" =~ /$ ]]; then
            dirsToCreate+=("$p")
        else
            filesToCreate+=("$p")
        fi
    done

    # Create all the necessary paths.
    # This is done with only a fixed number of processes,
    # in order to not be too slow
    # Though this does mean we're a bit limited with how many files can be created
    if (( ${#dirsToCreate[@]} != 0 )); then
        mkdir -p "${dirsToCreate[@]}"
    fi
    if (( ${#filesToCreate[@]} != 0 )); then
        readarray -d '' -t parentsToCreate < <(dirname -z "${filesToCreate[@]}")
        mkdir -p "${parentsToCreate[@]}"
        touch "${filesToCreate[@]}"
    fi
}

# Check whether a file set includes/excludes declared paths as expected, usage:
#
# tree=(
#   [a/b] =1  # Declare that file       a/b should exist and expect it to be included in the store path
#   [c/a] =   # Declare that file       c/a should exist and expect it to be excluded in the store path
#   [c/d/]=   # Declare that directory c/d/ should exist and expect it to be excluded in the store path
# )
# checkFileset './a' # Pass the fileset as the argument
checkFileset() {
    local fileset=$1

    # Create the tree
    createTree

    # Process the tree into separate arrays for included paths, excluded paths and excluded files.
    local -a included=()
    local -a includedFiles=()
    local -a excluded=()
    local -a excludedFiles=()
    for p in "${!tree[@]}"; do
        case "${tree[$p]}" in
            1)
                included+=("$p")
                # If keys end with a `/` we treat them as directories, otherwise files
                if [[ ! "$p" =~ /$ ]]; then
                    includedFiles+=("$p")
                fi
                ;;
            0)
                excluded+=("$p")
                if [[ ! "$p" =~ /$ ]]; then
                    excludedFiles+=("$p")
                fi
                ;;
            *)
                die "Unsupported tree value: ${tree[$p]}"
        esac
    done

    # Test that lib.fileset.toList contains exactly the included files.
    # The /#/./ part prefixes each element with `./`
    expectEqual "toList ($fileset)" "sort lessThan [ ${includedFiles[*]/#/./} ]"

    expression="toSource { root = ./.; fileset = $fileset; }"

    # We don't have lambda's in bash unfortunately,
    # so we just define a function instead and then pass its name
    # shellcheck disable=SC2317
    run() {
        # Call toSource with the fileset, triggering open events for all files that are added to the store
        expectStorePath "$expression"
        if (( ${#excludedFiles[@]} != 0 )); then
            rm "${excludedFiles[@]}"
        fi
    }

    # Runs the function while checking that the given excluded files aren't read
    storePath=$(withFileMonitor run "${excludedFiles[@]}")

    # For each path that should be included, make sure it does occur in the resulting store path
    for p in "${included[@]}"; do
        if [[ ! -e "$storePath/$p" ]]; then
            die "$expression doesn't include path $p when it should have"
        fi
    done

    # For each path that should be excluded, make sure it doesn't occur in the resulting store path
    for p in "${excluded[@]}"; do
        if [[ -e "$storePath/$p" ]]; then
            die "$expression included path $p when it shouldn't have"
        fi
    done

    rm -rf -- *
}


#### Error messages #####

# We're using [[:blank:]] here instead of \s, because only the former is POSIX
# (see https://pubs.opengroup.org/onlinepubs/007908799/xbd/re.html#tag_007_003_005).
# And indeed, Darwin's bash only supports the former

# Absolute paths in strings cannot be passed as `root`
expectFailure 'toSource { root = "/nix/store/foobar"; fileset = ./.; }' 'lib.fileset.toSource: `root` \(/nix/store/foobar\) is a string-like value, but it should be a path instead.
[[:blank:]]*Paths in strings are not supported by `lib.fileset`, use `lib.sources` or derivations instead.'

expectFailure 'toSource { root = cleanSourceWith { src = ./.; }; fileset = ./.; }' 'lib.fileset.toSource: `root` is a `lib.sources`-based value, but it should be a path instead.
[[:blank:]]*To use a `lib.sources`-based value, convert it to a file set using `lib.fileset.fromSource` and pass it as `fileset`.
[[:blank:]]*Note that this only works for sources created from paths.'

# Only paths are accepted as `root`
expectFailure 'toSource { root = 10; fileset = ./.; }' 'lib.fileset.toSource: `root` is of type int, but it should be a path instead.'

# Different filesystem roots in root and fileset are not supported
mkdir -p {foo,bar}/mock-root
expectFailure 'with ((import <nixpkgs/lib>).extend (import <nixpkgs/lib/fileset/mock-splitRoot.nix>)).fileset;
  toSource { root = ./foo/mock-root; fileset = ./bar/mock-root; }
' 'lib.fileset.toSource: Filesystem roots are not the same for `fileset` and `root` \('"$work"'/foo/mock-root\):
[[:blank:]]*`root`: Filesystem root is "'"$work"'/foo/mock-root"
[[:blank:]]*`fileset`: Filesystem root is "'"$work"'/bar/mock-root"
[[:blank:]]*Different filesystem roots are not supported.'
rm -rf -- *

# `root` needs to exist
expectFailure 'toSource { root = ./a; fileset = ./.; }' 'lib.fileset.toSource: `root` \('"$work"'/a\) is a path that does not exist.'

# `root` needs to be a file
touch a
expectFailure 'toSource { root = ./a; fileset = ./a; }' 'lib.fileset.toSource: `root` \('"$work"'/a\) is a file, but it should be a directory instead. Potential solutions:
[[:blank:]]*- If you want to import the file into the store _without_ a containing directory, use string interpolation or `builtins.path` instead of this function.
[[:blank:]]*- If you want to import the file into the store _with_ a containing directory, set `root` to the containing directory, such as '"$work"', and set `fileset` to the file path.'
rm -rf -- *

# The fileset argument should be evaluated, even if the directory is empty
expectFailure 'toSource { root = ./.; fileset = abort "This should be evaluated"; }' 'evaluation aborted with the following error message: '\''This should be evaluated'\'

# Only paths under `root` should be able to influence the result
mkdir a
expectFailure 'toSource { root = ./a; fileset = ./.; }' 'lib.fileset.toSource: `fileset` could contain files in '"$work"', which is not under the `root` \('"$work"'/a\). Potential solutions:
[[:blank:]]*- Set `root` to '"$work"' or any directory higher up. This changes the layout of the resulting store path.
[[:blank:]]*- Set `fileset` to a file set that cannot contain files outside the `root` \('"$work"'/a\). This could change the files included in the result.'
rm -rf -- *

# non-regular and non-symlink files cannot be added to the Nix store
mkfifo a
expectFailure 'toSource { root = ./.; fileset = ./a; }' 'lib.fileset.toSource: `fileset` contains a file that cannot be added to the store: '"$work"'/a
[[:blank:]]*This file is neither a regular file nor a symlink, the only file types supported by the Nix store.
[[:blank:]]*Therefore the file set cannot be added to the Nix store as is. Make sure to not include that file to avoid this error.'
rm -rf -- *

# Path coercion only works for paths
expectFailure 'toSource { root = ./.; fileset = 10; }' 'lib.fileset.toSource: `fileset` is of type int, but it should be a file set or a path instead.'
expectFailure 'toSource { root = ./.; fileset = "/some/path"; }' 'lib.fileset.toSource: `fileset` \("/some/path"\) is a string-like value, but it should be a file set or a path instead.
[[:blank:]]*Paths represented as strings are not supported by `lib.fileset`, use `lib.sources` or derivations instead.'
expectFailure 'toSource { root = ./.; fileset = cleanSourceWith { src = ./.; }; }' 'lib.fileset.toSource: `fileset` is a `lib.sources`-based value, but it should be a file set or a path instead.
[[:blank:]]*To convert a `lib.sources`-based value to a file set you can use `lib.fileset.fromSource`.
[[:blank:]]*Note that this only works for sources created from paths.'

# Path coercion errors for non-existent paths
expectFailure 'toSource { root = ./.; fileset = ./a; }' 'lib.fileset.toSource: `fileset` \('"$work"'/a\) is a path that does not exist.
[[:blank:]]*To create a file set from a path that may not exist, use `lib.fileset.maybeMissing`.'

# File sets cannot be evaluated directly
expectFailure 'union ./. ./.' 'lib.fileset: Directly evaluating a file set is not supported.
[[:blank:]]*To turn it into a usable source, use `lib.fileset.toSource`.
[[:blank:]]*To pretty-print the contents, use `lib.fileset.trace` or `lib.fileset.traceVal`.'
expectFailure '_emptyWithoutBase' 'lib.fileset: Directly evaluating a file set is not supported.
[[:blank:]]*To turn it into a usable source, use `lib.fileset.toSource`.
[[:blank:]]*To pretty-print the contents, use `lib.fileset.trace` or `lib.fileset.traceVal`.'

# Past versions of the internal representation are supported
expectEqual '_coerce "<tests>: value" { _type = "fileset"; _internalVersion = 0; _internalBase = ./.; }' \
    '{ _internalBase = ./.; _internalBaseComponents = path.subpath.components (path.splitRoot ./.).subpath; _internalBaseRoot = /.; _internalIsEmptyWithoutBase = false; _internalVersion = 3; _type = "fileset"; }'
expectEqual '_coerce "<tests>: value" { _type = "fileset"; _internalVersion = 1; }' \
    '{ _type = "fileset"; _internalIsEmptyWithoutBase = false; _internalVersion = 3; }'
expectEqual '_coerce "<tests>: value" { _type = "fileset"; _internalVersion = 2; }' \
    '{ _type = "fileset"; _internalIsEmptyWithoutBase = false; _internalVersion = 3; }'

# Future versions of the internal representation are unsupported
expectFailure '_coerce "<tests>: value" { _type = "fileset"; _internalVersion = 4; }' '<tests>: value is a file set created from a future version of the file set library with a different internal representation:
[[:blank:]]*- Internal version of the file set: 4
[[:blank:]]*- Internal version of the library: 3
[[:blank:]]*Make sure to update your Nixpkgs to have a newer version of `lib.fileset`.'

# _create followed by _coerce should give the inputs back without any validation
expectEqual '{
  inherit (_coerce "<test>" (_create ./. "directory"))
    _internalVersion _internalBase _internalTree;
}' '{ _internalBase = ./.; _internalTree = "directory"; _internalVersion = 3; }'

#### Resulting store path ####

# The store path name should be "source"
expectEqual 'toSource { root = ./.; fileset = ./.; }' 'sources.cleanSourceWith { name = "source"; src = ./.; }'

# We should be able to import an empty directory and end up with an empty result
tree=(
)
checkFileset './.'

# The empty value without a base should also result in an empty result
tree=(
    [a]=0
)
checkFileset '_emptyWithoutBase'

# Directories recursively containing no files are not included
tree=(
    [e/]=0
    [d/e/]=0
    [d/d/e/]=0
    [d/d/f]=1
    [d/f]=1
    [f]=1
)
checkFileset './.'

# Check trees that could cause a naïve string prefix checking implementation to fail
tree=(
    [a]=0
    [ab/x]=0
    [ab/xy]=1
    [ab/xyz]=0
    [abc]=0
)
checkFileset './ab/xy'

# Check path coercion examples in ../../doc/functions/fileset.section.md
tree=(
    [a/x]=1
    [a/b/y]=1
    [c/]=0
    [c/d/]=0
)
checkFileset './.'

tree=(
    [a/x]=1
    [a/b/y]=1
    [c/]=0
    [c/d/]=0
)
checkFileset './a'

tree=(
    [a/x]=1
    [a/b/y]=0
    [c/]=0
    [c/d/]=0
)
checkFileset './a/x'

tree=(
    [a/x]=0
    [a/b/y]=1
    [c/]=0
    [c/d/]=0
)
checkFileset './a/b'

tree=(
    [a/x]=0
    [a/b/y]=0
    [c/]=0
    [c/d/]=0
)
checkFileset './c'

# Test the source filter for the somewhat special case of files in the filesystem root
# We can't easily test this with the above functions because we can't write to the filesystem root and we don't want to make any assumptions which files are there in the sandbox
expectEqual '_toSourceFilter (_create /. null) "/foo" ""' 'false'
expectEqual '_toSourceFilter (_create /. { foo = "regular"; }) "/foo" ""' 'true'
expectEqual '_toSourceFilter (_create /. { foo = null; }) "/foo" ""' 'false'


## lib.fileset.toList
# This function is mainly tested in checkFileset

# The error context for an invalid argument must be correct
expectFailure 'toList null' 'lib.fileset.toList: Argument is of type null, but it should be a file set or a path instead.'

# Works for the empty fileset
expectEqual 'toList _emptyWithoutBase' '[ ]'

# Works on empty paths
expectEqual 'toList ./.' '[ ]'


## lib.fileset.union, lib.fileset.unions


# Different filesystem roots in root and fileset are not supported
mkdir -p {foo,bar}/mock-root
expectFailure 'with ((import <nixpkgs/lib>).extend (import <nixpkgs/lib/fileset/mock-splitRoot.nix>)).fileset;
  toSource { root = ./.; fileset = union ./foo/mock-root ./bar/mock-root; }
' 'lib.fileset.union: Filesystem roots are not the same:
[[:blank:]]*First argument: Filesystem root is "'"$work"'/foo/mock-root"
[[:blank:]]*Second argument: Filesystem root is "'"$work"'/bar/mock-root"
[[:blank:]]*Different filesystem roots are not supported.'

expectFailure 'with ((import <nixpkgs/lib>).extend (import <nixpkgs/lib/fileset/mock-splitRoot.nix>)).fileset;
  toSource { root = ./.; fileset = unions [ ./foo/mock-root ./bar/mock-root ]; }
' 'lib.fileset.unions: Filesystem roots are not the same:
[[:blank:]]*Element 0: Filesystem root is "'"$work"'/foo/mock-root"
[[:blank:]]*Element 1: Filesystem root is "'"$work"'/bar/mock-root"
[[:blank:]]*Different filesystem roots are not supported.'
rm -rf -- *

# Coercion errors show the correct context
expectFailure 'toSource { root = ./.; fileset = union ./a ./.; }' 'lib.fileset.union: First argument \('"$work"'/a\) is a path that does not exist.'
expectFailure 'toSource { root = ./.; fileset = union ./. ./b; }' 'lib.fileset.union: Second argument \('"$work"'/b\) is a path that does not exist.'
expectFailure 'toSource { root = ./.; fileset = unions [ ./a ./. ]; }' 'lib.fileset.unions: Element 0 \('"$work"'/a\) is a path that does not exist.'
expectFailure 'toSource { root = ./.; fileset = unions [ ./. ./b ]; }' 'lib.fileset.unions: Element 1 \('"$work"'/b\) is a path that does not exist.'

# unions needs a list
expectFailure 'toSource { root = ./.; fileset = unions null; }' 'lib.fileset.unions: Argument is of type null, but it should be a list instead.'

# The tree of later arguments should not be evaluated if a former argument already includes all files
tree=()
checkFileset 'union ./. (_create ./. (abort "This should not be used!"))'
checkFileset 'unions [ ./. (_create ./. (abort "This should not be used!")) ]'

# unions doesn't include any files for an empty list or only empty values without a base
tree=(
    [x]=0
    [y/z]=0
)
checkFileset 'unions [ ]'
checkFileset 'unions [ _emptyWithoutBase ]'
checkFileset 'unions [ _emptyWithoutBase _emptyWithoutBase ]'
checkFileset 'union _emptyWithoutBase _emptyWithoutBase'

# The empty value without a base is the left and right identity of union
tree=(
    [x]=1
    [y/z]=0
)
checkFileset 'union ./x _emptyWithoutBase'
checkFileset 'union _emptyWithoutBase ./x'

# union doesn't include files that weren't specified
tree=(
    [x]=1
    [y]=1
    [z]=0
)
checkFileset 'union ./x ./y'
checkFileset 'unions [ ./x ./y ]'

# Also for directories
tree=(
    [x/a]=1
    [x/b]=1
    [y/a]=1
    [y/b]=1
    [z/a]=0
    [z/b]=0
)
checkFileset 'union ./x ./y'
checkFileset 'unions [ ./x ./y ]'

# And for very specific paths
tree=(
    [x/a]=1
    [x/b]=0
    [y/a]=0
    [y/b]=1
    [z/a]=0
    [z/b]=0
)
checkFileset 'union ./x/a ./y/b'
checkFileset 'unions [ ./x/a ./y/b ]'

# unions or chained union's can include more paths
tree=(
    [x/a]=1
    [x/b]=1
    [y/a]=1
    [y/b]=0
    [z/a]=0
    [z/b]=1
)
checkFileset 'unions [ ./x/a ./x/b ./y/a ./z/b ]'
checkFileset 'union (union ./x/a ./x/b) (union ./y/a ./z/b)'
checkFileset 'union (union (union ./x/a ./x/b) ./y/a) ./z/b'

# unions should not stack overflow, even if many elements are passed
tree=()
for i in $(seq 1000); do
    tree[$i/a]=1
    tree[$i/b]=0
done
# This is actually really hard to test:
# A lot of files would be needed to cause a stack overflow.
# And while we could limit the maximum stack size using `ulimit -s`,
# that turns out to not be very deterministic: https://github.com/NixOS/nixpkgs/pull/256417#discussion_r1339396686.
# Meanwhile, the test infra here is not the fastest, creating 10000 would be too slow.
# So, just using 1000 files for now.
checkFileset 'unions (mapAttrsToList (name: _: ./. + "/${name}/a") (builtins.readDir ./.))'


## lib.fileset.intersection


# Different filesystem roots in root and fileset are not supported
mkdir -p {foo,bar}/mock-root
expectFailure 'with ((import <nixpkgs/lib>).extend (import <nixpkgs/lib/fileset/mock-splitRoot.nix>)).fileset;
  toSource { root = ./.; fileset = intersection ./foo/mock-root ./bar/mock-root; }
' 'lib.fileset.intersection: Filesystem roots are not the same:
[[:blank:]]*First argument: Filesystem root is "'"$work"'/foo/mock-root"
[[:blank:]]*Second argument: Filesystem root is "'"$work"'/bar/mock-root"
[[:blank:]]*Different filesystem roots are not supported.'
rm -rf -- *

# Coercion errors show the correct context
expectFailure 'toSource { root = ./.; fileset = intersection ./a ./.; }' 'lib.fileset.intersection: First argument \('"$work"'/a\) is a path that does not exist.'
expectFailure 'toSource { root = ./.; fileset = intersection ./. ./b; }' 'lib.fileset.intersection: Second argument \('"$work"'/b\) is a path that does not exist.'

# The tree of later arguments should not be evaluated if a former argument already excludes all files
tree=(
    [a]=0
)
checkFileset 'intersection _emptyWithoutBase (_create ./. (abort "This should not be used!"))'
# We don't have any combinators that can explicitly remove files yet, so we need to rely on internal functions to test this for now
checkFileset 'intersection (_create ./. { a = null; }) (_create ./. { a = abort "This should not be used!"; })'

# If either side is empty, the result is empty
tree=(
    [a]=0
)
checkFileset 'intersection _emptyWithoutBase _emptyWithoutBase'
checkFileset 'intersection _emptyWithoutBase (_create ./. null)'
checkFileset 'intersection (_create ./. null) _emptyWithoutBase'
checkFileset 'intersection (_create ./. null) (_create ./. null)'

# If the intersection base paths are not overlapping, the result is empty and has no base path
mkdir a b c
touch {a,b,c}/x
expectEqual 'toSource { root = ./c; fileset = intersection ./a ./b; }' 'toSource { root = ./c; fileset = _emptyWithoutBase; }'
rm -rf -- *

# If the intersection exists, the resulting base path is the longest of them
mkdir a
touch x a/b
expectEqual 'toSource { root = ./a; fileset = intersection ./a ./.; }' 'toSource { root = ./a; fileset = ./a; }'
expectEqual 'toSource { root = ./a; fileset = intersection ./. ./a; }' 'toSource { root = ./a; fileset = ./a; }'
rm -rf -- *

# Also finds the intersection with null'd filesetTree's
tree=(
    [a]=0
    [b]=1
    [c]=0
)
checkFileset 'intersection (_create ./. { a = "regular"; b = "regular"; c = null; }) (_create ./. { a = null; b = "regular"; c = "regular"; })'

# Actually computes the intersection between files
tree=(
    [a]=0
    [b]=0
    [c]=1
    [d]=1
    [e]=0
    [f]=0
)
checkFileset 'intersection (unions [ ./a ./b ./c ./d ]) (unions [ ./c ./d ./e ./f ])'

tree=(
    [a/x]=0
    [a/y]=0
    [b/x]=1
    [b/y]=1
    [c/x]=0
    [c/y]=0
)
checkFileset 'intersection ./b ./.'
checkFileset 'intersection ./b (unions [ ./a/x ./a/y ./b/x ./b/y ./c/x ./c/y ])'

# Complicated case
tree=(
    [a/x]=0
    [a/b/i]=1
    [c/d/x]=0
    [c/d/f]=1
    [c/x]=0
    [c/e/i]=1
    [c/e/j]=1
)
checkFileset 'intersection (unions [ ./a/b ./c/d ./c/e ]) (unions [ ./a ./c/d/f ./c/e ])'

## Difference

# Subtracting something from itself results in nothing
tree=(
    [a]=0
)
checkFileset 'difference ./. ./.'

# The tree of the second argument should not be evaluated if not needed
checkFileset 'difference _emptyWithoutBase (_create ./. (abort "This should not be used!"))'
checkFileset 'difference (_create ./. null) (_create ./. (abort "This should not be used!"))'

# Subtracting nothing gives the same thing back
tree=(
    [a]=1
)
checkFileset 'difference ./. _emptyWithoutBase'
checkFileset 'difference ./. (_create ./. null)'

# Subtracting doesn't influence the base path
mkdir a b
touch {a,b}/x
expectEqual 'toSource { root = ./a; fileset = difference ./a ./b; }' 'toSource { root = ./a; fileset = ./a; }'
rm -rf -- *

# Also not the other way around
mkdir a
expectFailure 'toSource { root = ./a; fileset = difference ./. ./a; }' 'lib.fileset.toSource: `fileset` could contain files in '"$work"', which is not under the `root` \('"$work"'/a\). Potential solutions:
[[:blank:]]*- Set `root` to '"$work"' or any directory higher up. This changes the layout of the resulting store path.
[[:blank:]]*- Set `fileset` to a file set that cannot contain files outside the `root` \('"$work"'/a\). This could change the files included in the result.'
rm -rf -- *

# Difference actually works
# We test all combinations of ./., ./a, ./a/x and ./b
tree=(
    [a/x]=0
    [a/y]=0
    [b]=0
    [c]=0
)
checkFileset 'difference ./. ./.'
checkFileset 'difference ./a ./.'
checkFileset 'difference ./a/x ./.'
checkFileset 'difference ./b ./.'
checkFileset 'difference ./a ./a'
checkFileset 'difference ./a/x ./a'
checkFileset 'difference ./a/x ./a/x'
checkFileset 'difference ./b ./b'
tree=(
    [a/x]=0
    [a/y]=0
    [b]=1
    [c]=1
)
checkFileset 'difference ./. ./a'
tree=(
    [a/x]=1
    [a/y]=1
    [b]=0
    [c]=0
)
checkFileset 'difference ./a ./b'
tree=(
    [a/x]=1
    [a/y]=0
    [b]=0
    [c]=0
)
checkFileset 'difference ./a/x ./b'
tree=(
    [a/x]=0
    [a/y]=1
    [b]=0
    [c]=0
)
checkFileset 'difference ./a ./a/x'
tree=(
    [a/x]=0
    [a/y]=0
    [b]=1
    [c]=0
)
checkFileset 'difference ./b ./a'
checkFileset 'difference ./b ./a/x'
tree=(
    [a/x]=0
    [a/y]=1
    [b]=1
    [c]=1
)
checkFileset 'difference ./. ./a/x'
tree=(
    [a/x]=1
    [a/y]=1
    [b]=0
    [c]=1
)
checkFileset 'difference ./. ./b'

## File filter

# The first argument needs to be a function
expectFailure 'fileFilter null (abort "this is not needed")' 'lib.fileset.fileFilter: First argument is of type null, but it should be a function instead.'

# The second argument needs to be an existing path
expectFailure 'fileFilter (file: abort "this is not needed") _emptyWithoutBase' 'lib.fileset.fileFilter: Second argument is a file set, but it should be a path instead.
[[:blank:]]*If you need to filter files in a file set, use `intersection fileset \(fileFilter pred \./\.\)` instead.'
expectFailure 'fileFilter (file: abort "this is not needed") null' 'lib.fileset.fileFilter: Second argument is of type null, but it should be a path instead.'
expectFailure 'fileFilter (file: abort "this is not needed") ./a' 'lib.fileset.fileFilter: Second argument \('"$work"'/a\) is a path that does not exist.'

# The predicate is not called when there's no files
tree=()
checkFileset 'fileFilter (file: abort "this is not needed") ./.'

# The predicate must be able to handle extra attributes
touch a
expectFailure 'toSource { root = ./.; fileset = fileFilter ({ name, type, hasExt }: true) ./.; }' 'called with unexpected argument '\''"lib.fileset.fileFilter: The predicate function passed as the first argument must be able to handle extra attributes for future compatibility. If you'\''re using `\{ name, file, hasExt \}:`, use `\{ name, file, hasExt, ... \}:` instead."'\'
rm -rf -- *

# .name is the name, and it works correctly, even recursively
tree=(
    [a]=1
    [b]=0
    [c/a]=1
    [c/b]=0
    [d/c/a]=1
    [d/c/b]=0
)
checkFileset 'fileFilter (file: file.name == "a") ./.'
tree=(
    [a]=0
    [b]=1
    [c/a]=0
    [c/b]=1
    [d/c/a]=0
    [d/c/b]=1
)
checkFileset 'fileFilter (file: file.name != "a") ./.'

# `.type` is the file type
mkdir d
touch d/a
ln -s d/b d/b
mkfifo d/c
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type == "regular") ./.; }' \
    'toSource { root = ./.; fileset = ./d/a; }'
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type == "symlink") ./.; }' \
    'toSource { root = ./.; fileset = ./d/b; }'
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type == "unknown") ./.; }' \
    'toSource { root = ./.; fileset = ./d/c; }'
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type != "regular") ./.; }' \
    'toSource { root = ./.; fileset = union ./d/b ./d/c; }'
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type != "symlink") ./.; }' \
    'toSource { root = ./.; fileset = union ./d/a ./d/c; }'
expectEqual \
    'toSource { root = ./.; fileset = fileFilter (file: file.type != "unknown") ./.; }' \
    'toSource { root = ./.; fileset = union ./d/a ./d/b; }'
rm -rf -- *

# Check that .hasExt checks for the file extension
# The empty extension is the same as a file ending with a .
tree=(
    [a]=0
    [a.]=1
    [a.b]=0
    [a.b.]=1
    [a.b.c]=0
)
checkFileset 'fileFilter (file: file.hasExt "") ./.'

# It can check for the last extension
tree=(
    [a]=0
    [.a]=1
    [.a.]=0
    [.b.a]=1
    [.b.a.]=0
)
checkFileset 'fileFilter (file: file.hasExt "a") ./.'

# It can check for any extension
tree=(
    [a.b.c.d]=1
)
checkFileset 'fileFilter (file:
  all file.hasExt [
    "b.c.d"
    "c.d"
    "d"
  ]
) ./.'

# It's lazy
tree=(
    [b]=1
    [c/a]=1
)
# Note that union evaluates the first argument first if necessary, that's why we can use ./c/a here
checkFileset 'union ./c/a (fileFilter (file: assert file.name != "a"; true) ./.)'
# but here we need to use ./c
checkFileset 'union (fileFilter (file: assert file.name != "a"; true) ./.) ./c'

# Make sure single files are filtered correctly
tree=(
    [a]=1
    [b]=0
)
checkFileset 'fileFilter (file: assert file.name == "a"; true) ./a'
tree=(
    [a]=0
    [b]=0
)
checkFileset 'fileFilter (file: assert file.name == "a"; false) ./a'

## Tracing

# The second trace argument is returned
expectEqual 'trace ./. "some value"' 'builtins.trace "(empty)" "some value"'

# The fileset traceVal argument is returned
expectEqual 'traceVal ./.' 'builtins.trace "(empty)" (_create ./. "directory")'

# The tracing happens before the final argument is needed
expectEqual 'trace ./.' 'builtins.trace "(empty)" (x: x)'

# Tracing an empty directory shows it as such
expectTrace './.' '(empty)'

# This also works if there are directories, but all recursively without files
mkdir -p a/b/c
expectTrace './.' '(empty)'
rm -rf -- *

# The empty file set without a base also prints as empty
expectTrace '_emptyWithoutBase' '(empty)'
expectTrace 'unions [ ]' '(empty)'
mkdir foo bar
touch {foo,bar}/x
expectTrace 'intersection ./foo ./bar' '(empty)'
rm -rf -- *

# If a directory is fully included, print it as such
touch a
expectTrace './.' "$work"' (all files in directory)'
rm -rf -- *

# If a directory is not fully included, recurse
mkdir a b
touch a/{x,y} b/{x,y}
expectTrace 'union ./a/x ./b' "$work"'
- a
  - x (regular)
- b (all files in directory)'
rm -rf -- *

# If an included path is a file, print its type
touch a x
ln -s a b
mkfifo c
expectTrace 'unions [ ./a ./b ./c ]' "$work"'
- a (regular)
- b (symlink)
- c (unknown)'
rm -rf -- *

# Do not print directories without any files recursively
mkdir -p a/b/c
touch b x
expectTrace 'unions [ ./a ./b ]' "$work"'
- b (regular)'
rm -rf -- *

# If all children are either fully included or empty directories,
# the parent should be printed as fully included
touch a
mkdir b
expectTrace 'union ./a ./b' "$work"' (all files in directory)'
rm -rf -- *

mkdir -p x/b x/c
touch x/a
touch a
# If all children are either fully excluded or empty directories,
# the parent should be shown (or rather not shown) as fully excluded
expectTrace 'unions [ ./a ./x/b ./x/c ]' "$work"'
- a (regular)'
rm -rf -- *

# Completely filtered out directories also print as empty
touch a
expectTrace '_create ./. {}' '(empty)'
rm -rf -- *

# A general test to make sure the resulting format makes sense
# Such as indentation and ordering
mkdir -p bar/{qux,someDir}
touch bar/{baz,qux,someDir/a} foo
touch bar/qux/x
ln -s x bar/qux/a
mkfifo bar/qux/b
expectTrace 'unions [
  ./bar/baz
  ./bar/qux/a
  ./bar/qux/b
  ./bar/someDir/a
  ./foo
]' "$work"'
- bar
  - baz (regular)
  - qux
    - a (symlink)
    - b (unknown)
  - someDir (all files in directory)
- foo (regular)'
rm -rf -- *

# For recursively included directories,
# `(all files in directory)` should only be used if there's at least one file (otherwise it would be `(empty)`)
# and this should be determined without doing a full search
#
# a is intentionally ordered first here in order to allow triggering the short-circuit behavior
# We then check that b is not read
# In a more realistic scenario, some directories might need to be recursed into,
# but a file would be quickly found to trigger the short-circuit.
touch a
mkdir b
# We don't have lambda's in bash unfortunately,
# so we just define a function instead and then pass its name
# shellcheck disable=SC2317
run() {
    # This shouldn't read b/
    expectTrace './.' "$work"' (all files in directory)'
    # Remove all files immediately after, triggering delete_self events for all of them
    rmdir b
}
# Runs the function while checking that b isn't read
withFileMonitor run b
rm -rf -- *

# Partially included directories trace entries as they are evaluated
touch a b c
expectTrace '_create ./. { a = null; b = "regular"; c = throw "b"; }' "$work"'
- b (regular)'

# Except entries that need to be evaluated to even figure out if it's only partially included:
# Here the directory could be fully excluded or included just from seeing a and b,
# so c needs to be evaluated before anything can be traced
expectTrace '_create ./. { a = null; b = null; c = throw "c"; }' ''
expectTrace '_create ./. { a = "regular"; b = "regular"; c = throw "c"; }' ''
rm -rf -- *

# We can trace large directories (10000 here) without any problems
filesToCreate=({0..9}{0..9}{0..9}{0..9})
expectedTrace=$work$'\n'$(printf -- '- %s (regular)\n' "${filesToCreate[@]}")
# We need an excluded file so it doesn't print as `(all files in directory)`
touch 0 "${filesToCreate[@]}"
expectTrace 'unions (mapAttrsToList (n: _: ./. + "/${n}") (removeAttrs (builtins.readDir ./.) [ "0" ]))' "$expectedTrace"
rm -rf -- *

## lib.fileset.fromSource

# Check error messages

# String-like values are not supported
expectFailure 'fromSource (lib.cleanSource "")' 'lib.fileset.fromSource: The source origin of the argument is a string-like value \(""\), but it should be a path instead.
[[:blank:]]*Sources created from paths in strings cannot be turned into file sets, use `lib.sources` or derivations instead.'

# Wrong type
expectFailure 'fromSource null' 'lib.fileset.fromSource: The source origin of the argument is of type null, but it should be a path instead.'
expectFailure 'fromSource (lib.cleanSource null)' 'lib.fileset.fromSource: The source origin of the argument is of type null, but it should be a path instead.'

# fromSource on non-existent paths gives an error
expectFailure 'fromSource ./a' 'lib.fileset.fromSource: The source origin \('"$work"'/a\) of the argument is a path that does not exist.'

# fromSource on a path works and is the same as coercing that path
mkdir a
touch a/b c
expectEqual 'trace (fromSource ./.) null' 'trace ./. null'
rm -rf -- *

# Check that converting to a file set doesn't read the included files
mkdir a
touch a/b
run() {
    expectEqual "trace (fromSource (lib.cleanSourceWith { src = ./a; })) null" "builtins.trace \"$work/a (all files in directory)\" null"
    rm a/b
}
withFileMonitor run a/b
rm -rf -- *

# Check that converting to a file set doesn't read entries for directories that are filtered out
mkdir -p a/b
touch a/b/c
run() {
    expectEqual "trace (fromSource (lib.cleanSourceWith {
      src = ./a;
      filter = pathString: type: false;
    })) null" "builtins.trace \"(empty)\" null"
    rm a/b/c
    rmdir a/b
}
withFileMonitor run a/b
rm -rf -- *

# The filter is not needed on empty directories
expectEqual 'trace (fromSource (lib.cleanSourceWith {
  src = ./.;
  filter = abort "filter should not be needed";
})) null' 'trace _emptyWithoutBase null'

# Single files also work
touch a b
expectEqual 'trace (fromSource (cleanSourceWith { src = ./a; })) null' 'trace ./a null'
rm -rf -- *

# For a tree assigning each subpath true/false,
# check whether a source filter with those results includes the same files
# as a file set created using fromSource. Usage:
#
# tree=(
#   [a]=1  # ./a is a file and the filter should return true for it
#   [b/]=0 # ./b is a directory and the filter should return false for it
# )
# checkSource
checkSource() {
    createTree

    # Serialise the tree as JSON (there's only minimal savings with jq,
    # and we don't need to handle escapes)
    {
        echo "{"
        first=1
        for p in "${!tree[@]}"; do
            if [[ -z "$first" ]]; then
                echo ","
            else
                first=
            fi
            echo "\"$p\":"
            case "${tree[$p]}" in
                1)
                    echo "true"
                    ;;
                0)
                    echo "false"
                    ;;
                *)
                    die "Unsupported tree value: ${tree[$p]}"
            esac
        done
        echo "}"
    } > "$tmp/tree.json"

    # An expression to create a source value with a filter matching the tree
    sourceExpr='
      let
        tree = importJSON '"$tmp"'/tree.json;
      in
      cleanSourceWith {
        src = ./.;
        filter =
          pathString: type:
          let
            stripped = removePrefix (toString ./. + "/") pathString;
            key = stripped + optionalString (type == "directory") "/";
          in
          tree.${key} or
            (throw "tree key ${key} missing");
      }
    '

    filesetExpr='
      toSource {
        root = ./.;
        fileset = fromSource ('"$sourceExpr"');
      }
    '

    # Turn both into store paths
    sourceStorePath=$(expectStorePath "$sourceExpr")
    filesetStorePath=$(expectStorePath "$filesetExpr")

    # Loop through each path in the tree
    while IFS= read -r -d $'\0' subpath; do
        if [[ ! -e "$sourceStorePath"/"$subpath" ]]; then
            # If it's not in the source store path, it's also not in the file set store path
            if [[ -e "$filesetStorePath"/"$subpath" ]]; then
                die "The store path $sourceStorePath created by $expr doesn't contain $subpath, but the corresponding store path $filesetStorePath created via fromSource does contain $subpath"
            fi
        elif [[ -z "$(find "$sourceStorePath"/"$subpath" -type f)" ]]; then
            # If it's an empty directory in the source store path, it shouldn't be in the file set store path
            if [[ -e "$filesetStorePath"/"$subpath" ]]; then
                die "The store path $sourceStorePath created by $expr contains the path $subpath without any files, but the corresponding store path $filesetStorePath created via fromSource didn't omit it"
            fi
        else
            # If it's non-empty directory or a file, it should be in the file set store path
            if [[ ! -e "$filesetStorePath"/"$subpath" ]]; then
                die "The store path $sourceStorePath created by $expr contains the non-empty path $subpath, but the corresponding store path $filesetStorePath created via fromSource doesn't include it"
            fi
        fi
    done < <(find . -mindepth 1 -print0)

    rm -rf -- *
}

# Check whether the filter is evaluated correctly
tree=(
    [a]=
    [b/]=
    [b/c]=
    [b/d]=
    [e/]=
    [e/e/]=
)
# We fill out the above tree values with all possible combinations of 0 and 1
# Then check whether a filter based on those return values gets turned into the corresponding file set
for i in $(seq 0 $((2 ** ${#tree[@]} - 1 ))); do
    for p in "${!tree[@]}"; do
        tree[$p]=$(( i % 2 ))
        (( i /= 2 )) || true
    done
    checkSource
done

# The filter is called with the same arguments in the same order
mkdir a e
touch a/b a/c d e
expectEqual '
  trace (fromSource (cleanSourceWith {
    src = ./.;
    filter = pathString: type: builtins.trace "${pathString} ${toString type}" true;
  })) null
' '
  builtins.seq (cleanSourceWith {
    src = ./.;
    filter = pathString: type: builtins.trace "${pathString} ${toString type}" true;
  }).outPath
  builtins.trace "'"$work"' (all files in directory)"
  null
'
rm -rf -- *

# Test that if a directory is not included, the filter isn't called on its contents
mkdir a b
touch a/c b/d
expectEqual 'trace (fromSource (cleanSourceWith {
  src = ./.;
  filter = pathString: type:
    if pathString == toString ./a then
      false
    else if pathString == toString ./b then
      true
    else if pathString == toString ./b/d then
      true
    else
      abort "This filter should not be called with path ${pathString}";
})) null' 'trace (_create ./. { b = "directory"; }) null'
rm -rf -- *

# The filter is called lazily:
# If a later say intersection removes a part of the tree, the filter won't run on it
mkdir a d
touch a/{b,c} d/e
expectEqual 'trace (intersection ./a (fromSource (lib.cleanSourceWith {
  src = ./.;
  filter = pathString: type:
    if pathString == toString ./a || pathString == toString ./a/b then
      true
    else if pathString == toString ./a/c then
      false
    else
      abort "filter should not be called on ${pathString}";
}))) null' 'trace ./a/b null'
rm -rf -- *

## lib.fileset.gitTracked/gitTrackedWith

# The first/second argument has to be a path
expectFailure 'gitTracked null' 'lib.fileset.gitTracked: Expected the argument to be a path, but it'\''s a null instead.'
expectFailure 'gitTrackedWith {} null' 'lib.fileset.gitTrackedWith: Expected the second argument to be a path, but it'\''s a null instead.'

# The path must be a directory
touch a
expectFailure 'gitTracked ./a' 'lib.fileset.gitTracked: Expected the argument \('"$work"'/a\) to be a directory, but it'\''s a file instead'
expectFailure 'gitTrackedWith {} ./a' 'lib.fileset.gitTrackedWith: Expected the second argument \('"$work"'/a\) to be a directory, but it'\''s a file instead'
rm -rf -- *

# The path has to contain a .git directory
expectFailure 'gitTracked ./.' 'lib.fileset.gitTracked: Expected the argument \('"$work"'\) to point to a local working tree of a Git repository, but it'\''s not.'
expectFailure 'gitTrackedWith {} ./.' 'lib.fileset.gitTrackedWith: Expected the second argument \('"$work"'\) to point to a local working tree of a Git repository, but it'\''s not.'

# recurseSubmodules has to be a boolean
expectFailure 'gitTrackedWith { recurseSubmodules = null; } ./.' 'lib.fileset.gitTrackedWith: Expected the attribute `recurseSubmodules` of the first argument to be a boolean, but it'\''s a null instead.'

# recurseSubmodules = true is not supported on all Nix versions
if [[ "$(nix-instantiate --eval --expr "$prefixExpression (versionAtLeast builtins.nixVersion _fetchGitSubmodulesMinver)")" == true ]]; then
    fetchGitSupportsSubmodules=1
else
    fetchGitSupportsSubmodules=
    expectFailure 'gitTrackedWith { recurseSubmodules = true; } ./.' 'lib.fileset.gitTrackedWith: Setting the attribute `recurseSubmodules` to `true` is only supported for Nix version 2.4 and after, but Nix version [0-9.]+ is used.'
fi

# Checks that `gitTrackedWith` contains the same files as `git ls-files`
# for the current working directory.
# If --recurse-submodules is passed, the flag is passed through to `git ls-files`
# and as `recurseSubmodules` to `gitTrackedWith`
checkGitTrackedWith() {
    if [[ "${1:-}" == "--recurse-submodules" ]]; then
        gitLsFlags="--recurse-submodules"
        gitTrackedArg="{ recurseSubmodules = true; }"
    else
        gitLsFlags=""
        gitTrackedArg="{ }"
    fi

    # All files listed by `git ls-files`
    expectedFiles=()
    while IFS= read -r -d $'\0' file; do
        # If there are submodules but --recurse-submodules isn't passed,
        # `git ls-files` lists them as empty directories,
        # we need to filter that out since we only want to check/count files
        if [[ -f "$file" ]]; then
            expectedFiles+=("$file")
        fi
    done < <(git ls-files -z $gitLsFlags)

    storePath=$(expectStorePath 'toSource { root = ./.; fileset = gitTrackedWith '"$gitTrackedArg"' ./.; }')

    # Check that each expected file is also in the store path with the same content
    for expectedFile in "${expectedFiles[@]}"; do
        if [[ ! -e "$storePath"/"$expectedFile" ]]; then
            die "Expected file $expectedFile to exist in $storePath, but it doesn't.\nGit status:\n$(git status)\nStore path contents:\n$(find "$storePath")"
        fi
        if ! diff "$expectedFile" "$storePath"/"$expectedFile"; then
            die "Expected file $expectedFile to have the same contents as in $storePath, but it doesn't.\nGit status:\n$(git status)\nStore path contents:\n$(find "$storePath")"
        fi
    done

    # This is a cheap way to verify the inverse: That all files in the store path are also expected
    # We just count the number of files in both and verify they're the same
    actualFileCount=$(find "$storePath" -type f -printf . | wc -c)
    if [[ "${#expectedFiles[@]}" != "$actualFileCount" ]]; then
        die "Expected ${#expectedFiles[@]} files in $storePath, but got $actualFileCount.\nGit status:\n$(git status)\nStore path contents:\n$(find "$storePath")"
    fi
}


# Runs checkGitTrackedWith with and without --recurse-submodules
# Allows testing both variants together
checkGitTracked() {
    checkGitTrackedWith
    if [[ -n "$fetchGitSupportsSubmodules" ]]; then
        checkGitTrackedWith --recurse-submodules
    fi
}

createGitRepo() {
    git init -q "$1"
    # Only repo-local config
    git -C "$1" config user.name "Nixpkgs"
    git -C "$1" config user.email "nixpkgs@nixos.org"
    # Get at least a HEAD commit, needed for older Nix versions
    git -C "$1" commit -q --allow-empty -m "Empty commit"
}

# Check that gitTracked[With] works as expected when evaluated out-of-tree

## First we create a git repositories (and a subrepository) with `default.nix` files referring to their local paths
## Simulating how it would be used in the wild
createGitRepo .
echo '{ fs }: fs.toSource { root = ./.; fileset = fs.gitTracked ./.; }' > default.nix
git add .

## We can evaluate it locally just fine, `fetchGit` is used underneath to filter git-tracked files
expectEqual '(import ./. { fs = lib.fileset; }).outPath' '(builtins.fetchGit ./.).outPath'

## We can also evaluate when importing from fetched store paths
storePath=$(expectStorePath 'builtins.fetchGit ./.')
expectEqual '(import '"$storePath"' { fs = lib.fileset; }).outPath' \""$storePath"\"

## But it fails if the path is imported with a fetcher that doesn't remove .git (like just using "${./.}")
expectFailure 'import "${./.}" { fs = lib.fileset; }' 'lib.fileset.gitTracked: The argument \(.*\) is a store path within a working tree of a Git repository.
[[:blank:]]*This indicates that a source directory was imported into the store using a method such as `import "\$\{./.\}"` or `path:.`.
[[:blank:]]*This function currently does not support such a use case, since it currently relies on `builtins.fetchGit`.
[[:blank:]]*You could make this work by using a fetcher such as `fetchGit` instead of copying the whole repository.
[[:blank:]]*If you can'\''t avoid copying the repo to the store, see https://github.com/NixOS/nix/issues/9292.'

## Even with submodules
if [[ -n "$fetchGitSupportsSubmodules" ]]; then
    ## Both the main repo with the submodule
    echo '{ fs }: fs.toSource { root = ./.; fileset = fs.gitTrackedWith { recurseSubmodules = true; } ./.; }' > default.nix
    createGitRepo sub
    git submodule add ./sub sub >/dev/null
    ## But also the submodule itself
    echo '{ fs }: fs.toSource { root = ./.; fileset = fs.gitTracked ./.; }' > sub/default.nix
    git -C sub add .

    ## We can evaluate it locally just fine, `fetchGit` is used underneath to filter git-tracked files
    expectEqual '(import ./. { fs = lib.fileset; }).outPath' '(builtins.fetchGit { url = ./.; submodules = true; }).outPath'
    expectEqual '(import ./sub { fs = lib.fileset; }).outPath' '(builtins.fetchGit ./sub).outPath'

    ## We can also evaluate when importing from fetched store paths
    storePathWithSub=$(expectStorePath 'builtins.fetchGit { url = ./.; submodules = true; }')
    expectEqual '(import '"$storePathWithSub"' { fs = lib.fileset; }).outPath' \""$storePathWithSub"\"
    storePathSub=$(expectStorePath 'builtins.fetchGit ./sub')
    expectEqual '(import '"$storePathSub"' { fs = lib.fileset; }).outPath' \""$storePathSub"\"

    ## But it fails if the path is imported with a fetcher that doesn't remove .git (like just using "${./.}")
    expectFailure 'import "${./.}" { fs = lib.fileset; }' 'lib.fileset.gitTrackedWith: The second argument \(.*\) is a store path within a working tree of a Git repository.
    [[:blank:]]*This indicates that a source directory was imported into the store using a method such as `import "\$\{./.\}"` or `path:.`.
    [[:blank:]]*This function currently does not support such a use case, since it currently relies on `builtins.fetchGit`.
    [[:blank:]]*You could make this work by using a fetcher such as `fetchGit` instead of copying the whole repository.
    [[:blank:]]*If you can'\''t avoid copying the repo to the store, see https://github.com/NixOS/nix/issues/9292.'
    expectFailure 'import "${./.}/sub" { fs = lib.fileset; }' 'lib.fileset.gitTracked: The argument \(.*/sub\) is a store path within a working tree of a Git repository.
    [[:blank:]]*This indicates that a source directory was imported into the store using a method such as `import "\$\{./.\}"` or `path:.`.
    [[:blank:]]*This function currently does not support such a use case, since it currently relies on `builtins.fetchGit`.
    [[:blank:]]*You could make this work by using a fetcher such as `fetchGit` instead of copying the whole repository.
    [[:blank:]]*If you can'\''t avoid copying the repo to the store, see https://github.com/NixOS/nix/issues/9292.'
fi
rm -rf -- *

# shallow = true is not supported on all Nix versions
# and older versions don't support shallow clones at all
if [[ "$(nix-instantiate --eval --expr "$prefixExpression (versionAtLeast builtins.nixVersion _fetchGitShallowMinver)")" == true ]]; then
    createGitRepo full
    # Extra commit such that there's a commit that won't be in the shallow clone
    git -C full commit --allow-empty -q -m extra
    git clone -q --depth 1 "file://${PWD}/full" shallow
    cd shallow
    checkGitTracked
    cd ..
    rm -rf -- *
fi

# Go through all stages of Git files
# See https://www.git-scm.com/book/en/v2/Git-Basics-Recording-Changes-to-the-Repository

# Empty repository
createGitRepo .
checkGitTracked

# Untracked file
echo a > a
checkGitTracked

# Staged file
git add a
checkGitTracked

# Committed file
git commit -q -m "Added a"
checkGitTracked

# Edited file
echo b > a
checkGitTracked

# Removed file
git rm -f -q a
checkGitTracked

rm -rf -- *

# gitignored file
createGitRepo .
echo a > .gitignore
touch a
git add -A
checkGitTracked

# Add it regardless (needs -f)
git add -f a
checkGitTracked
rm -rf -- *

# Directory
createGitRepo .
mkdir -p d1/d2/d3
touch d1/d2/d3/a
git add d1
checkGitTracked
rm -rf -- *

# Submodules
createGitRepo .
createGitRepo sub

# Untracked submodule
git -C sub commit -q --allow-empty -m "Empty commit"
checkGitTracked

# Tracked submodule
git submodule add ./sub sub >/dev/null
checkGitTracked

# Untracked file
echo a > sub/a
checkGitTracked

# Staged file
git -C sub add a
checkGitTracked

# Committed file
git -C sub commit -q -m "Add a"
checkGitTracked

# Changed file
echo b > sub/b
checkGitTracked

# Removed file
git -C sub rm -f -q a
checkGitTracked

rm -rf -- *

## lib.fileset.maybeMissing

# Argument must be a path
expectFailure 'maybeMissing "someString"' 'lib.fileset.maybeMissing: Argument \("someString"\) is a string-like value, but it should be a path instead.'
expectFailure 'maybeMissing null' 'lib.fileset.maybeMissing: Argument is of type null, but it should be a path instead.'

tree=(
)
checkFileset 'maybeMissing ./a'
checkFileset 'maybeMissing ./b'
checkFileset 'maybeMissing ./b/c'

# Works on single files
tree=(
    [a]=1
    [b/c]=0
    [b/d]=0
)
checkFileset 'maybeMissing ./a'
tree=(
    [a]=0
    [b/c]=1
    [b/d]=0
)
checkFileset 'maybeMissing ./b/c'

# Works on directories
tree=(
    [a]=0
    [b/c]=1
    [b/d]=1
)
checkFileset 'maybeMissing ./b'

# TODO: Once we have combinators and a property testing library, derive property tests from https://en.wikipedia.org/wiki/Algebra_of_sets

echo >&2 tests ok
</file>

<file path="lib/network/default.nix">
{ lib }:
let
  inherit (import ./internal.nix { inherit lib; }) _ipv6;
in
{
  ipv6 = {
    /**
      Creates an `IPv6Address` object from an IPv6 address as a string. If
      the prefix length is omitted, it defaults to 64. The parser is limited
      to the first two versions of IPv6 addresses addressed in RFC 4291.
      The form "x:x:x:x:x:x:d.d.d.d" is not yet implemented. Addresses are
      NOT compressed, so they are not always the same as the canonical text
      representation of IPv6 addresses defined in RFC 5952.

      # Type

      ```
      fromString :: String -> IPv6Address
      ```

      # Examples

      ```nix
      fromString "2001:DB8::ffff/32"
      => {
        address = "2001:db8:0:0:0:0:0:ffff";
        prefixLength = 32;
      }
      ```

      # Arguments

      - [addr] An IPv6 address with optional prefix length.
    */
    fromString =
      addr:
      let
        splittedAddr = _ipv6.split addr;

        addrInternal = splittedAddr.address;
        prefixLength = splittedAddr.prefixLength;

        address = _ipv6.toStringFromExpandedIp addrInternal;
      in
      {
        inherit address prefixLength;
      };
  };
}
</file>

<file path="lib/network/internal.nix">
{
  lib ? import ../.,
}:
let
  inherit (builtins)
    map
    match
    genList
    length
    concatMap
    head
    toString
    ;

  inherit (lib) lists strings trivial;

  inherit (lib.lists) last;

  /**
    IPv6 addresses are 128-bit identifiers. The preferred form is 'x:x:x:x:x:x:x:x',
    where the 'x's are one to four hexadecimal digits of the eight 16-bit pieces of
    the address. See RFC 4291.
  */
  ipv6Bits = 128;
  ipv6Pieces = 8; # 'x:x:x:x:x:x:x:x'
  ipv6PieceBits = 16; # One piece in range from 0 to 0xffff.
  ipv6PieceMaxValue = 65535; # 2^16 - 1
in
let
  /**
    Expand an IPv6 address by removing the "::" compression and padding them
    with the necessary number of zeros. Converts an address from the string to
    the list of strings which then can be parsed using `_parseExpanded`.
    Throws an error when the address is malformed.

    # Type: String -> [ String ]

    # Example:

    ```nix
    expandIpv6 "2001:DB8::ffff"
    => ["2001" "DB8" "0" "0" "0" "0" "0" "ffff"]
    ```
  */
  expandIpv6 =
    addr:
    if match "^[0-9A-Fa-f:]+$" addr == null then
      throw "${addr} contains malformed characters for IPv6 address"
    else
      let
        pieces = strings.splitString ":" addr;
        piecesNoEmpty = lists.remove "" pieces;
        piecesNoEmptyLen = length piecesNoEmpty;
        zeros = genList (_: "0") (ipv6Pieces - piecesNoEmptyLen);
        hasPrefix = strings.hasPrefix "::" addr;
        hasSuffix = strings.hasSuffix "::" addr;
        hasInfix = strings.hasInfix "::" addr;
      in
      if addr == "::" then
        zeros
      else if
        let
          emptyCount = length pieces - piecesNoEmptyLen;
          emptyExpected =
            # splitString produces two empty pieces when "::" in the beginning
            # or in the end, and only one when in the middle of an address.
            if hasPrefix || hasSuffix then
              2
            else if hasInfix then
              1
            else
              0;
        in
        emptyCount != emptyExpected
        || (hasInfix && piecesNoEmptyLen >= ipv6Pieces) # "::" compresses at least one group of zeros.
        || (!hasInfix && piecesNoEmptyLen != ipv6Pieces)
      then
        throw "${addr} is not a valid IPv6 address"
      # Create a list of 8 elements, filling some of them with zeros depending
      # on where the "::" was found.
      else if hasPrefix then
        zeros ++ piecesNoEmpty
      else if hasSuffix then
        piecesNoEmpty ++ zeros
      else if hasInfix then
        concatMap (piece: if piece == "" then zeros else [ piece ]) pieces
      else
        pieces;

  /**
    Parses an expanded IPv6 address (see `expandIpv6`), converting each part
    from a string to an u16 integer. Returns an internal representation of IPv6
    address (list of integers) that can be easily processed by other helper
    functions.
    Throws an error some element is not an u16 integer.

    # Type: [ String ] -> IPv6

    # Example:

    ```nix
    parseExpandedIpv6 ["2001" "DB8" "0" "0" "0" "0" "0" "ffff"]
    => [8193 3512 0 0 0 0 0 65535]
    ```
  */
  parseExpandedIpv6 =
    addr:
    assert lib.assertMsg (
      length addr == ipv6Pieces
    ) "parseExpandedIpv6: expected list of integers with ${ipv6Pieces} elements";
    let
      u16FromHexStr =
        hex:
        let
          parsed = trivial.fromHexString hex;
        in
        if 0 <= parsed && parsed <= ipv6PieceMaxValue then
          parsed
        else
          throw "0x${hex} is not a valid u16 integer";
    in
    map (piece: u16FromHexStr piece) addr;
in
let
  /**
    Parses an IPv6 address from a string to the internal representation (list
    of integers).

    # Type: String -> IPv6

    # Example:

    ```nix
    parseIpv6FromString "2001:DB8::ffff"
    => [8193 3512 0 0 0 0 0 65535]
    ```
  */
  parseIpv6FromString = addr: parseExpandedIpv6 (expandIpv6 addr);
in
{
  /**
    Internally, an IPv6 address is stored as a list of 16-bit integers with 8
    elements. Wherever you see `IPv6` in internal functions docs, it means that
    it is a list of integers produced by one of the internal parsers, such as
    `parseIpv6FromString`
  */
  _ipv6 = {
    /**
      Converts an internal representation of an IPv6 address (i.e, a list
      of integers) to a string. The returned string is not a canonical
      representation as defined in RFC 5952, i.e zeros are not compressed.

      # Type: IPv6 -> String

      # Example:

      ```nix
      parseIpv6FromString [8193 3512 0 0 0 0 0 65535]
      => "2001:db8:0:0:0:0:0:ffff"
      ```
    */
    toStringFromExpandedIp =
      pieces: strings.concatMapStringsSep ":" (piece: strings.toLower (trivial.toHexString piece)) pieces;

    /**
      Extract an address and subnet prefix length from a string. The subnet
      prefix length is optional and defaults to 128. The resulting address and
      prefix length are validated and converted to an internal representation
      that can be used by other functions.

      # Type: String -> [ {address :: IPv6, prefixLength :: Int} ]

      # Example:

      ```nix
      split "2001:DB8::ffff/32"
      => {
        address = [8193 3512 0 0 0 0 0 65535];
        prefixLength = 32;
      }
      ```
    */
    split =
      addr:
      let
        splitted = strings.splitString "/" addr;
        splittedLength = length splitted;
      in
      if splittedLength == 1 then # [ ip ]
        {
          address = parseIpv6FromString addr;
          prefixLength = ipv6Bits;
        }
      else if splittedLength == 2 then # [ ip subnet ]
        {
          address = parseIpv6FromString (head splitted);
          prefixLength =
            let
              n = strings.toInt (last splitted);
            in
            if 1 <= n && n <= ipv6Bits then
              n
            else
              throw "${addr} IPv6 subnet should be in range [1;${toString ipv6Bits}], got ${toString n}";
        }
      else
        throw "${addr} is not a valid IPv6 address in CIDR notation";
  };
}
</file>

<file path="lib/path/tests/default.nix">
{
  nixpkgs ? ../../..,
  system ? builtins.currentSystem,
  pkgs ? import nixpkgs {
    config = { };
    overlays = [ ];
    inherit system;
  },
  nixVersions ? import ../../tests/nix-for-tests.nix { inherit pkgs; },
  libpath ? ../..,
  # Random seed
  seed ? null,
}:

pkgs.runCommand "lib-path-tests"
  {
    nativeBuildInputs = [
      nixVersions.stable
    ]
    ++ (with pkgs; [
      jq
      bc
    ]);
  }
  ''
    # Needed to make Nix evaluation work
    export TEST_ROOT=$(pwd)/test-tmp
    export NIX_BUILD_HOOK=
    export NIX_CONF_DIR=$TEST_ROOT/etc
    export NIX_LOCALSTATE_DIR=$TEST_ROOT/var
    export NIX_LOG_DIR=$TEST_ROOT/var/log/nix
    export NIX_STATE_DIR=$TEST_ROOT/var/nix
    export NIX_STORE_DIR=$TEST_ROOT/store
    export PAGER=cat

    cp -r ${libpath} lib
    export TEST_LIB=$PWD/lib

    echo "Running unit tests lib/path/tests/unit.nix"
    nix-instantiate --eval --show-trace \
      --argstr libpath "$TEST_LIB" \
      lib/path/tests/unit.nix

    echo "Running property tests lib/path/tests/prop.sh"
    bash lib/path/tests/prop.sh ${toString seed}

    touch $out
  ''
</file>

<file path="lib/path/tests/generate.awk">
# Generate random path-like strings, separated by null characters.
#
# Invocation:
#
#     awk -f ./generate.awk -v <variable>=<value> | tr '\0' '\n'
#
# Customizable variables (all default to 0):
# - seed: Deterministic random seed to use for generation
# - count: Number of paths to generate
# - extradotweight: Give extra weight to dots being generated
# - extraslashweight: Give extra weight to slashes being generated
# - extranullweight: Give extra weight to null being generated, making paths shorter
BEGIN {
  # Random seed, passed explicitly for reproducibility
  srand(seed)

  # Don't include special characters below 32
  minascii = 32
  # Don't include DEL at 128
  maxascii = 127
  upperascii = maxascii - minascii

  # add extra weight for ., in addition to the one weight from the ascii range
  upperdot = upperascii + extradotweight

  # add extra weight for /, in addition to the one weight from the ascii range
  upperslash = upperdot + extraslashweight

  # add extra weight for null, indicating the end of the string
  # Must be at least 1 to have strings end at all
  total = upperslash + 1 + extranullweight

  # new=1 indicates that it's a new string
  new=1
  while (count > 0) {

    # Random integer between [0, total)
    value = int(rand() * total)

    if (value < upperascii) {
      # Ascii range
      printf("%c", value + minascii)
      new=0

    } else if (value < upperdot) {
      # Dot range
      printf "."
      new=0

    } else if (value < upperslash) {
      # If it's the start of a new path, only generate a / in 10% of cases
      # This is always an invalid subpath, which is not a very interesting case
      if (new && rand() > 0.1) continue
      printf "/"

    } else {
      # Do not generate empty strings
      if (new) continue
      printf "\x00"
      count--
      new=1
    }
  }
}
</file>

<file path="lib/path/tests/prop.nix">
# Given a list of path-like strings, check some properties of the path library
# using those paths and return a list of attribute sets of the following form:
#
#     { <string> = <lib.path.subpath.normalise string>; }
#
# If `normalise` fails to evaluate, the attribute value is set to `""`.
# If not, the resulting value is normalised again and an appropriate attribute set added to the output list.
{
  # The path to the nixpkgs lib to use
  libpath,
  # A flat directory containing files with randomly-generated
  # path-like values
  dir,
}:
let
  lib = import libpath;

  # read each file into a string
  strings = map (name: builtins.readFile (dir + "/${name}")) (
    builtins.attrNames (builtins.readDir dir)
  );

  inherit (lib.path.subpath) normalise isValid;
  inherit (lib.asserts) assertMsg;

  normaliseAndCheck =
    str:
    let
      originalValid = isValid str;

      tryOnce = builtins.tryEval (normalise str);
      tryTwice = builtins.tryEval (normalise tryOnce.value);

      absConcatOrig = /. + ("/" + str);
      absConcatNormalised = /. + ("/" + tryOnce.value);
    in
    # Check the lib.path.subpath.normalise property to only error on invalid subpaths
    assert assertMsg (
      originalValid -> tryOnce.success
    ) "Even though string \"${str}\" is valid as a subpath, the normalisation for it failed";
    assert assertMsg (
      !originalValid -> !tryOnce.success
    ) "Even though string \"${str}\" is invalid as a subpath, the normalisation for it succeeded";

    # Check normalisation idempotency
    assert assertMsg (
      originalValid -> tryTwice.success
    ) "For valid subpath \"${str}\", the normalisation \"${tryOnce.value}\" was not a valid subpath";
    assert assertMsg (originalValid -> tryOnce.value == tryTwice.value)
      "For valid subpath \"${str}\", normalising it once gives \"${tryOnce.value}\" but normalising it twice gives a different result: \"${tryTwice.value}\"";

    # Check that normalisation doesn't change a string when appended to an absolute Nix path value
    assert assertMsg (originalValid -> absConcatOrig == absConcatNormalised)
      "For valid subpath \"${str}\", appending to an absolute Nix path value gives \"${absConcatOrig}\", but appending the normalised result \"${tryOnce.value}\" gives a different value \"${absConcatNormalised}\"";

    # Return an empty string when failed
    if tryOnce.success then tryOnce.value else "";

in
lib.genAttrs strings normaliseAndCheck
</file>

<file path="lib/path/tests/prop.sh">
#!/usr/bin/env bash

# Property tests for lib/path/default.nix
# It generates random path-like strings and runs the functions on
# them, checking that the expected laws of the functions hold
# Run:
# [nixpkgs]$ lib/path/tests/prop.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -euo pipefail
shopt -s inherit_errexit

# https://stackoverflow.com/a/246128
SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

if test -z "${TEST_LIB:-}"; then
    TEST_LIB=$SCRIPT_DIR/../..
fi

tmp="$(mktemp -d)"
clean_up() {
    rm -rf "$tmp"
}
trap clean_up EXIT
mkdir -p "$tmp/work"
cd "$tmp/work"

# Defaulting to a random seed but the first argument can override this
seed=${1:-$RANDOM}
echo >&2 "Using seed $seed, use \`lib/path/tests/prop.sh $seed\` to reproduce this result"

# The number of random paths to generate. This specific number was chosen to
# be fast enough while still generating enough variety to detect bugs.
count=500

debug=0
# debug=1 # print some extra info
# debug=2 # print generated values

# Fine tuning parameters to balance the number of generated invalid paths
# to the variance in generated paths.
extradotweight=64   # Larger value: more dots
extraslashweight=64 # Larger value: more slashes
extranullweight=16  # Larger value: shorter strings

die() {
    echo >&2 "test case failed: " "$@"
    exit 1
}

if [[ "$debug" -ge 1 ]]; then
    echo >&2 "Generating $count random path-like strings"
fi

# Read stream of null-terminated strings entry-by-entry into bash,
# write it to a file and the `strings` array.
declare -a strings=()
mkdir -p "$tmp/strings"
while IFS= read -r -d $'\0' str; do
    printf "%s" "$str" > "$tmp/strings/${#strings[@]}"
    strings+=("$str")
done < <(awk \
    -f "$SCRIPT_DIR"/generate.awk \
    -v seed="$seed" \
    -v count="$count" \
    -v extradotweight="$extradotweight" \
    -v extraslashweight="$extraslashweight" \
    -v extranullweight="$extranullweight")

if [[ "$debug" -ge 1 ]]; then
    echo >&2 "Trying to normalise the generated path-like strings with Nix"
fi

# Precalculate all normalisations with a single Nix call. Calling Nix for each
# string individually would take way too long
nix-instantiate --eval --strict --json --show-trace \
    --argstr libpath "$TEST_LIB" \
    --argstr dir "$tmp/strings" \
    "$SCRIPT_DIR"/prop.nix \
    >"$tmp/result.json"

# Uses some jq magic to turn the resulting attribute set into an associative
# bash array assignment
declare -A normalised_result="($(jq '
    to_entries
    | map("[\(.key | @sh)]=\(.value | @sh)")
    | join(" \n")' -r < "$tmp/result.json"))"

# Looks up a normalisation result for a string
# Checks that the normalisation is only failing iff it's an invalid subpath
# For valid subpaths, returns 0 and prints the normalisation result
# For invalid subpaths, returns 1
normalise() {
    local str=$1
    # Uses the same check for validity as in the library implementation
    if [[ "$str" == "" || "$str" == /* || "$str" =~ ^(.*/)?\.\.(/.*)?$ ]]; then
        valid=
    else
        valid=1
    fi

    normalised=${normalised_result[$str]}
    # An empty string indicates failure, this is encoded in ./prop.nix
    if [[ -n "$normalised" ]]; then
        if [[ -n "$valid" ]]; then
            echo "$normalised"
        else
            die "For invalid subpath \"$str\", lib.path.subpath.normalise returned this result: \"$normalised\""
        fi
    else
        if [[ -n "$valid" ]]; then
            die "For valid subpath \"$str\", lib.path.subpath.normalise failed"
        else
            if [[ "$debug" -ge 2 ]]; then
                echo >&2 "String \"$str\" is not a valid subpath"
            fi
            # Invalid and it correctly failed, we let the caller continue if they catch the exit code
            return 1
        fi
    fi
}

# Intermediate result populated by test_idempotency_realpath
# and used in test_normalise_uniqueness
#
# Contains a mapping from a normalised subpath to the realpath result it represents
declare -A norm_to_real

test_idempotency_realpath() {
    if [[ "$debug" -ge 1 ]]; then
        echo >&2 "Checking idempotency of each result and making sure the realpath result isn't changed"
    fi

    # Count invalid subpaths to display stats
    invalid=0
    for str in "${strings[@]}"; do
        if ! result=$(normalise "$str"); then
            ((invalid++)) || true
            continue
        fi

        # Check the law that it doesn't change the result of a realpath
        mkdir -p -- "$str" "$result"
        real_orig=$(realpath -- "$str")
        real_norm=$(realpath -- "$result")

        if [[ "$real_orig" != "$real_norm" ]]; then
            die "realpath of the original string \"$str\" (\"$real_orig\") is not the same as realpath of the normalisation \"$result\" (\"$real_norm\")"
        fi

        if [[ "$debug" -ge 2 ]]; then
            echo >&2 "String \"$str\" gets normalised to \"$result\" and file path \"$real_orig\""
        fi
        norm_to_real["$result"]="$real_orig"
    done
    if [[ "$debug" -ge 1 ]]; then
        echo >&2 "$(bc <<< "scale=1; 100 / $count * $invalid")% of the total $count generated strings were invalid subpath strings, and were therefore ignored"
    fi
}

test_normalise_uniqueness() {
    if [[ "$debug" -ge 1 ]]; then
        echo >&2 "Checking for the uniqueness law"
    fi

    for norm_p in "${!norm_to_real[@]}"; do
        real_p=${norm_to_real["$norm_p"]}
        for norm_q in "${!norm_to_real[@]}"; do
            real_q=${norm_to_real["$norm_q"]}
            # Checks normalisation uniqueness law for each pair of values
            if [[ "$norm_p" != "$norm_q" && "$real_p" == "$real_q" ]]; then
                die "Normalisations \"$norm_p\" and \"$norm_q\" are different, but the realpath of them is the same: \"$real_p\""
            fi
        done
    done
}

test_idempotency_realpath
test_normalise_uniqueness

echo >&2 tests ok
</file>

<file path="lib/path/tests/unit.nix">
# Unit tests for lib.path functions. Use `nix-build` in this directory to
# run these
{ libpath }:
let
  lib = import libpath;
  inherit (lib.path)
    hasPrefix
    removePrefix
    append
    splitRoot
    hasStorePathPrefix
    subpath
    ;

  # This is not allowed generally, but we're in the tests here, so we'll allow ourselves.
  storeDirPath = /. + builtins.storeDir;

  cases = lib.runTests {
    # Test examples from the lib.path.append documentation
    testAppendExample1 = {
      expr = append /foo "bar/baz";
      expected = /foo/bar/baz;
    };
    testAppendExample2 = {
      expr = append /foo "./bar//baz/./";
      expected = /foo/bar/baz;
    };
    testAppendExample3 = {
      expr = append /. "foo/bar";
      expected = /foo/bar;
    };
    testAppendExample4 = {
      expr = (builtins.tryEval (append "/foo" "bar")).success;
      expected = false;
    };
    testAppendExample5 = {
      expr = (builtins.tryEval (append /foo /bar)).success;
      expected = false;
    };
    testAppendExample6 = {
      expr = (builtins.tryEval (append /foo "")).success;
      expected = false;
    };
    testAppendExample7 = {
      expr = (builtins.tryEval (append /foo "/bar")).success;
      expected = false;
    };
    testAppendExample8 = {
      expr = (builtins.tryEval (append /foo "../bar")).success;
      expected = false;
    };

    testHasPrefixExample1 = {
      expr = hasPrefix /foo /foo/bar;
      expected = true;
    };
    testHasPrefixExample2 = {
      expr = hasPrefix /foo /foo;
      expected = true;
    };
    testHasPrefixExample3 = {
      expr = hasPrefix /foo/bar /foo;
      expected = false;
    };
    testHasPrefixExample4 = {
      expr = hasPrefix /. /foo;
      expected = true;
    };

    testRemovePrefixExample1 = {
      expr = removePrefix /foo /foo/bar/baz;
      expected = "./bar/baz";
    };
    testRemovePrefixExample2 = {
      expr = removePrefix /foo /foo;
      expected = "./.";
    };
    testRemovePrefixExample3 = {
      expr = (builtins.tryEval (removePrefix /foo/bar /foo)).success;
      expected = false;
    };
    testRemovePrefixExample4 = {
      expr = removePrefix /. /foo;
      expected = "./foo";
    };

    testSplitRootExample1 = {
      expr = splitRoot /foo/bar;
      expected = {
        root = /.;
        subpath = "./foo/bar";
      };
    };
    testSplitRootExample2 = {
      expr = splitRoot /.;
      expected = {
        root = /.;
        subpath = "./.";
      };
    };
    testSplitRootExample3 = {
      expr = splitRoot /foo/../bar;
      expected = {
        root = /.;
        subpath = "./bar";
      };
    };
    testSplitRootExample4 = {
      expr = (builtins.tryEval (splitRoot "/foo/bar")).success;
      expected = false;
    };

    # Root path (empty path components list)
    testHasStorePathPrefixRoot = {
      expr = hasStorePathPrefix /.;
      expected = false;
    };

    testHasStorePathPrefixExample1 = {
      expr = hasStorePathPrefix (storeDirPath + "/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo/bar/baz");
      expected = true;
    };
    testHasStorePathPrefixExample2 = {
      expr = hasStorePathPrefix storeDirPath;
      expected = false;
    };
    testHasStorePathPrefixExample3 = {
      expr = hasStorePathPrefix (storeDirPath + "/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo");
      expected = true;
    };
    testHasStorePathPrefixExample4 = {
      expr = hasStorePathPrefix /home/user;
      expected = false;
    };
    testHasStorePathPrefixExample5 = {
      expr = hasStorePathPrefix (
        storeDirPath + "/.links/10gg8k3rmbw8p7gszarbk7qyd9jwxhcfq9i6s5i0qikx8alkk4hq"
      );
      expected = false;
    };
    testHasStorePathPrefixExample6 = {
      expr = hasStorePathPrefix (storeDirPath + "/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo.drv");
      expected = true;
    };

    # Test paths for content‐addressed derivations
    testHasStorePathPrefixExample7 = {
      expr = hasStorePathPrefix (/. + "/1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab");
      expected = true;
    };
    testHasStorePathPrefixExample8 = {
      expr = hasStorePathPrefix (/. + "/1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab/foo/bar");
      expected = true;
    };

    # Test examples from the lib.path.subpath.isValid documentation
    testSubpathIsValidExample1 = {
      expr = subpath.isValid null;
      expected = false;
    };
    testSubpathIsValidExample2 = {
      expr = subpath.isValid "";
      expected = false;
    };
    testSubpathIsValidExample3 = {
      expr = subpath.isValid "/foo";
      expected = false;
    };
    testSubpathIsValidExample4 = {
      expr = subpath.isValid "../foo";
      expected = false;
    };
    testSubpathIsValidExample5 = {
      expr = subpath.isValid "foo/bar";
      expected = true;
    };
    testSubpathIsValidExample6 = {
      expr = subpath.isValid "./foo//bar/";
      expected = true;
    };
    # Some extra tests
    testSubpathIsValidTwoDotsEnd = {
      expr = subpath.isValid "foo/..";
      expected = false;
    };
    testSubpathIsValidTwoDotsMiddle = {
      expr = subpath.isValid "foo/../bar";
      expected = false;
    };
    testSubpathIsValidTwoDotsPrefix = {
      expr = subpath.isValid "..foo";
      expected = true;
    };
    testSubpathIsValidTwoDotsSuffix = {
      expr = subpath.isValid "foo..";
      expected = true;
    };
    testSubpathIsValidTwoDotsPrefixComponent = {
      expr = subpath.isValid "foo/..bar/baz";
      expected = true;
    };
    testSubpathIsValidTwoDotsSuffixComponent = {
      expr = subpath.isValid "foo/bar../baz";
      expected = true;
    };
    testSubpathIsValidThreeDots = {
      expr = subpath.isValid "...";
      expected = true;
    };
    testSubpathIsValidFourDots = {
      expr = subpath.isValid "....";
      expected = true;
    };
    testSubpathIsValidThreeDotsComponent = {
      expr = subpath.isValid "foo/.../bar";
      expected = true;
    };
    testSubpathIsValidFourDotsComponent = {
      expr = subpath.isValid "foo/..../bar";
      expected = true;
    };

    # Test examples from the lib.path.subpath.join documentation
    testSubpathJoinExample1 = {
      expr = subpath.join [
        "foo"
        "bar/baz"
      ];
      expected = "./foo/bar/baz";
    };
    testSubpathJoinExample2 = {
      expr = subpath.join [
        "./foo"
        "."
        "bar//./baz/"
      ];
      expected = "./foo/bar/baz";
    };
    testSubpathJoinExample3 = {
      expr = subpath.join [ ];
      expected = "./.";
    };
    testSubpathJoinExample4 = {
      expr = (builtins.tryEval (subpath.join [ /foo ])).success;
      expected = false;
    };
    testSubpathJoinExample5 = {
      expr = (builtins.tryEval (subpath.join [ "" ])).success;
      expected = false;
    };
    testSubpathJoinExample6 = {
      expr = (builtins.tryEval (subpath.join [ "/foo" ])).success;
      expected = false;
    };
    testSubpathJoinExample7 = {
      expr = (builtins.tryEval (subpath.join [ "../foo" ])).success;
      expected = false;
    };

    # Test examples from the lib.path.subpath.normalise documentation
    testSubpathNormaliseExample1 = {
      expr = subpath.normalise "foo//bar";
      expected = "./foo/bar";
    };
    testSubpathNormaliseExample2 = {
      expr = subpath.normalise "foo/./bar";
      expected = "./foo/bar";
    };
    testSubpathNormaliseExample3 = {
      expr = subpath.normalise "foo/bar";
      expected = "./foo/bar";
    };
    testSubpathNormaliseExample4 = {
      expr = subpath.normalise "foo/bar/";
      expected = "./foo/bar";
    };
    testSubpathNormaliseExample5 = {
      expr = subpath.normalise "foo/bar/.";
      expected = "./foo/bar";
    };
    testSubpathNormaliseExample6 = {
      expr = subpath.normalise ".";
      expected = "./.";
    };
    testSubpathNormaliseExample7 = {
      expr = (builtins.tryEval (subpath.normalise "foo/../bar")).success;
      expected = false;
    };
    testSubpathNormaliseExample8 = {
      expr = (builtins.tryEval (subpath.normalise "")).success;
      expected = false;
    };
    testSubpathNormaliseExample9 = {
      expr = (builtins.tryEval (subpath.normalise "/foo")).success;
      expected = false;
    };
    # Some extra tests
    testSubpathNormaliseIsValidDots = {
      expr = subpath.normalise "./foo/.bar/.../baz...qux";
      expected = "./foo/.bar/.../baz...qux";
    };
    testSubpathNormaliseWrongType = {
      expr = (builtins.tryEval (subpath.normalise null)).success;
      expected = false;
    };
    testSubpathNormaliseTwoDots = {
      expr = (builtins.tryEval (subpath.normalise "..")).success;
      expected = false;
    };

    testSubpathComponentsExample1 = {
      expr = subpath.components ".";
      expected = [ ];
    };
    testSubpathComponentsExample2 = {
      expr = subpath.components "./foo//bar/./baz/";
      expected = [
        "foo"
        "bar"
        "baz"
      ];
    };
    testSubpathComponentsExample3 = {
      expr = (builtins.tryEval (subpath.components "/foo")).success;
      expected = false;
    };
  };
in
if cases == [ ] then
  "Unit tests successful"
else
  throw "Path unit tests failed: ${lib.generators.toPretty { } cases}"
</file>

<file path="lib/path/default.nix">
# Functions for working with path values.
# See ./README.md for internal docs
{ lib }:
let

  inherit (builtins)
    isString
    isPath
    split
    match
    typeOf
    storeDir
    ;

  inherit (lib.lists)
    length
    head
    last
    genList
    elemAt
    all
    concatMap
    foldl'
    take
    drop
    ;

  listHasPrefix = lib.lists.hasPrefix;

  inherit (lib.strings)
    concatStringsSep
    substring
    ;

  inherit (lib.asserts)
    assertMsg
    ;

  inherit (lib.path.subpath)
    isValid
    ;

  # Return the reason why a subpath is invalid, or `null` if it's valid
  subpathInvalidReason =
    value:
    if !isString value then
      "The given value is of type ${builtins.typeOf value}, but a string was expected"
    else if value == "" then
      "The given string is empty"
    else if substring 0 1 value == "/" then
      "The given string \"${value}\" starts with a `/`, representing an absolute path"
    # We don't support ".." components, see ./path.md#parent-directory
    else if match "(.*/)?\\.\\.(/.*)?" value != null then
      "The given string \"${value}\" contains a `..` component, which is not allowed in subpaths"
    else
      null;

  # Split and normalise a relative path string into its components.
  # Error for ".." components and doesn't include "." components
  splitRelPath =
    path:
    let
      # Split the string into its parts using regex for efficiency. This regex
      # matches patterns like "/", "/./", "/././", with arbitrarily many "/"s
      # together. These are the main special cases:
      # - Leading "./" gets split into a leading "." part
      # - Trailing "/." or "/" get split into a trailing "." or ""
      #   part respectively
      #
      # These are the only cases where "." and "" parts can occur
      parts = split "/+(\\./+)*" path;

      # `split` creates a list of 2 * k + 1 elements, containing the k +
      # 1 parts, interleaved with k matches where k is the number of
      # (non-overlapping) matches. This calculation here gets the number of parts
      # back from the list length
      # floor( (2 * k + 1) / 2 ) + 1 == floor( k + 1/2 ) + 1 == k + 1
      partCount = length parts / 2 + 1;

      # To assemble the final list of components we want to:
      # - Skip a potential leading ".", normalising "./foo" to "foo"
      # - Skip a potential trailing "." or "", normalising "foo/" and "foo/." to
      #   "foo". See ./path.md#trailing-slashes
      skipStart = if head parts == "." then 1 else 0;
      skipEnd = if last parts == "." || last parts == "" then 1 else 0;

      # We can now know the length of the result by removing the number of
      # skipped parts from the total number
      componentCount = partCount - skipEnd - skipStart;

    in
    # Special case of a single "." path component. Such a case leaves a
    # componentCount of -1 due to the skipStart/skipEnd not verifying that
    # they don't refer to the same character
    if path == "." then
      [ ]

    # Generate the result list directly. This is more efficient than a
    # combination of `filter`, `init` and `tail`, because here we don't
    # allocate any intermediate lists
    else
      genList (
        index:
        # To get to the element we need to add the number of parts we skip and
        # multiply by two due to the interleaved layout of `parts`
        elemAt parts ((skipStart + index) * 2)
      ) componentCount;

  # Join relative path components together
  joinRelPath =
    components:
    # Always return relative paths with `./` as a prefix (./path.md#leading-dots-for-relative-paths)
    "./"
    +
      # An empty string is not a valid relative path, so we need to return a `.` when we have no components
      (if components == [ ] then "." else concatStringsSep "/" components);

  # Type: Path -> { root :: Path, components :: [ String ] }
  #
  # Deconstruct a path value type into:
  # - root: The filesystem root of the path, generally `/`
  # - components: All the path's components
  #
  # This is similar to `splitString "/" (toString path)` but safer
  # because it can distinguish different filesystem roots
  deconstructPath =
    let
      recurse =
        components: base:
        # If the parent of a path is the path itself, then it's a filesystem root
        if base == dirOf base then
          {
            root = base;
            inherit components;
          }
        else
          recurse ([ (baseNameOf base) ] ++ components) (dirOf base);
    in
    recurse [ ];

  # The components of the store directory, typically [ "nix" "store" ]
  storeDirComponents = splitRelPath ("./" + storeDir);
  # The number of store directory components, typically 2
  storeDirLength = length storeDirComponents;

  # Type: [ String ] -> Bool
  #
  # Whether path components have a store path as a prefix, according to
  # https://nixos.org/manual/nix/stable/store/store-path.html#store-path.
  componentsHaveStorePathPrefix =
    components:
    # path starts with the store directory (typically /nix/store)
    listHasPrefix storeDirComponents components
    # is not the store directory itself, meaning there's at least one extra component
    && storeDirComponents != components
    # and the first component after the store directory has the expected format.
    # NOTE: We could change the hash regex to be [0-9a-df-np-sv-z],
    # because these are the actual ASCII characters used by Nix's base32 implementation,
    # but this is not fully specified, so let's tie this too much to the currently implemented concept of store paths.
    # Similar reasoning applies to the validity of the name part.
    # We care more about discerning store path-ness on realistic values. Making it airtight would be fragile and slow.
    && match ".{32}-.+" (elemAt components storeDirLength) != null
    # alternatively match content‐addressed derivations, which _currently_ do
    # not have a store directory prefix.
    # This is a workaround for https://github.com/NixOS/nix/issues/12361 which
    # was needed during the experimental phase of ca-derivations and should be
    # removed once the issue has been resolved.
    || components != [ ] && match "[0-9a-z]{52}" (head components) != null;

in
# No rec! Add dependencies on this file at the top.
{

  /**
    Append a subpath string to a path.

    Like `path + ("/" + string)` but safer, because it errors instead of returning potentially surprising results.
    More specifically, it checks that the first argument is a [path value type](https://nixos.org/manual/nix/stable/language/values.html#type-path"),
    and that the second argument is a [valid subpath string](#function-library-lib.path.subpath.isValid).

    Laws:

    - Not influenced by subpath [normalisation](#function-library-lib.path.subpath.normalise):

          append p s == append p (subpath.normalise s)

    # Inputs

    `path`

    : The absolute path to append to

    `subpath`

    : The subpath string to append

    # Type

    ```
    append :: Path -> String -> Path
    ```

    # Examples
    :::{.example}
    ## `append` usage example

    ```nix
    append /foo "bar/baz"
    => /foo/bar/baz

    # subpaths don't need to be normalised
    append /foo "./bar//baz/./"
    => /foo/bar/baz

    # can append to root directory
    append /. "foo/bar"
    => /foo/bar

    # first argument needs to be a path value type
    append "/foo" "bar"
    => <error>

    # second argument needs to be a valid subpath string
    append /foo /bar
    => <error>
    append /foo ""
    => <error>
    append /foo "/bar"
    => <error>
    append /foo "../bar"
    => <error>
    ```

    :::
  */
  append =
    # The absolute path to append to
    path:
    # The subpath string to append
    subpath:
    assert assertMsg (isPath path)
      ''lib.path.append: The first argument is of type ${builtins.typeOf path}, but a path was expected'';
    assert assertMsg (isValid subpath) ''
      lib.path.append: Second argument is not a valid subpath string:
          ${subpathInvalidReason subpath}'';
    path + ("/" + subpath);

  /**
    Whether the first path is a component-wise prefix of the second path.

    Laws:

    - `hasPrefix p q` is only true if [`q == append p s`](#function-library-lib.path.append) for some [subpath](#function-library-lib.path.subpath.isValid) `s`.

    - `hasPrefix` is a [non-strict partial order](https://en.wikipedia.org/wiki/Partially_ordered_set#Non-strict_partial_order) over the set of all path values.

    # Inputs

    `path1`

    : 1\. Function argument

    # Type

    ```
    hasPrefix :: Path -> Path -> Bool
    ```

    # Examples
    :::{.example}
    ## `hasPrefix` usage example

    ```nix
    hasPrefix /foo /foo/bar
    => true
    hasPrefix /foo /foo
    => true
    hasPrefix /foo/bar /foo
    => false
    hasPrefix /. /foo
    => true
    ```

    :::
  */
  hasPrefix =
    path1:
    assert assertMsg (isPath path1)
      "lib.path.hasPrefix: First argument is of type ${typeOf path1}, but a path was expected";
    let
      path1Deconstructed = deconstructPath path1;
    in
    path2:
    assert assertMsg (isPath path2)
      "lib.path.hasPrefix: Second argument is of type ${typeOf path2}, but a path was expected";
    let
      path2Deconstructed = deconstructPath path2;
    in
    assert assertMsg (path1Deconstructed.root == path2Deconstructed.root) ''
      lib.path.hasPrefix: Filesystem roots must be the same for both paths, but paths with different roots were given:
          first argument: "${toString path1}" with root "${toString path1Deconstructed.root}"
          second argument: "${toString path2}" with root "${toString path2Deconstructed.root}"'';
    take (length path1Deconstructed.components) path2Deconstructed.components
    == path1Deconstructed.components;

  /**
    Remove the first path as a component-wise prefix from the second path.
    The result is a [normalised subpath string](#function-library-lib.path.subpath.normalise).

    Laws:

    - Inverts [`append`](#function-library-lib.path.append) for [normalised subpath string](#function-library-lib.path.subpath.normalise):

          removePrefix p (append p s) == subpath.normalise s

    # Inputs

    `path1`

    : 1\. Function argument

    # Type

    ```
    removePrefix :: Path -> Path -> String
    ```

    # Examples
    :::{.example}
    ## `removePrefix` usage example

    ```nix
    removePrefix /foo /foo/bar/baz
    => "./bar/baz"
    removePrefix /foo /foo
    => "./."
    removePrefix /foo/bar /foo
    => <error>
    removePrefix /. /foo
    => "./foo"
    ```

    :::
  */
  removePrefix =
    path1:
    assert assertMsg (isPath path1)
      "lib.path.removePrefix: First argument is of type ${typeOf path1}, but a path was expected.";
    let
      path1Deconstructed = deconstructPath path1;
      path1Length = length path1Deconstructed.components;
    in
    path2:
    assert assertMsg (isPath path2)
      "lib.path.removePrefix: Second argument is of type ${typeOf path2}, but a path was expected.";
    let
      path2Deconstructed = deconstructPath path2;
      success = take path1Length path2Deconstructed.components == path1Deconstructed.components;
      components =
        if success then
          drop path1Length path2Deconstructed.components
        else
          throw ''lib.path.removePrefix: The first path argument "${toString path1}" is not a component-wise prefix of the second path argument "${toString path2}".'';
    in
    assert assertMsg (path1Deconstructed.root == path2Deconstructed.root) ''
      lib.path.removePrefix: Filesystem roots must be the same for both paths, but paths with different roots were given:
          first argument: "${toString path1}" with root "${toString path1Deconstructed.root}"
          second argument: "${toString path2}" with root "${toString path2Deconstructed.root}"'';
    joinRelPath components;

  /**
    Split the filesystem root from a [path](https://nixos.org/manual/nix/stable/language/values.html#type-path).
    The result is an attribute set with these attributes:
    - `root`: The filesystem root of the path, meaning that this directory has no parent directory.
    - `subpath`: The [normalised subpath string](#function-library-lib.path.subpath.normalise) that when [appended](#function-library-lib.path.append) to `root` returns the original path.

    Laws:
    - [Appending](#function-library-lib.path.append) the `root` and `subpath` gives the original path:

          p ==
            append
              (splitRoot p).root
              (splitRoot p).subpath

    - Trying to get the parent directory of `root` using [`dirOf`](https://nixos.org/manual/nix/stable/language/builtins.html#builtins-dirOf) returns `root` itself:

          dirOf (splitRoot p).root == (splitRoot p).root

    # Inputs

    `path`

    : The path to split the root off of

    # Type

    ```
    splitRoot :: Path -> { root :: Path, subpath :: String }
    ```

    # Examples
    :::{.example}
    ## `splitRoot` usage example

    ```nix
    splitRoot /foo/bar
    => { root = /.; subpath = "./foo/bar"; }

    splitRoot /.
    => { root = /.; subpath = "./."; }

    # Nix neutralises `..` path components for all path values automatically
    splitRoot /foo/../bar
    => { root = /.; subpath = "./bar"; }

    splitRoot "/foo/bar"
    => <error>
    ```

    :::
  */
  splitRoot =
    # The path to split the root off of
    path:
    assert assertMsg (isPath path)
      "lib.path.splitRoot: Argument is of type ${typeOf path}, but a path was expected";
    let
      deconstructed = deconstructPath path;
    in
    {
      root = deconstructed.root;
      subpath = joinRelPath deconstructed.components;
    };

  /**
    Whether a [path](https://nixos.org/manual/nix/stable/language/values.html#type-path)
    has a [store path](https://nixos.org/manual/nix/stable/store/store-path.html#store-path)
    as a prefix.

    :::{.note}
    As with all functions of this `lib.path` library, it does not work on paths in strings,
    which is how you'd typically get store paths.

    Instead, this function only handles path values themselves,
    which occur when Nix files in the store use relative path expressions.
    :::

    # Inputs

    `path`

    : 1\. Function argument

    # Type

    ```
    hasStorePathPrefix :: Path -> Bool
    ```

    # Examples
    :::{.example}
    ## `hasStorePathPrefix` usage example

    ```nix
    # Subpaths of derivation outputs have a store path as a prefix
    hasStorePathPrefix /nix/store/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo/bar/baz
    => true

    # The store directory itself is not a store path
    hasStorePathPrefix /nix/store
    => false

    # Derivation outputs are store paths themselves
    hasStorePathPrefix /nix/store/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo
    => true

    # Paths outside the Nix store don't have a store path prefix
    hasStorePathPrefix /home/user
    => false

    # Not all paths under the Nix store are store paths
    hasStorePathPrefix /nix/store/.links/10gg8k3rmbw8p7gszarbk7qyd9jwxhcfq9i6s5i0qikx8alkk4hq
    => false

    # Store derivations are also store paths themselves
    hasStorePathPrefix /nix/store/nvl9ic0pj1fpyln3zaqrf4cclbqdfn1j-foo.drv
    => true
    ```

    :::
  */
  hasStorePathPrefix =
    path:
    let
      deconstructed = deconstructPath path;
    in
    assert assertMsg (isPath path)
      "lib.path.hasStorePathPrefix: Argument is of type ${typeOf path}, but a path was expected";
    assert assertMsg
      # This function likely breaks or needs adjustment if used with other filesystem roots, if they ever get implemented.
      # Let's try to error nicely in such a case, though it's unclear how an implementation would work even and whether this could be detected.
      # See also https://github.com/NixOS/nix/pull/6530#discussion_r1422843117
      (deconstructed.root == /. && toString deconstructed.root == "/")
      "lib.path.hasStorePathPrefix: Argument has a filesystem root (${toString deconstructed.root}) that's not /, which is currently not supported.";
    componentsHaveStorePathPrefix deconstructed.components;

  /**
    Whether a value is a valid subpath string.

    A subpath string points to a specific file or directory within an absolute base directory.
    It is a stricter form of a relative path that excludes `..` components, since those could escape the base directory.

    - The value is a string.

    - The string is not empty.

    - The string doesn't start with a `/`.

    - The string doesn't contain any `..` path components.

    # Inputs

    `value`

    : The value to check

    # Type

    ```
    subpath.isValid :: String -> Bool
    ```

    # Examples
    :::{.example}
    ## `subpath.isValid` usage example

    ```nix
    # Not a string
    subpath.isValid null
    => false

    # Empty string
    subpath.isValid ""
    => false

    # Absolute path
    subpath.isValid "/foo"
    => false

    # Contains a `..` path component
    subpath.isValid "../foo"
    => false

    # Valid subpath
    subpath.isValid "foo/bar"
    => true

    # Doesn't need to be normalised
    subpath.isValid "./foo//bar/"
    => true
    ```

    :::
  */
  subpath.isValid =
    # The value to check
    value: subpathInvalidReason value == null;

  /**
    Join subpath strings together using `/`, returning a normalised subpath string.

    Like `concatStringsSep "/"` but safer, specifically:

    - All elements must be [valid subpath strings](#function-library-lib.path.subpath.isValid).

    - The result gets [normalised](#function-library-lib.path.subpath.normalise).

    - The edge case of an empty list gets properly handled by returning the neutral subpath `"./."`.

    Laws:

    - Associativity:

          subpath.join [ x (subpath.join [ y z ]) ] == subpath.join [ (subpath.join [ x y ]) z ]

    - Identity - `"./."` is the neutral element for normalised paths:

          subpath.join [ ] == "./."
          subpath.join [ (subpath.normalise p) "./." ] == subpath.normalise p
          subpath.join [ "./." (subpath.normalise p) ] == subpath.normalise p

    - Normalisation - the result is [normalised](#function-library-lib.path.subpath.normalise):

          subpath.join ps == subpath.normalise (subpath.join ps)

    - For non-empty lists, the implementation is equivalent to [normalising](#function-library-lib.path.subpath.normalise) the result of `concatStringsSep "/"`.
      Note that the above laws can be derived from this one:

          ps != [] -> subpath.join ps == subpath.normalise (concatStringsSep "/" ps)

    # Inputs

    `subpaths`

    : The list of subpaths to join together

    # Type

    ```
    subpath.join :: [ String ] -> String
    ```

    # Examples
    :::{.example}
    ## `subpath.join` usage example

    ```nix
    subpath.join [ "foo" "bar/baz" ]
    => "./foo/bar/baz"

    # normalise the result
    subpath.join [ "./foo" "." "bar//./baz/" ]
    => "./foo/bar/baz"

    # passing an empty list results in the current directory
    subpath.join [ ]
    => "./."

    # elements must be valid subpath strings
    subpath.join [ /foo ]
    => <error>
    subpath.join [ "" ]
    => <error>
    subpath.join [ "/foo" ]
    => <error>
    subpath.join [ "../foo" ]
    => <error>
    ```

    :::
  */
  subpath.join =
    # The list of subpaths to join together
    subpaths:
    # Fast in case all paths are valid
    if all isValid subpaths then
      joinRelPath (concatMap splitRelPath subpaths)
    else
      # Otherwise we take our time to gather more info for a better error message
      # Strictly go through each path, throwing on the first invalid one
      # Tracks the list index in the fold accumulator
      foldl' (
        i: path:
        if isValid path then
          i + 1
        else
          throw ''
            lib.path.subpath.join: Element at index ${toString i} is not a valid subpath string:
                ${subpathInvalidReason path}''
      ) 0 subpaths;

  /**
    Split [a subpath](#function-library-lib.path.subpath.isValid) into its path component strings.
    Throw an error if the subpath isn't valid.
    Note that the returned path components are also [valid subpath strings](#function-library-lib.path.subpath.isValid), though they are intentionally not [normalised](#function-library-lib.path.subpath.normalise).

    Laws:

    - Splitting a subpath into components and [joining](#function-library-lib.path.subpath.join) the components gives the same subpath but [normalised](#function-library-lib.path.subpath.normalise):

          subpath.join (subpath.components s) == subpath.normalise s

    # Inputs

    `subpath`

    : The subpath string to split into components

    # Type

    ```
    subpath.components :: String -> [ String ]
    ```

    # Examples
    :::{.example}
    ## `subpath.components` usage example

    ```nix
    subpath.components "."
    => [ ]

    subpath.components "./foo//bar/./baz/"
    => [ "foo" "bar" "baz" ]

    subpath.components "/foo"
    => <error>
    ```

    :::
  */
  subpath.components =
    # The subpath string to split into components
    subpath:
    assert assertMsg (isValid subpath) ''
      lib.path.subpath.components: Argument is not a valid subpath string:
          ${subpathInvalidReason subpath}'';
    splitRelPath subpath;

  /**
    Normalise a subpath. Throw an error if the subpath isn't [valid](#function-library-lib.path.subpath.isValid).

    - Limit repeating `/` to a single one.

    - Remove redundant `.` components.

    - Remove trailing `/` and `/.`.

    - Add leading `./`.

    Laws:

    - Idempotency - normalising multiple times gives the same result:

          subpath.normalise (subpath.normalise p) == subpath.normalise p

    - Uniqueness - there's only a single normalisation for the paths that lead to the same file system node:

          subpath.normalise p != subpath.normalise q -> $(realpath ${p}) != $(realpath ${q})

    - Don't change the result when [appended](#function-library-lib.path.append) to a Nix path value:

          append base p == append base (subpath.normalise p)

    - Don't change the path according to `realpath`:

          $(realpath ${p}) == $(realpath ${subpath.normalise p})

    - Only error on [invalid subpaths](#function-library-lib.path.subpath.isValid):

          builtins.tryEval (subpath.normalise p)).success == subpath.isValid p

    # Inputs

    `subpath`

    : The subpath string to normalise

    # Type

    ```
    subpath.normalise :: String -> String
    ```

    # Examples
    :::{.example}
    ## `subpath.normalise` usage example

    ```nix
    # limit repeating `/` to a single one
    subpath.normalise "foo//bar"
    => "./foo/bar"

    # remove redundant `.` components
    subpath.normalise "foo/./bar"
    => "./foo/bar"

    # add leading `./`
    subpath.normalise "foo/bar"
    => "./foo/bar"

    # remove trailing `/`
    subpath.normalise "foo/bar/"
    => "./foo/bar"

    # remove trailing `/.`
    subpath.normalise "foo/bar/."
    => "./foo/bar"

    # Return the current directory as `./.`
    subpath.normalise "."
    => "./."

    # error on `..` path components
    subpath.normalise "foo/../bar"
    => <error>

    # error on empty string
    subpath.normalise ""
    => <error>

    # error on absolute path
    subpath.normalise "/foo"
    => <error>
    ```

    :::
  */
  subpath.normalise =
    # The subpath string to normalise
    subpath:
    assert assertMsg (isValid subpath) ''
      lib.path.subpath.normalise: Argument is not a valid subpath string:
          ${subpathInvalidReason subpath}'';
    joinRelPath (splitRelPath subpath);

}
</file>

<file path="lib/path/README.md">
# Path library

This document explains why the `lib.path` library is designed the way it is.

The purpose of this library is to process [filesystem paths].
It does not read files from the filesystem.
It exists to support the native Nix [path value type] with extra functionality.

[filesystem paths]: https://en.m.wikipedia.org/wiki/Path_(computing)
[path value type]: https://nixos.org/manual/nix/stable/language/values.html#type-path

As an extension of the path value type, it inherits the same intended use cases and limitations:
- Only use paths to access files at evaluation time, such as the local project source.
- Paths cannot point to derivations, so they are unfit to represent dependencies.
- A path implicitly imports the referenced files into the Nix store when interpolated to a string.
  Therefore paths are not suitable to access files at build- or run-time, as you risk importing the path from the evaluation system instead.

Overall, this library works with two types of paths:
- Absolute paths are represented with the Nix [path value type].
  Nix automatically normalises these paths.
- Subpaths are represented with the [string value type] since path value types don't support relative paths.
  This library normalises these paths as safely as possible.
  Absolute paths in strings are not supported.

  A subpath refers to a specific file or directory within an absolute base directory.
  It is a stricter form of a relative path, notably [without support for `..` components][parents] since those could escape the base directory.

[string value type]: https://nixos.org/manual/nix/stable/language/values.html#type-string

This library is designed to be as safe and intuitive as possible, throwing errors when operations are attempted that would produce surprising results, and giving the expected result otherwise.

This library is designed to work well as a dependency for the `lib.filesystem` and `lib.sources` library components.
Contrary to these library components, `lib.path` does not read any paths from the filesystem.

This library makes only these assumptions about paths and no others:
- `dirOf path` returns the path to the parent directory of `path`, unless `path` is the filesystem root, in which case `path` is returned.
  - There can be multiple filesystem roots: `p == dirOf p` and `q == dirOf q` does not imply `p == q`.
    - While there's only a single filesystem root in stable Nix, the [lazy trees feature](https://github.com/NixOS/nix/pull/6530) introduces [additional filesystem roots](https://github.com/NixOS/nix/pull/6530#discussion_r1041442173).
- `path + ("/" + string)` returns the path to the `string` subdirectory in `path`.
  - If `string` contains no `/` characters, then `dirOf (path + ("/" + string)) == path`.
  - If `string` contains no `/` characters, then `baseNameOf (path + ("/" + string)) == string`.
- `path1 == path2` returns `true` only if `path1` points to the same filesystem path as `path2`.

Notably we do not make the assumption that we can turn paths into strings using `toString path`.

## Design decisions

Each subsection here contains a decision along with arguments and counter-arguments for (+) and against (-) that decision.

### Leading dots for relative paths
[leading-dots]: #leading-dots-for-relative-paths

Observing: Since subpaths are a form of relative paths, they can have a leading `./` to indicate it being a relative path, this is generally not necessary for tools though.

Considering: Paths should be as explicit, consistent and unambiguous as possible.

Decision: Returned subpaths should always have a leading `./`.

<details>
<summary>Arguments</summary>

- (+) In shells, just running `foo` as a command wouldn't execute the file `foo`, whereas `./foo` would execute the file.
  In contrast, `foo/bar` does execute that file without the need for `./`.
  This can lead to confusion about when a `./` needs to be prefixed.
  If a `./` is always included, this becomes a non-issue.
  This effectively then means that paths don't overlap with command names.
- (+) Prepending with `./` makes the subpaths always valid as relative Nix path expressions.
- (+) Using paths in command line arguments could give problems if not escaped properly, e.g. if a path was `--version`.
  This is not a problem with `./--version`.
  This effectively then means that paths don't overlap with GNU-style command line options.
- (-) `./` is not required to resolve relative paths, resolution always has an implicit `./` as prefix.
- (-) It's less noisy without the `./`, e.g. in error messages.
  - (+) But similarly, it could be confusing whether something was even a path.
    e.g. `foo` could be anything, but `./foo` is more clearly a path.
- (+) Makes it more uniform with absolute paths (those always start with `/`).
  - (-) That is not relevant for practical purposes.
- (+) `find` also outputs results with `./`.
  - (-) But only if you give it an argument of `.`.
    If you give it the argument `some-directory`, it won't prefix that.
- (-) `realpath --relative-to` doesn't prefix relative paths with `./`.
  - (+) There is no need to return the same result as `realpath`.

</details>

### Representation of the current directory
[curdir]: #representation-of-the-current-directory

Observing: The subpath that produces the base directory can be represented with `.` or `./` or `./.`.

Considering: Paths should be as consistent and unambiguous as possible.

Decision: It should be `./.`.

<details>
<summary>Arguments</summary>

- (+) `./` would be inconsistent with [the decision to not persist trailing slashes][trailing-slashes].
- (-) `.` is how `realpath` normalises paths.
- (+) `.` can be interpreted as a shell command (it's a builtin for sourcing files in `bash` and `zsh`).
- (+) `.` would be the only path without a `/`.
  It could not be used as a Nix path expression, since those require at least one `/` to be parsed as such.
- (-) `./.` is rather long.
  - (-) We don't require users to type this though, as it's only output by the library.
    As inputs all three variants are supported for subpaths (and we can't do anything about absolute paths)
- (-) `builtins.dirOf "foo" == "."`, so `.` would be consistent with that.
- (+) `./.` is consistent with the [decision to have leading `./`][leading-dots].
- (+) `./.` is a valid Nix path expression, although this property does not hold for every relative path or subpath.

</details>

### Subpath representation
[relrepr]: #subpath-representation

Observing: Subpaths such as `foo/bar` can be represented in various ways:
- string: `"foo/bar"`
- list with all the components: `[ "foo" "bar" ]`
- attribute set: `{ type = "relative-path"; components = [ "foo" "bar" ]; }`

Considering: Paths should be as safe to use as possible.
We should generate string outputs in the library and not encourage users to do that themselves.

Decision: Paths are represented as strings.

<details>
<summary>Arguments</summary>

- (+) It's simpler for the users of the library.
  One doesn't have to convert a path a string before it can be used.
  - (+) Naively converting the list representation to a string with `concatStringsSep "/"` would break for `[]`, requiring library users to be more careful.
- (+) It doesn't encourage people to do their own path processing and instead use the library.
  With a list representation it would seem easy to just use `lib.lists.init` to get the parent directory, but then it breaks for `.`, which would be represented as `[ ]`.
- (+) `+` is convenient and doesn't work on lists and attribute sets.
  - (-) Shouldn't use `+` anyways, we export safer functions for path manipulation.

</details>

### Parent directory
[parents]: #parent-directory

Observing: Relative paths can have `..` components, which refer to the parent directory.

Considering: Paths should be as safe and unambiguous as possible.

Decision: `..` path components in string paths are not supported, neither as inputs nor as outputs.
Hence, string paths are called subpaths, rather than relative paths.

<details>
<summary>Arguments</summary>

- (+) If we wanted relative paths to behave according to the "physical" interpretation (as a directory tree with relations between nodes), it would require resolving symlinks, since e.g. `foo/..` would not be the same as `.` if `foo` is a symlink.
  - (-) The "logical" interpretation is also valid (treating paths as a sequence of names), and is used by some software.
    It is simpler, and not using symlinks at all is safer.
  - (+) Mixing both models can lead to surprises.
  - (+) We can't resolve symlinks without filesystem access.
  - (+) Nix also doesn't support reading symlinks at evaluation time.
  - (-) We could just not handle such cases, e.g. `equals "foo" "foo/bar/.. == false`.
    The paths are different, we don't need to check whether the paths point to the same thing.
    - (+) Assume we said `relativeTo /foo /bar == "../bar"`.
      If this is used like `/bar/../foo` in the end, and `bar` turns out to be a symlink to somewhere else, this won't be accurate.
      - (-) We could decide to not support such ambiguous operations, or mark them as such, e.g. the normal `relativeTo` will error on such a case, but there could be `extendedRelativeTo` supporting that.
- (-) `..` are a part of paths, a path library should therefore support it.
  - (+) If we can convincingly argue that all such use cases are better done e.g. with runtime tools, the library not supporting it can nudge people towards using those.
- (-) We could allow "..", but only in the prefix.
  - (+) Then we'd have to throw an error for doing `append /some/path "../foo"`, making it non-composable.
  - (+) The same is for returning paths with `..`: `relativeTo /foo /bar => "../bar"` would produce a non-composable path.
- (+) We argue that `..` is not needed at the Nix evaluation level, since we'd always start evaluation from the project root and don't go up from there.
  - (+) `..` is supported in Nix paths, turning them into absolute paths.
    - (-) This is ambiguous in the presence of symlinks.
- (+) If you need `..` for building or runtime, you can use build-/run-time tooling to create those (e.g. `realpath` with `--relative-to`), or use absolute paths instead.
  This also gives you the ability to correctly handle symlinks.

</details>

### Trailing slashes
[trailing-slashes]: #trailing-slashes

Observing: Subpaths can contain trailing slashes, like `foo/`, indicating that the path points to a directory and not a file.

Considering: Paths should be as consistent as possible, there should only be a single normalisation for the same path.

Decision: All functions remove trailing slashes in their results.

<details>
<summary>Arguments</summary>

- (+) It allows normalisations to be unique, in that there's only a single normalisation for the same path.
  If trailing slashes were preserved, both `foo/bar` and `foo/bar/` would be valid but different normalisations for the same path.
- Comparison to other frameworks to figure out the least surprising behavior:
  - (+) Nix itself doesn't support trailing slashes when parsing and doesn't preserve them when appending paths.
  - (-) [Rust's std::path](https://doc.rust-lang.org/std/path/index.html) does preserve them during [construction](https://doc.rust-lang.org/std/path/struct.Path.html#method.new).
    - (+) Doesn't preserve them when returning individual [components](https://doc.rust-lang.org/std/path/struct.Path.html#method.components).
    - (+) Doesn't preserve them when [canonicalizing](https://doc.rust-lang.org/std/path/struct.Path.html#method.canonicalize).
  - (+) [Python 3's pathlib](https://docs.python.org/3/library/pathlib.html#module-pathlib) doesn't preserve them during [construction](https://docs.python.org/3/library/pathlib.html#pathlib.PurePath).
    - Notably it represents the individual components as a list internally.
  - (-) [Haskell's filepath](https://hackage.haskell.org/package/filepath-1.4.100.0) has [explicit support](https://hackage.haskell.org/package/filepath-1.4.100.0/docs/System-FilePath.html#g:6) for handling trailing slashes.
    - (-) Does preserve them for [normalisation](https://hackage.haskell.org/package/filepath-1.4.100.0/docs/System-FilePath.html#v:normalise).
  - (-) [NodeJS's Path library](https://nodejs.org/api/path.html) preserves trailing slashes for [normalisation](https://nodejs.org/api/path.html#pathnormalizepath).
    - (+) For [parsing a path](https://nodejs.org/api/path.html#pathparsepath) into its significant elements, trailing slashes are not preserved.
- (+) Nix's builtin function `dirOf` gives an unexpected result for paths with trailing slashes: `dirOf "foo/bar/" == "foo/bar"`.
  Inconsistently, `baseNameOf` works correctly though: `baseNameOf "foo/bar/" == "bar"`.
  - (-) We are writing a path library to improve handling of paths though, so we shouldn't use these functions and discourage their use.
- (-) Unexpected result when normalising intermediate paths, like `relative.normalise ("foo" + "/") + "bar" == "foobar"`.
  - (+) This is not a practical use case though.
  - (+) Don't use `+` to append paths, this library has a `join` function for that.
    - (-) Users might use `+` out of habit though.
- (+) The `realpath` command also removes trailing slashes.
- (+) Even with a trailing slash, the path is the same, it's only an indication that it's a directory.

</details>

### Prefer returning subpaths over components
[subpath-preference]: #prefer-returning-subpaths-over-components

Observing: Functions could return subpaths or lists of path component strings.

Considering: Subpaths are used as inputs for some functions.
Using them for outputs, too, makes the library more consistent and composable.

Decision: Subpaths should be preferred over list of path component strings.

<details>
<summary>Arguments</summary>

- (+) It is consistent with functions accepting subpaths, making the library more composable
- (-) It is less efficient when the components are needed, because after creating the normalised subpath string, it will have to be parsed into components again
  - (+) If necessary, we can still make it faster by adding builtins to Nix
  - (+) Alternatively if necessary, versions of these functions that return components could later still be introduced.
- (+) It makes the path library simpler because there's only two types (paths and subpaths).
  Only `lib.path.subpath.components` can be used to get a list of components.
  And once we have a list of component strings, `lib.lists` and `lib.strings` can be used to operate on them.
  For completeness, `lib.path.subpath.join` allows converting the list of components back to a subpath.
</details>

## Other implementations and references

- [Rust](https://doc.rust-lang.org/std/path/struct.Path.html)
- [Python](https://docs.python.org/3/library/pathlib.html)
- [Haskell](https://hackage.haskell.org/package/filepath-1.4.100.0/docs/System-FilePath.html)
- [Nodejs](https://nodejs.org/api/path.html)
- [POSIX.1-2017](https://pubs.opengroup.org/onlinepubs/9699919799/nframe.html)
</file>

<file path="lib/systems/architectures.nix">
{ lib }:

rec {
  # gcc.arch to its features (as in /proc/cpuinfo)
  features = {
    # x86_64 Generic
    # Spec: https://gitlab.com/x86-psABIs/x86-64-ABI/
    default = [ ];
    x86-64 = [ ];
    x86-64-v2 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
    ];
    x86-64-v3 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
      "avx2"
      "fma"
    ];
    x86-64-v4 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    # x86_64 Intel
    nehalem = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
    ];
    westmere = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
    ];
    silvermont = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
    ];
    sandybridge = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
    ];
    ivybridge = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
    ];
    haswell = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
      "avx2"
      "fma"
    ];
    broadwell = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "avx"
      "avx2"
      "fma"
    ];
    skylake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    skylake-avx512 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    cannonlake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    icelake-client = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    icelake-server = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    cascadelake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    cooperlake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    tigerlake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    alderlake = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    sapphirerapids = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    emeraldrapids = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    sierraforest = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    # x86_64 AMD
    btver1 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
    ];
    btver2 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "aes"
      "avx"
    ];
    bdver1 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "fma"
      "fma4"
    ];
    bdver2 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "fma"
      "fma4"
    ];
    bdver3 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "fma"
      "fma4"
    ];
    bdver4 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "fma"
      "fma4"
    ];
    znver1 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    znver2 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    znver3 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "fma"
    ];
    znver4 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    znver5 = [
      "sse3"
      "ssse3"
      "sse4_1"
      "sse4_2"
      "sse4a"
      "aes"
      "avx"
      "avx2"
      "avx512"
      "fma"
    ];
    # LoongArch64
    # https://github.com/loongson/la-toolchain-conventions
    loongarch64 = [
      "fpu64"
    ];
    la464 = [
      "fpu64"
      "lsx"
      "lasx"
    ];
    la664 = [
      "fpu64"
      "lsx"
      "lasx"
      "div32"
      "frecipe"
      "lam-bh"
      "lamcas"
      "ld-seq-sa"
    ];
    "la64v1.0" = [
      "fpu64"
      "lsx"
    ];
    "la64v1.1" = [
      "fpu64"
      "lsx"
      "div32"
      "frecipe"
      "lam-bh"
      "lamcas"
      "ld-seq-sa"
    ];
    # other
    armv5te = [ ];
    armv6 = [ ];
    armv7-a = [ ];
    armv8-a = [ ];
    mips32 = [ ];
    loongson2f = [ ];
  };

  # a superior CPU has all the features of an inferior and is able to build and test code for it
  inferiors =
    let
      withInferiors = archs: lib.unique (archs ++ lib.flatten (lib.attrVals archs inferiors));
    in
    {
      # x86_64 Generic
      default = [ ];
      x86-64 = [ ];
      x86-64-v2 = [ "x86-64" ];
      x86-64-v3 = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      x86-64-v4 = [ "x86-64-v3" ] ++ inferiors.x86-64-v3;

      # x86_64 Intel
      # https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html
      nehalem = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      westmere = [ "nehalem" ] ++ inferiors.nehalem;
      sandybridge = [ "westmere" ] ++ inferiors.westmere;
      ivybridge = [ "sandybridge" ] ++ inferiors.sandybridge;

      haswell = lib.unique (
        [
          "ivybridge"
          "x86-64-v3"
        ]
        ++ inferiors.ivybridge
        ++ inferiors.x86-64-v3
      );
      broadwell = [ "haswell" ] ++ inferiors.haswell;
      skylake = [ "broadwell" ] ++ inferiors.broadwell;

      skylake-avx512 = lib.unique (
        [
          "skylake"
          "x86-64-v4"
        ]
        ++ inferiors.skylake
        ++ inferiors.x86-64-v4
      );
      cannonlake = [ "skylake-avx512" ] ++ inferiors.skylake-avx512;
      icelake-client = [ "cannonlake" ] ++ inferiors.cannonlake;
      icelake-server = [ "icelake-client" ] ++ inferiors.icelake-client;
      cascadelake = [ "cannonlake" ] ++ inferiors.cannonlake;
      cooperlake = [ "cascadelake" ] ++ inferiors.cascadelake;
      tigerlake = [ "icelake-server" ] ++ inferiors.icelake-server;
      sapphirerapids = [ "tigerlake" ] ++ inferiors.tigerlake;
      emeraldrapids = [ "sapphirerapids" ] ++ inferiors.sapphirerapids;

      alderlake = [ "skylake" ] ++ inferiors.skylake;
      sierraforest = [ "alderlake" ] ++ inferiors.alderlake;

      # x86_64 AMD
      # TODO: fill in specific CPU architecture inferiors
      btver1 = [ "x86-64" ];
      btver2 = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      bdver1 = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      bdver2 = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      bdver3 = [ "x86-64-v2" ] ++ inferiors.x86-64-v2;
      bdver4 = [ "x86-64-v3" ] ++ inferiors.x86-64-v3;
      # Regarding `skylake` as inferior of `znver1`, there are reports of
      # successful usage by Gentoo users and Phoronix benchmarking of different
      # `-march` targets.
      #
      # The GCC documentation on extensions used and wikichip documentation
      # regarding supperted extensions on znver1 and skylake was used to create
      # this partial order.
      #
      # Note:
      #
      # - The successors of `skylake` (`cannonlake`, `icelake`, etc) use `avx512`
      #   which no current AMD Zen michroarch support.
      # - `znver1` uses `ABM`, `CLZERO`, `CX16`, `MWAITX`, and `SSE4A` which no
      #   current Intel microarch support.
      #
      # https://www.phoronix.com/scan.php?page=article&item=amd-znver3-gcc11&num=1
      # https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html
      # https://en.wikichip.org/wiki/amd/microarchitectures/zen
      # https://en.wikichip.org/wiki/intel/microarchitectures/skylake
      znver1 = [ "skylake" ] ++ inferiors.skylake; # Includes haswell and x86-64-v3
      znver2 = [ "znver1" ] ++ inferiors.znver1;
      znver3 = [ "znver2" ] ++ inferiors.znver2;
      znver4 = lib.unique (
        [
          "znver3"
          "x86-64-v4"
        ]
        ++ inferiors.znver3
        ++ inferiors.x86-64-v4
      );
      znver5 = [ "znver4" ] ++ inferiors.znver4;

      # ARM64 (AArch64)
      armv8-a = [ ];
      "armv8.1-a" = [ "armv8-a" ];
      "armv8.2-a" = [ "armv8.1-a" ] ++ inferiors."armv8.1-a";
      "armv8.3-a" = [ "armv8.2-a" ] ++ inferiors."armv8.2-a";
      "armv8.4-a" = [ "armv8.3-a" ] ++ inferiors."armv8.3-a";
      "armv8.5-a" = [ "armv8.4-a" ] ++ inferiors."armv8.4-a";
      "armv8.6-a" = [ "armv8.5-a" ] ++ inferiors."armv8.5-a";
      "armv8.7-a" = [ "armv8.6-a" ] ++ inferiors."armv8.6-a";
      "armv8.8-a" = [ "armv8.7-a" ] ++ inferiors."armv8.7-a";
      "armv8.9-a" = [ "armv8.8-a" ] ++ inferiors."armv8.8-a";
      armv9-a = [ "armv8.5-a" ] ++ inferiors."armv8.5-a";
      "armv9.1-a" = [
        "armv9-a"
        "armv8.6-a"
      ]
      ++ inferiors."armv8.6-a";
      "armv9.2-a" = lib.unique (
        [
          "armv9.1-a"
          "armv8.7-a"
        ]
        ++ inferiors."armv9.1-a"
        ++ inferiors."armv8.7-a"
      );
      "armv9.3-a" = lib.unique (
        [
          "armv9.2-a"
          "armv8.8-a"
        ]
        ++ inferiors."armv9.2-a"
        ++ inferiors."armv8.8-a"
      );
      "armv9.4-a" = [ "armv9.3-a" ] ++ inferiors."armv9.3-a";

      # ARM
      cortex-a53 = [ "armv8-a" ];
      cortex-a72 = [ "armv8-a" ];
      cortex-a55 = [
        "armv8.2-a"
        "cortex-a53"
        "cortex-a72"
      ]
      ++ inferiors."armv8.2-a";
      cortex-a76 = [
        "armv8.2-a"
        "cortex-a53"
        "cortex-a72"
      ]
      ++ inferiors."armv8.2-a";

      # Ampere
      ampere1 = withInferiors [
        "armv8.6-a"
        "cortex-a55"
        "cortex-a76"
      ];
      ampere1a = [ "ampere1" ] ++ inferiors.ampere1;
      ampere1b = [ "ampere1a" ] ++ inferiors.ampere1a;

      # LoongArch64
      loongarch64 = [ ];
      "la64v1.0" = [ "loongarch64" ];
      la464 = [ "la64v1.0" ] ++ inferiors."la64v1.0";
      "la64v1.1" = [ "la64v1.0" ] ++ inferiors."la64v1.0";
      la664 = withInferiors [
        "la464"
        "la64v1.1"
      ];

      # other
      armv5te = [ ];
      armv6 = [ ];
      armv7-a = [ ];
      mips32 = [ ];
      loongson2f = [ ];
    };

  /**
    Check whether one GCC architecture has the the other inferior architecture.

    # Inputs

    `arch1`
    : GCC architecture in string

    `arch2`
    : GCC architecture in string

    # Type

    ```
    hasInferior :: string -> string -> bool
    ```

    # Examples
    ::: {.example}
    ## `lib.systems.architectures.hasInferior` usage example

    ```nix
    hasInferior "x86-64-v3" "x86-64"
    => true
    hasInferior "x86-64" "x86-64-v3"
    => false
    hasInferior "x86-64" "x86-64"
    => false
    ```
  */
  hasInferior = arch1: arch2: inferiors ? ${arch1} && lib.elem arch2 inferiors.${arch1};

  /**
    Check whether one GCC architecture can execute the other.

    # Inputs

    `arch1`
    : GCC architecture in string

    `arch2`
    : GCC architecture in string

    # Type

    ```
    canExecute :: string -> string -> bool
    ```

    # Examples
    ::: {.example}
    ## `lib.systems.architectures.canExecute` usage example

    ```nix
    canExecute "x86-64" "x86-64-v3"
    => false
    canExecute "x86-64-v3" "x86-64"
    => true
    canExecute "x86-64" "x86-64"
    => true
    ```
  */
  canExecute = arch1: arch2: arch1 == arch2 || hasInferior arch1 arch2;

  predicates =
    let
      featureSupport = feature: x: builtins.elem feature features.${x} or [ ];
    in
    {
      sse3Support = featureSupport "sse3";
      ssse3Support = featureSupport "ssse3";
      sse4_1Support = featureSupport "sse4_1";
      sse4_2Support = featureSupport "sse4_2";
      sse4_aSupport = featureSupport "sse4a";
      avxSupport = featureSupport "avx";
      avx2Support = featureSupport "avx2";
      avx512Support = featureSupport "avx512";
      aesSupport = featureSupport "aes";
      fmaSupport = featureSupport "fma";
      fma4Support = featureSupport "fma4";
      lsxSupport = featureSupport "lsx";
      lasxSupport = featureSupport "lasx";
    };
}
</file>

<file path="lib/systems/default.nix">
{ lib }:

let
  inherit (lib)
    any
    filterAttrs
    foldl
    hasInfix
    isAttrs
    isFunction
    isList
    mapAttrs
    optional
    optionalAttrs
    optionalString
    removeSuffix
    replaceString
    toUpper
    ;

  inherit (lib.strings) toJSON;

  doubles = import ./doubles.nix { inherit lib; };
  parse = import ./parse.nix { inherit lib; };
  inspect = import ./inspect.nix { inherit lib; };
  platforms = import ./platforms.nix { inherit lib; };
  examples = import ./examples.nix { inherit lib; };
  architectures = import ./architectures.nix { inherit lib; };

  /**
    Elaborated systems contain functions, which means that they don't satisfy
    `==` for a lack of reflexivity.

    They might *appear* to satisfy `==` reflexivity when the same exact value is
    compared to itself, because object identity is used as an "optimization";
    compare the value with a reconstruction of itself, e.g. with `f == a: f a`,
    or perhaps calling `elaborate` twice, and one will see reflexivity fail as described.

    Hence a custom equality test.

    Note that this does not canonicalize the systems, so you'll want to make sure
    both arguments have been `elaborate`-d.
  */
  equals =
    let
      removeFunctions = a: filterAttrs (_: v: !isFunction v) a;
    in
    a: b: removeFunctions a == removeFunctions b;

  /**
    List of all Nix system doubles the nixpkgs flake will expose the package set
    for. All systems listed here must be supported by nixpkgs as `localSystem`.

    :::{.warning}
    This attribute is considered experimental and is subject to change.
    :::
  */
  flakeExposed = import ./flake-systems.nix { };

  # Turn localSystem or crossSystem, which could be system-string or attrset, into
  # attrset.
  systemToAttrs =
    systemOrArgs: if isAttrs systemOrArgs then systemOrArgs else { system = systemOrArgs; };

  # Elaborate a `localSystem` or `crossSystem` so that it contains everything
  # necessary.
  #
  # `parsed` is inferred from args, both because there are two options with one
  # clearly preferred, and to prevent cycles. A simpler fixed point where the RHS
  # always just used `final.*` would fail on both counts.
  elaborate =
    systemOrArgs:
    let
      allArgs = systemToAttrs systemOrArgs;

      # Those two will always be derived from "config", if given, so they should NOT
      # be overridden further down with "// args".
      args = builtins.removeAttrs allArgs [
        "parsed"
        "system"
      ];

      # TODO: deprecate args.rustc in favour of args.rust after 23.05 is EOL.
      rust = args.rust or args.rustc or { };

      final = {
        # Prefer to parse `config` as it is strictly more informative.
        parsed = parse.mkSystemFromString (args.config or allArgs.system);
        # This can be losslessly-extracted from `parsed` iff parsing succeeds.
        system = parse.doubleFromSystem final.parsed;
        # TODO: This currently can't be losslessly-extracted from `parsed`, for example
        # because of -mingw32.
        config = parse.tripleFromSystem final.parsed;
        # Determine whether we can execute binaries built for the provided platform.
        canExecute =
          platform:
          final.isAndroid == platform.isAndroid
          && parse.isCompatible final.parsed.cpu platform.parsed.cpu
          && final.parsed.kernel == platform.parsed.kernel
          && (
            # Only perform this check when cpus have the same type;
            # assume compatible cpu have all the instructions included
            final.parsed.cpu == platform.parsed.cpu
            ->
              # if both have gcc.arch defined, check whether final can execute the given platform
              (
                (final ? gcc.arch && platform ? gcc.arch)
                -> architectures.canExecute final.gcc.arch platform.gcc.arch
              )
              # if platform has gcc.arch defined but final doesn't, don't assume it can be executed
              || (platform ? gcc.arch -> !(final ? gcc.arch))
          );

        isCompatible =
          _:
          throw "2022-05-23: isCompatible has been removed in favor of canExecute, refer to the 22.11 changelog for details";
        # Derived meta-data
        useLLVM = final.isFreeBSD || final.isOpenBSD;

        libc =
          if final.isDarwin then
            "libSystem"
          else if final.isMsvc then
            "ucrt"
          else if final.isMinGW then
            "msvcrt"
          else if final.isWasi then
            "wasilibc"
          else if final.isWasm && !final.isWasi then
            null
          else if final.isRedox then
            "relibc"
          else if final.isMusl then
            "musl"
          else if final.isUClibc then
            "uclibc"
          else if final.isAndroid then
            "bionic"
          else if
            final.isLinux # default
          then
            "glibc"
          else if final.isFreeBSD then
            "fblibc"
          else if final.isOpenBSD then
            "oblibc"
          else if final.isNetBSD then
            "nblibc"
          else if final.isAvr then
            "avrlibc"
          else if final.isGhcjs then
            null
          else if final.isNone then
            "newlib"
          # TODO(@Ericson2314) think more about other operating systems
          else
            "native/impure";
        # Choose what linker we wish to use by default. Someday we might also
        # choose the C compiler, runtime library, C++ standard library, etc. in
        # this way, nice and orthogonally, and deprecate `useLLVM`. But due to
        # the monolithic GCC build we cannot actually make those choices
        # independently, so we are just doing `linker` and keeping `useLLVM` for
        # now.
        linker =
          if final.useLLVM or false then
            "lld"
          else if final.isDarwin then
            "cctools"
          # "bfd" and "gold" both come from GNU binutils. The existence of Gold
          # is why we use the more obscure "bfd" and not "binutils" for this
          # choice.
          else
            "bfd";
        # The standard lib directory name that non-nixpkgs binaries distributed
        # for this platform normally assume.
        libDir =
          if final.isLinux then
            if final.isx86_64 || final.isMips64 || final.isPower64 then "lib64" else "lib"
          else
            null;
        extensions =
          optionalAttrs final.hasSharedLibraries {
            sharedLibrary =
              if final.isDarwin then
                ".dylib"
              else if final.isWindows then
                ".dll"
              else
                ".so";
          }
          // {
            staticLibrary = if final.isWindows then ".lib" else ".a";
            library = if final.isStatic then final.extensions.staticLibrary else final.extensions.sharedLibrary;
            executable = if final.isWindows then ".exe" else "";
          };
        # Misc boolean options
        useAndroidPrebuilt = false;
        useiOSPrebuilt = false;

        # Output from uname
        uname = {
          # uname -s
          system =
            {
              linux = "Linux";
              windows = "Windows";
              darwin = "Darwin";
              netbsd = "NetBSD";
              freebsd = "FreeBSD";
              openbsd = "OpenBSD";
              wasi = "Wasi";
              redox = "Redox";
              genode = "Genode";
            }
            .${final.parsed.kernel.name} or null;

          # uname -m
          processor =
            if final.isPower64 then
              "ppc64${optionalString final.isLittleEndian "le"}"
            else if final.isPower then
              "ppc${optionalString final.isLittleEndian "le"}"
            else if final.isMips64 then
              "mips64" # endianness is *not* included on mips64
            else if final.isDarwin then
              final.darwinArch
            else
              final.parsed.cpu.name;

          # uname -r
          release = null;
        };

        # It is important that hasSharedLibraries==false when the platform has no
        # dynamic library loader.  Various tools (including the gcc build system)
        # have knowledge of which platforms are incapable of dynamic linking, and
        # will still build on/for those platforms with --enable-shared, but simply
        # omit any `.so` build products such as libgcc_s.so.  When that happens,
        # it causes hard-to-troubleshoot build failures.
        hasSharedLibraries =
          with final;
          (
            isAndroid
            || isGnu
            || isMusl # Linux (allows multiple libcs)
            || isDarwin
            || isSunOS
            || isOpenBSD
            || isFreeBSD
            || isNetBSD # BSDs
            || isCygwin
            || isMinGW
            || isWindows # Windows
            || isWasm # WASM
          )
          && !isStatic;

        # The difference between `isStatic` and `hasSharedLibraries` is mainly the
        # addition of the `staticMarker` (see make-derivation.nix).  Some
        # platforms, like embedded machines without a libc (e.g. arm-none-eabi)
        # don't support dynamic linking, but don't get the `staticMarker`.
        # `pkgsStatic` sets `isStatic=true`, so `pkgsStatic.hostPlatform` always
        # has the `staticMarker`.
        isStatic = final.isWasi || final.isRedox;

        # Just a guess, based on `system`
        inherit
          (
            {
              linux-kernel = args.linux-kernel or { };
              gcc = args.gcc or { };
            }
            // platforms.select final
          )
          linux-kernel
          gcc
          ;

        # TODO: remove after 23.05 is EOL, with an error pointing to the rust.* attrs.
        rustc = args.rustc or { };

        linuxArch =
          if final.isAarch32 then
            "arm"
          else if final.isAarch64 then
            "arm64"
          else if final.isx86_32 then
            "i386"
          else if final.isx86_64 then
            "x86_64"
          # linux kernel does not distinguish microblaze/microblazeel
          else if final.isMicroBlaze then
            "microblaze"
          else if final.isMips32 then
            "mips"
          else if final.isMips64 then
            "mips" # linux kernel does not distinguish mips32/mips64
          else if final.isPower then
            "powerpc"
          else if final.isRiscV then
            "riscv"
          else if final.isS390 then
            "s390"
          else if final.isLoongArch64 then
            "loongarch"
          else
            final.parsed.cpu.name;

        # https://source.denx.de/u-boot/u-boot/-/blob/9bfb567e5f1bfe7de8eb41f8c6d00f49d2b9a426/common/image.c#L81-106
        ubootArch =
          if final.isx86_32 then
            "x86" # not i386
          else if final.isMips64 then
            "mips64" # uboot *does* distinguish between mips32/mips64
          else
            final.linuxArch; # other cases appear to agree with linuxArch

        qemuArch =
          if final.isAarch32 then
            "arm"
          else if final.isAarch64 then
            "aarch64"
          else if final.isS390 && !final.isS390x then
            null
          else if final.isx86_64 then
            "x86_64"
          else if final.isx86 then
            "i386"
          else if final.isMips64n32 then
            "mipsn32${optionalString final.isLittleEndian "el"}"
          else if final.isMips64 then
            "mips64${optionalString final.isLittleEndian "el"}"
          else
            final.uname.processor;

        # Name used by UEFI for architectures.
        efiArch =
          if final.isx86_32 then
            "ia32"
          else if final.isx86_64 then
            "x64"
          else if final.isAarch32 then
            "arm"
          else if final.isAarch64 then
            "aa64"
          else
            final.parsed.cpu.name;

        darwinArch = parse.darwinArch final.parsed.cpu;

        darwinPlatform =
          if final.isMacOS then
            "macos"
          else if final.isiOS then
            "ios"
          else
            null;
        # The canonical name for this attribute is darwinSdkVersion, but some
        # platforms define the old name "sdkVer".
        darwinSdkVersion = final.sdkVer or "11.3";
        darwinMinVersion = final.darwinSdkVersion;
        darwinMinVersionVariable =
          if final.isMacOS then
            "MACOSX_DEPLOYMENT_TARGET"
          else if final.isiOS then
            "IPHONEOS_DEPLOYMENT_TARGET"
          else
            null;

        # Handle Android SDK and NDK versions.
        androidSdkVersion = args.androidSdkVersion or null;
        androidNdkVersion = args.androidNdkVersion or null;
      }
      // (
        let
          selectEmulator =
            pkgs:
            let
              wine = (pkgs.winePackagesFor "wine${toString final.parsed.cpu.bits}").minimal;
            in
            # Note: we guarantee that the return value is either `null` or a path
            # to an emulator program. That is, if an emulator requires additional
            # arguments, a wrapper should be used.
            if pkgs.stdenv.hostPlatform.canExecute final then
              lib.getExe (pkgs.writeShellScriptBin "exec" ''exec "$@"'')
            else if final.isWindows then
              "${wine}/bin/wine${optionalString (final.parsed.cpu.bits == 64) "64"}"
            else if final.isLinux && pkgs.stdenv.hostPlatform.isLinux && final.qemuArch != null then
              "${pkgs.qemu-user}/bin/qemu-${final.qemuArch}"
            else if final.isWasi then
              "${pkgs.wasmtime}/bin/wasmtime"
            else if final.isMmix then
              "${pkgs.mmixware}/bin/mmix"
            else
              null;
        in
        {
          emulatorAvailable = pkgs: (selectEmulator pkgs) != null;

          # whether final.emulator pkgs.pkgsStatic works
          staticEmulatorAvailable =
            pkgs: final.emulatorAvailable pkgs && (final.isLinux || final.isWasi || final.isMmix);

          emulator =
            pkgs:
            if (final.emulatorAvailable pkgs) then
              selectEmulator pkgs
            else
              throw "Don't know how to run ${final.config} executables.";

        }
      )
      // mapAttrs (n: v: v final.parsed) inspect.predicates
      // mapAttrs (n: v: v final.gcc.arch or "default") architectures.predicates
      // args
      // {
        rust = rust // {
          # Once args.rustc.platform.target-family is deprecated and
          # removed, there will no longer be any need to modify any
          # values from args.rust.platform, so we can drop all the
          # "args ? rust" etc. checks, and merge args.rust.platform in
          # /after/.
          platform = rust.platform or { } // {
            # https://doc.rust-lang.org/reference/conditional-compilation.html#target_arch
            arch =
              if rust ? platform then
                rust.platform.arch
              else if final.isAarch32 then
                "arm"
              else if final.isMips64 then
                "mips64" # never add "el" suffix
              else if final.isPower64 then
                "powerpc64" # never add "le" suffix
              else
                final.parsed.cpu.name;

            # https://doc.rust-lang.org/reference/conditional-compilation.html#target_os
            os =
              if rust ? platform then
                rust.platform.os or "none"
              else if final.isDarwin then
                "macos"
              else if final.isWasm && !final.isWasi then
                "unknown" # Needed for {wasm32,wasm64}-unknown-unknown.
              else
                final.parsed.kernel.name;

            # https://doc.rust-lang.org/reference/conditional-compilation.html#target_family
            target-family =
              if args ? rust.platform.target-family then
                args.rust.platform.target-family
              else if args ? rustc.platform.target-family then
                (
                  # Since https://github.com/rust-lang/rust/pull/84072
                  # `target-family` is a list instead of single value.
                  let
                    f = args.rustc.platform.target-family;
                  in
                  if isList f then f else [ f ]
                )
              else
                optional final.isUnix "unix" ++ optional final.isWindows "windows" ++ optional final.isWasm "wasm";

            # https://doc.rust-lang.org/reference/conditional-compilation.html#target_vendor
            vendor =
              let
                inherit (final.parsed) vendor;
              in
              rust.platform.vendor or {
                "w64" = "pc";
              }
              .${vendor.name} or vendor.name;
          };

          # The name of the rust target, even if it is custom. Adjustments are
          # because rust has slightly different naming conventions than we do.
          rustcTarget =
            let
              inherit (final.parsed) cpu kernel abi;
              cpu_ =
                rust.platform.arch or {
                  "armv7a" = "armv7";
                  "armv7l" = "armv7";
                  "armv6l" = "arm";
                  "armv5tel" = "armv5te";
                  "riscv32" = "riscv32gc";
                  "riscv64" = "riscv64gc";
                }
                .${cpu.name} or cpu.name;
              vendor_ = final.rust.platform.vendor;
            in
            # TODO: deprecate args.rustc in favour of args.rust after 23.05 is EOL.
            args.rust.rustcTarget or args.rustc.config or (
              # Rust uses `wasm32-wasip?` rather than `wasm32-unknown-wasi`.
              # We cannot know which subversion does the user want, and
              # currently use WASI 0.1 as default for compatibility. Custom
              # users can set `rust.rustcTarget` to override it.
              if final.isWasi then
                "${cpu_}-wasip1"
              else
                "${cpu_}-${vendor_}-${kernel.name}${optionalString (abi.name != "unknown") "-${abi.name}"}"
            );

          # The name of the rust target if it is standard, or the json file
          # containing the custom target spec.
          rustcTargetSpec =
            rust.rustcTargetSpec or (
              if rust ? platform then
                builtins.toFile (final.rust.rustcTarget + ".json") (toJSON rust.platform)
              else
                final.rust.rustcTarget
            );

          # The name of the rust target if it is standard, or the
          # basename of the file containing the custom target spec,
          # without the .json extension.
          #
          # This is the name used by Cargo for target subdirectories.
          cargoShortTarget = removeSuffix ".json" (baseNameOf "${final.rust.rustcTargetSpec}");

          # When used as part of an environment variable name, triples are
          # uppercased and have all hyphens replaced by underscores:
          #
          # https://github.com/rust-lang/cargo/pull/9169
          # https://github.com/rust-lang/cargo/issues/8285#issuecomment-634202431
          cargoEnvVarTarget = replaceString "-" "_" (toUpper final.rust.cargoShortTarget);

          # True if the target is no_std
          # https://github.com/rust-lang/rust/blob/2e44c17c12cec45b6a682b1e53a04ac5b5fcc9d2/src/bootstrap/config.rs#L415-L421
          isNoStdTarget = any (t: hasInfix t final.rust.rustcTarget) [
            "-none"
            "nvptx"
            "switch"
            "-uefi"
          ];
        };
      }
      // {
        go = {
          # See https://pkg.go.dev/internal/platform for a list of known platforms
          GOARCH =
            {
              "aarch64" = "arm64";
              "arm" = "arm";
              "armv5tel" = "arm";
              "armv6l" = "arm";
              "armv7l" = "arm";
              "i686" = "386";
              "loongarch64" = "loong64";
              "mips" = "mips";
              "mips64el" = "mips64le";
              "mipsel" = "mipsle";
              "powerpc64" = "ppc64";
              "powerpc64le" = "ppc64le";
              "riscv64" = "riscv64";
              "s390x" = "s390x";
              "x86_64" = "amd64";
              "wasm32" = "wasm";
            }
            .${final.parsed.cpu.name} or null;
          GOOS = if final.isWasi then "wasip1" else final.parsed.kernel.name;

          # See https://go.dev/wiki/GoArm
          GOARM = toString (lib.intersectLists [ (final.parsed.cpu.version or "") ] [ "5" "6" "7" ]);
        };
      };
    in
    assert final.useAndroidPrebuilt -> final.isAndroid;
    assert foldl (pass: { assertion, message }: if assertion final then pass else throw message) true (
      final.parsed.abi.assertions or [ ]
    );
    final;

in

# Everything in this attrset is the public interface of the file.
{
  inherit
    architectures
    doubles
    elaborate
    equals
    examples
    flakeExposed
    inspect
    parse
    platforms
    systemToAttrs
    ;
}
</file>

<file path="lib/systems/doubles.nix">
{ lib }:
let
  inherit (lib) lists;
  inherit (lib.systems) parse;
  inherit (lib.systems.inspect) predicates;
  inherit (lib.attrsets) matchAttrs;

  all = [
    # Cygwin
    "i686-cygwin"
    "x86_64-cygwin"

    # Darwin
    "x86_64-darwin"
    "aarch64-darwin"

    # FreeBSD
    "i686-freebsd"
    "x86_64-freebsd"
    "aarch64-freebsd"

    # Genode
    "aarch64-genode"
    "i686-genode"
    "x86_64-genode"

    # illumos
    "x86_64-solaris"

    # JS
    "javascript-ghcjs"

    # Linux
    "aarch64-linux"
    "armv5tel-linux"
    "armv6l-linux"
    "armv7a-linux"
    "armv7l-linux"
    "i686-linux"
    "loongarch64-linux"
    "m68k-linux"
    "microblaze-linux"
    "microblazeel-linux"
    "mips-linux"
    "mips64-linux"
    "mips64el-linux"
    "mipsel-linux"
    "powerpc64-linux"
    "powerpc64le-linux"
    "riscv32-linux"
    "riscv64-linux"
    "s390-linux"
    "s390x-linux"
    "x86_64-linux"

    # MMIXware
    "mmix-mmixware"

    # NetBSD
    "aarch64-netbsd"
    "armv6l-netbsd"
    "armv7a-netbsd"
    "armv7l-netbsd"
    "i686-netbsd"
    "m68k-netbsd"
    "mipsel-netbsd"
    "powerpc-netbsd"
    "riscv32-netbsd"
    "riscv64-netbsd"
    "x86_64-netbsd"

    # none
    "aarch64_be-none"
    "aarch64-none"
    "arm-none"
    "armv6l-none"
    "avr-none"
    "i686-none"
    "microblaze-none"
    "microblazeel-none"
    "mips-none"
    "mips64-none"
    "msp430-none"
    "or1k-none"
    "m68k-none"
    "powerpc-none"
    "powerpcle-none"
    "riscv32-none"
    "riscv64-none"
    "rx-none"
    "s390-none"
    "s390x-none"
    "vc4-none"
    "x86_64-none"

    # OpenBSD
    "i686-openbsd"
    "x86_64-openbsd"

    # Redox
    "x86_64-redox"

    # WASI
    "wasm64-wasi"
    "wasm32-wasi"

    # Windows
    "aarch64-windows"
    "x86_64-windows"
    "i686-windows"
  ];

  allParsed = map parse.mkSystemFromString all;

  filterDoubles = f: map parse.doubleFromSystem (lists.filter f allParsed);

in
{
  inherit all;

  none = [ ];

  arm = filterDoubles predicates.isAarch32;
  armv7 = filterDoubles predicates.isArmv7;
  aarch = filterDoubles predicates.isAarch;
  aarch64 = filterDoubles predicates.isAarch64;
  x86 = filterDoubles predicates.isx86;
  i686 = filterDoubles predicates.isi686;
  x86_64 = filterDoubles predicates.isx86_64;
  microblaze = filterDoubles predicates.isMicroBlaze;
  mips = filterDoubles predicates.isMips;
  mmix = filterDoubles predicates.isMmix;
  power = filterDoubles predicates.isPower;
  riscv = filterDoubles predicates.isRiscV;
  riscv32 = filterDoubles predicates.isRiscV32;
  riscv64 = filterDoubles predicates.isRiscV64;
  rx = filterDoubles predicates.isRx;
  vc4 = filterDoubles predicates.isVc4;
  or1k = filterDoubles predicates.isOr1k;
  m68k = filterDoubles predicates.isM68k;
  s390 = filterDoubles predicates.isS390;
  s390x = filterDoubles predicates.isS390x;
  loongarch64 = filterDoubles predicates.isLoongArch64;
  js = filterDoubles predicates.isJavaScript;

  bigEndian = filterDoubles predicates.isBigEndian;
  littleEndian = filterDoubles predicates.isLittleEndian;

  cygwin = filterDoubles predicates.isCygwin;
  darwin = filterDoubles predicates.isDarwin;
  freebsd = filterDoubles predicates.isFreeBSD;
  # Should be better, but MinGW is unclear.
  gnu =
    filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnu;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnueabi;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnueabihf;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnuabin32;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnuabi64;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnuabielfv1;
    })
    ++ filterDoubles (matchAttrs {
      kernel = parse.kernels.linux;
      abi = parse.abis.gnuabielfv2;
    });
  illumos = filterDoubles predicates.isSunOS;
  linux = filterDoubles predicates.isLinux;
  netbsd = filterDoubles predicates.isNetBSD;
  openbsd = filterDoubles predicates.isOpenBSD;
  unix = filterDoubles predicates.isUnix;
  wasi = filterDoubles predicates.isWasi;
  redox = filterDoubles predicates.isRedox;
  windows = filterDoubles predicates.isWindows;
  genode = filterDoubles predicates.isGenode;

  embedded = filterDoubles predicates.isNone;
}
</file>

<file path="lib/systems/examples.nix">
# These can be passed to nixpkgs as either the `localSystem` or
# `crossSystem`. They are put here for user convenience, but also used by cross
# tests and linux cross stdenv building, so handle with care!
{ lib }:
let
  platforms = import ./platforms.nix { inherit lib; };

  riscv = bits: {
    config = "riscv${bits}-unknown-linux-gnu";
  };
in

rec {
  #
  # Linux
  #
  powernv = {
    config = "powerpc64le-unknown-linux-gnu";
  };
  musl-power = {
    config = "powerpc64le-unknown-linux-musl";
  };

  ppc64-elfv1 = {
    config = "powerpc64-unknown-linux-gnuabielfv1";
    rust.rustcTarget = "powerpc64-unknown-linux-gnu";
  };
  ppc64-elfv2 = {
    config = "powerpc64-unknown-linux-gnuabielfv2";
  };
  ppc64 = ppc64-elfv2;
  ppc64-musl = {
    config = "powerpc64-unknown-linux-musl";
    gcc = {
      abi = "elfv2";
    };
  };

  sheevaplug = {
    config = "armv5tel-unknown-linux-gnueabi";
  }
  // platforms.sheevaplug;

  raspberryPi = {
    config = "armv6l-unknown-linux-gnueabihf";
  }
  // platforms.raspberrypi;

  bluefield2 = {
    config = "aarch64-unknown-linux-gnu";
  }
  // platforms.bluefield2;

  remarkable1 = {
    config = "armv7l-unknown-linux-gnueabihf";
  }
  // platforms.zero-gravitas;

  remarkable2 = {
    config = "armv7l-unknown-linux-gnueabihf";
  }
  // platforms.zero-sugar;

  armv7l-hf-multiplatform = {
    config = "armv7l-unknown-linux-gnueabihf";
  };

  aarch64-multiplatform = {
    config = "aarch64-unknown-linux-gnu";
  };

  armv7a-android-prebuilt = {
    config = "armv7a-unknown-linux-androideabi";
    rust.rustcTarget = "armv7-linux-androideabi";
    androidSdkVersion = "33";
    androidNdkVersion = "26";
    useAndroidPrebuilt = true;
  }
  // platforms.armv7a-android;

  aarch64-android-prebuilt = {
    config = "aarch64-unknown-linux-android";
    rust.rustcTarget = "aarch64-linux-android";
    androidSdkVersion = "33";
    androidNdkVersion = "26";
    useAndroidPrebuilt = true;
  };

  aarch64-android = {
    config = "aarch64-unknown-linux-android";
    androidSdkVersion = "33";
    androidNdkVersion = "26";
    libc = "bionic";
    useAndroidPrebuilt = false;
    useLLVM = true;
  };

  pogoplug4 = {
    config = "armv5tel-unknown-linux-gnueabi";
  }
  // platforms.pogoplug4;

  ben-nanonote = {
    config = "mipsel-unknown-linux-uclibc";
  }
  // platforms.ben_nanonote;

  fuloongminipc = {
    config = "mipsel-unknown-linux-gnu";
  }
  // platforms.fuloong2f_n32;

  # can execute on 32bit chip
  mips-linux-gnu = {
    config = "mips-unknown-linux-gnu";
  }
  // platforms.gcc_mips32r2_o32;
  mipsel-linux-gnu = {
    config = "mipsel-unknown-linux-gnu";
  }
  // platforms.gcc_mips32r2_o32;

  # require 64bit chip (for more registers, 64-bit floating point, 64-bit "long long") but use 32bit pointers
  mips64-linux-gnuabin32 = {
    config = "mips64-unknown-linux-gnuabin32";
  }
  // platforms.gcc_mips64r2_n32;
  mips64el-linux-gnuabin32 = {
    config = "mips64el-unknown-linux-gnuabin32";
  }
  // platforms.gcc_mips64r2_n32;

  # 64bit pointers
  mips64-linux-gnuabi64 = {
    config = "mips64-unknown-linux-gnuabi64";
  }
  // platforms.gcc_mips64r2_64;
  mips64el-linux-gnuabi64 = {
    config = "mips64el-unknown-linux-gnuabi64";
  }
  // platforms.gcc_mips64r2_64;

  muslpi = raspberryPi // {
    config = "armv6l-unknown-linux-musleabihf";
  };

  aarch64-multiplatform-musl = {
    config = "aarch64-unknown-linux-musl";
  };

  gnu64 = {
    config = "x86_64-unknown-linux-gnu";
  };
  gnu64_simplekernel = gnu64 // platforms.pc_simplekernel; # see test/cross/default.nix
  gnu32 = {
    config = "i686-unknown-linux-gnu";
  };

  musl64 = {
    config = "x86_64-unknown-linux-musl";
  };
  musl32 = {
    config = "i686-unknown-linux-musl";
  };

  riscv64 = riscv "64";
  riscv32 = riscv "32";

  riscv64-musl = {
    config = "riscv64-unknown-linux-musl";
  };

  riscv64-embedded = {
    config = "riscv64-none-elf";
    libc = "newlib";
  };

  riscv32-embedded = {
    config = "riscv32-none-elf";
    libc = "newlib";
  };

  mips64-embedded = {
    config = "mips64-none-elf";
    libc = "newlib";
  };

  mips-embedded = {
    config = "mips-none-elf";
    libc = "newlib";
  };

  # https://github.com/loongson/la-softdev-convention/blob/master/la-softdev-convention.adoc#10-operating-system-package-build-requirements
  loongarch64-linux = lib.recursiveUpdate platforms.loongarch64-multiplatform {
    config = "loongarch64-unknown-linux-gnu";
  };
  loongarch64-linux-embedded = lib.recursiveUpdate platforms.loongarch64-multiplatform {
    config = "loongarch64-unknown-linux-gnu";
    gcc = {
      arch = "loongarch64";
      strict-align = true;
    };
  };

  mmix = {
    config = "mmix-unknown-mmixware";
    libc = "newlib";
  };

  rx-embedded = {
    config = "rx-none-elf";
    libc = "newlib";
  };

  msp430 = {
    config = "msp430-elf";
    libc = "newlib";
  };

  avr = {
    config = "avr";
  };

  vc4 = {
    config = "vc4-elf";
    libc = "newlib";
  };

  or1k = {
    config = "or1k-elf";
    libc = "newlib";
  };

  m68k = {
    config = "m68k-unknown-linux-gnu";
  };

  s390 = {
    config = "s390-unknown-linux-gnu";
  };

  s390x = {
    config = "s390x-unknown-linux-gnu";
  };

  arm-embedded = {
    config = "arm-none-eabi";
    libc = "newlib";
  };
  arm-embedded-nano = {
    config = "arm-none-eabi";
    libc = "newlib-nano";
  };
  armhf-embedded = {
    config = "arm-none-eabihf";
    libc = "newlib";
    # GCC8+ does not build without this
    # (https://www.mail-archive.com/gcc-bugs@gcc.gnu.org/msg552339.html):
    gcc = {
      arch = "armv5t";
      fpu = "vfp";
    };
  };

  aarch64-embedded = {
    config = "aarch64-none-elf";
    libc = "newlib";
    rust.rustcTarget = "aarch64-unknown-none";
  };

  aarch64be-embedded = {
    config = "aarch64_be-none-elf";
    libc = "newlib";
  };

  ppc-embedded = {
    config = "powerpc-none-eabi";
    libc = "newlib";
  };

  ppcle-embedded = {
    config = "powerpcle-none-eabi";
    libc = "newlib";
  };

  i686-embedded = {
    config = "i686-elf";
    libc = "newlib";
  };

  x86_64-embedded = {
    config = "x86_64-elf";
    libc = "newlib";
  };

  microblaze-embedded = {
    config = "microblazeel-none-elf";
    libc = "newlib";
  };

  #
  # Redox
  #

  x86_64-unknown-redox = {
    config = "x86_64-unknown-redox";
    libc = "relibc";
  };

  #
  # Darwin
  #

  iphone64 = {
    config = "arm64-apple-ios";
    # config = "aarch64-apple-darwin14";
    darwinSdkVersion = "14.3";
    xcodeVer = "12.3";
    xcodePlatform = "iPhoneOS";
    useiOSPrebuilt = true;
  };

  iphone64-simulator = {
    config = "x86_64-apple-ios";
    # config = "x86_64-apple-darwin14";
    darwinSdkVersion = "14.3";
    xcodeVer = "12.3";
    xcodePlatform = "iPhoneSimulator";
    darwinPlatform = "ios-simulator";
    useiOSPrebuilt = true;
  };

  aarch64-darwin = {
    config = "arm64-apple-darwin";
    xcodePlatform = "MacOSX";
    platform = { };
  };

  x86_64-darwin = {
    config = "x86_64-apple-darwin";
    xcodePlatform = "MacOSX";
    platform = { };
  };

  #
  # Windows
  #

  # 32 bit mingw-w64
  mingw32 = {
    config = "i686-w64-mingw32";
    libc = "msvcrt"; # This distinguishes the mingw (non posix) toolchain
  };

  # 64 bit mingw-w64
  mingwW64 = {
    # That's the triplet they use in the mingw-w64 docs.
    config = "x86_64-w64-mingw32";
    libc = "msvcrt"; # This distinguishes the mingw (non posix) toolchain
  };

  ucrt64 = {
    config = "x86_64-w64-mingw32";
    libc = "ucrt"; # This distinguishes the mingw (non posix) toolchain
  };

  # LLVM-based mingw-w64 for ARM
  ucrtAarch64 = {
    config = "aarch64-w64-mingw32";
    libc = "ucrt";
    rust.rustcTarget = "aarch64-pc-windows-gnullvm";
    useLLVM = true;
  };

  # Target the MSVC ABI
  x86_64-windows = {
    config = "x86_64-pc-windows-msvc";
    useLLVM = true;
  };

  aarch64-windows = {
    config = "aarch64-pc-windows-msvc";
    useLLVM = true;
  };

  # BSDs

  aarch64-freebsd = {
    config = "aarch64-unknown-freebsd";
    useLLVM = true;
  };

  x86_64-freebsd = {
    config = "x86_64-unknown-freebsd";
    useLLVM = true;
  };

  x86_64-netbsd = {
    config = "x86_64-unknown-netbsd";
  };

  # this is broken and never worked fully
  x86_64-netbsd-llvm = {
    config = "x86_64-unknown-netbsd";
    useLLVM = true;
  };

  x86_64-openbsd = {
    config = "x86_64-unknown-openbsd";
    useLLVM = true;
  };

  #
  # WASM
  #

  wasi32 = {
    config = "wasm32-unknown-wasi";
    useLLVM = true;
  };

  wasm32-unknown-none = {
    config = "wasm32-unknown-none";
    rust.rustcTarget = "wasm32-unknown-unknown";
    useLLVM = true;
  };

  # Ghcjs
  ghcjs = {
    # This triple is special to GHC/Cabal/GHCJS and not recognized by autotools
    # See: https://gitlab.haskell.org/ghc/ghc/-/commit/6636b670233522f01d002c9b97827d00289dbf5c
    # https://github.com/ghcjs/ghcjs/issues/53
    config = "javascript-unknown-ghcjs";
  };
}
</file>

<file path="lib/systems/flake-systems.nix">
# See [RFC 46] for mandated platform support and ../../pkgs/stdenv for
# implemented platform support. This list is mainly descriptive, i.e. all
# system doubles for platforms where nixpkgs can do native compilation
# reasonably well are included.
#
# [RFC 46]: https://github.com/NixOS/rfcs/blob/master/rfcs/0046-platform-support-tiers.md
{ }:

[
  # Tier 1
  "x86_64-linux"
  # Tier 2
  "aarch64-linux"
  "x86_64-darwin"
  # Tier 3
  "armv6l-linux"
  "armv7l-linux"
  "i686-linux"
  # "mipsel-linux" is excluded because it is not bootstrapped

  # Other platforms with sufficient support in stdenv which is not formally
  # mandated by their platform tier.
  "aarch64-darwin"
  # "armv5tel-linux" is excluded because it is not bootstrapped
  "powerpc64le-linux"
  "riscv64-linux"
  "x86_64-freebsd"
]
</file>

<file path="lib/systems/inspect.nix">
{ lib }:

let
  inherit (lib)
    any
    attrValues
    concatMap
    filter
    hasPrefix
    isList
    mapAttrs
    matchAttrs
    recursiveUpdateUntil
    toList
    ;

  inherit (lib.strings) toJSON;

  inherit (lib.systems.parse)
    kernels
    kernelFamilies
    significantBytes
    cpuTypes
    execFormats
    ;

  abis = mapAttrs (_: abi: removeAttrs abi [ "assertions" ]) lib.systems.parse.abis;
in

rec {
  # these patterns are to be matched against {host,build,target}Platform.parsed
  patterns = rec {
    # The patterns below are lists in sum-of-products form.
    #
    # Each attribute is list of product conditions; non-list values are treated
    # as a singleton list.  If *any* product condition in the list matches then
    # the predicate matches.  Each product condition is tested by
    # `lib.attrsets.matchAttrs`, which requires a match on *all* attributes of
    # the product.

    isi686 = {
      cpu = cpuTypes.i686;
    };
    isx86_32 = {
      cpu = {
        family = "x86";
        bits = 32;
      };
    };
    isx86_64 = {
      cpu = {
        family = "x86";
        bits = 64;
      };
    };
    isPower = {
      cpu = {
        family = "power";
      };
    };
    isPower64 = {
      cpu = {
        family = "power";
        bits = 64;
      };
    };
    isAbiElfv1 = {
      abi = {
        abi = "elfv1";
      };
    };
    # This ABI is the default in NixOS PowerPC64 BE, but not on mainline GCC,
    # so it sometimes causes issues in certain packages that makes the wrong
    # assumption on the used ABI.
    isAbiElfv2 = [
      {
        abi = {
          abi = "elfv2";
        };
      }
      {
        abi = {
          name = "musl";
        };
        cpu = {
          family = "power";
          bits = 64;
        };
      }
    ];
    isx86 = {
      cpu = {
        family = "x86";
      };
    };
    isAarch32 = {
      cpu = {
        family = "arm";
        bits = 32;
      };
    };
    isArmv7 = map (
      { arch, ... }:
      {
        cpu = { inherit arch; };
      }
    ) (filter (cpu: hasPrefix "armv7" cpu.arch or "") (attrValues cpuTypes));
    isAarch64 = {
      cpu = {
        family = "arm";
        bits = 64;
      };
    };
    isAarch = {
      cpu = {
        family = "arm";
      };
    };
    isMicroBlaze = {
      cpu = {
        family = "microblaze";
      };
    };
    isMips = {
      cpu = {
        family = "mips";
      };
    };
    isMips32 = {
      cpu = {
        family = "mips";
        bits = 32;
      };
    };
    isMips64 = {
      cpu = {
        family = "mips";
        bits = 64;
      };
    };
    isMips64n32 = {
      cpu = {
        family = "mips";
        bits = 64;
      };
      abi = {
        abi = "n32";
      };
    };
    isMips64n64 = {
      cpu = {
        family = "mips";
        bits = 64;
      };
      abi = {
        abi = "64";
      };
    };
    isMmix = {
      cpu = {
        family = "mmix";
      };
    };
    isRiscV = {
      cpu = {
        family = "riscv";
      };
    };
    isRiscV32 = {
      cpu = {
        family = "riscv";
        bits = 32;
      };
    };
    isRiscV64 = {
      cpu = {
        family = "riscv";
        bits = 64;
      };
    };
    isRx = {
      cpu = {
        family = "rx";
      };
    };
    isSparc = {
      cpu = {
        family = "sparc";
      };
    };
    isSparc64 = {
      cpu = {
        family = "sparc";
        bits = 64;
      };
    };
    isWasm = {
      cpu = {
        family = "wasm";
      };
    };
    isMsp430 = {
      cpu = {
        family = "msp430";
      };
    };
    isVc4 = {
      cpu = {
        family = "vc4";
      };
    };
    isAvr = {
      cpu = {
        family = "avr";
      };
    };
    isAlpha = {
      cpu = {
        family = "alpha";
      };
    };
    isOr1k = {
      cpu = {
        family = "or1k";
      };
    };
    isM68k = {
      cpu = {
        family = "m68k";
      };
    };
    isS390 = {
      cpu = {
        family = "s390";
      };
    };
    isS390x = {
      cpu = {
        family = "s390";
        bits = 64;
      };
    };
    isLoongArch64 = {
      cpu = {
        family = "loongarch";
        bits = 64;
      };
    };
    isJavaScript = {
      cpu = cpuTypes.javascript;
    };

    is32bit = {
      cpu = {
        bits = 32;
      };
    };
    is64bit = {
      cpu = {
        bits = 64;
      };
    };
    isILP32 = [
      {
        cpu = {
          family = "wasm";
          bits = 32;
        };
      }
    ]
    ++
      map
        (a: {
          abi = {
            abi = a;
          };
        })
        [
          "n32"
          "ilp32"
          "x32"
        ];
    isBigEndian = {
      cpu = {
        significantByte = significantBytes.bigEndian;
      };
    };
    isLittleEndian = {
      cpu = {
        significantByte = significantBytes.littleEndian;
      };
    };

    isBSD = {
      kernel = {
        families = { inherit (kernelFamilies) bsd; };
      };
    };
    isDarwin = {
      kernel = {
        families = { inherit (kernelFamilies) darwin; };
      };
    };
    isUnix = [
      isBSD
      isDarwin
      isLinux
      isSunOS
      isCygwin
      isRedox
    ];

    isMacOS = {
      kernel = kernels.macos;
    };
    isiOS = {
      kernel = kernels.ios;
    };
    isLinux = {
      kernel = kernels.linux;
    };
    isSunOS = {
      kernel = kernels.solaris;
    };
    isFreeBSD = {
      kernel = {
        name = "freebsd";
      };
    };
    isNetBSD = {
      kernel = kernels.netbsd;
    };
    isOpenBSD = {
      kernel = kernels.openbsd;
    };
    isWindows = {
      kernel = kernels.windows;
    };
    isCygwin = {
      kernel = kernels.windows;
      abi = abis.cygnus;
    };
    isMinGW = {
      kernel = kernels.windows;
      abi = abis.gnu;
    };
    isMsvc = {
      kernel = kernels.windows;
      abi = abis.msvc;
    };
    isWasi = {
      kernel = kernels.wasi;
    };
    isRedox = {
      kernel = kernels.redox;
    };
    isGhcjs = {
      kernel = kernels.ghcjs;
    };
    isGenode = {
      kernel = kernels.genode;
    };
    isNone = {
      kernel = kernels.none;
    };

    isAndroid = [
      { abi = abis.android; }
      { abi = abis.androideabi; }
    ];
    isGnu =
      with abis;
      map (a: { abi = a; }) [
        gnuabi64
        gnuabin32
        gnu
        gnueabi
        gnueabihf
        gnuabielfv1
        gnuabielfv2
      ];
    isMusl =
      with abis;
      map (a: { abi = a; }) [
        musl
        musleabi
        musleabihf
        muslabin32
        muslabi64
      ];
    isUClibc =
      with abis;
      map (a: { abi = a; }) [
        uclibc
        uclibceabi
        uclibceabihf
      ];

    isEfi = [
      {
        cpu = {
          family = "arm";
          version = "6";
        };
      }
      {
        cpu = {
          family = "arm";
          version = "7";
        };
      }
      {
        cpu = {
          family = "arm";
          version = "8";
        };
      }
      {
        cpu = {
          family = "riscv";
        };
      }
      {
        cpu = {
          family = "x86";
        };
      }
      {
        cpu = {
          family = "loongarch";
        };
      }
    ];

    isElf = {
      kernel.execFormat = execFormats.elf;
    };
    isMacho = {
      kernel.execFormat = execFormats.macho;
    };
  };

  # given two patterns, return a pattern which is their logical AND.
  # Since a pattern is a list-of-disjuncts, this needs to
  patternLogicalAnd =
    pat1_: pat2_:
    let
      # patterns can be either a list or a (bare) singleton; turn
      # them into singletons for uniform handling
      pat1 = toList pat1_;
      pat2 = toList pat2_;
    in
    concatMap (
      attr1:
      map (
        attr2:
        recursiveUpdateUntil (
          path: subattr1: subattr2:
          if (builtins.intersectAttrs subattr1 subattr2) == { } || subattr1 == subattr2 then
            true
          else
            throw ''
              pattern conflict at path ${toString path}:
                ${toJSON subattr1}
                ${toJSON subattr2}
            ''
        ) attr1 attr2
      ) pat2
    ) pat1;

  matchAnyAttrs =
    patterns:
    if isList patterns then
      attrs: any (pattern: matchAttrs pattern attrs) patterns
    else
      matchAttrs patterns;

  predicates = mapAttrs (_: matchAnyAttrs) patterns;

  # these patterns are to be matched against the entire
  # {host,build,target}Platform structure; they include a `parsed={}` marker so
  # that `lib.meta.availableOn` can distinguish them from the patterns which
  # apply only to the `parsed` field.

  platformPatterns = mapAttrs (_: p: { parsed = { }; } // p) {
    isStatic = {
      isStatic = true;
    };
  };
}
</file>

<file path="lib/systems/parse.nix">
# Define the list of system with their properties.
#
# See https://clang.llvm.org/docs/CrossCompilation.html and
# http://llvm.org/docs/doxygen/html/Triple_8cpp_source.html especially
# Triple::normalize. Parsing should essentially act as a more conservative
# version of that last function.
#
# Most of the types below come in "open" and "closed" pairs. The open ones
# specify what information we need to know about systems in general, and the
# closed ones are sub-types representing the whitelist of systems we support in
# practice.
#
# Code in the remainder of nixpkgs shouldn't rely on the closed ones in
# e.g. exhaustive cases. Its more a sanity check to make sure nobody defines
# systems that overlap with existing ones and won't notice something amiss.
#
{ lib }:

let
  inherit (lib)
    all
    any
    attrValues
    elem
    elemAt
    hasPrefix
    id
    length
    mapAttrs
    mergeOneOption
    optionalString
    splitString
    versionAtLeast
    ;

  inherit (lib.strings) match;

  inherit (lib.systems.inspect.predicates)
    isAarch32
    isBigEndian
    isDarwin
    isLinux
    isPower64
    isWindows
    ;

  inherit (lib.types)
    enum
    float
    isType
    mkOptionType
    number
    setType
    string
    types
    ;

  setTypes =
    type:
    mapAttrs (
      name: value:
      assert type.check value;
      setType type.name ({ inherit name; } // value)
    );

  # gnu-config will ignore the portion of a triple matching the
  # regex `e?abi.*$` when determining the validity of a triple.  In
  # other words, `i386-linuxabichickenlips` is a valid triple.
  removeAbiSuffix =
    x:
    let
      found = match "(.*)e?abi.*" x;
    in
    if found == null then x else elemAt found 0;

in

rec {

  ################################################################################

  types.openSignificantByte = mkOptionType {
    name = "significant-byte";
    description = "Endianness";
    merge = mergeOneOption;
  };

  types.significantByte = enum (attrValues significantBytes);

  significantBytes = setTypes types.openSignificantByte {
    bigEndian = { };
    littleEndian = { };
  };

  ################################################################################

  # Reasonable power of 2
  types.bitWidth = enum [
    8
    16
    32
    64
    128
  ];

  ################################################################################

  types.openCpuType = mkOptionType {
    name = "cpu-type";
    description = "instruction set architecture name and information";
    merge = mergeOneOption;
    check =
      x:
      types.bitWidth.check x.bits
      && (if 8 < x.bits then types.significantByte.check x.significantByte else !(x ? significantByte));
  };

  types.cpuType = enum (attrValues cpuTypes);

  cpuTypes =
    let
      inherit (significantBytes) bigEndian littleEndian;
    in
    setTypes types.openCpuType {
      arm = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
      };
      armv5tel = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "5";
        arch = "armv5t";
      };
      armv6m = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "6";
        arch = "armv6-m";
      };
      armv6l = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "6";
        arch = "armv6";
      };
      armv7a = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "7";
        arch = "armv7-a";
      };
      armv7r = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "7";
        arch = "armv7-r";
      };
      armv7m = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "7";
        arch = "armv7-m";
      };
      armv7l = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "7";
        arch = "armv7";
      };
      armv8a = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "8";
        arch = "armv8-a";
      };
      armv8r = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "8";
        arch = "armv8-a";
      };
      armv8m = {
        bits = 32;
        significantByte = littleEndian;
        family = "arm";
        version = "8";
        arch = "armv8-m";
      };
      aarch64 = {
        bits = 64;
        significantByte = littleEndian;
        family = "arm";
        version = "8";
        arch = "armv8-a";
      };
      aarch64_be = {
        bits = 64;
        significantByte = bigEndian;
        family = "arm";
        version = "8";
        arch = "armv8-a";
      };

      i386 = {
        bits = 32;
        significantByte = littleEndian;
        family = "x86";
        arch = "i386";
      };
      i486 = {
        bits = 32;
        significantByte = littleEndian;
        family = "x86";
        arch = "i486";
      };
      i586 = {
        bits = 32;
        significantByte = littleEndian;
        family = "x86";
        arch = "i586";
      };
      i686 = {
        bits = 32;
        significantByte = littleEndian;
        family = "x86";
        arch = "i686";
      };
      x86_64 = {
        bits = 64;
        significantByte = littleEndian;
        family = "x86";
        arch = "x86-64";
      };

      microblaze = {
        bits = 32;
        significantByte = bigEndian;
        family = "microblaze";
      };
      microblazeel = {
        bits = 32;
        significantByte = littleEndian;
        family = "microblaze";
      };

      mips = {
        bits = 32;
        significantByte = bigEndian;
        family = "mips";
      };
      mipsel = {
        bits = 32;
        significantByte = littleEndian;
        family = "mips";
      };
      mips64 = {
        bits = 64;
        significantByte = bigEndian;
        family = "mips";
      };
      mips64el = {
        bits = 64;
        significantByte = littleEndian;
        family = "mips";
      };

      mmix = {
        bits = 64;
        significantByte = bigEndian;
        family = "mmix";
      };

      m68k = {
        bits = 32;
        significantByte = bigEndian;
        family = "m68k";
      };

      powerpc = {
        bits = 32;
        significantByte = bigEndian;
        family = "power";
      };
      powerpc64 = {
        bits = 64;
        significantByte = bigEndian;
        family = "power";
      };
      powerpc64le = {
        bits = 64;
        significantByte = littleEndian;
        family = "power";
      };
      powerpcle = {
        bits = 32;
        significantByte = littleEndian;
        family = "power";
      };

      riscv32 = {
        bits = 32;
        significantByte = littleEndian;
        family = "riscv";
      };
      riscv64 = {
        bits = 64;
        significantByte = littleEndian;
        family = "riscv";
      };

      s390 = {
        bits = 32;
        significantByte = bigEndian;
        family = "s390";
      };
      s390x = {
        bits = 64;
        significantByte = bigEndian;
        family = "s390";
      };

      sparc = {
        bits = 32;
        significantByte = bigEndian;
        family = "sparc";
      };
      sparc64 = {
        bits = 64;
        significantByte = bigEndian;
        family = "sparc";
      };

      wasm32 = {
        bits = 32;
        significantByte = littleEndian;
        family = "wasm";
      };
      wasm64 = {
        bits = 64;
        significantByte = littleEndian;
        family = "wasm";
      };

      alpha = {
        bits = 64;
        significantByte = littleEndian;
        family = "alpha";
      };

      rx = {
        bits = 32;
        significantByte = littleEndian;
        family = "rx";
      };
      msp430 = {
        bits = 16;
        significantByte = littleEndian;
        family = "msp430";
      };
      avr = {
        bits = 8;
        family = "avr";
      };

      vc4 = {
        bits = 32;
        significantByte = littleEndian;
        family = "vc4";
      };

      or1k = {
        bits = 32;
        significantByte = bigEndian;
        family = "or1k";
      };

      loongarch64 = {
        bits = 64;
        significantByte = littleEndian;
        family = "loongarch";
      };

      javascript = {
        bits = 32;
        significantByte = littleEndian;
        family = "javascript";
      };
    }
    // {
      # aliases
      # Apple architecture name, as used by `darwinArch`; required by
      # LLVM ≥ 20.
      arm64 = cpuTypes.aarch64;
    };

  # GNU build systems assume that older NetBSD architectures are using a.out.
  gnuNetBSDDefaultExecFormat =
    cpu:
    if
      (cpu.family == "arm" && cpu.bits == 32)
      || (cpu.family == "sparc" && cpu.bits == 32)
      || (cpu.family == "m68k" && cpu.bits == 32)
      || (cpu.family == "x86" && cpu.bits == 32)
    then
      execFormats.aout
    else
      execFormats.elf;

  # Determine when two CPUs are compatible with each other. That is,
  # can code built for system B run on system A? For that to happen,
  # the programs that system B accepts must be a subset of the
  # programs that system A accepts.
  #
  # We have the following properties of the compatibility relation,
  # which must be preserved when adding compatibility information for
  # additional CPUs.
  # - (reflexivity)
  #   Every CPU is compatible with itself.
  # - (transitivity)
  #   If A is compatible with B and B is compatible with C then A is compatible with C.
  #
  # Note: Since 22.11 the archs of a mode switching CPU are no longer considered
  # pairwise compatible. Mode switching implies that binaries built for A
  # and B respectively can't be executed at the same time.
  isCompatible =
    with cpuTypes;
    a: b:
    any id [
      # x86
      (b == i386 && isCompatible a i486)
      (b == i486 && isCompatible a i586)
      (b == i586 && isCompatible a i686)

      # XXX: Not true in some cases. Like in WSL mode.
      (b == i686 && isCompatible a x86_64)

      # ARMv4
      (b == arm && isCompatible a armv5tel)

      # ARMv5
      (b == armv5tel && isCompatible a armv6l)

      # ARMv6
      (b == armv6l && isCompatible a armv6m)
      (b == armv6m && isCompatible a armv7l)

      # ARMv7
      (b == armv7l && isCompatible a armv7a)
      (b == armv7l && isCompatible a armv7r)
      (b == armv7l && isCompatible a armv7m)

      # ARMv8
      (b == aarch64 && a == armv8a)
      (b == armv8a && isCompatible a aarch64)
      (b == armv8r && isCompatible a armv8a)
      (b == armv8m && isCompatible a armv8a)

      # PowerPC
      (b == powerpc && isCompatible a powerpc64)
      (b == powerpcle && isCompatible a powerpc64le)

      # MIPS
      (b == mips && isCompatible a mips64)
      (b == mipsel && isCompatible a mips64el)

      # RISCV
      (b == riscv32 && isCompatible a riscv64)

      # SPARC
      (b == sparc && isCompatible a sparc64)

      # WASM
      (b == wasm32 && isCompatible a wasm64)

      # identity
      (b == a)
    ];

  ################################################################################

  types.openVendor = mkOptionType {
    name = "vendor";
    description = "vendor for the platform";
    merge = mergeOneOption;
  };

  types.vendor = enum (attrValues vendors);

  vendors = setTypes types.openVendor {
    apple = { };
    pc = { };
    knuth = { };

    # Actually matters, unlocking some MinGW-w64-specific options in GCC. See
    # bottom of https://sourceforge.net/p/mingw-w64/wiki2/Unicode%20apps/
    w64 = { };

    none = { };
    unknown = { };
  };

  ################################################################################

  types.openExecFormat = mkOptionType {
    name = "exec-format";
    description = "executable container used by the kernel";
    merge = mergeOneOption;
  };

  types.execFormat = enum (attrValues execFormats);

  execFormats = setTypes types.openExecFormat {
    aout = { }; # a.out
    elf = { };
    macho = { };
    pe = { };
    wasm = { };

    unknown = { };
  };

  ################################################################################

  types.openKernelFamily = mkOptionType {
    name = "exec-format";
    description = "executable container used by the kernel";
    merge = mergeOneOption;
  };

  types.kernelFamily = enum (attrValues kernelFamilies);

  kernelFamilies = setTypes types.openKernelFamily {
    bsd = { };
    darwin = { };
  };

  ################################################################################

  types.openKernel = mkOptionType {
    name = "kernel";
    description = "kernel name and information";
    merge = mergeOneOption;
    check =
      x: types.execFormat.check x.execFormat && all types.kernelFamily.check (attrValues x.families);
  };

  types.kernel = enum (attrValues kernels);

  kernels =
    let
      inherit (execFormats)
        elf
        pe
        wasm
        unknown
        macho
        ;
      inherit (kernelFamilies) bsd darwin;
    in
    setTypes types.openKernel {
      # TODO(@Ericson2314): Don't want to mass-rebuild yet to keeping 'darwin' as
      # the normalized name for macOS.
      macos = {
        execFormat = macho;
        families = { inherit darwin; };
        name = "darwin";
      };
      ios = {
        execFormat = macho;
        families = { inherit darwin; };
      };
      freebsd = {
        execFormat = elf;
        families = { inherit bsd; };
        name = "freebsd";
      };
      linux = {
        execFormat = elf;
        families = { };
      };
      netbsd = {
        execFormat = elf;
        families = { inherit bsd; };
      };
      none = {
        execFormat = unknown;
        families = { };
      };
      openbsd = {
        execFormat = elf;
        families = { inherit bsd; };
      };
      solaris = {
        execFormat = elf;
        families = { };
      };
      wasi = {
        execFormat = wasm;
        families = { };
      };
      redox = {
        execFormat = elf;
        families = { };
      };
      windows = {
        execFormat = pe;
        families = { };
      };
      ghcjs = {
        execFormat = unknown;
        families = { };
      };
      genode = {
        execFormat = elf;
        families = { };
      };
      mmixware = {
        execFormat = unknown;
        families = { };
      };
    }
    // {
      # aliases
      # 'darwin' is the kernel for all of them. We choose macOS by default.
      darwin = kernels.macos;
      watchos = kernels.ios;
      tvos = kernels.ios;
      win32 = kernels.windows;
    };

  ################################################################################

  types.openAbi = mkOptionType {
    name = "abi";
    description = "binary interface for compiled code and syscalls";
    merge = mergeOneOption;
  };

  types.abi = enum (attrValues abis);

  abis = setTypes types.openAbi {
    cygnus = { };
    msvc = { };

    # Note: eabi is specific to ARM and PowerPC.
    # On PowerPC, this corresponds to PPCEABI.
    # On ARM, this corresponds to ARMEABI.
    eabi = {
      float = "soft";
    };
    eabihf = {
      float = "hard";
    };

    # Other architectures should use ELF in embedded situations.
    elf = { };

    androideabi = { };
    android = {
      assertions = [
        {
          assertion = platform: !platform.isAarch32;
          message = ''
            The "android" ABI is not for 32-bit ARM. Use "androideabi" instead.
          '';
        }
      ];
    };

    gnueabi = {
      float = "soft";
    };
    gnueabihf = {
      float = "hard";
    };
    gnu = {
      assertions = [
        {
          assertion = platform: !platform.isAarch32;
          message = ''
            The "gnu" ABI is ambiguous on 32-bit ARM. Use "gnueabi" or "gnueabihf" instead.
          '';
        }
        {
          assertion = platform: !(platform.isPower64 && platform.isBigEndian);
          message = ''
            The "gnu" ABI is ambiguous on big-endian 64-bit PowerPC. Use "gnuabielfv2" or "gnuabielfv1" instead.
          '';
        }
      ];
    };
    gnuabi64 = {
      abi = "64";
    };
    muslabi64 = {
      abi = "64";
    };

    # NOTE: abi=n32 requires a 64-bit MIPS chip!  That is not a typo.
    # It is basically the 64-bit abi with 32-bit pointers.  Details:
    # https://www.linux-mips.org/pub/linux/mips/doc/ABI/MIPS-N32-ABI-Handbook.pdf
    gnuabin32 = {
      abi = "n32";
    };
    muslabin32 = {
      abi = "n32";
    };

    gnuabielfv2 = {
      abi = "elfv2";
    };
    gnuabielfv1 = {
      abi = "elfv1";
    };

    musleabi = {
      float = "soft";
    };
    musleabihf = {
      float = "hard";
    };
    musl = { };

    uclibceabi = {
      float = "soft";
    };
    uclibceabihf = {
      float = "hard";
    };
    uclibc = { };

    unknown = { };
  };

  ################################################################################

  types.parsedPlatform = mkOptionType {
    name = "system";
    description = "fully parsed representation of llvm- or nix-style platform tuple";
    merge = mergeOneOption;
    check =
      {
        cpu,
        vendor,
        kernel,
        abi,
      }:
      types.cpuType.check cpu
      && types.vendor.check vendor
      && types.kernel.check kernel
      && types.abi.check abi;
  };

  isSystem = isType "system";

  mkSystem =
    components:
    assert types.parsedPlatform.check components;
    setType "system" components;

  mkSkeletonFromList =
    l:
    {
      "1" =
        if elemAt l 0 == "avr" then
          {
            cpu = elemAt l 0;
            kernel = "none";
            abi = "unknown";
          }
        else
          throw "system string '${lib.concatStringsSep "-" l}' with 1 component is ambiguous";
      "2" = # We only do 2-part hacks for things Nix already supports
        if elemAt l 1 == "cygwin" then
          {
            cpu = elemAt l 0;
            kernel = "windows";
            abi = "cygnus";
          }
        # MSVC ought to be the default ABI so this case isn't needed. But then it
        # becomes difficult to handle the gnu* variants for Aarch32 correctly for
        # minGW. So it's easier to make gnu* the default for the MinGW, but
        # hack-in MSVC for the non-MinGW case right here.
        else if elemAt l 1 == "windows" then
          {
            cpu = elemAt l 0;
            kernel = "windows";
            abi = "msvc";
          }
        else if (elemAt l 1) == "elf" then
          {
            cpu = elemAt l 0;
            vendor = "unknown";
            kernel = "none";
            abi = elemAt l 1;
          }
        else
          {
            cpu = elemAt l 0;
            kernel = elemAt l 1;
          };
      "3" =
        # cpu-kernel-environment
        if
          elemAt l 1 == "linux"
          || elem (elemAt l 2) [
            "eabi"
            "eabihf"
            "elf"
            "gnu"
          ]
        then
          {
            cpu = elemAt l 0;
            kernel = elemAt l 1;
            abi = elemAt l 2;
            vendor = "unknown";
          }
        # cpu-vendor-os
        else if
          elemAt l 1 == "apple"
          || elem (elemAt l 2) [
            "redox"
            "mmixware"
            "ghcjs"
            "mingw32"
          ]
          || hasPrefix "freebsd" (elemAt l 2)
          || hasPrefix "netbsd" (elemAt l 2)
          || hasPrefix "openbsd" (elemAt l 2)
          || hasPrefix "genode" (elemAt l 2)
          || hasPrefix "wasm32" (elemAt l 0)
        then
          {
            cpu = elemAt l 0;
            vendor = elemAt l 1;
            kernel =
              if elemAt l 2 == "mingw32" then
                "windows" # autotools breaks on -gnu for window
              else
                elemAt l 2;
          }
        else
          throw "system string '${lib.concatStringsSep "-" l}' with 3 components is ambiguous";
      "4" = {
        cpu = elemAt l 0;
        vendor = elemAt l 1;
        kernel = elemAt l 2;
        abi = elemAt l 3;
      };
    }
    .${toString (length l)}
    or (throw "system string '${lib.concatStringsSep "-" l}' has invalid number of hyphen-separated components");

  # This should revert the job done by config.guess from the gcc compiler.
  mkSystemFromSkeleton =
    {
      cpu,
      # Optional, but fallback too complex for here.
      # Inferred below instead.
      vendor ?
        assert false;
        null,
      kernel,
      # Also inferred below
      abi ?
        assert false;
        null,
    }@args:
    let
      getCpu = name: cpuTypes.${name} or (throw "Unknown CPU type: ${name}");
      getVendor = name: vendors.${name} or (throw "Unknown vendor: ${name}");
      getKernel = name: kernels.${name} or (throw "Unknown kernel: ${name}");
      getAbi = name: abis.${name} or (throw "Unknown ABI: ${name}");

      parsed = {
        cpu = getCpu args.cpu;
        vendor =
          if args ? vendor then
            getVendor args.vendor
          else if isDarwin parsed then
            vendors.apple
          else if isWindows parsed then
            vendors.pc
          else
            vendors.unknown;
        kernel =
          if hasPrefix "darwin" args.kernel then
            getKernel "darwin"
          else if hasPrefix "netbsd" args.kernel then
            getKernel "netbsd"
          else
            getKernel (removeAbiSuffix args.kernel);
        abi =
          if args ? abi then
            getAbi args.abi
          else if isLinux parsed || isWindows parsed then
            if isAarch32 parsed then
              if versionAtLeast (parsed.cpu.version or "0") "6" then abis.gnueabihf else abis.gnueabi
            # Default ppc64 BE to ELFv2
            else if isPower64 parsed && isBigEndian parsed then
              abis.gnuabielfv2
            else
              abis.gnu
          else
            abis.unknown;
      };

    in
    mkSystem parsed;

  mkSystemFromString = s: mkSystemFromSkeleton (mkSkeletonFromList (splitString "-" s));

  kernelName = kernel: kernel.name + toString (kernel.version or "");

  darwinArch = cpu: if cpu.name == "aarch64" then "arm64" else cpu.name;

  doubleFromSystem =
    {
      cpu,
      kernel,
      abi,
      ...
    }:
    if abi == abis.cygnus then
      "${cpu.name}-cygwin"
    else if kernel.families ? darwin then
      "${cpu.name}-darwin"
    else
      "${cpu.name}-${kernelName kernel}";

  tripleFromSystem =
    {
      cpu,
      vendor,
      kernel,
      abi,
      ...
    }@sys:
    assert isSystem sys;
    let
      optExecFormat = optionalString (
        kernel.name == "netbsd" && gnuNetBSDDefaultExecFormat cpu != kernel.execFormat
      ) kernel.execFormat.name;
      optAbi = optionalString (abi != abis.unknown) "-${abi.name}";
      cpuName = if kernel.families ? darwin then darwinArch cpu else cpu.name;
    in
    "${cpuName}-${vendor.name}-${kernelName kernel}${optExecFormat}${optAbi}";

  ################################################################################

}
</file>

<file path="lib/systems/platforms.nix">
# Note: lib/systems/default.nix takes care of producing valid,
# fully-formed "platform" values (e.g. hostPlatform, buildPlatform,
# targetPlatform, etc) containing at least the minimal set of attrs
# required (see types.parsedPlatform in lib/systems/parse.nix).  This
# file takes an already-valid platform and further elaborates it with
# optional fields; currently these are: linux-kernel, gcc, and rustc.

{ lib }:
rec {
  pc = {
    linux-kernel = {
      name = "pc";

      baseConfig = "defconfig";
      # Build whatever possible as a module, if not stated in the extra config.
      autoModules = true;
      target = "bzImage";
    };
  };

  pc_simplekernel = lib.recursiveUpdate pc {
    linux-kernel.autoModules = false;
  };

  powernv = {
    linux-kernel = {
      name = "PowerNV";

      baseConfig = "powernv_defconfig";
      target = "vmlinux";
      autoModules = true;
      # avoid driver/FS trouble arising from unusual page size
      extraConfig = ''
        PPC_64K_PAGES n
        PPC_4K_PAGES y
        IPV6 y

        ATA_BMDMA y
        ATA_SFF y
        VIRTIO_MENU y
      '';
    };
  };

  ##
  ## ARM
  ##

  pogoplug4 = {
    linux-kernel = {
      name = "pogoplug4";

      baseConfig = "multi_v5_defconfig";
      autoModules = false;
      extraConfig = ''
        # Ubi for the mtd
        MTD_UBI y
        UBIFS_FS y
        UBIFS_FS_XATTR y
        UBIFS_FS_ADVANCED_COMPR y
        UBIFS_FS_LZO y
        UBIFS_FS_ZLIB y
        UBIFS_FS_DEBUG n
      '';
      makeFlags = [ "LOADADDR=0x8000" ];
      target = "uImage";
      # TODO reenable once manual-config's config actually builds a .dtb and this is checked to be working
      #DTB = true;
    };
    gcc = {
      arch = "armv5te";
    };
  };

  sheevaplug = {
    linux-kernel = {
      name = "sheevaplug";

      baseConfig = "multi_v5_defconfig";
      autoModules = false;
      extraConfig = ''
        BLK_DEV_RAM y
        BLK_DEV_INITRD y
        BLK_DEV_CRYPTOLOOP m
        BLK_DEV_DM m
        DM_CRYPT m
        MD y
        REISERFS_FS m
        BTRFS_FS m
        XFS_FS m
        JFS_FS m
        EXT4_FS m
        USB_STORAGE_CYPRESS_ATACB m

        # mv cesa requires this sw fallback, for mv-sha1
        CRYPTO_SHA1 y
        # Fast crypto
        CRYPTO_TWOFISH y
        CRYPTO_TWOFISH_COMMON y
        CRYPTO_BLOWFISH y
        CRYPTO_BLOWFISH_COMMON y

        IP_PNP y
        IP_PNP_DHCP y
        NFS_FS y
        ROOT_NFS y
        TUN m
        NFS_V4 y
        NFS_V4_1 y
        NFS_FSCACHE y
        NFSD m
        NFSD_V2_ACL y
        NFSD_V3 y
        NFSD_V3_ACL y
        NFSD_V4 y
        NETFILTER y
        IP_NF_IPTABLES y
        IP_NF_FILTER y
        IP_NF_MATCH_ADDRTYPE y
        IP_NF_TARGET_LOG y
        IP_NF_MANGLE y
        IPV6 m
        VLAN_8021Q m

        CIFS y
        CIFS_XATTR y
        CIFS_POSIX y
        CIFS_FSCACHE y
        CIFS_ACL y

        WATCHDOG y
        WATCHDOG_CORE y
        ORION_WATCHDOG m

        ZRAM m
        NETCONSOLE m

        # Disable OABI to have seccomp_filter (required for systemd)
        # https://github.com/raspberrypi/firmware/issues/651
        OABI_COMPAT n

        # Fail to build
        DRM n
        SCSI_ADVANSYS n
        USB_ISP1362_HCD n
        SND_SOC n
        SND_ALI5451 n
        FB_SAVAGE n
        SCSI_NSP32 n
        ATA_SFF n
        SUNGEM n
        IRDA n
        ATM_HE n
        SCSI_ACARD n
        BLK_DEV_CMD640_ENHANCED n

        FUSE_FS m

        # systemd uses cgroups
        CGROUPS y

        # Latencytop
        LATENCYTOP y

        # Ubi for the mtd
        MTD_UBI y
        UBIFS_FS y
        UBIFS_FS_XATTR y
        UBIFS_FS_ADVANCED_COMPR y
        UBIFS_FS_LZO y
        UBIFS_FS_ZLIB y
        UBIFS_FS_DEBUG n

        # Kdb, for kernel troubles
        KGDB y
        KGDB_SERIAL_CONSOLE y
        KGDB_KDB y
      '';
      makeFlags = [ "LOADADDR=0x0200000" ];
      target = "uImage";
      DTB = true; # Beyond 3.10
    };
    gcc = {
      arch = "armv5te";
    };
  };

  raspberrypi = {
    linux-kernel = {
      name = "raspberrypi";

      baseConfig = "bcm2835_defconfig";
      DTB = true;
      autoModules = true;
      preferBuiltin = true;
      extraConfig = ''
        # Disable OABI to have seccomp_filter (required for systemd)
        # https://github.com/raspberrypi/firmware/issues/651
        OABI_COMPAT n
      '';
      target = "zImage";
    };
    gcc = {
      # https://en.wikipedia.org/wiki/Raspberry_Pi#Specifications
      arch = "armv6kz";
      fpu = "vfpv2";
    };
  };

  # Legacy attribute, for compatibility with existing configs only.
  raspberrypi2 = armv7l-hf-multiplatform;

  # Nvidia Bluefield 2 (w. crypto support)
  bluefield2 = {
    gcc = {
      arch = "armv8-a+fp+simd+crc+crypto";
    };
  };

  zero-gravitas = {
    linux-kernel = {
      name = "zero-gravitas";

      baseConfig = "zero-gravitas_defconfig";
      # Target verified by checking /boot on reMarkable 1 device
      target = "zImage";
      autoModules = false;
      DTB = true;
    };
    gcc = {
      fpu = "neon";
      cpu = "cortex-a9";
    };
  };

  zero-sugar = {
    linux-kernel = {
      name = "zero-sugar";

      baseConfig = "zero-sugar_defconfig";
      DTB = true;
      autoModules = false;
      preferBuiltin = true;
      target = "zImage";
    };
    gcc = {
      cpu = "cortex-a7";
      fpu = "neon-vfpv4";
      float-abi = "hard";
    };
  };

  utilite = {
    linux-kernel = {
      name = "utilite";
      maseConfig = "multi_v7_defconfig";
      autoModules = false;
      extraConfig = ''
        # Ubi for the mtd
        MTD_UBI y
        UBIFS_FS y
        UBIFS_FS_XATTR y
        UBIFS_FS_ADVANCED_COMPR y
        UBIFS_FS_LZO y
        UBIFS_FS_ZLIB y
        UBIFS_FS_DEBUG n
      '';
      makeFlags = [ "LOADADDR=0x10800000" ];
      target = "uImage";
      DTB = true;
    };
    gcc = {
      cpu = "cortex-a9";
      fpu = "neon";
    };
  };

  guruplug = lib.recursiveUpdate sheevaplug {
    # Define `CONFIG_MACH_GURUPLUG' (see
    # <http://kerneltrap.org/mailarchive/git-commits-head/2010/5/19/33618>)
    # and other GuruPlug-specific things.  Requires the `guruplug-defconfig'
    # patch.
    linux-kernel.baseConfig = "guruplug_defconfig";
  };

  beaglebone = lib.recursiveUpdate armv7l-hf-multiplatform {
    linux-kernel = {
      name = "beaglebone";
      baseConfig = "bb.org_defconfig";
      autoModules = false;
      extraConfig = ""; # TBD kernel config
      target = "zImage";
    };
  };

  # https://developer.android.com/ndk/guides/abis#v7a
  armv7a-android = {
    linux-kernel.name = "armeabi-v7a";
    gcc = {
      arch = "armv7-a";
      float-abi = "softfp";
      fpu = "vfpv3-d16";
    };
  };

  armv7l-hf-multiplatform = {
    linux-kernel = {
      name = "armv7l-hf-multiplatform";
      Major = "2.6"; # Using "2.6" enables 2.6 kernel syscalls in glibc.
      baseConfig = "multi_v7_defconfig";
      DTB = true;
      autoModules = true;
      preferBuiltin = true;
      target = "zImage";
      extraConfig = ''
        # Serial port for Raspberry Pi 3. Wasn't included in ARMv7 defconfig
        # until 4.17.
        SERIAL_8250_BCM2835AUX y
        SERIAL_8250_EXTENDED y
        SERIAL_8250_SHARE_IRQ y

        # Hangs ODROID-XU4
        ARM_BIG_LITTLE_CPUIDLE n

        # Disable OABI to have seccomp_filter (required for systemd)
        # https://github.com/raspberrypi/firmware/issues/651
        OABI_COMPAT n

        # >=5.12 fails with:
        # drivers/net/ethernet/micrel/ks8851_common.o: in function `ks8851_probe_common':
        # ks8851_common.c:(.text+0x179c): undefined reference to `__this_module'
        # See: https://lore.kernel.org/netdev/20210116164828.40545-1-marex@denx.de/T/
        KS8851_MLL y
      '';
    };
    gcc = {
      # Some table about fpu flags:
      # http://community.arm.com/servlet/JiveServlet/showImage/38-1981-3827/blogentry-103749-004812900+1365712953_thumb.png
      # Cortex-A5: -mfpu=neon-fp16
      # Cortex-A7 (rpi2): -mfpu=neon-vfpv4
      # Cortex-A8 (beaglebone): -mfpu=neon
      # Cortex-A9: -mfpu=neon-fp16
      # Cortex-A15: -mfpu=neon-vfpv4

      # More about FPU:
      # https://wiki.debian.org/ArmHardFloatPort/VfpComparison

      # vfpv3-d16 is what Debian uses and seems to be the best compromise: NEON is not supported in e.g. Scaleway or Tegra 2,
      # and the above page suggests NEON is only an improvement with hand-written assembly.
      arch = "armv7-a";
      fpu = "vfpv3-d16";

      # For Raspberry Pi the 2 the best would be:
      #   cpu = "cortex-a7";
      #   fpu = "neon-vfpv4";
    };
  };

  aarch64-multiplatform = {
    linux-kernel = {
      name = "aarch64-multiplatform";
      baseConfig = "defconfig";
      DTB = true;
      autoModules = true;
      preferBuiltin = true;
      extraConfig = ''
        # Raspberry Pi 3 stuff. Not needed for   s >= 4.10.
        ARCH_BCM2835 y
        BCM2835_MBOX y
        BCM2835_WDT y
        RASPBERRYPI_FIRMWARE y
        RASPBERRYPI_POWER y
        SERIAL_8250_BCM2835AUX y
        SERIAL_8250_EXTENDED y
        SERIAL_8250_SHARE_IRQ y

        # Cavium ThunderX stuff.
        PCI_HOST_THUNDER_ECAM y

        # Nvidia Tegra stuff.
        PCI_TEGRA y

        # The default (=y) forces us to have the XHCI firmware available in initrd,
        # which our initrd builder can't currently do easily.
        USB_XHCI_TEGRA m
      '';
      target = "Image";
    };
    gcc = {
      arch = "armv8-a";
    };
  };

  apple-m1 = {
    gcc = {
      arch = "armv8.3-a+crypto+sha2+aes+crc+fp16+lse+simd+ras+rdm+rcpc";
      cpu = "apple-a13";
    };
  };

  ##
  ## MIPS
  ##

  ben_nanonote = {
    linux-kernel = {
      name = "ben_nanonote";
    };
    gcc = {
      arch = "mips32";
      float = "soft";
    };
  };

  fuloong2f_n32 = {
    linux-kernel = {
      name = "fuloong2f_n32";
      baseConfig = "lemote2f_defconfig";
      autoModules = false;
      extraConfig = ''
        MIGRATION n
        COMPACTION n

        # nixos mounts some cgroup
        CGROUPS y

        BLK_DEV_RAM y
        BLK_DEV_INITRD y
        BLK_DEV_CRYPTOLOOP m
        BLK_DEV_DM m
        DM_CRYPT m
        MD y
        REISERFS_FS m
        EXT4_FS m
        USB_STORAGE_CYPRESS_ATACB m

        IP_PNP y
        IP_PNP_DHCP y
        IP_PNP_BOOTP y
        NFS_FS y
        ROOT_NFS y
        TUN m
        NFS_V4 y
        NFS_V4_1 y
        NFS_FSCACHE y
        NFSD m
        NFSD_V2_ACL y
        NFSD_V3 y
        NFSD_V3_ACL y
        NFSD_V4 y

        # Fail to build
        DRM n
        SCSI_ADVANSYS n
        USB_ISP1362_HCD n
        SND_SOC n
        SND_ALI5451 n
        FB_SAVAGE n
        SCSI_NSP32 n
        ATA_SFF n
        SUNGEM n
        IRDA n
        ATM_HE n
        SCSI_ACARD n
        BLK_DEV_CMD640_ENHANCED n

        FUSE_FS m

        # Needed for udev >= 150
        SYSFS_DEPRECATED_V2 n

        VGA_CONSOLE n
        VT_HW_CONSOLE_BINDING y
        SERIAL_8250_CONSOLE y
        FRAMEBUFFER_CONSOLE y
        EXT2_FS y
        EXT3_FS y
        REISERFS_FS y
        MAGIC_SYSRQ y

        # The kernel doesn't boot at all, with FTRACE
        FTRACE n
      '';
      target = "vmlinux";
    };
    gcc = {
      arch = "loongson2f";
      float = "hard";
      abi = "n32";
    };
  };

  # can execute on 32bit chip
  gcc_mips32r2_o32 = {
    gcc = {
      arch = "mips32r2";
      abi = "32";
    };
  };
  gcc_mips32r6_o32 = {
    gcc = {
      arch = "mips32r6";
      abi = "32";
    };
  };
  gcc_mips64r2_n32 = {
    gcc = {
      arch = "mips64r2";
      abi = "n32";
    };
  };
  gcc_mips64r6_n32 = {
    gcc = {
      arch = "mips64r6";
      abi = "n32";
    };
  };
  gcc_mips64r2_64 = {
    gcc = {
      arch = "mips64r2";
      abi = "64";
    };
  };
  gcc_mips64r6_64 = {
    gcc = {
      arch = "mips64r6";
      abi = "64";
    };
  };

  # based on:
  #   https://www.mail-archive.com/qemu-discuss@nongnu.org/msg05179.html
  #   https://gmplib.org/~tege/qemu.html#mips64-debian
  mips64el-qemu-linux-gnuabi64 = {
    linux-kernel = {
      name = "mips64el";
      baseConfig = "64r2el_defconfig";
      target = "vmlinuz";
      autoModules = false;
      DTB = true;
      # for qemu 9p passthrough filesystem
      extraConfig = ''
        MIPS_MALTA y
        PAGE_SIZE_4KB y
        CPU_LITTLE_ENDIAN y
        CPU_MIPS64_R2 y
        64BIT y
        CPU_MIPS64_R2 y

        NET_9P y
        NET_9P_VIRTIO y
        9P_FS y
        9P_FS_POSIX_ACL y
        PCI y
        VIRTIO_PCI y
      '';
    };
  };

  ##
  ## Other
  ##

  riscv-multiplatform = {
    linux-kernel = {
      name = "riscv-multiplatform";
      target = "Image";
      autoModules = true;
      preferBuiltin = true;
      baseConfig = "defconfig";
      DTB = true;
    };
  };

  loongarch64-multiplatform = {
    gcc = {
      # https://github.com/loongson/la-softdev-convention/blob/master/la-softdev-convention.adoc#10-operating-system-package-build-requirements
      arch = "la64v1.0";
      strict-align = false;
      # Avoid text sections of large apps exceeding default code model
      # Will be default behavior in LLVM 21 and hopefully GCC16
      # https://github.com/loongson-community/discussions/issues/43
      # https://github.com/llvm/llvm-project/pull/132173
      cmodel = "medium";
    };
    linux-kernel = {
      name = "loongarch-multiplatform";
      target = "vmlinuz.efi";
      autoModules = true;
      preferBuiltin = true;
      baseConfig = "defconfig";
      DTB = true;
    };
  };

  # This function takes a minimally-valid "platform" and returns an
  # attrset containing zero or more additional attrs which should be
  # included in the platform in order to further elaborate it.
  select =
    platform:
    # x86
    if platform.isx86 then
      pc

    # ARM
    else if platform.isAarch32 then
      let
        version = platform.parsed.cpu.version or null;
      in
      if version == null then
        pc
      else if lib.versionOlder version "6" then
        sheevaplug
      else if lib.versionOlder version "7" then
        raspberrypi
      else
        armv7l-hf-multiplatform

    else if platform.isAarch64 then
      if platform.isDarwin then apple-m1 else aarch64-multiplatform

    else if platform.isLoongArch64 then
      loongarch64-multiplatform

    else if platform.isRiscV then
      riscv-multiplatform

    else if platform.parsed.cpu == lib.systems.parse.cpuTypes.mipsel then
      (import ./examples.nix { inherit lib; }).mipsel-linux-gnu

    else if platform.parsed.cpu == lib.systems.parse.cpuTypes.powerpc64le then
      powernv

    else if platform.isLoongArch64 then
      loongarch64-multiplatform
    else
      { };
}
</file>

<file path="lib/systems/supported.nix">
# Supported systems according to RFC0046's definition.
#
# https://github.com/NixOS/rfcs/blob/master/rfcs/0046-platform-support-tiers.md
{ lib }:
rec {
  # List of systems that are built by Hydra.
  hydra = tier1 ++ tier2 ++ tier3 ++ [
    "aarch64-darwin"
  ];

  tier1 = [
    "x86_64-linux"
  ];

  tier2 = [
    "aarch64-linux"
    "x86_64-darwin"
  ];

  tier3 = [
    "armv6l-linux"
    "armv7l-linux"
    "i686-linux"
    "mipsel-linux"
  ];
}
</file>

<file path="lib/tests/flakes/subflakeTest/subflake/flake.nix">
{
  outputs = { self }: {
    subflakeOutput = 1;
  };
}
</file>

<file path="lib/tests/flakes/subflakeTest/flake.nix">
{
  outputs = { self, subflake, callLocklessFlake }: rec {
    x = (callLocklessFlake {
      path = subflake;
      inputs = {};
    }).subflakeOutput;
  };
}
</file>

<file path="lib/tests/modules/disable-recursive/bar.nix">
{
  imports = [
    ../declare-enable.nix
  ];
}
</file>

<file path="lib/tests/modules/disable-recursive/disable-bar.nix">
{

  disabledModules = [
    ./bar.nix
  ];

}
</file>

<file path="lib/tests/modules/disable-recursive/disable-foo.nix">
{

  disabledModules = [
    ./foo.nix
  ];

}
</file>

<file path="lib/tests/modules/disable-recursive/foo.nix">
{
  imports = [
    ../declare-enable.nix
  ];
}
</file>

<file path="lib/tests/modules/disable-recursive/main.nix">
{
  imports = [
    ./foo.nix
    ./bar.nix
  ];

  enable = true;
}
</file>

<file path="lib/tests/modules/functionTo/list-order.nix">
{ lib, config, ... }:
let
  inherit (lib) types;
in
{
  options = {
    fun = lib.mkOption {
      type = types.functionTo (types.listOf types.str);
    };

    result = lib.mkOption {
      type = types.str;
      default = toString (
        config.fun {
          a = "a";
          b = "b";
          c = "c";
        }
      );
    };
  };

  config.fun = lib.mkMerge [
    (input: lib.mkAfter [ input.a ])
    (input: [ input.b ])
  ];
}
</file>

<file path="lib/tests/modules/functionTo/merging-attrs.nix">
{ lib, config, ... }:
let
  inherit (lib) types;
in
{
  options = {
    fun = lib.mkOption {
      type = types.functionTo (types.attrsOf types.str);
    };

    result = lib.mkOption {
      type = types.str;
      default = toString (
        lib.attrValues (
          config.fun {
            a = "a";
            b = "b";
            c = "c";
          }
        )
      );
    };
  };

  config.fun = lib.mkMerge [
    (input: { inherit (input) a; })
    (input: { inherit (input) b; })
    (input: {
      b = lib.mkForce input.c;
    })
  ];
}
</file>

<file path="lib/tests/modules/functionTo/merging-list.nix">
{ lib, config, ... }:
let
  inherit (lib) types;
in
{
  options = {
    fun = lib.mkOption {
      type = types.functionTo (types.listOf types.str);
    };

    result = lib.mkOption {
      type = types.str;
      default = toString (
        config.fun {
          a = "a";
          b = "b";
          c = "c";
        }
      );
    };
  };

  config.fun = lib.mkMerge [
    (input: [ input.a ])
    (input: [ input.b ])
  ];
}
</file>

<file path="lib/tests/modules/functionTo/submodule-options.nix">
{
  lib,
  config,
  options,
  ...
}:
let
  inherit (lib) types;
in
{
  imports = [

    # fun.<function-body>.a
    (
      { ... }:
      {
        options = {
          fun = lib.mkOption {
            type = types.functionTo (
              types.submodule {
                options.a = lib.mkOption { default = "a"; };
              }
            );
          };
        };
      }
    )

    # fun.<function-body>.b
    (
      { ... }:
      {
        options = {
          fun = lib.mkOption {
            type = types.functionTo (
              types.submodule {
                options.b = lib.mkOption { default = "b"; };
              }
            );
          };
        };
      }
    )
  ];

  options = {
    result = lib.mkOption {
      type = types.str;
      default = lib.concatStringsSep " " (
        lib.attrValues (config.fun (throw "shouldn't use input param"))
      );
    };

    optionsResult = lib.mkOption {
      type = types.str;
      default = lib.concatStringsSep " " (
        lib.concatLists (
          lib.mapAttrsToList (k: v: if k == "_module" then [ ] else [ (lib.showOption v.loc) ]) (
            (options.fun.type.getSubOptions [ "fun" ])
          )
        )
      );
    };
  };

  config.fun = lib.mkMerge [
    (input: { b = "bee"; })
  ];
}
</file>

<file path="lib/tests/modules/functionTo/trivial.nix">
{ lib, config, ... }:
let
  inherit (lib) types;
in
{
  options = {
    fun = lib.mkOption {
      type = types.functionTo types.str;
    };

    result = lib.mkOption {
      type = types.str;
      default = config.fun "input";
    };
  };

  config.fun = input: "input is ${input}";
}
</file>

<file path="lib/tests/modules/functionTo/wrong-type.nix">
{ lib, config, ... }:
let
  inherit (lib) types;
in
{
  options = {
    fun = lib.mkOption {
      type = types.functionTo types.str;
    };

    result = lib.mkOption {
      type = types.str;
      default = config.fun 0;
    };
  };

  config.fun = input: input + 1;
}
</file>

<file path="lib/tests/modules/graph/a.nix">
{
  imports = [
    {
      imports = [ { } ];
    }
  ];
  disabledModules = [ ./b.nix ];
}
</file>

<file path="lib/tests/modules/graph/b.nix">
args: {
  imports = [ { key = "explicit-key"; } ];
}
</file>

<file path="lib/tests/modules/graph/test.nix">
let
  lib = import ../../..;

  evaluation = lib.evalModules {
    modules = [
      { }
      (args: { })
      ./a.nix
      ./b.nix
    ];
  };

  actual = evaluation.graph;

  expected = [
    {
      key = ":anon-1";
      file = "<unknown-file>";
      imports = [ ];
      disabled = false;
    }
    {
      key = ":anon-2";
      file = "<unknown-file>";
      imports = [ ];
      disabled = false;
    }
    {
      key = toString ./a.nix;
      file = toString ./a.nix;
      imports = [
        {
          key = "${toString ./a.nix}:anon-1";
          file = toString ./a.nix;
          imports = [
            {
              key = "${toString ./a.nix}:anon-1:anon-1";
              file = toString ./a.nix;
              imports = [ ];
              disabled = false;
            }
          ];
          disabled = false;
        }
      ];
      disabled = false;
    }
    {
      key = toString ./b.nix;
      file = toString ./b.nix;
      imports = [
        {
          key = "explicit-key";
          file = toString ./b.nix;
          imports = [ ];
          disabled = false;
        }
      ];
      disabled = true;
    }
  ];
in
assert actual == expected;
null
</file>

<file path="lib/tests/modules/types-anything/attrs-coercible.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  config.value = {
    outPath = "foo";
    err = throw "err";
  };

}
</file>

<file path="lib/tests/modules/types-anything/equal-atoms.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  config = lib.mkMerge [
    {
      value.int = 0;
      value.bool = false;
      value.string = "";
      value.path = ./.;
      value.null = null;
      value.float = 0.1;
      value.list = [
        1
        "a"
        { x = null; }
      ];
    }
    {
      value.int = 0;
      value.bool = false;
      value.string = "";
      value.path = ./.;
      value.null = null;
      value.float = 0.1;
      value.list = [
        1
        "a"
        { x = null; }
      ];
    }
  ];

}
</file>

<file path="lib/tests/modules/types-anything/functions.nix">
{ lib, config, ... }:
{

  options.valueIsFunction = lib.mkOption {
    default = lib.mapAttrs (name: lib.isFunction) config.value;
  };

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  options.applied = lib.mkOption {
    default = lib.mapAttrs (name: fun: fun null) config.value;
  };

  config = lib.mkMerge [
    {
      value.single-lambda = x: x;
      value.multiple-lambdas = x: { inherit x; };
      value.merging-lambdas = x: { inherit x; };
    }
    {
      value.multiple-lambdas = x: [ x ];
      value.merging-lambdas = y: { inherit y; };
    }
  ];

}
</file>

<file path="lib/tests/modules/types-anything/lists.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  config = lib.mkMerge [
    {
      value = [ "a value" ];
    }
    {
      value = [ "another value" ];
    }
  ];

}
</file>

<file path="lib/tests/modules/types-anything/mk-mods.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  config = lib.mkMerge [
    {
      value.mkiffalse = lib.mkIf false { };
    }
    {
      value.mkiftrue = lib.mkIf true { };
    }
    {
      value.mkdefault = lib.mkDefault 0;
    }
    {
      value.mkdefault = 1;
    }
    {
      value.mkmerge = lib.mkMerge [
        { }
      ];
    }
    {
      value.mkbefore = lib.mkBefore true;
    }
    {
      value.nested = lib.mkMerge [
        {
          foo = lib.mkDefault 0;
          bar = lib.mkIf false 0;
        }
        (lib.mkIf true {
          foo = lib.mkIf true (lib.mkForce 1);
          bar = {
            baz = lib.mkDefault "baz";
          };
        })
      ];
    }
  ];

}
</file>

<file path="lib/tests/modules/types-anything/nested-attrs.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.anything;
  };

  config = lib.mkMerge [
    {
      value.foo = null;
    }
    {
      value.l1.foo = null;
    }
    {
      value.l1.l2.foo = null;
    }
    {
      value.l1.l2.l3.foo = null;
    }
  ];

}
</file>

<file path="lib/tests/modules/adhoc-freeformType-survives-type-merge.nix">
{ lib, ... }:
{
  options.dummy = lib.mkOption {
    type = lib.types.anything;
    default = { };
  };
  freeformType =
    let
      a = lib.types.attrsOf (lib.types.submodule { options.bar = lib.mkOption { }; });
    in
    # modifying types like this breaks type merging.
    # This test makes sure that type merging is not performed when only a single declaration exists.
    # Don't modify types in practice!
    a
    // {
      merge = loc: defs: { freeformItems = a.merge loc defs; };
    };
  config.foo.bar = "ok";
}
</file>

<file path="lib/tests/modules/alias-with-priority-can-override.nix">
# This is a test to show that mkAliasOptionModule sets the priority correctly
# for aliased options.
#
# This test shows that an alias with a high priority is able to override
# a non-aliased option.

{ config, lib, ... }:

let
  inherit (lib)
    mkAliasOptionModule
    mkForce
    mkOption
    types
    ;
in

{
  options = {
    # A simple boolean option that can be enabled or disabled.
    enable = mkOption {
      type = types.nullOr types.bool;
      default = null;
      example = true;
      description = ''
        Some descriptive text
      '';
    };

    # mkAliasOptionModule sets warnings, so this has to be defined.
    warnings = mkOption {
      internal = true;
      default = [ ];
      type = types.listOf types.str;
      example = [ "The `foo' service is deprecated and will go away soon!" ];
      description = ''
        This option allows modules to show warnings to users during
        the evaluation of the system configuration.
      '';
    };
  };

  imports = [
    # Create an alias for the "enable" option.
    (mkAliasOptionModule [ "enableAlias" ] [ "enable" ])

    # Disable the aliased option with a high priority so it
    # should override the next import.
    (
      { config, lib, ... }:
      {
        enableAlias = mkForce false;
      }
    )

    # Enable the normal (non-aliased) option.
    (
      { config, lib, ... }:
      {
        enable = true;
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/alias-with-priority.nix">
# This is a test to show that mkAliasOptionModule sets the priority correctly
# for aliased options.
#
# This test shows that an alias with a low priority is able to be overridden
# with a non-aliased option.

{ config, lib, ... }:

let
  inherit (lib)
    mkAliasOptionModule
    mkDefault
    mkOption
    types
    ;
in

{
  options = {
    # A simple boolean option that can be enabled or disabled.
    enable = mkOption {
      type = types.nullOr types.bool;
      default = null;
      example = true;
      description = ''
        Some descriptive text
      '';
    };

    # mkAliasOptionModule sets warnings, so this has to be defined.
    warnings = mkOption {
      internal = true;
      default = [ ];
      type = types.listOf types.str;
      example = [ "The `foo' service is deprecated and will go away soon!" ];
      description = ''
        This option allows modules to show warnings to users during
        the evaluation of the system configuration.
      '';
    };
  };

  imports = [
    # Create an alias for the "enable" option.
    (mkAliasOptionModule [ "enableAlias" ] [ "enable" ])

    # Disable the aliased option, but with a default (low) priority so it
    # should be able to be overridden by the next import.
    (
      { config, lib, ... }:
      {
        enableAlias = mkDefault false;
      }
    )

    # Enable the normal (non-aliased) option.
    (
      { config, lib, ... }:
      {
        enable = true;
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/assert-module-class-is-nixos.nix">
{ _class, ... }:
assert _class == "nixos";
{ }
</file>

<file path="lib/tests/modules/attrsOf-conditional-check.nix">
{ lib, config, ... }:
{
  options.conditionalWorks = lib.mkOption {
    default = !config.value ? foo;
  };

  config.value.foo = lib.mkIf false "should not be defined";
}
</file>

<file path="lib/tests/modules/attrsOf-lazy-check.nix">
{ lib, config, ... }:
{
  options.isLazy = lib.mkOption {
    default = !config.value ? foo;
  };

  config.value.bar = throw "is not lazy";
}
</file>

<file path="lib/tests/modules/boolByOr.nix">
{ lib, ... }:
{

  options.value = lib.mkOption {
    type = lib.types.lazyAttrsOf lib.types.boolByOr;
  };

  config.value = {
    falseFalse = lib.mkMerge [
      false
      false
    ];
    trueFalse = lib.mkMerge [
      true
      false
    ];
    falseTrue = lib.mkMerge [
      false
      true
    ];
    trueTrue = lib.mkMerge [
      true
      true
    ];
  };
}
</file>

<file path="lib/tests/modules/class-check.nix">
{ lib, ... }:
{
  options = {
    sub = {
      nixosOk = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "nixos";
          modules = [
            ./assert-module-class-is-nixos.nix
          ];
        };
      };
      # Same but will have bad definition
      nixosFail = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "nixos";
          modules = [ ];
        };
      };

      mergeFail = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "nixos";
          modules = [ ];
        };
        default = { };
      };
    };
  };
  imports = [
    {
      options = {
        sub = {
          mergeFail = lib.mkOption {
            type = lib.types.submoduleWith {
              class = "darwin";
              modules = [ ];
            };
          };
        };
      };
    }
  ];
  config = {
    _module.freeformType = lib.types.anything;
    ok = lib.evalModules {
      class = "nixos";
      modules = [
        ./module-class-is-nixos.nix
        ./assert-module-class-is-nixos.nix
      ];
    };

    fail = lib.evalModules {
      class = "nixos";
      modules = [
        ./module-class-is-nixos.nix
        ./module-class-is-darwin.nix
      ];
    };

    fail-anon = lib.evalModules {
      class = "nixos";
      modules = [
        ./module-class-is-nixos.nix
        {
          _file = "foo.nix#darwinModules.default";
          _class = "darwin";
          config = { };
          imports = [ ];
        }
      ];
    };

    sub.nixosOk = {
      _class = "nixos";
    };
    sub.nixosFail = {
      imports = [ ./module-class-is-darwin.nix ];
    };
  };
}
</file>

<file path="lib/tests/modules/declaration-positions.nix">
{ lib, options, ... }:
let
  discardPositions = lib.mapAttrs (k: v: v);
in
# unsafeGetAttrPos is unspecified best-effort behavior, so we only want to consider this test on an evaluator that satisfies some basic assumptions about this function.
assert builtins.unsafeGetAttrPos "a" { a = true; } != null;
assert
  builtins.unsafeGetAttrPos "a" (discardPositions {
    a = true;
  }) == null;
{
  imports = [
    {
      options.imported.line14 = lib.mkOption {
        type = lib.types.int;
      };

      # Simulates various patterns of generating modules such as
      # programs.firefox.nativeMessagingHosts.ff2mpv. We don't expect to get
      # line numbers for these, but we can fall back on knowing the file.
      options.generated = discardPositions {
        line22 = lib.mkOption {
          type = lib.types.int;
        };
      };

      options.submoduleLine38.extraOptLine27 = lib.mkOption {
        default = 1;
        type = lib.types.int;
      };
    }
  ];

  options.nested.nestedLine34 = lib.mkOption {
    type = lib.types.int;
  };

  options.submoduleLine38 = lib.mkOption {
    default = { };
    type = lib.types.submoduleWith {
      modules = [
        (
          { options, ... }:
          {
            options.submodDeclLine45 = lib.mkOption { };
          }
        )
        { freeformType = with lib.types; lazyAttrsOf (uniq unspecified); }
      ];
    };
  };

  config = {
    submoduleLine38.submodDeclLine45 =
      (options.submoduleLine38.type.getSubOptions [ ]).submodDeclLine45.declarationPositions;
  };
}
</file>

<file path="lib/tests/modules/declare-attrsOf.nix">
{ lib, ... }:
let
  deathtrapArgs = lib.mapAttrs (
    k: _: throw "The module system is too strict, accessing an unused option's ${k} mkOption-attribute."
  ) (lib.functionArgs lib.mkOption);
in
{
  options.value = lib.mkOption {
    type = lib.types.attrsOf lib.types.str;
    default = { };
  };
  options.testing-laziness-so-don't-read-me = lib.mkOption deathtrapArgs;
}
</file>

<file path="lib/tests/modules/declare-attrsOfSub-any-enable.nix">
{ lib, ... }:

let
  submod =
    { ... }:
    {
      options = {
        enable = lib.mkOption {
          default = false;
          example = true;
          type = lib.types.bool;
          description = ''
            Some descriptive text
          '';
        };
      };
    };
in

{
  options = {
    attrsOfSub = lib.mkOption {
      default = { };
      example = { };
      type = lib.types.attrsOf (lib.types.submodule [ submod ]);
      description = ''
        Some descriptive text
      '';
    };
  };
}
</file>

<file path="lib/tests/modules/declare-bare-submodule-deep-option-duplicate.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.bare-submodule.deep = mkOption {
    type = types.int;
    default = 2;
  };
}
</file>

<file path="lib/tests/modules/declare-bare-submodule-deep-option.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.bare-submodule.deep = mkOption {
    type = types.int;
    default = 2;
  };
}
</file>

<file path="lib/tests/modules/declare-bare-submodule-nested-option.nix">
{ config, lib, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.bare-submodule = mkOption {
    type = types.submoduleWith {
      shorthandOnlyDefinesConfig = config.shorthandOnlyDefinesConfig;
      modules = [
        {
          options.nested = mkOption {
            type = types.int;
            default = 1;
          };
        }
      ];
    };
  };
}
</file>

<file path="lib/tests/modules/declare-bare-submodule.nix">
{ config, lib, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.bare-submodule = mkOption {
    type = types.submoduleWith {
      modules = [ ];
      shorthandOnlyDefinesConfig = config.shorthandOnlyDefinesConfig;
    };
    default = { };
  };

  # config-dependent options: won't recommend, but useful for making this test parameterized
  options.shorthandOnlyDefinesConfig = mkOption {
    default = false;
  };
}
</file>

<file path="lib/tests/modules/declare-coerced-value-no-default.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      type = lib.types.coercedTo lib.types.int builtins.toString lib.types.str;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-coerced-value-unsound.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      default = "12";
      type = lib.types.coercedTo lib.types.str lib.toInt lib.types.ints.s8;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-coerced-value.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      default = 42;
      type = lib.types.coercedTo lib.types.int builtins.toString lib.types.str;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-either.nix">
{ lib, ... }:
{
  options.value = lib.mkOption {
    type = lib.types.either lib.types.int lib.types.str;
  };
}
</file>

<file path="lib/tests/modules/declare-enable-nested.nix">
{ lib, ... }:

{
  options.set = {
    enable = lib.mkOption {
      default = false;
      example = true;
      type = lib.types.bool;
      description = ''
        Some descriptive text
      '';
    };
  };
}
</file>

<file path="lib/tests/modules/declare-enable.nix">
{ lib, ... }:

{
  options = {
    enable = lib.mkOption {
      default = false;
      example = true;
      type = lib.types.bool;
      description = ''
        Some descriptive text
      '';
    };
  };
}
</file>

<file path="lib/tests/modules/declare-int-between-value.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      type = lib.types.ints.between (-21) 43;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-int-positive-value-nested.nix">
{ lib, ... }:

{
  options.set = {
    value = lib.mkOption {
      type = lib.types.ints.positive;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-int-positive-value.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      type = lib.types.ints.positive;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-int-unsigned-value.nix">
{ lib, ... }:

{
  options = {
    value = lib.mkOption {
      type = lib.types.ints.unsigned;
    };
  };
}
</file>

<file path="lib/tests/modules/declare-lazyAttrsOf.nix">
{ lib, ... }:
{
  options.value = lib.mkOption {
    type = lib.types.lazyAttrsOf (lib.types.str // { emptyValue.value = "empty"; });
    default = { };
  };
}
</file>

<file path="lib/tests/modules/declare-mkPackageOption.nix">
{ lib, ... }:
let
  pkgs.hello = {
    type = "derivation";
    pname = "hello";
  };
in
{
  options = {
    package = lib.mkPackageOption pkgs "hello" { };

    namedPackage = lib.mkPackageOption pkgs "Hello" {
      default = [ "hello" ];
    };

    namedPackageSingletonDefault = lib.mkPackageOption pkgs "Hello" {
      default = "hello";
    };

    pathPackage = lib.mkPackageOption pkgs [ "hello" ] { };

    packageWithExample = lib.mkPackageOption pkgs "hello" {
      example = "pkgs.hello.override { stdenv = pkgs.clangStdenv; }";
    };

    packageWithPathExample = lib.mkPackageOption pkgs "hello" {
      example = [ "hello" ];
    };

    packageWithExtraDescription = lib.mkPackageOption pkgs "hello" {
      extraDescription = "Example extra description.";
    };

    undefinedPackage = lib.mkPackageOption pkgs "hello" {
      default = null;
    };

    nullablePackage = lib.mkPackageOption pkgs "hello" {
      nullable = true;
      default = null;
    };

    nullablePackageWithDefault = lib.mkPackageOption pkgs "hello" {
      nullable = true;
    };

    packageWithPkgsText = lib.mkPackageOption pkgs "hello" {
      pkgsText = "myPkgs";
    };

    packageFromOtherSet =
      let
        myPkgs = {
          hello = pkgs.hello // {
            pname = "hello-other";
          };
        };
      in
      lib.mkPackageOption myPkgs "hello" { };

    packageInvalidIdentifier =
      let
        myPkgs."123"."with\"quote" = { inherit (pkgs) hello; };
      in
      lib.mkPackageOption myPkgs [ "123" "with\"quote" "hello" ] { };

    packageInvalidIdentifierExample = lib.mkPackageOption pkgs "hello" {
      example = [
        "123"
        "with\"quote"
        "hello"
      ];
    };
  };
}
</file>

<file path="lib/tests/modules/declare-oneOf.nix">
{ lib, ... }:
{
  options.value = lib.mkOption {
    type = lib.types.oneOf [
      lib.types.int
      (lib.types.listOf lib.types.int)
      lib.types.str
    ];
  };
}
</file>

<file path="lib/tests/modules/declare-set.nix">
{ lib, ... }:

{
  options.set = lib.mkOption {
    default = { };
    example = {
      a = 1;
    };
    type = lib.types.attrsOf lib.types.int;
    description = ''
      Some descriptive text
    '';
  };
}
</file>

<file path="lib/tests/modules/declare-submodule-via-evalModules.nix">
{ lib, ... }:
{
  options.submodule = lib.mkOption {
    inherit
      (lib.evalModules {
        modules = [
          {
            options.inner = lib.mkOption {
              type = lib.types.bool;
              default = false;
            };
          }
        ];
      })
      type
      ;
    default = { };
  };

  config.submodule = lib.mkMerge [
    (
      { lib, ... }:
      {
        options.outer = lib.mkOption {
          type = lib.types.bool;
          default = false;
        };
      }
    )
    {
      inner = true;
      outer = true;
    }
  ];
}
</file>

<file path="lib/tests/modules/declare-submoduleWith-modules.nix">
{ lib, ... }:
{
  options.submodule = lib.mkOption {
    type = lib.types.submoduleWith {
      modules = [
        {
          options.inner = lib.mkOption {
            type = lib.types.bool;
            default = false;
          };
        }
      ];
    };
    default = { };
  };

  config.submodule = lib.mkMerge [
    (
      { lib, ... }:
      {
        options.outer = lib.mkOption {
          type = lib.types.bool;
          default = false;
        };
      }
    )
    {
      inner = true;
      outer = true;
    }
  ];
}
</file>

<file path="lib/tests/modules/declare-submoduleWith-noshorthand.nix">
{ lib, ... }:
let
  sub.options.config = lib.mkOption {
    type = lib.types.bool;
    default = false;
  };
in
{
  options.submodule = lib.mkOption {
    type = lib.types.submoduleWith {
      modules = [ sub ];
    };
    default = { };
  };
}
</file>

<file path="lib/tests/modules/declare-submoduleWith-path.nix">
{ lib, ... }:
{
  options.submodule = lib.mkOption {
    type = lib.types.submoduleWith {
      modules = [
        ./declare-enable.nix
      ];
    };
    default = { };
  };

  config.submodule = ./define-enable.nix;
}
</file>

<file path="lib/tests/modules/declare-submoduleWith-shorthand.nix">
{ lib, ... }:
let
  sub.options.config = lib.mkOption {
    type = lib.types.bool;
    default = false;
  };
in
{
  options.submodule = lib.mkOption {
    type = lib.types.submoduleWith {
      modules = [ sub ];
      shorthandOnlyDefinesConfig = true;
    };
    default = { };
  };
}
</file>

<file path="lib/tests/modules/declare-submoduleWith-special.nix">
{ lib, ... }:
{
  options.submodule = lib.mkOption {
    type = lib.types.submoduleWith {
      modules = [
        (
          { lib, ... }:
          {
            options.foo = lib.mkOption {
              default = lib.foo;
            };
          }
        )
      ];
      specialArgs.lib = lib // {
        foo = "foo";
      };
    };
    default = { };
  };
}
</file>

<file path="lib/tests/modules/declare-variants.nix">
{ lib, moduleType, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.variants = mkOption {
    type = types.lazyAttrsOf moduleType;
    default = { };
  };
}
</file>

<file path="lib/tests/modules/default-type-merge-both.nix">
{ lib, options, ... }:
let
  foo = lib.mkOptionType {
    name = "foo";
    functor = lib.types.defaultFunctor "foo" // {
      wrapped = lib.types.int;
      payload = 10;
    };
  };
in
{
  imports = [
    {
      options.foo = lib.mkOption {
        type = foo;
      };
    }
    {
      options.foo = lib.mkOption {
        type = foo;
      };
    }
  ];

  options.result = lib.mkOption {
    default = builtins.seq options.foo null;
  };
}
</file>

<file path="lib/tests/modules/default.nix">
{
  lib ? import ../..,
  modules ? [ ],
}:

{
  inherit
    (lib.evalModules {
      inherit modules;
      specialArgs.modulesPath = ./.;
    })
    config
    options
    ;
}
</file>

<file path="lib/tests/modules/deferred-module-error.nix">
{ config, lib, ... }:
let
  inherit (lib)
    types
    mkOption
    setDefaultModuleLocation
    evalModules
    ;
  inherit (types)
    deferredModule
    lazyAttrsOf
    submodule
    str
    raw
    enum
    ;
in
{
  options = {
    deferred = mkOption {
      type = deferredModule;
    };
    result = mkOption {
      default = (evalModules { modules = [ config.deferred ]; }).config.result;
    };
  };
  config = {
    deferred =
      { ... }:
      # this should be an attrset, so this fails
      true;
  };
}
</file>

<file path="lib/tests/modules/deferred-module.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption setDefaultModuleLocation;
  inherit (types)
    deferredModule
    lazyAttrsOf
    submodule
    str
    raw
    enum
    ;
in
{
  imports = [
    # generic module, declaring submodules:
    #   - nodes.<name>
    #   - default
    # where all nodes include the default
    (
      { config, ... }:
      {
        _file = "generic.nix";
        options.nodes = mkOption {
          type = lazyAttrsOf (submodule {
            imports = [ config.default ];
          });
          default = { };
        };
        options.default = mkOption {
          type = deferredModule;
          default = { };
          description = ''
            Module that is included in all nodes.
          '';
        };
      }
    )

    {
      _file = "default-1.nix";
      default =
        { config, ... }:
        {
          options.settingsDict = lib.mkOption {
            type = lazyAttrsOf str;
            default = { };
          };
          options.bottom = lib.mkOption { type = enum [ ]; };
        };
    }

    {
      _file = "default-a-is-b.nix";
      default = ./define-settingsDict-a-is-b.nix;
    }

    {
      _file = "nodes-foo.nix";
      nodes.foo.settingsDict.b = "beta";
    }

    {
      _file = "the-file-that-contains-the-bad-config.nix";
      default.bottom = "bogus";
    }

    {
      _file = "nodes-foo-c-is-a.nix";
      nodes.foo =
        { config, ... }:
        {
          settingsDict.c = config.settingsDict.a;
        };
    }

  ];
}
</file>

<file path="lib/tests/modules/define-_module-args-custom.nix">
{ ... }:

{
  config = {
    _module.args.custom = true;
  };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-bar-enable.nix">
{
  attrsOfSub.bar.enable = true;
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-bar.nix">
{
  attrsOfSub.bar = { };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo-enable-force.nix">
{ lib, ... }:

{
  attrsOfSub.foo.enable = lib.mkForce false;
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo-enable-if.nix">
{ config, lib, ... }:

{
  attrsOfSub.foo.enable = lib.mkIf config.enable true;
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo-enable.nix">
{
  attrsOfSub.foo.enable = true;
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo-force-enable.nix">
{ lib, ... }:

{
  attrsOfSub.foo = lib.mkForce {
    enable = false;
  };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo-if-enable.nix">
{ config, lib, ... }:

{
  attrsOfSub.foo = lib.mkIf config.enable {
    enable = true;
  };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-foo.nix">
{
  attrsOfSub.foo = { };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-force-foo-enable.nix">
{ lib, ... }:

{
  attrsOfSub = lib.mkForce {
    foo.enable = false;
  };
}
</file>

<file path="lib/tests/modules/define-attrsOfSub-if-foo-enable.nix">
{ config, lib, ... }:

{
  attrsOfSub = lib.mkIf config.enable {
    foo.enable = true;
  };
}
</file>

<file path="lib/tests/modules/define-bare-submodule-values.nix">
{
  bare-submodule.nested = 42;
  bare-submodule.deep = 420;
}
</file>

<file path="lib/tests/modules/define-enable-abort.nix">
{
  config.enable = abort "oops";
}
</file>

<file path="lib/tests/modules/define-enable-force.nix">
{ lib, ... }:

{
  enable = lib.mkForce false;
}
</file>

<file path="lib/tests/modules/define-enable-throw.nix">
{
  config.enable = throw "oops";
}
</file>

<file path="lib/tests/modules/define-enable-with-custom-arg.nix">
{ custom, ... }:

{
  config = {
    enable = custom;
  };
}
</file>

<file path="lib/tests/modules/define-enable-with-top-level-mkIf.nix">
{ lib, ... }:
# I think this might occur more realistically in a submodule
{
  imports = [ (lib.mkIf true { enable = true; }) ];
}
</file>

<file path="lib/tests/modules/define-enable.nix">
{
  enable = true;
}
</file>

<file path="lib/tests/modules/define-force-attrsOfSub-foo-enable.nix">
{ lib, ... }:

lib.mkForce {
  attrsOfSub.foo.enable = false;
}
</file>

<file path="lib/tests/modules/define-force-enable.nix">
{ lib, ... }:

lib.mkForce {
  enable = false;
}
</file>

<file path="lib/tests/modules/define-freeform-keywords-shorthand.nix">
{ config, ... }:
{
  class = {
    "just" = "data";
  };
  a = "one";
  b = "two";
  meta = "meta";

  _module.args.result =
    let
      r = builtins.removeAttrs config [ "_module" ];
    in
    builtins.trace (builtins.deepSeq r r) (
      r == {
        a = "one";
        b = "two";
        class = {
          "just" = "data";
        };
        meta = "meta";
      }
    );
}
</file>

<file path="lib/tests/modules/define-if-attrsOfSub-foo-enable.nix">
{ config, lib, ... }:

lib.mkIf config.enable {
  attrsOfSub.foo.enable = true;
}
</file>

<file path="lib/tests/modules/define-module-check.nix">
{
  _module.check = false;
}
</file>

<file path="lib/tests/modules/define-option-dependently-nested.nix">
{ lib, options, ... }:

# Some modules may be distributed separately and need to adapt to other modules
# that are distributed and versioned separately.
{

  # Always defined, but the value depends on the presence of an option.
  config.set = {
    value = if options ? set.enable then 360 else 7;
  }
  # Only define if possible.
  // lib.optionalAttrs (options ? set.enable) {
    enable = true;
  };

}
</file>

<file path="lib/tests/modules/define-option-dependently.nix">
{ lib, options, ... }:

# Some modules may be distributed separately and need to adapt to other modules
# that are distributed and versioned separately.
{

  # Always defined, but the value depends on the presence of an option.
  config = {
    value = if options ? enable then 360 else 7;
  }
  # Only define if possible.
  // lib.optionalAttrs (options ? enable) {
    enable = true;
  };

}
</file>

<file path="lib/tests/modules/define-settingsDict-a-is-b.nix">
{ config, ... }:
{
  settingsDict.a = config.settingsDict.b;
}
</file>

<file path="lib/tests/modules/define-shorthandOnlyDefinesConfig-true.nix">
{ shorthandOnlyDefinesConfig = true; }
</file>

<file path="lib/tests/modules/define-submoduleWith-noshorthand.nix">
{
  submodule.config.config = true;
}
</file>

<file path="lib/tests/modules/define-submoduleWith-shorthand.nix">
{
  submodule.config = true;
}
</file>

<file path="lib/tests/modules/define-value-int-negative.nix">
{
  value = -23;
}
</file>

<file path="lib/tests/modules/define-value-int-positive.nix">
{
  value = 42;
}
</file>

<file path="lib/tests/modules/define-value-int-zero.nix">
{
  value = 0;
}
</file>

<file path="lib/tests/modules/define-value-list.nix">
{
  value = [ ];
}
</file>

<file path="lib/tests/modules/define-value-string-arbitrary.nix">
{
  value = "foobar";
}
</file>

<file path="lib/tests/modules/define-value-string-bigint.nix">
{
  value = "1000";
}
</file>

<file path="lib/tests/modules/define-value-string-properties.nix">
{ lib, ... }:
{

  imports = [
    {
      value = lib.mkDefault "def";
    }
  ];

  value = lib.mkMerge [
    (lib.mkIf false "nope")
    "yes"
  ];

}
</file>

<file path="lib/tests/modules/define-value-string.nix">
{
  value = "24";
}
</file>

<file path="lib/tests/modules/define-variant.nix">
{ config, lib, ... }:
let
  inherit (lib) types mkOption attrNames;
in
{
  options = {
    attrs = mkOption { type = types.attrsOf lib.types.int; };
    result = mkOption { };
    resultFoo = mkOption { };
    resultFooBar = mkOption { };
    resultFooFoo = mkOption { };
  };
  config = {
    attrs.a = 1;
    variants.foo.attrs.b = 1;
    variants.bar.attrs.y = 1;
    variants.foo.variants.bar.attrs.z = 1;
    variants.foo.variants.foo.attrs.c = 3;
    resultFoo = lib.concatMapStringsSep " " toString (attrNames config.variants.foo.attrs);
    resultFooBar = lib.concatMapStringsSep " " toString (
      attrNames config.variants.foo.variants.bar.attrs
    );
    resultFooFoo = lib.concatMapStringsSep " " toString (
      attrNames config.variants.foo.variants.foo.attrs
    );
  };
}
</file>

<file path="lib/tests/modules/deprecated-wrapped.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption;

  inherit (types)
    # attrsOf uses attrsWith internally
    attrsOf
    listOf
    unique
    nullOr
    functionTo
    coercedTo
    either
    ;
in
{
  imports = [
    #  Module A
    (
      { ... }:
      {
        options.attrsWith = mkOption {
          type = attrsOf (listOf types.str);
        };
        options.mergedAttrsWith = mkOption {
          type = attrsOf (listOf types.str);
        };
        options.listOf = mkOption {
          type = listOf (listOf types.str);
        };
        options.mergedListOf = mkOption {
          type = listOf (listOf types.str);
        };
        # unique
        options.unique = mkOption {
          type = unique { message = ""; } (listOf types.str);
        };
        options.mergedUnique = mkOption {
          type = unique { message = ""; } (listOf types.str);
        };
        # nullOr
        options.nullOr = mkOption {
          type = nullOr (listOf types.str);
        };
        options.mergedNullOr = mkOption {
          type = nullOr (listOf types.str);
        };
        # functionTo
        options.functionTo = mkOption {
          type = functionTo (listOf types.str);
        };
        options.mergedFunctionTo = mkOption {
          type = functionTo (listOf types.str);
        };
        # coercedTo
        # Note: coercedTo is a non-mergeable option-type
        options.coercedTo = mkOption {
          type = coercedTo (listOf types.str) lib.id (listOf types.str);
        };
        options.either = mkOption {
          type = either (listOf types.str) (listOf types.str);
        };
        options.mergedEither = mkOption {
          type = either (listOf types.str) (listOf types.str);
        };
      }
    )
    # Module B
    (
      { ... }:
      {
        options.mergedAttrsWith = mkOption {
          type = attrsOf (listOf types.str);
        };
        options.mergedListOf = mkOption {
          type = listOf (listOf types.str);
        };
        options.mergedUnique = mkOption {
          type = unique { message = ""; } (listOf types.str);
        };
        options.mergedNullOr = mkOption {
          type = nullOr (listOf types.str);
        };
        options.mergedFunctionTo = mkOption {
          type = functionTo (listOf types.str);
        };
        options.mergedEither = mkOption {
          type = either (listOf types.str) (listOf types.str);
        };
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/disable-declare-enable.nix">
{ ... }:

{
  disabledModules = [ ./declare-enable.nix ];
}
</file>

<file path="lib/tests/modules/disable-define-enable-string-path.nix">
{ ... }:

{
  disabledModules = [ (toString ./define-enable.nix) ];
}
</file>

<file path="lib/tests/modules/disable-define-enable.nix">
{ ... }:

{
  disabledModules = [ ./define-enable.nix ];
}
</file>

<file path="lib/tests/modules/disable-enable-modules.nix">
{ ... }:

{
  disabledModules = [
    "define-enable.nix"
    "declare-enable.nix"
  ];
}
</file>

<file path="lib/tests/modules/disable-module-bad-key.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;

  moduleWithKey =
    { config, ... }:
    {
      config = {
        enable = true;
      };
    };
in
{
  imports = [
    ./declare-enable.nix
  ];
  disabledModules = [ { } ];
}
</file>

<file path="lib/tests/modules/disable-module-with-key.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;

  moduleWithKey = {
    key = "disable-module-with-key.nix#moduleWithKey";
    config = {
      enable = true;
    };
  };
in
{
  options = {
    positive = mkOption {
      type = types.submodule {
        imports = [
          ./declare-enable.nix
          moduleWithKey
        ];
      };
      default = { };
    };
    negative = mkOption {
      type = types.submodule {
        imports = [
          ./declare-enable.nix
          moduleWithKey
        ];
        disabledModules = [ moduleWithKey ];
      };
      default = { };
    };
  };
}
</file>

<file path="lib/tests/modules/disable-module-with-toString-key.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;

  moduleWithKey = {
    key = 123;
    config = {
      enable = true;
    };
  };
in
{
  options = {
    positive = mkOption {
      type = types.submodule {
        imports = [
          ./declare-enable.nix
          moduleWithKey
        ];
      };
      default = { };
    };
    negative = mkOption {
      type = types.submodule {
        imports = [
          ./declare-enable.nix
          moduleWithKey
        ];
        disabledModules = [ 123 ];
      };
      default = { };
    };
  };
}
</file>

<file path="lib/tests/modules/docs.nix">
/*
  A basic documentation generating module.
  Declares and defines a `docs` option, suitable for making assertions about
  the extraction "phase" of documentation generation.
*/
{ lib, options, ... }:

let
  inherit (lib)
    head
    length
    mkOption
    types
    ;

  traceListSeq = l: v: lib.foldl' (a: b: lib.traceSeq b a) v l;

in

{
  options.docs = mkOption {
    type = types.lazyAttrsOf types.raw;
    description = ''
      All options to be rendered, without any visibility filtering applied.
    '';
  };
  config.docs = lib.zipAttrsWith (
    name: values:
    if length values > 1 then
      traceListSeq values abort "Multiple options with the same name: ${name}"
    else
      assert length values == 1;
      head values
  ) (map (opt: { ${opt.name} = opt; }) (lib.optionAttrSetToDocList options));
}
</file>

<file path="lib/tests/modules/doRename-basic.nix">
{ lib, ... }:
{
  imports = [
    (lib.doRename {
      from = [
        "a"
        "b"
      ];
      to = [
        "c"
        "d"
        "e"
      ];
      warn = true;
      use = x: x;
      visible = true;
    })
  ];
  options = {
    c.d.e = lib.mkOption { };
  };
  config = {
    a.b = 1234;
  };
}
</file>

<file path="lib/tests/modules/doRename-condition-enable.nix">
{ config, ... }:
{
  config = {
    services.foo.enable = true;
    services.foo.bar = "baz";
    result =
      assert
        config.services.foos == {
          "" = {
            bar = "baz";
          };
        };
      true;
  };
}
</file>

<file path="lib/tests/modules/doRename-condition-migrated.nix">
{ config, ... }:
{
  config = {
    services.foos."".bar = "baz";
    result =
      assert
        config.services.foos == {
          "" = {
            bar = "baz";
          };
        };
      assert config.services.foo.bar == "baz";
      true;
  };
}
</file>

<file path="lib/tests/modules/doRename-condition-no-enable.nix">
{ config, options, ... }:
{
  config = {
    result =
      assert config.services.foos == { };
      assert !options.services.foo.bar.isDefined;
      true;
  };
}
</file>

<file path="lib/tests/modules/doRename-condition.nix">
/**
  Simulate a migration from a single-instance `services.foo` to a multi instance
  `services.foos.<name>` module, where `name = ""` serves as the legacy /
  compatibility instance.

  - No instances must exist, unless one is defined in the multi-instance module,
  or if the legacy enable option is set to true.
  - The legacy instance options must be renamed to the new instance, if it exists.

  The relevant scenarios are tested in separate files:
  - ./doRename-condition-enable.nix
  - ./doRename-condition-no-enable.nix
*/
{ config, lib, ... }:
let
  inherit (lib)
    mkOption
    mkEnableOption
    types
    doRename
    ;
in
{
  options = {
    services.foo.enable = mkEnableOption "foo";
    services.foos = mkOption {
      type = types.attrsOf (
        types.submodule {
          options = {
            bar = mkOption { type = types.str; };
          };
        }
      );
      default = { };
    };
    result = mkOption { };
  };
  imports = [
    (doRename {
      from = [
        "services"
        "foo"
        "bar"
      ];
      to = [
        "services"
        "foos"
        ""
        "bar"
      ];
      visible = true;
      warn = false;
      use = x: x;
      withPriority = true;
      condition = config.services.foo.enable;
    })
  ];
}
</file>

<file path="lib/tests/modules/doRename-warnings.nix">
{ lib, config, ... }:
{
  imports = [
    (lib.doRename {
      from = [
        "a"
        "b"
      ];
      to = [
        "c"
        "d"
        "e"
      ];
      warn = true;
      use = x: x;
      visible = true;
    })
  ];
  options = {
    warnings = lib.mkOption { type = lib.types.listOf lib.types.str; };
    c.d.e = lib.mkOption { };
    result = lib.mkOption { };
  };
  config = {
    a.b = 1234;
    result = lib.concatStringsSep "%" config.warnings;
  };
}
</file>

<file path="lib/tests/modules/emptyValues.nix">
{ lib, ... }:
let
  inherit (lib) types;
in
{

  options = {
    int = lib.mkOption {
      type = types.lazyAttrsOf types.int;
    };
    list = lib.mkOption {
      type = types.lazyAttrsOf (types.listOf types.int);
    };
    nonEmptyList = lib.mkOption {
      type = types.lazyAttrsOf (types.nonEmptyListOf types.int);
    };
    attrs = lib.mkOption {
      type = types.lazyAttrsOf (types.attrsOf types.int);
    };
    null = lib.mkOption {
      type = types.lazyAttrsOf (types.nullOr types.int);
    };
    submodule = lib.mkOption {
      type = types.lazyAttrsOf (types.submodule { });
    };
  };

  config = {
    int.a = lib.mkIf false null;
    list.a = lib.mkIf false null;
    nonEmptyList.a = lib.mkIf false null;
    attrs.a = lib.mkIf false null;
    null.a = lib.mkIf false null;
    submodule.a = lib.mkIf false null;
  };

}
</file>

<file path="lib/tests/modules/error-mkOption-in-config.nix">
{ lib, ... }:
let
  inherit (lib) mkOption;
in
{
  wrong1 = mkOption {
  };
  # This is not actually reported separately, so could be omitted from the test
  # but it makes the example more realistic.
  # Making it parse this _config_ as options would too risky. What if it's not
  # options but other values, that abort, throw, diverge, etc?
  nest.wrong2 = mkOption {
  };
}
</file>

<file path="lib/tests/modules/error-mkOption-in-submodule-config.nix">
{ lib, ... }:
let
  inherit (lib) mkOption;
in
{
  options.sub = lib.mkOption {
    type = lib.types.submodule {
      wrong2 = mkOption { };
    };
    default = { };
  };
}
</file>

<file path="lib/tests/modules/error-nonEmptyListOf-submodule.nix">
{ lib, ... }:
{
  options.bad = lib.mkOption {
    type = lib.types.nonEmptyListOf (lib.types.submodule { });
    default = [ ];
  };
}
</file>

<file path="lib/tests/modules/expose-module-class.nix">
{ _class, lib, ... }:
{
  options = {
    foo = lib.mkOption {
      default = _class;
    };
  };
}
</file>

<file path="lib/tests/modules/extendModules-168767-imports.nix">
{
  lib,
  extendModules,
  ...
}:

let
  inherit (lib)
    mkOption
    mkOverride
    types
    ;
in
{
  imports = [

    {
      options.sub = mkOption {
        default = { };
        type = types.submodule (
          {
            config,
            extendModules,
            ...
          }:
          {
            options.value = mkOption {
              type = types.int;
            };

            options.specialisation = mkOption {
              default = { };
              inherit
                (extendModules {
                  modules = [
                    {
                      specialisation = mkOverride 0 { };
                    }
                  ];
                })
                type
                ;
            };
          }
        );
      };
    }

    { config.sub.value = 1; }

  ];
}
</file>

<file path="lib/tests/modules/freeform-attrsOf.nix">
{ lib, ... }:
{
  freeformType = with lib.types; attrsOf (either str (attrsOf str));
}
</file>

<file path="lib/tests/modules/freeform-lazyAttrsOf.nix">
{ lib, ... }:
{
  freeformType = with lib.types; lazyAttrsOf (either str (lazyAttrsOf str));
}
</file>

<file path="lib/tests/modules/freeform-nested.nix">
{ lib, ... }:
let
  deathtrapArgs = lib.mapAttrs (
    k: _: throw "The module system is too strict, accessing an unused option's ${k} mkOption-attribute."
  ) (lib.functionArgs lib.mkOption);
in
{
  options.nest.foo = lib.mkOption {
    type = lib.types.bool;
    default = false;
  };
  options.nest.unused = lib.mkOption deathtrapArgs;
  config.nest.bar = "bar";
}
</file>

<file path="lib/tests/modules/freeform-str-dep-unstr.nix">
{ lib, config, ... }:
{
  options.foo = lib.mkOption {
    type = lib.types.nullOr lib.types.str;
    default = null;
  };

  config.foo = lib.mkIf (config ? value) config.value;
}
</file>

<file path="lib/tests/modules/freeform-submodules.nix">
{ lib, options, ... }:
with lib.types;
{

  options.fooDeclarations = lib.mkOption {
    default = (options.free.type.getSubOptions [ ])._freeformOptions.foo.declarations;
  };

  options.free = lib.mkOption {
    type = submodule {
      config._module.freeformType = lib.mkMerge [
        (attrsOf (submodule {
          options.foo = lib.mkOption { };
        }))
        (attrsOf (submodule {
          options.bar = lib.mkOption { };
        }))
      ];
    };
  };

  config.free.xxx.foo = 10;
  config.free.yyy.bar = 10;
}
</file>

<file path="lib/tests/modules/freeform-unstr-dep-str.nix">
{ lib, config, ... }:
{
  options.value = lib.mkOption {
    type = lib.types.nullOr lib.types.str;
    default = null;
  };

  config.foo = lib.mkIf (config.value != null) config.value;
}
</file>

<file path="lib/tests/modules/gvariant.nix">
{ config, lib, ... }:

{
  options = {
    examples = lib.mkOption { type = lib.types.attrs; };
    assertion = lib.mkOption { type = lib.types.bool; };
  };

  config = {
    examples = with lib.gvariant; {
      bool = true;
      float = 3.14;
      int32 = mkInt32 (-42);
      uint32 = mkUint32 42;
      int16 = mkInt16 (-42);
      uint16 = mkUint16 42;
      int64 = mkInt64 (-42);
      uint64 = mkUint64 42;
      array1 = [ "one" ];
      array2 = mkArray [ (mkInt32 1) ];
      array3 = mkArray [ (mkUint32 2) ];
      emptyArray = mkEmptyArray type.uint32;
      string = "foo";
      escapedString = ''
        '\
      '';
      tuple = mkTuple [
        (mkInt32 1)
        [ "foo" ]
      ];
      maybe1 = mkNothing type.string;
      maybe2 = mkJust (mkUint32 4);
      variant = mkVariant "foo";
      dictionaryEntry = mkDictionaryEntry (mkInt32 1) [ "foo" ];
    };

    assertion =
      let
        mkLine = n: v: "${n} = ${toString (lib.gvariant.mkValue v)}";
        result = lib.concatStringsSep "\n" (lib.mapAttrsToList mkLine config.examples);
      in
      (result + "\n") == ''
        array1 = @as ['one']
        array2 = @ai [1]
        array3 = @au [@u 2]
        bool = true
        dictionaryEntry = @{ias} {1,@as ['foo']}
        emptyArray = @au []
        escapedString = '\'\\\n'
        float = 3.140000
        int16 = @n -42
        int32 = -42
        int64 = @x -42
        maybe1 = @ms nothing
        maybe2 = just @u 4
        string = 'foo'
        tuple = @(ias) (1,@as ['foo'])
        uint16 = @q 42
        uint32 = @u 42
        uint64 = @t 42
        variant = <'foo'>
      '';
  };
}
</file>

<file path="lib/tests/modules/import-configuration.nix">
{ lib, ... }:
let
  myconf = lib.evalModules { modules = [ { } ]; };
in
{
  imports = [
    # We can't do this. A configuration is not equal to its set of a modules.
    # Equating those would lead to a mess, as specialArgs, anonymous modules
    # that can't be deduplicated, and possibly more come into play.
    myconf
  ];
}
</file>

<file path="lib/tests/modules/import-custom-arg.nix">
{ lib, custom, ... }:

{
  imports = [ ] ++ lib.optional custom ./define-enable-force.nix;
}
</file>

<file path="lib/tests/modules/import-error-submodule.nix">
{ lib, ... }:
let
  myconf = lib.evalModules { modules = [ { } ]; };
in
{
  options.foo = lib.mkOption {
    type = lib.types.submodule { };
    default = { };
  };
  config.foo =
    { ... }:
    {
      imports = [
        # error, like `import-configuration.nix`, but in a submodule this time
        myconf
      ];
    };
}
</file>

<file path="lib/tests/modules/import-from-store.nix">
{ ... }:
{

  imports = [
    "${builtins.toFile "drv" "{}"}"
    ./declare-enable.nix
    ./define-enable.nix
  ];

}
</file>

<file path="lib/tests/modules/importApply-disabling.nix">
{
  imports = [ ./importApply.nix ];
  disabledModules = [ ./importApply-function.nix ];
}
</file>

<file path="lib/tests/modules/importApply-function.nix">
{ foo }:
{ lib, config, ... }:
{
  value = foo;
}
</file>

<file path="lib/tests/modules/importApply.nix">
{ lib, ... }:
{
  options.value = lib.mkOption { default = 1; };
  imports = [ (lib.modules.importApply ./importApply-function.nix { foo = "abc"; }) ];
}
</file>

<file path="lib/tests/modules/lazy-attrsWith.nix">
# Check that AttrsWith { lazy = true; } is lazy
{ lib, ... }:
let
  inherit (lib) types mkOption;

  lazyAttrsOf = mkOption {
    # Same as lazyAttrsOf
    type = types.attrsWith {
      lazy = true;
      elemType = types.int;
    };
  };

  attrsOf = mkOption {
    # Same as lazyAttrsOf
    type = types.attrsWith {
      elemType = types.int;
    };
  };
in
{
  imports = [
    #  Module A
    (
      { ... }:
      {
        options.mergedLazyLazy = lazyAttrsOf;
        options.mergedLazyNonLazy = lazyAttrsOf;
        options.mergedNonLazyNonLazy = attrsOf;
      }
    )
    # Module B
    (
      { ... }:
      {
        options.mergedLazyLazy = lazyAttrsOf;
        options.mergedLazyNonLazy = attrsOf;
        options.mergedNonLazyNonLazy = attrsOf;
      }
    )
    # Result
    (
      { config, ... }:
      {
        # Can only evaluate if lazy
        config.mergedLazyLazy.bar = config.mergedLazyLazy.baz + 1;
        config.mergedLazyLazy.baz = 10;
        options.lazyResult = mkOption { default = config.mergedLazyLazy.bar; };

        # Can not only evaluate if not lazy
        config.mergedNonLazyNonLazy.bar = config.mergedNonLazyNonLazy.baz + 1;
        config.mergedNonLazyNonLazy.baz = 10;
        options.nonLazyResult = mkOption { default = config.mergedNonLazyNonLazy.bar; };
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/merge-module-with-key.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;

  moduleWithoutKey = {
    config = {
      raw = "pear";
    };
  };

  moduleWithKey = {
    key = __curPos.file + "#moduleWithKey";
    config = {
      raw = "pear";
    };
  };

  decl = {
    options = {
      raw = mkOption {
        type = types.lines;
      };
    };
  };
in
{
  options = {
    once = mkOption {
      type = types.submodule {
        imports = [
          decl
          moduleWithKey
          moduleWithKey
        ];
      };
      default = { };
    };
    twice = mkOption {
      type = types.submodule {
        imports = [
          decl
          moduleWithoutKey
          moduleWithoutKey
        ];
      };
      default = { };
    };
  };
}
</file>

<file path="lib/tests/modules/merge-typeless-option.nix">
{ ... }:

let
  typeless =
    { lib, ... }:

    {
      options.group = lib.mkOption { };
    };
  childOfTypeless =
    { lib, ... }:

    {
      options.group.enable = lib.mkEnableOption "nothing";
    };
in

{
  imports = [
    typeless
    childOfTypeless
  ];

  config.group.enable = false;
}
</file>

<file path="lib/tests/modules/mkDefinition.nix">
{ lib, ... }:
let
  inherit (lib)
    mkOption
    mkDefinition
    mkOptionDefault
    ;
in
{
  imports = [
    {
      _file = "file";
      options.conflict = mkOption {
        default = 1;
      };
      config.conflict = mkDefinition {
        file = "other";
        value = mkOptionDefault 42;
      };
    }
    {
      # Check that mkDefinition works within 'config'
      options.viaConfig = mkOption { };
      config.viaConfig = mkDefinition {
        file = "other";
        value = true;
      };
    }
    {
      # Check mkMerge can wrap mkDefinitions
      # Not the other way around
      options.mkMerge = mkOption {
        type = lib.types.bool;
      };
      config.mkMerge = lib.mkMerge [
        (mkDefinition {
          file = "a.nix";
          value = true;
        })
        (mkDefinition {
          file = "b.nix";
          value = true;
        })
      ];
    }
    {
      # Check mkDefinition can use mkForce on the value
      # Not the other way around
      options.mkForce = mkOption {
        type = lib.types.bool;
        default = false;
      };
      config.mkForce = mkDefinition {
        file = "other";
        value = lib.mkForce true;
      };
    }
    {
      # Currently expects an error
      # mkDefinition doesn't work on option default
      # This is a limitation and might be resolved in the future
      options.viaOptionDefault = mkOption {
        type = lib.types.bool;
        default = mkDefinition {
          file = "other";
          value = true;
        };
      };
    }
  ];
}
</file>

<file path="lib/tests/modules/module-argument-default.nix">
{
  a ? false,
  lib,
  ...
}:
{
  options = {
    result = lib.mkOption { };
  };
  config = {
    _module.args.a = true;
    result = a;
  };
}
</file>

<file path="lib/tests/modules/module-class-is-darwin.nix">
{
  _class = "darwin";
  config = { };
}
</file>

<file path="lib/tests/modules/module-class-is-nixos.nix">
{
  _class = "nixos";
  config = { };
}
</file>

<file path="lib/tests/modules/module-imports-_type-check.nix">
{
  imports = [ { _type = "flake"; } ];
}
</file>

<file path="lib/tests/modules/name-merge-attrsWith-1.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption;
in
{
  imports = [
    # Module A
    (
      { ... }:
      {
        options.mergedName = mkOption {
          default = { };
          type = types.attrsWith {
            placeholder = "id"; # <- This is beeing tested
            elemType = types.submodule {
              options.nested = mkOption {
                type = types.int;
                default = 1;
              };
            };
          };
        };
      }
    )
    # Module B
    (
      { ... }:
      {
        # defines the default placeholder "name"
        # type merging should resolve to "id"
        options.mergedName = mkOption {
          type = types.attrsOf (types.submodule { });
        };
      }
    )

    # Output
    (
      {
        options,
        ...
      }:
      {
        options.result = mkOption {
          default = lib.concatStringsSep "." (options.mergedName.type.getSubOptions options.mergedName.loc)
          .nested.loc;
        };
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/name-merge-attrsWith-2.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption;
in
{
  imports = [
    # Module A
    (
      { ... }:
      {
        options.mergedName = mkOption {
          default = { };
          type = types.attrsWith {
            placeholder = "id"; # <- this is beeing tested
            elemType = types.submodule {
              options.nested = mkOption {
                type = types.int;
                default = 1;
              };
            };
          };
        };
      }
    )
    # Module B
    (
      { ... }:
      {
        options.mergedName = mkOption {
          type = types.attrsWith {
            placeholder = "other"; # <- define placeholder = "other" (conflict)
            elemType = types.submodule { };
          };
        };
      }
    )
  ];
}
</file>

<file path="lib/tests/modules/options-type-error-configuration.nix">
{ lib, ... }:
{
  options = {
    # unlikely mistake, but we can catch any attrset with _type
    result = lib.evalModules { modules = [ ]; };
  };
}
</file>

<file path="lib/tests/modules/options-type-error-typical-nested.nix">
{ lib, ... }:
{
  options = {
    result.here = lib.types.str;
  };
}
</file>

<file path="lib/tests/modules/options-type-error-typical.nix">
{ lib, ... }:
{
  options = {
    result = lib.types.str;
  };
}
</file>

<file path="lib/tests/modules/optionTypeFile.nix">
{ config, lib, ... }:
{

  _file = "optionTypeFile.nix";

  options.theType = lib.mkOption {
    type = lib.types.optionType;
  };

  options.theOption = lib.mkOption {
    type = config.theType;
    default = { };
  };

  config.theType = lib.mkMerge [
    (lib.types.submodule {
      options.nested = lib.mkOption {
        type = lib.types.int;
      };
    })
    (lib.types.submodule {
      _file = "other.nix";
      options.nested = lib.mkOption {
        type = lib.types.str;
      };
    })
  ];

}
</file>

<file path="lib/tests/modules/optionTypeMerging.nix">
{ config, lib, ... }:
{

  options.theType = lib.mkOption {
    type = lib.types.optionType;
  };

  options.theOption = lib.mkOption {
    type = config.theType;
  };

  config.theType = lib.mkMerge [
    (lib.types.submodule {
      options.int = lib.mkOption {
        type = lib.types.int;
        default = 10;
      };
    })
    (lib.types.submodule {
      options.str = lib.mkOption {
        type = lib.types.str;
      };
    })
  ];

  config.theOption.str = "hello";

}
</file>

<file path="lib/tests/modules/pathWith.nix">
{ lib, ... }:
let
  inherit (builtins)
    storeDir
    ;
  inherit (lib)
    types
    mkOption
    ;
in
{
  imports = [
    {
      options = {
        pathInStore = mkOption { type = types.lazyAttrsOf (types.pathWith { inStore = true; }); };
        pathNotInStore = mkOption { type = types.lazyAttrsOf (types.pathWith { inStore = false; }); };
        anyPath = mkOption { type = types.lazyAttrsOf (types.pathWith { }); };
        absolutePathNotInStore = mkOption {
          type = types.lazyAttrsOf (
            types.pathWith {
              inStore = false;
              absolute = true;
            }
          );
        };

        # This conflicts with `conflictingPathOptionType` below.
        conflictingPathOptionType = mkOption { type = types.pathWith { absolute = true; }; };

        # This doesn't make sense: the only way to have something be `inStore`
        # is to have an absolute path.
        impossiblePathOptionType = mkOption {
          type = types.pathWith {
            inStore = true;
            absolute = false;
          };
        };
      };
    }
    {
      options = {
        # This should merge cleanly with `pathNotInStore` above.
        pathNotInStore = mkOption {
          type = types.lazyAttrsOf (
            types.pathWith {
              inStore = false;
              absolute = null;
            }
          );
        };

        # This conflicts with `conflictingPathOptionType` above.
        conflictingPathOptionType = mkOption { type = types.pathWith { absolute = false; }; };
      };
    }
  ];

  pathInStore.ok1 = "${storeDir}/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv";
  pathInStore.ok2 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15";
  pathInStore.ok3 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash";
  pathInStore.ok4 = "/1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab"; # CA derivation
  pathInStore.ok5 = "/1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab/bin/bash"; # CA derivation
  pathInStore.ok6 = /1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab; # CA derivation, path type
  pathInStore.bad1 = "";
  pathInStore.bad2 = "${storeDir}";
  pathInStore.bad3 = "${storeDir}/";
  pathInStore.bad4 = "${storeDir}/.links"; # technically true, but not reasonable
  pathInStore.bad5 = "/foo/bar";

  pathNotInStore.ok1 = "/foo/bar";
  pathNotInStore.ok2 = "${storeDir}"; # strange, but consistent with `pathInStore` above
  pathNotInStore.ok3 = "${storeDir}/"; # also strange, but also consistent
  pathNotInStore.ok4 = "";
  pathNotInStore.ok5 = "${storeDir}/.links"; # strange, but consistent with `pathInStore` above
  pathNotInStore.bad1 = "${storeDir}/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv";
  pathNotInStore.bad2 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15";
  pathNotInStore.bad3 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash";
  pathNotInStore.bad4 = ./pathWith.nix;

  anyPath.ok1 = "/this/is/absolute";
  anyPath.ok2 = "./this/is/relative";
  anyPath.bad1 = 42;

  absolutePathNotInStore.ok1 = "/this/is/absolute";
  absolutePathNotInStore.bad1 = "./this/is/relative";
  absolutePathNotInStore.bad2 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15";

  conflictingPathOptionType = "/foo/bar";

  impossiblePathOptionType = "/foo/bar";
}
</file>

<file path="lib/tests/modules/polymorphic-module.nix">
{ _class, lib, ... }:
let
  nixosModule =
    { ... }:
    {
      options.foo = lib.mkOption {
        default = "bar";
      };
    };
  darwinModule =
    { ... }:
    {
      options.bar = lib.mkOption {
        default = "foo";
      };
    };
in
{
  imports = [
    (lib.optionalAttrs (_class == "nixos") nixosModule)
    (lib.optionalAttrs (_class == "darwin") darwinModule)
  ];
}
</file>

<file path="lib/tests/modules/prefix-module-argument.nix">
{ lib, ... }:
{
  options.foo = lib.mkOption {
    type = lib.types.submodule { };
    default = { };
  };

  config = {
    foo =
      { _prefix, ... }:
      assert _prefix == [ "foo" ];
      {
        options.ok = lib.mkOption { };
        config.ok = true;
      };
  };
}
</file>

<file path="lib/tests/modules/raw.nix">
{ lib, config, ... }:
{

  options = {
    processedToplevel = lib.mkOption {
      type = lib.types.raw;
    };
    unprocessedNesting = lib.mkOption {
      type = lib.types.raw;
    };
    multiple = lib.mkOption {
      type = lib.types.raw;
    };
    priorities = lib.mkOption {
      type = lib.types.raw;
    };
    unprocessedNestingEvaluates = lib.mkOption {
      default = builtins.tryEval config.unprocessedNesting;
    };
  };

  config = {
    processedToplevel = lib.mkIf true 10;
    unprocessedNesting.foo = throw "foo";
    multiple = lib.mkMerge [
      "foo"
      "foo"
    ];
    priorities = lib.mkMerge [
      "foo"
      (lib.mkForce "bar")
    ];
  };
}
</file>

<file path="lib/tests/modules/shorthand-meta.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption;
in
{
  imports = [
    (
      { config, ... }:
      {
        options = {
          meta.foo = mkOption {
            type = types.listOf types.str;
          };
          result = mkOption { default = lib.concatStringsSep " " config.meta.foo; };
        };
      }
    )
    {
      meta.foo = [
        "one"
        "two"
      ];
    }
  ];
}
</file>

<file path="lib/tests/modules/specialArgs-class.nix">
{ lib, ... }:
{
  options = {
    sub = {
      nixos = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "nixos";
          modules = [
            ./expose-module-class.nix
          ];
        };
        default = { };
      };

      conditionalImportAsNixos = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "nixos";
          modules = [
            ./polymorphic-module.nix
          ];
        };
        default = { };
      };

      conditionalImportAsDarwin = lib.mkOption {
        type = lib.types.submoduleWith {
          class = "darwin";
          modules = [
            ./polymorphic-module.nix
          ];
        };
        default = { };
      };
    };
  };
  config = {
    _module.freeformType = lib.types.anything;

    nixos = lib.evalModules {
      class = "nixos";
      modules = [ ./expose-module-class.nix ];
    };

    conditionalImportAsNixos = lib.evalModules {
      class = "nixos";
      modules = [ ./polymorphic-module.nix ];
    };

    conditionalImportAsDarwin = lib.evalModules {
      class = "darwin";
      modules = [ ./polymorphic-module.nix ];
    };
  };
}
</file>

<file path="lib/tests/modules/specialArgs-lib.nix">
{ config, lib, ... }:

{
  options = {
    result = lib.mkOption { };
    weird = lib.mkOption {
      type = lib.types.submoduleWith {
        # I generally recommend against overriding lib, because that leads to
        # slightly incompatible dialects of the module system.
        # Nonetheless, it's worth guarding the property that the module system
        # evaluates with a completely custom lib, as a matter of separation of
        # concerns.
        specialArgs.lib = { };
        modules = [ ];
      };
    };
  };
  config.weird =
    args@{
      ... # note the lack of a `lib` argument
    }:
    assert args.lib == { };
    assert args.specialArgs == { lib = { }; };
    {
      options.foo = lib.mkOption { };
      config.foo = lib.mkIf true "alright";
    };
  config.result =
    assert config.weird.foo == "alright";
    "ok";
}
</file>

<file path="lib/tests/modules/strMatching-merge.nix">
{ lib, ... }:
{
  imports = [
    {
      options.sm = lib.mkOption {
        type = lib.types.strMatching "\\(.*\\)";
      };
    }
    {
      options.sm = lib.mkOption {
        type = lib.types.strMatching "\\(.*\\)";
      };
    }
  ];
}
</file>

<file path="lib/tests/modules/submoduleFiles.nix">
{ lib, ... }:
{
  options.submodule = lib.mkOption {
    default = { };
    type = lib.types.submoduleWith {
      modules = [
        (
          { options, ... }:
          {
            options.value = lib.mkOption { };

            options.internalFiles = lib.mkOption {
              default = options.value.files;
            };
          }
        )
      ];
    };
  };

  imports = [
    {
      _file = "the-file.nix";
      submodule.value = 10;
    }
  ];
}
</file>

<file path="lib/tests/modules/test-mergeAttrDefinitionsWithPrio.nix">
{ lib, options, ... }:

let
  defs = lib.modules.mergeAttrDefinitionsWithPrio options._module.args;
  assertLazy =
    pos:
    throw "${pos.file}:${toString pos.line}:${toString pos.column}: The test must not evaluate this the assertLazy thunk, but it did. Unexpected strictness leads to unexpected errors and performance problems.";
in

{
  options.result = lib.mkOption { };
  config._module.args = {
    default = lib.mkDefault (assertLazy __curPos);
    regular = null;
    force = lib.mkForce (assertLazy __curPos);
    unused = assertLazy __curPos;
  };
  config.result =
    assert defs.default.highestPrio == (lib.mkDefault (assertLazy __curPos)).priority;
    assert defs.regular.highestPrio == lib.modules.defaultOverridePriority;
    assert defs.force.highestPrio == (lib.mkForce (assertLazy __curPos)).priority;
    true;
}
</file>

<file path="lib/tests/modules/types-attrTag-wrong-decl.nix">
{ lib, ... }:
let
  inherit (lib) types mkOption;
in
{
  options = {
    opt = mkOption {
      type = types.attrTag {
        int = types.int;
      };
      default = {
        int = 1;
      };
    };
  };
}
</file>

<file path="lib/tests/modules/types-attrTag.nix">
{
  lib,
  config,
  options,
  ...
}:
let
  inherit (lib) mkOption types;
  forceDeep = x: builtins.deepSeq x x;
  mergedSubOption = (options.merged.type.getSubOptions options.merged.loc).extensible;
in
{
  options = {
    intStrings = mkOption {
      type = types.attrsOf (
        types.attrTag {
          left = mkOption {
            type = types.int;
          };
          right = mkOption {
            type = types.str;
          };
        }
      );
    };
    nested = mkOption {
      type = types.attrTag {
        left = mkOption {
          type = types.int;
        };
        right = mkOption {
          type = types.attrTag {
            left = mkOption {
              type = types.int;
            };
            right = mkOption {
              type = types.str;
            };
          };
        };
      };
    };
    merged = mkOption {
      type = types.attrsOf (
        types.attrTag {
          yay = mkOption {
            type = types.int;
          };
          extensible = mkOption {
            type = types.enum [ "foo" ];
          };
        }
      );
    };
    submodules = mkOption {
      type = types.attrsOf (
        types.attrTag {
          foo = mkOption {
            type = types.submodule {
              options = {
                bar = mkOption {
                  type = types.int;
                };
              };
            };
          };
          qux = mkOption {
            type = types.str;
            description = "A qux for when you don't want a foo";
          };
        }
      );
    };
    okChecks = mkOption { };
  };
  imports = [
    ./docs.nix
    {
      options.merged = mkOption {
        type = types.attrsOf (
          types.attrTag {
            nay = mkOption {
              type = types.bool;
            };
            extensible = mkOption {
              type = types.enum [ "bar" ];
            };
          }
        );
      };
    }
  ];
  config = {
    intStrings.syntaxError = 1;
    intStrings.syntaxError2 = { };
    intStrings.syntaxError3 = {
      a = true;
      b = true;
    };
    intStrings.syntaxError4 = lib.mkMerge [
      { a = true; }
      { b = true; }
    ];
    intStrings.mergeError = lib.mkMerge [
      { int = throw "do not eval"; }
      { string = throw "do not eval"; }
    ];
    intStrings.badTagError.rite = throw "do not eval";
    intStrings.badTagTypeError.left = "bad";
    intStrings.numberOne.left = 1;
    intStrings.hello.right = "hello world";
    nested.right.left = "not a number";
    merged.negative.nay = false;
    merged.positive.yay = 100;
    merged.extensi-foo.extensible = "foo";
    merged.extensi-bar.extensible = "bar";
    okChecks = builtins.addErrorContext "while evaluating the assertions" (
      assert config.intStrings.hello == { right = "hello world"; };
      assert config.intStrings.numberOne == { left = 1; };
      assert config.merged.negative == { nay = false; };
      assert config.merged.positive == { yay = 100; };
      assert config.merged.extensi-foo == { extensible = "foo"; };
      assert config.merged.extensi-bar == { extensible = "bar"; };
      assert config.docs."submodules.<name>.foo.bar".type == "signed integer";
      assert config.docs."submodules.<name>.qux".type == "string";
      assert config.docs."submodules.<name>.qux".declarations == [ __curPos.file ];
      assert
        config.docs."submodules.<name>.qux".loc == [
          "submodules"
          "<name>"
          "qux"
        ];
      assert config.docs."submodules.<name>.qux".name == "submodules.<name>.qux";
      assert config.docs."submodules.<name>.qux".description == "A qux for when you don't want a foo";
      assert config.docs."submodules.<name>.qux".readOnly == false;
      assert config.docs."submodules.<name>.qux".visible == true;
      # Not available (yet?)
      # assert config.docs."submodules.<name>.qux".declarationsWithPositions == [ ... ];
      assert options.submodules.declarations == [ __curPos.file ];
      assert lib.length options.submodules.declarationPositions == 1;
      assert (lib.head options.submodules.declarationPositions).file == __curPos.file;
      assert
        options.merged.declarations == [
          __curPos.file
          __curPos.file
        ];
      assert lib.length options.merged.declarationPositions == 2;
      assert (lib.elemAt options.merged.declarationPositions 0).file == __curPos.file;
      assert (lib.elemAt options.merged.declarationPositions 1).file == __curPos.file;
      assert
        (lib.elemAt options.merged.declarationPositions 0).line
        != (lib.elemAt options.merged.declarationPositions 1).line;
      assert
        mergedSubOption.declarations == [
          __curPos.file
          __curPos.file
        ];
      assert lib.length mergedSubOption.declarationPositions == 2;
      assert (lib.elemAt mergedSubOption.declarationPositions 0).file == __curPos.file;
      assert (lib.elemAt mergedSubOption.declarationPositions 1).file == __curPos.file;
      assert
        (lib.elemAt mergedSubOption.declarationPositions 0).line
        != (lib.elemAt mergedSubOption.declarationPositions 1).line;
      assert lib.length config.docs."merged.<name>.extensible".declarations == 2;
      true
    );
  };
}
</file>

<file path="lib/tests/modules/types-unique.nix">
{ lib, ... }:
let
  inherit (lib) mkOption types;
in
{
  options.examples = mkOption {
    type = types.lazyAttrsOf (
      types.unique {
        message = "We require a single definition, because seeing the whole value at once helps us maintain critical invariants of our system.";
      } (types.attrsOf types.str)
    );
  };
  imports = [
    {
      examples.merged = {
        b = "bee";
      };
    }
    { examples.override = lib.mkForce { b = "bee"; }; }
  ];
  config.examples = {
    merged = {
      a = "aye";
    };
    override = {
      a = "aye";
    };
    badLazyType = {
      a = true;
    };
  };
}
</file>

<file path="lib/tests/modules/types.nix">
{ lib, ... }:
let
  inherit (builtins)
    storeDir
    ;
  inherit (lib)
    types
    mkOption
    ;
in
{
  options = {
    pathInStore = mkOption { type = types.lazyAttrsOf types.pathInStore; };
  };
  config = {
    pathInStore.ok1 = "${storeDir}/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv";
    pathInStore.ok2 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15";
    pathInStore.ok3 = "${storeDir}/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash";
    pathInStore.bad1 = "";
    pathInStore.bad2 = "${storeDir}";
    pathInStore.bad3 = "${storeDir}/";
    pathInStore.bad4 = "${storeDir}/.links"; # technically true, but not reasonable
    pathInStore.bad5 = "/foo/bar";
  };
}
</file>

<file path="lib/tests/packages-from-directory/c/not-a-namespace/not-a-package.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/c/package.nix">
{ }: "c"
</file>

<file path="lib/tests/packages-from-directory/c/support-definitions.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/my-namespace/f/package.nix">
{ }: "f"
</file>

<file path="lib/tests/packages-from-directory/my-namespace/my-sub-namespace/g.nix">
{ }: "g"
</file>

<file path="lib/tests/packages-from-directory/my-namespace/my-sub-namespace/h.nix">
{ }: "h"
</file>

<file path="lib/tests/packages-from-directory/my-namespace/d.nix">
{ }: "d"
</file>

<file path="lib/tests/packages-from-directory/my-namespace/e.nix">
{ }: "e"
</file>

<file path="lib/tests/packages-from-directory/plain/c/not-a-namespace/not-a-package.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/plain/c/package.nix">
{ }: "c"
</file>

<file path="lib/tests/packages-from-directory/plain/c/support-definitions.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/plain/my-namespace/f/package.nix">
{ }: "f"
</file>

<file path="lib/tests/packages-from-directory/plain/my-namespace/my-sub-namespace/g.nix">
{ }: "g"
</file>

<file path="lib/tests/packages-from-directory/plain/my-namespace/my-sub-namespace/h.nix">
{ }: "h"
</file>

<file path="lib/tests/packages-from-directory/plain/my-namespace/d.nix">
{ }: "d"
</file>

<file path="lib/tests/packages-from-directory/plain/my-namespace/e.nix">
{ }: "e"
</file>

<file path="lib/tests/packages-from-directory/plain/a.nix">
{ }: "a"
</file>

<file path="lib/tests/packages-from-directory/plain/b.nix">
{ }: "b"
</file>

<file path="lib/tests/packages-from-directory/scope/c/not-a-namespace/not-a-package.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/scope/c/package.nix">
{ }: "c"
</file>

<file path="lib/tests/packages-from-directory/scope/c/support-definitions.nix">
{ }
</file>

<file path="lib/tests/packages-from-directory/scope/my-namespace/f/package.nix">
{ }: "f"
</file>

<file path="lib/tests/packages-from-directory/scope/my-namespace/my-sub-namespace/g.nix">
{
  a,
  d,
  h,
}:
# Check we can get parameters from ancestral scopes (e.g. the scope's grandparent)
"g"
</file>

<file path="lib/tests/packages-from-directory/scope/my-namespace/my-sub-namespace/h.nix">
{ }: "h"
</file>

<file path="lib/tests/packages-from-directory/scope/my-namespace/d.nix">
{ a, e }:
# Check we can get parameter from the parent scope(s) as well as the current one
assert a == "a";
assert e == "e";
"d"
</file>

<file path="lib/tests/packages-from-directory/scope/my-namespace/e.nix">
{ d }:
# Check that mutual recursion is possible
"e"
</file>

<file path="lib/tests/packages-from-directory/scope/a.nix">
{ }: "a"
</file>

<file path="lib/tests/packages-from-directory/scope/b.nix">
{ a }:
assert a == "a";
"b"
</file>

<file path="lib/tests/packages-from-directory/a.nix">
{ }: "a"
</file>

<file path="lib/tests/packages-from-directory/b.nix">
{ }: "b"
</file>

<file path="lib/tests/.editorconfig">
[*.plist]
indent_style = tab
insert_final_newline = unset
</file>

<file path="lib/tests/check-eval.nix">
# Throws an error if any of our lib tests fail.

let
  tests = [
    "misc"
    "systems"
  ];
  all = builtins.concatLists (map (f: import (./. + "/${f}.nix")) tests);
in
if all == [ ] then null else throw (builtins.toJSON all)
</file>

<file path="lib/tests/fetchers.nix">
let
  lib = import ./..;

  inherit (lib)
    fakeHash
    fakeSha256
    fakeSha512
    flip
    functionArgs
    runTests
    ;
  inherit (lib.fetchers) normalizeHash withNormalizedHash;

  testingThrow = expr: {
    expr = with builtins; tryEval (seq expr "didn't throw");
    expected = {
      success = false;
      value = false;
    };
  };

  # hashes of empty
  sri256 = "sha256-d6xi4mKdjkX2JFicDIv5niSzpyI0m/Hnm8GGAIU04kY=";
  sri512 = "sha512-AXFyVo7jiZ5we10fxZ5E9qfPjSfqkizY2apCzORKFVYZaNhCIVbooY+J4cYST00ztLf0EjivIBPPdtIYFUMfzQ==";

  unionOfDisjoints = lib.foldl lib.attrsets.unionOfDisjoint { };

  genTests = n: f: {
    "test${n}AlreadyNormalized" = {
      expr = f { } {
        outputHash = "";
        outputHashAlgo = "md42";
      };
      expected = {
        outputHash = "";
        outputHashAlgo = "md42";
      };
    };

    "test${n}EmptySha256" = {
      expr = f { } { sha256 = ""; };
      expected = {
        outputHash = fakeSha256;
        outputHashAlgo = "sha256";
      };
    };

    "test${n}EmptySha512" = {
      expr = f { hashTypes = [ "sha512" ]; } { sha512 = ""; };
      expected = {
        outputHash = fakeSha512;
        outputHashAlgo = "sha512";
      };
    };

    "test${n}EmptyHash" = {
      expr = f { } { hash = ""; };
      expected = {
        outputHash = fakeHash;
        outputHashAlgo = null;
      };
    };

    "test${n}Sri256" = {
      expr = f { } { hash = sri256; };
      expected = {
        outputHash = sri256;
        outputHashAlgo = null;
      };
    };

    "test${n}Sri512" = {
      expr = f { } { hash = sri512; };
      expected = {
        outputHash = sri512;
        outputHashAlgo = null;
      };
    };

    "test${n}PreservesAttrs" = {
      expr = f { } {
        hash = "aaaa";
        destination = "Earth";
      };
      expected = {
        outputHash = "aaaa";
        outputHashAlgo = null;
        destination = "Earth";
      };
    };

    "test${n}RejectsSha1ByDefault" = testingThrow (f { } { sha1 = ""; });
    "test${n}RejectsSha512ByDefault" = testingThrow (f { } { sha512 = ""; });

    "test${n}ThrowsOnMissing" = testingThrow (f { } { gibi = false; });
  };
in
runTests (unionOfDisjoints [
  (genTests "NormalizeHash" normalizeHash)
  (genTests "WithNormalized" (
    flip withNormalizedHash ({ outputHash, outputHashAlgo, ... }@args: args)
  ))
  {
    testNormalizeNotRequiredEquivalent = {
      expr = normalizeHash { required = false; } {
        hash = "";
        prof = "shadoko";
      };
      expected = normalizeHash { } {
        hash = "";
        prof = "shadoko";
      };
    };

    testNormalizeNotRequiredPassthru = {
      expr = normalizeHash { required = false; } { "ga bu" = "zo meu"; };
      expected."ga bu" = "zo meu";
    };

    testOptionalArg = {
      expr = withNormalizedHash { } (
        {
          outputHash ? "",
          outputHashAlgo ? null,
          ...
        }@args:
        args
      ) { author = "Jacques Rouxel"; };
      expected.author = "Jacques Rouxel";
    };

    testOptionalArgMetadata = {
      expr = functionArgs (
        withNormalizedHash { } (
          {
            outputHash ? "",
            outputHashAlgo ? null,
          }:
          { }
        )
      );
      expected.hash = true;
    };

    testPreservesArgsMetadata = {
      expr = functionArgs (
        withNormalizedHash { } (
          {
            outputHash,
            outputHashAlgo,
            pumping ? true,
          }:
          { }
        )
      );
      expected = {
        hash = false;
        pumping = true;
      };
    };

    testRejectsMissingHashArg = testingThrow (withNormalizedHash { } ({ outputHashAlgo }: { }));
    testRejectsMissingAlgoArg = testingThrow (withNormalizedHash { } ({ outputHash }: { }));
  }
])
</file>

<file path="lib/tests/filesystem.sh">
#!/usr/bin/env bash

# Tests lib/filesystem.nix
# Run:
# [nixpkgs]$ lib/tests/filesystem.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -euo pipefail
shopt -s inherit_errexit

# Use
#     || die
die() {
  echo >&2 "test case failed: " "$@"
  exit 1
}

if test -n "${TEST_LIB:-}"; then
  NIX_PATH=nixpkgs="$(dirname "$TEST_LIB")"
else
  NIX_PATH=nixpkgs="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.."; pwd)"
fi
export NIX_PATH

work="$(mktemp -d)"
clean_up() {
  rm -rf "$work"
}
trap clean_up EXIT
cd "$work"

mkdir directory
touch regular
ln -s target symlink
mkfifo fifo

expectSuccess() {
    local expr=$1
    local expectedResultRegex=$2
    if ! result=$(nix-instantiate --eval --strict --json \
        --expr "with (import <nixpkgs/lib>).filesystem; $expr"); then
        die "$expr failed to evaluate, but it was expected to succeed"
    fi
    if [[ ! "$result" =~ $expectedResultRegex ]]; then
        die "$expr == $result, but $expectedResultRegex was expected"
    fi
}

expectFailure() {
    local expr=$1
    local expectedErrorRegex=$2
    if result=$(nix-instantiate --eval --strict --json 2>"$work/stderr" \
        --expr "with (import <nixpkgs/lib>).filesystem; $expr"); then
        die "$expr evaluated successfully to $result, but it was expected to fail"
    fi
    if [[ ! "$(<"$work/stderr")" =~ $expectedErrorRegex ]]; then
        die "Error was $(<"$work/stderr"), but $expectedErrorRegex was expected"
    fi
}

expectSuccess "pathType /." '"directory"'
expectSuccess "pathType $PWD/directory" '"directory"'
expectSuccess "pathType $PWD/regular" '"regular"'
expectSuccess "pathType $PWD/symlink" '"symlink"'
expectSuccess "pathType $PWD/fifo" '"unknown"'

# Only check error message when a Nixpkgs-specified error is thrown,
# which is only the case when `readFileType` is not available
# and the fallback implementation needs to be used.
if [[ "$(nix-instantiate --eval --expr 'builtins ? readFileType')" == false ]]; then
    expectFailure "pathType $PWD/non-existent" \
        "error: evaluation aborted with the following error message: 'lib.filesystem.pathType: Path $PWD/non-existent does not exist.'"
fi

expectSuccess "pathIsDirectory /." "true"
expectSuccess "pathIsDirectory $PWD/directory" "true"
expectSuccess "pathIsDirectory $PWD/regular" "false"
expectSuccess "pathIsDirectory $PWD/symlink" "false"
expectSuccess "pathIsDirectory $PWD/fifo" "false"
expectSuccess "pathIsDirectory $PWD/non-existent" "false"

expectSuccess "pathIsRegularFile /." "false"
expectSuccess "pathIsRegularFile $PWD/directory" "false"
expectSuccess "pathIsRegularFile $PWD/regular" "true"
expectSuccess "pathIsRegularFile $PWD/symlink" "false"
expectSuccess "pathIsRegularFile $PWD/fifo" "false"
expectSuccess "pathIsRegularFile $PWD/non-existent" "false"

echo >&2 tests ok
</file>

<file path="lib/tests/maintainer-module.nix">
{ lib, ... }:
let
  inherit (lib) types;
in
{
  options = {
    name = lib.mkOption {
      type = types.str;
    };
    email = lib.mkOption {
      type = types.nullOr types.str;
      default = null;
    };
    matrix = lib.mkOption {
      type = types.nullOr types.str;
      default = null;
    };
    github = lib.mkOption {
      type = types.nullOr types.str;
      default = null;
    };
    githubId = lib.mkOption {
      type = types.nullOr types.ints.unsigned;
      default = null;
    };
    keys = lib.mkOption {
      type = types.listOf (
        types.submodule {
          options.fingerprint = lib.mkOption { type = types.str; };
        }
      );
      default = [ ];
    };
  };
}
</file>

<file path="lib/tests/maintainers.nix">
# to run these tests (and the others)
# nix-build nixpkgs/lib/tests/release.nix
# These tests should stay in sync with the comment in maintainers/maintainer-list.nix
{
  # The pkgs used for dependencies for the testing itself
  pkgs ? import ../.. { },
  lib ? pkgs.lib,
}:

let
  checkMaintainer =
    handle: uncheckedAttrs:
    let
      prefix = [
        "lib"
        "maintainers"
        handle
      ];
      checkedAttrs =
        (lib.modules.evalModules {
          inherit prefix;
          modules = [
            ./maintainer-module.nix
            {
              _file = toString ../../maintainers/maintainer-list.nix;
              config = uncheckedAttrs;
            }
          ];
        }).config;

      checks =
        lib.optional (checkedAttrs.github != null && checkedAttrs.githubId == null) ''
          echo ${lib.escapeShellArg (lib.showOption prefix)}': If `github` is specified, `githubId` must be too.'
          # Calling this too often would hit non-authenticated API limits, but this
          # shouldn't happen since such errors will get fixed rather quickly
          info=$(curl -sS https://api.github.com/users/${checkedAttrs.github})
          id=$(jq -r '.id' <<< "$info")
          echo "The GitHub ID for GitHub user ${checkedAttrs.github} is $id:"
          echo -e "    githubId = $id;\n"
        ''
        ++
          lib.optional
            (checkedAttrs.email == null && checkedAttrs.github == null && checkedAttrs.matrix == null)
            ''
              echo ${lib.escapeShellArg (lib.showOption prefix)}': At least one of `email`, `github` or `matrix` must be specified, so that users know how to reach you.'
            ''
        ++
          lib.optional (checkedAttrs.email != null && lib.hasSuffix "noreply.github.com" checkedAttrs.email)
            ''
              echo ${lib.escapeShellArg (lib.showOption prefix)}': If an email address is given, it should allow people to reach you. If you do not want that, you can just provide `github` or `matrix` instead.'
            '';
    in
    lib.deepSeq checkedAttrs checks;

  missingGithubIds = lib.concatLists (lib.mapAttrsToList checkMaintainer lib.maintainers);

  success = pkgs.runCommand "checked-maintainers-success" { } "mkdir $out";

  failure =
    pkgs.runCommand "checked-maintainers-failure"
      {
        nativeBuildInputs = [
          pkgs.curl
          pkgs.jq
        ];
        outputHash = "sha256:${lib.fakeSha256}";
        outputHAlgo = "sha256";
        outputHashMode = "flat";
        SSL_CERT_FILE = "${pkgs.cacert}/etc/ssl/certs/ca-bundle.crt";
      }
      ''
        ${lib.concatStringsSep "\n" missingGithubIds}
        exit 1
      '';
in
if missingGithubIds == [ ] then success else failure
</file>

<file path="lib/tests/misc.nix">
/**
  Nix evaluation tests for various lib functions.

  Since these tests are implemented with Nix evaluation,
  error checking is limited to what `builtins.tryEval` can detect,
  which is `throw`'s and `abort`'s, without error messages.

  If you need to test error messages or more complex evaluations, see
  `lib/tests/modules.sh`, `lib/tests/sources.sh` or `lib/tests/filesystem.sh` as examples.

  To run these tests:

    [nixpkgs]$ nix-instantiate --eval --strict lib/tests/misc.nix

  If the resulting list is empty, all tests passed.
  Alternatively, to run all `lib` tests:

    [nixpkgs]$ nix-build lib/tests/release.nix
*/

let
  lib = import ../default.nix;

  inherit (lib)
    allUnique
    and
    attrNames
    attrsets
    attrsToList
    bitAnd
    bitOr
    bitXor
    boolToString
    callPackagesWith
    callPackageWith
    cartesianProduct
    cli
    composeExtensions
    composeManyExtensions
    concatLines
    concatMapAttrs
    concatMapAttrsStringSep
    concatMapStrings
    concatStrings
    concatStringsSep
    const
    escapeXML
    evalModules
    extends
    filter
    filterAttrs
    fix
    fold
    foldAttrs
    foldl
    foldl'
    foldlAttrs
    foldr
    functionArgs
    generators
    genList
    getExe
    getExe'
    getLicenseFromSpdxIdOr
    groupBy
    groupBy'
    hasAttrByPath
    hasInfix
    id
    ifilter0
    isStorePath
    lazyDerivation
    length
    lists
    listToAttrs
    makeExtensible
    makeIncludePath
    makeOverridable
    mapAttrs
    mapCartesianProduct
    matchAttrs
    mergeAttrs
    meta
    mod
    nameValuePair
    optionalDrvAttr
    optionAttrSetToDocList
    overrideExisting
    packagesFromDirectoryRecursive
    pipe
    range
    recursiveUpdateUntil
    removePrefix
    replaceString
    replicate
    runTests
    setFunctionArgs
    showAttrPath
    sort
    sortOn
    stringLength
    strings
    stringToCharacters
    systems
    tail
    take
    testAllTrue
    toBaseDigits
    toExtension
    toHexString
    fromHexString
    toInt
    toIntBase10
    toShellVars
    types
    updateManyAttrsByPath
    versions
    xor
    ;

  testingThrow = expr: {
    expr = (builtins.tryEval (builtins.seq expr "didn't throw"));
    expected = {
      success = false;
      value = false;
    };
  };
  testingEval = expr: {
    expr = (builtins.tryEval expr).success;
    expected = true;
  };

  testSanitizeDerivationName =
    { name, expected }:
    let
      drv = derivation {
        name = strings.sanitizeDerivationName name;
        builder = "x";
        system = "x";
      };
    in
    {
      # Evaluate the derivation so an invalid name would be caught
      expr = builtins.seq drv.drvPath drv.name;
      inherit expected;
    };

in

runTests {

  # CUSTOMIZATION

  testFunctionArgsMakeOverridable = {
    expr = functionArgs (
      makeOverridable (
        {
          a,
          b,
          c ? null,
        }:
        { }
      )
    );
    expected = {
      a = false;
      b = false;
      c = true;
    };
  };

  testFunctionArgsMakeOverridableOverride = {
    expr =
      functionArgs
        (makeOverridable
          (
            {
              a,
              b,
              c ? null,
            }:
            { }
          )
          {
            a = 1;
            b = 2;
          }
        ).override;
    expected = {
      a = false;
      b = false;
      c = true;
    };
  };

  testCallPackageWithOverridePreservesArguments =
    let
      f =
        {
          a ? 0,
          b,
        }:
        { };
      f' = callPackageWith {
        a = 1;
        b = 2;
      } f { };
    in
    {
      expr = functionArgs f'.override;
      expected = functionArgs f;
    };

  testCallPackagesWithOverridePreservesArguments =
    let
      f =
        {
          a ? 0,
          b,
        }:
        {
          nested = { };
        };
      f' = callPackagesWith {
        a = 1;
        b = 2;
      } f { };
    in
    {
      expr = functionArgs f'.nested.override;
      expected = functionArgs f;
    };

  # TRIVIAL

  testId = {
    expr = id 1;
    expected = 1;
  };

  testConst = {
    expr = const 2 3;
    expected = 2;
  };

  testPipe = {
    expr = pipe 2 [
      (x: x + 2) # 2 + 2 = 4
      (x: x * 2) # 4 * 2 = 8
    ];
    expected = 8;
  };

  testPipeEmpty = {
    expr = pipe 2 [ ];
    expected = 2;
  };

  testPipeStrings = {
    expr =
      pipe
        [ 3 4 ]
        [
          (map toString)
          (map (s: s + "\n"))
          concatStrings
        ];
    expected = ''
      3
      4
    '';
  };

  /*
    testOr = {
      expr = or true false;
      expected = true;
    };
  */

  testAnd = {
    expr = and true false;
    expected = false;
  };

  testXor = {
    expr = [
      (xor true false)
      (xor true true)
      (xor false false)
      (xor false true)
    ];
    expected = [
      true
      false
      false
      true
    ];
  };

  testComposeExtensions = {
    expr =
      let
        obj = makeExtensible (self: {
          foo = self.bar;
        });
        f = self: super: {
          bar = false;
          baz = true;
        };
        g = self: super: { bar = super.baz or false; };
        f_o_g = composeExtensions f g;
        composed = obj.extend f_o_g;
      in
      composed.foo;
    expected = true;
  };

  testComposeManyExtensions0 = {
    expr =
      let
        obj = makeExtensible (self: {
          foo = true;
        });
        emptyComposition = composeManyExtensions [ ];
        composed = obj.extend emptyComposition;
      in
      composed.foo;
    expected = true;
  };

  testComposeManyExtensions =
    let
      f = self: super: {
        bar = false;
        baz = true;
      };
      g = self: super: { bar = super.baz or false; };
      h = self: super: { qux = super.bar or false; };
      obj = makeExtensible (self: {
        foo = self.qux;
      });
    in
    {
      expr =
        let
          composition = composeManyExtensions [
            f
            g
            h
          ];
          composed = obj.extend composition;
        in
        composed.foo;
      expected = (obj.extend (composeExtensions f (composeExtensions g h))).foo;
    };

  testBitAnd = {
    expr = (bitAnd 3 10);
    expected = 2;
  };

  testBitOr = {
    expr = (bitOr 3 10);
    expected = 11;
  };

  testBitXor = {
    expr = (bitXor 3 10);
    expected = 9;
  };

  testToHexString = {
    expr = toHexString 250;
    expected = "FA";
  };

  testFromHexStringFirstExample = {
    expr = fromHexString "FF";
    expected = 255;
  };

  testFromHexStringSecondExample = {
    expr = fromHexString (builtins.hashString "sha256" "test");
    expected = 9223372036854775807;
  };

  testFromHexStringWithPrefix = {
    expr = fromHexString "0Xf";
    expected = 15;
  };

  testToBaseDigits = {
    expr = toBaseDigits 2 6;
    expected = [
      1
      1
      0
    ];
  };

  testFunctionArgsFunctor = {
    expr = functionArgs { __functor = self: { a, b }: null; };
    expected = {
      a = false;
      b = false;
    };
  };

  testFunctionArgsSetFunctionArgs = {
    expr = functionArgs (setFunctionArgs (args: args.x) { x = false; });
    expected = {
      x = false;
    };
  };

  # STRINGS

  testConcatMapStrings = {
    expr = concatMapStrings (x: x + ";") [
      "a"
      "b"
      "c"
    ];
    expected = "a;b;c;";
  };

  testConcatStringsSep = {
    expr = concatStringsSep "," [
      "a"
      "b"
      "c"
    ];
    expected = "a,b,c";
  };

  testConcatMapAttrsStringSepExamples = {
    expr = concatMapAttrsStringSep "\n" (name: value: "${name}: foo-${value}") {
      a = "0.1.0";
      b = "0.2.0";
    };
    expected = "a: foo-0.1.0\nb: foo-0.2.0";
  };

  testConcatLines = {
    expr = concatLines [
      "a"
      "b"
      "c"
    ];
    expected = "a\nb\nc\n";
  };

  testMakeIncludePathWithPkgs = {
    expr = (
      makeIncludePath [
        # makeIncludePath preferably selects the "dev" output
        {
          dev.outPath = "/dev";
          out.outPath = "/out";
          outPath = "/default";
        }
        # "out" is used if "dev" is not found
        {
          out.outPath = "/out";
          outPath = "/default";
        }
        # And it returns the derivation directly if there's no "out" either
        { outPath = "/default"; }
        # Same if the output is specified explicitly, even if there's a "dev"
        {
          dev.outPath = "/dev";
          outPath = "/default";
          outputSpecified = true;
        }
      ]
    );
    expected = "/dev/include:/out/include:/default/include:/default/include";
  };

  testMakeIncludePathWithEmptyList = {
    expr = (makeIncludePath [ ]);
    expected = "";
  };

  testMakeIncludePathWithOneString = {
    expr = (makeIncludePath [ "/usr" ]);
    expected = "/usr/include";
  };

  testMakeIncludePathWithManyString = {
    expr = (
      makeIncludePath [
        "/usr"
        "/usr/local"
      ]
    );
    expected = "/usr/include:/usr/local/include";
  };

  testReplaceStringString = {
    expr = strings.replaceString "." "_" "v1.2.3";
    expected = "v1_2_3";
  };

  testReplicateString = {
    expr = strings.replicate 5 "hello";
    expected = "hellohellohellohellohello";
  };

  # Test various strings are trimmed correctly
  testTrimString = {
    expr =
      let
        testValues =
          f:
          mapAttrs (_: f) {
            empty = "";
            cr = "\r";
            lf = "\n";
            tab = "\t";
            spaces = "   ";
            leading = "  Hello, world";
            trailing = "Hello, world   ";
            mixed = " Hello, world ";
            mixed-tabs = " \t\tHello, world \t \t ";
            multiline = "  Hello,\n  world!  ";
            multiline-crlf = "  Hello,\r\n  world!  ";
          };
      in
      {
        leading = testValues (strings.trimWith { start = true; });
        trailing = testValues (strings.trimWith { end = true; });
        both = testValues strings.trim;
      };
    expected = {
      leading = {
        empty = "";
        cr = "";
        lf = "";
        tab = "";
        spaces = "";
        leading = "Hello, world";
        trailing = "Hello, world   ";
        mixed = "Hello, world ";
        mixed-tabs = "Hello, world \t \t ";
        multiline = "Hello,\n  world!  ";
        multiline-crlf = "Hello,\r\n  world!  ";
      };
      trailing = {
        empty = "";
        cr = "";
        lf = "";
        tab = "";
        spaces = "";
        leading = "  Hello, world";
        trailing = "Hello, world";
        mixed = " Hello, world";
        mixed-tabs = " \t\tHello, world";
        multiline = "  Hello,\n  world!";
        multiline-crlf = "  Hello,\r\n  world!";
      };
      both = {
        empty = "";
        cr = "";
        lf = "";
        tab = "";
        spaces = "";
        leading = "Hello, world";
        trailing = "Hello, world";
        mixed = "Hello, world";
        mixed-tabs = "Hello, world";
        multiline = "Hello,\n  world!";
        multiline-crlf = "Hello,\r\n  world!";
      };
    };
  };

  testSplitStringsSimple = {
    expr = strings.splitString "." "a.b.c.d";
    expected = [
      "a"
      "b"
      "c"
      "d"
    ];
  };

  testSplitStringsEmpty = {
    expr = strings.splitString "." "a..b";
    expected = [
      "a"
      ""
      "b"
    ];
  };

  testSplitStringsOne = {
    expr = strings.splitString ":" "a.b";
    expected = [ "a.b" ];
  };

  testSplitStringsNone = {
    expr = strings.splitString "." "";
    expected = [ "" ];
  };

  testSplitStringsFirstEmpty = {
    expr = strings.splitString "/" "/a/b/c";
    expected = [
      ""
      "a"
      "b"
      "c"
    ];
  };

  testSplitStringsLastEmpty = {
    expr = strings.splitString ":" "2001:db8:0:0042::8a2e:370:";
    expected = [
      "2001"
      "db8"
      "0"
      "0042"
      ""
      "8a2e"
      "370"
      ""
    ];
  };

  testSplitStringsRegex = {
    expr = strings.splitString "\\[{}]()^$?*+|." "A\\[{}]()^$?*+|.B";
    expected = [
      "A"
      "B"
    ];
  };

  testSplitStringBySimpleDelimiter = {
    expr = strings.splitStringBy (
      prev: curr:
      builtins.elem curr [
        "."
        "-"
      ]
    ) false "foo.bar-baz";
    expected = [
      "foo"
      "bar"
      "baz"
    ];
  };

  testSplitStringByLeadingDelimiter = {
    expr = strings.splitStringBy (prev: curr: builtins.elem curr [ "." ]) false ".foo.bar.baz";
    expected = [
      ""
      "foo"
      "bar"
      "baz"
    ];
  };

  testSplitStringByTrailingDelimiter = {
    expr = strings.splitStringBy (prev: curr: builtins.elem curr [ "." ]) false "foo.bar.baz.";
    expected = [
      "foo"
      "bar"
      "baz"
      ""
    ];
  };

  testSplitStringByMultipleConsecutiveDelimiters = {
    expr = strings.splitStringBy (prev: curr: builtins.elem curr [ "." ]) false "foo...bar";
    expected = [
      "foo"
      ""
      ""
      "bar"
    ];
  };

  testSplitStringByKeepingSplitChar = {
    expr = strings.splitStringBy (prev: curr: builtins.elem curr [ "." ]) true "foo.bar.baz";
    expected = [
      "foo"
      ".bar"
      ".baz"
    ];
  };

  testSplitStringByCaseTransition = {
    expr = strings.splitStringBy (
      prev: curr: builtins.match "[a-z]" prev != null && builtins.match "[A-Z]" curr != null
    ) true "fooBarBaz";
    expected = [
      "foo"
      "Bar"
      "Baz"
    ];
  };

  testSplitStringByEmptyString = {
    expr = strings.splitStringBy (prev: curr: builtins.elem curr [ "." ]) false "";
    expected = [ "" ];
  };

  testSplitStringByComplexPredicate = {
    expr = strings.splitStringBy (
      prev: curr:
      prev != ""
      && curr != ""
      && builtins.match "[0-9]" prev != null
      && builtins.match "[a-z]" curr != null
    ) true "123abc456def";
    expected = [
      "123"
      "abc456"
      "def"
    ];
  };

  testSplitStringByUpperCaseStart = {
    expr = strings.splitStringBy (prev: curr: builtins.match "[A-Z]" curr != null) true "FooBarBaz";
    expected = [
      ""
      "Foo"
      "Bar"
      "Baz"
    ];
  };

  testEscapeShellArg = {
    expr = strings.escapeShellArg "esc'ape\nme";
    expected = "'esc'\\''ape\nme'";
  };

  testEscapeShellArgEmpty = {
    expr = strings.escapeShellArg "";
    expected = "''";
  };

  testEscapeShellArgs = {
    expr = strings.escapeShellArgs [
      "one"
      "two three"
      "four'five"
    ];
    expected = "one 'two three' 'four'\\''five'";
  };

  testEscapeShellArgsUnicode = {
    expr = strings.escapeShellArg "á";
    expected = "'á'";
  };

  testSplitStringsDerivation = {
    expr = take 3 (
      strings.splitString "/" (derivation {
        name = "name";
        builder = "builder";
        system = "system";
      })
    );
    expected = [
      ""
      "nix"
      "store"
    ];
  };

  testSplitVersionSingle = {
    expr = versions.splitVersion "1";
    expected = [ "1" ];
  };

  testSplitVersionDouble = {
    expr = versions.splitVersion "1.2";
    expected = [
      "1"
      "2"
    ];
  };

  testSplitVersionTriple = {
    expr = versions.splitVersion "1.2.3";
    expected = [
      "1"
      "2"
      "3"
    ];
  };

  testPadVersionLess = {
    expr = versions.pad 3 "1.2";
    expected = "1.2.0";
  };

  testPadVersionLessExtra = {
    expr = versions.pad 3 "1.3-rc1";
    expected = "1.3.0-rc1";
  };

  testPadVersionMore = {
    expr = versions.pad 3 "1.2.3.4";
    expected = "1.2.3";
  };

  testIsStorePath = {
    expr =
      let
        goodPath = "${builtins.storeDir}/d945ibfx9x185xf04b890y4f9g3cbb63-python-2.7.11";
        goodCAPath = "/1121rp0gvr1qya7hvy925g5kjwg66acz6sn1ra1hca09f1z5dsab";
      in
      {
        storePath = isStorePath goodPath;
        storePathDerivation = isStorePath (import ../.. { system = "x86_64-linux"; }).hello;
        storePathAppendix = isStorePath "${goodPath}/bin/python";
        nonAbsolute = isStorePath (concatStrings (tail (stringToCharacters goodPath)));
        asPath = isStorePath (/. + goodPath);
        otherPath = isStorePath "/something/else";

        caPath = isStorePath goodCAPath;
        caPathAppendix = isStorePath "${goodCAPath}/bin/python";
        caAsPath = isStorePath (/. + goodCAPath);

        otherVals = {
          attrset = isStorePath { };
          list = isStorePath [ ];
          int = isStorePath 42;
        };
      };
    expected = {
      storePath = true;
      storePathDerivation = true;
      storePathAppendix = false;
      nonAbsolute = false;
      asPath = true;
      caPath = true;
      caPathAppendix = false;
      caAsPath = true;
      otherPath = false;
      otherVals = {
        attrset = false;
        list = false;
        int = false;
      };
    };
  };

  testEscapeXML = {
    expr = escapeXML ''"test" 'test' < & >'';
    expected = "&quot;test&quot; &apos;test&apos; &lt; &amp; &gt;";
  };

  testToShellVars = {
    expr = ''
      ${toShellVars {
        STRing01 = "just a 'string'";
        _array_ = [
          "with"
          "more strings"
        ];
        assoc."with some" = ''
          strings
          possibly newlines
        '';
        drv = {
          outPath = "/drv";
          foo = "ignored attribute";
        };
        path = /path;
        stringable = {
          __toString = _: "hello toString";
          bar = "ignored attribute";
        };
      }}
    '';
    expected = ''
      STRing01='just a '\'''string'\''''
      declare -a _array_=(with 'more strings')
      declare -A assoc=(['with some']='strings
      possibly newlines
      ')
      drv=/drv
      path=/path
      stringable='hello toString'
    '';
  };

  testHasInfixFalse = {
    expr = hasInfix "c" "abde";
    expected = false;
  };

  testHasInfixTrue = {
    expr = hasInfix "c" "abcde";
    expected = true;
  };

  testHasInfixDerivation = {
    expr = hasInfix "hello" (import ../.. { system = "x86_64-linux"; }).hello;
    expected = true;
  };

  testHasInfixPath = {
    expr = hasInfix "tests" ./.;
    expected = true;
  };

  testHasInfixPathStoreDir = {
    expr = hasInfix builtins.storeDir ./.;
    expected = true;
  };

  testHasInfixToString = {
    expr = hasInfix "a" { __toString = _: "a"; };
    expected = true;
  };

  testRemovePrefixExample1 = {
    expr = removePrefix "foo." "foo.bar.baz";
    expected = "bar.baz";
  };
  testRemovePrefixExample2 = {
    expr = removePrefix "xxx" "foo.bar.baz";
    expected = "foo.bar.baz";
  };
  testRemovePrefixEmptyPrefix = {
    expr = removePrefix "" "foo";
    expected = "foo";
  };
  testRemovePrefixEmptyString = {
    expr = removePrefix "foo" "";
    expected = "";
  };
  testRemovePrefixEmptyBoth = {
    expr = removePrefix "" "";
    expected = "";
  };

  testNormalizePath = {
    expr = strings.normalizePath "//a/b//c////d/";
    expected = "/a/b/c/d/";
  };

  testCharToInt = {
    expr = strings.charToInt "A";
    expected = 65;
  };

  testEscapeC = {
    expr = strings.escapeC [ "\n" " " ] "Hello World\n";
    expected = "Hello\\x20World\\x0a";
  };

  testEscapeURL = testAllTrue [
    ("" == strings.escapeURL "")
    ("Hello" == strings.escapeURL "Hello")
    ("Hello%20World" == strings.escapeURL "Hello World")
    ("Hello%2FWorld" == strings.escapeURL "Hello/World")
    ("42%25" == strings.escapeURL "42%")
    (
      "%20%3F%26%3D%23%2B%25%21%3C%3E%23%22%7B%7D%7C%5C%5E%5B%5D%60%09%3A%2F%40%24%27%28%29%2A%2C%3B"
      == strings.escapeURL " ?&=#+%!<>#\"{}|\\^[]`\t:/@$'()*,;"
    )
  ];

  testToSentenceCase = {
    expr = strings.toSentenceCase "hello world";
    expected = "Hello world";
  };

  testToSentenceCasePath = testingThrow (strings.toSentenceCase ./.);

  testToCamelCase = {
    expr = strings.toCamelCase "hello world";
    expected = "helloWorld";
  };

  testToCamelCaseFromKebab = {
    expr = strings.toCamelCase "hello-world";
    expected = "helloWorld";
  };

  testToCamelCaseFromSnake = {
    expr = strings.toCamelCase "hello_world";
    expected = "helloWorld";
  };

  testToCamelCaseFromPascal = {
    expr = strings.toCamelCase "HelloWorld";
    expected = "helloWorld";
  };

  testToCamelCasePath = testingThrow (strings.toCamelCase ./.);

  testToInt = testAllTrue [
    # Naive
    (123 == toInt "123")
    (0 == toInt "0")
    # Whitespace Padding
    (123 == toInt " 123")
    (123 == toInt "123 ")
    (123 == toInt " 123 ")
    (123 == toInt "   123   ")
    (0 == toInt " 0")
    (0 == toInt "0 ")
    (0 == toInt " 0 ")
    (-1 == toInt "-1")
    (-1 == toInt " -1 ")
  ];

  testToIntFails = testAllTrue [
    (
      builtins.tryEval (toInt "") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt "123 123") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt "0 123") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " 0d ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " 1d ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " d0 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt "00") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt "01") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt "002") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " 002 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " foo ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " foo 123 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toInt " foo123 ") == {
        success = false;
        value = false;
      }
    )
  ];

  testToIntBase10 = testAllTrue [
    # Naive
    (123 == toIntBase10 "123")
    (0 == toIntBase10 "0")
    # Whitespace Padding
    (123 == toIntBase10 " 123")
    (123 == toIntBase10 "123 ")
    (123 == toIntBase10 " 123 ")
    (123 == toIntBase10 "   123   ")
    (0 == toIntBase10 " 0")
    (0 == toIntBase10 "0 ")
    (0 == toIntBase10 " 0 ")
    # Zero Padding
    (123 == toIntBase10 "0123")
    (123 == toIntBase10 "0000123")
    (0 == toIntBase10 "000000")
    # Whitespace and Zero Padding
    (123 == toIntBase10 " 0123")
    (123 == toIntBase10 "0123 ")
    (123 == toIntBase10 " 0123 ")
    (123 == toIntBase10 " 0000123")
    (123 == toIntBase10 "0000123 ")
    (123 == toIntBase10 " 0000123 ")
    (0 == toIntBase10 " 000000")
    (0 == toIntBase10 "000000 ")
    (0 == toIntBase10 " 000000 ")
    (-1 == toIntBase10 "-1")
    (-1 == toIntBase10 " -1 ")
  ];

  testToIntBase10Fails = testAllTrue [
    (
      builtins.tryEval (toIntBase10 "") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 "123 123") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 "0 123") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " 0d ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " 1d ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " d0 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " foo ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " foo 123 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " foo 00123 ") == {
        success = false;
        value = false;
      }
    )
    (
      builtins.tryEval (toIntBase10 " foo00123 ") == {
        success = false;
        value = false;
      }
    )
  ];

  # LISTS

  testFilter = {
    expr = filter (x: x != "a") [
      "a"
      "b"
      "c"
      "a"
    ];
    expected = [
      "b"
      "c"
    ];
  };

  testIfilter0Example = {
    expr = ifilter0 (i: v: i == 0 || v > 2) [
      1
      2
      3
    ];
    expected = [
      1
      3
    ];
  };
  testIfilter0Empty = {
    expr = ifilter0 (i: v: abort "shouldn't be evaluated!") [ ];
    expected = [ ];
  };
  testIfilter0IndexOnly = {
    expr = length (
      ifilter0 (i: v: mod i 2 == 0) [
        (throw "0")
        (throw "1")
        (throw "2")
        (throw "3")
      ]
    );
    expected = 2;
  };
  testIfilter0All = {
    expr = ifilter0 (i: v: true) [
      10
      11
      12
      13
      14
      15
    ];
    expected = [
      10
      11
      12
      13
      14
      15
    ];
  };
  testIfilter0First = {
    expr = ifilter0 (i: v: i == 0) [
      10
      11
      12
      13
      14
      15
    ];
    expected = [ 10 ];
  };
  testIfilter0Last = {
    expr = ifilter0 (i: v: i == 5) [
      10
      11
      12
      13
      14
      15
    ];
    expected = [ 15 ];
  };

  testFold =
    let
      f = op: fold: fold op 0 (range 0 100);
      # fold with associative operator
      assoc = f builtins.add;
      # fold with non-associative operator
      nonAssoc = f builtins.sub;
    in
    {
      expr = {
        assocRight = assoc foldr;
        # right fold with assoc operator is same as left fold
        assocRightIsLeft = assoc foldr == assoc foldl;
        nonAssocRight = nonAssoc foldr;
        nonAssocLeft = nonAssoc foldl;
        # with non-assoc operator the fold results are not the same
        nonAssocRightIsNotLeft = nonAssoc foldl != nonAssoc foldr;
        # fold is an alias for foldr
        foldIsRight = nonAssoc fold == nonAssoc foldr;
      };
      expected = {
        assocRight = 5050;
        assocRightIsLeft = true;
        nonAssocRight = 50;
        nonAssocLeft = (-5050);
        nonAssocRightIsNotLeft = true;
        foldIsRight = true;
      };
    };

  testFoldl'Empty = {
    expr = foldl' (acc: el: abort "operation not called") 0 [ ];
    expected = 0;
  };

  testFoldl'IntegerAdding = {
    expr = foldl' (acc: el: acc + el) 0 [
      1
      2
      3
    ];
    expected = 6;
  };

  # The accumulator isn't forced deeply
  testFoldl'NonDeep = {
    expr = take 3 (foldl' (acc: el: [ el ] ++ acc) [ (abort "unevaluated list entry") ] [ 1 2 3 ]);
    expected = [
      3
      2
      1
    ];
  };

  # Compared to builtins.foldl', lib.foldl' evaluates the first accumulator strictly too
  testFoldl'StrictInitial = {
    expr = (builtins.tryEval (foldl' (acc: el: el) (throw "hello") [ ])).success;
    expected = false;
  };

  # Make sure we don't get a stack overflow for large lists
  # This number of elements would notably cause a stack overflow if it was implemented without the `foldl'` builtin
  testFoldl'Large = {
    expr = foldl' (acc: el: acc + el) 0 (range 0 100000);
    expected = 5000050000;
  };

  testTake = testAllTrue [
    (
      [ ] == (take 0 [
        1
        2
        3
      ])
    )
    (
      [ 1 ] == (take 1 [
        1
        2
        3
      ])
    )
    (
      [
        1
        2
      ] == (take 2 [
        1
        2
        3
      ])
    )
    (
      [
        1
        2
        3
      ] == (take 3 [
        1
        2
        3
      ])
    )
    (
      [
        1
        2
        3
      ] == (take 4 [
        1
        2
        3
      ])
    )
  ];

  testTakeEnd =
    let
      inherit (lib) takeEnd;
    in
    testAllTrue [
      (
        takeEnd 0 [
          1
          2
          3
        ] == [ ]
      )
      (
        takeEnd 1 [
          1
          2
          3
        ] == [ 3 ]
      )
      (
        takeEnd 2 [
          1
          2
          3
        ] == [
          2
          3
        ]
      )
      (
        takeEnd 3 [
          1
          2
          3
        ] == [
          1
          2
          3
        ]
      )
      (
        takeEnd 4 [
          1
          2
          3
        ] == [
          1
          2
          3
        ]
      )
      (takeEnd 0 [ ] == [ ])
      (takeEnd 1 [ ] == [ ])
      (
        takeEnd (-1) [
          1
          2
          3
        ] == [ ]
      )
      (takeEnd (-1) [ ] == [ ])
    ];

  testDrop =
    let
      inherit (lib) drop;
    in
    testAllTrue [
      # list index -1 is out of bounds
      # ([ 1 2 3 ] == (drop (-1) [  1 2 3 ]))
      (
        drop 0 [
          1
          2
          3
        ] == [
          1
          2
          3
        ]
      )
      (
        drop 1 [
          1
          2
          3
        ] == [
          2
          3
        ]
      )
      (
        drop 2 [
          1
          2
          3
        ] == [ 3 ]
      )
      (
        drop 3 [
          1
          2
          3
        ] == [ ]
      )
      (
        drop 4 [
          1
          2
          3
        ] == [ ]
      )
      (drop 0 [ ] == [ ])
      (drop 1 [ ] == [ ])
    ];

  testDropEnd =
    let
      inherit (lib) dropEnd;
    in
    testAllTrue [
      (
        dropEnd 0 [
          1
          2
          3
        ] == [
          1
          2
          3
        ]
      )
      (
        dropEnd 1 [
          1
          2
          3
        ] == [
          1
          2
        ]
      )
      (
        dropEnd 2 [
          1
          2
          3
        ] == [ 1 ]
      )
      (
        dropEnd 3 [
          1
          2
          3
        ] == [ ]
      )
      (
        dropEnd 4 [
          1
          2
          3
        ] == [ ]
      )
      (dropEnd 0 [ ] == [ ])
      (dropEnd 1 [ ] == [ ])
      (
        dropEnd (-1) [
          1
          2
          3
        ] == [
          1
          2
          3
        ]
      )
      (dropEnd (-1) [ ] == [ ])
    ];

  testListHasPrefixExample1 = {
    expr = lists.hasPrefix [ 1 2 ] [ 1 2 3 4 ];
    expected = true;
  };
  testListHasPrefixExample2 = {
    expr = lists.hasPrefix [ 0 1 ] [ 1 2 3 4 ];
    expected = false;
  };
  testListHasPrefixLazy = {
    expr = lists.hasPrefix [ 1 ] [ 1 (abort "lib.lists.hasPrefix is not lazy") ];
    expected = true;
  };
  testListHasPrefixEmptyPrefix = {
    expr = lists.hasPrefix [ ] [ 1 2 ];
    expected = true;
  };
  testListHasPrefixEmptyList = {
    expr = lists.hasPrefix [ 1 2 ] [ ];
    expected = false;
  };

  testListRemovePrefixExample1 = {
    expr = lists.removePrefix [ 1 2 ] [ 1 2 3 4 ];
    expected = [
      3
      4
    ];
  };
  testListRemovePrefixExample2 = {
    expr = (builtins.tryEval (lists.removePrefix [ 0 1 ] [ 1 2 3 4 ])).success;
    expected = false;
  };
  testListRemovePrefixEmptyPrefix = {
    expr = lists.removePrefix [ ] [ 1 2 ];
    expected = [
      1
      2
    ];
  };
  testListRemovePrefixEmptyList = {
    expr = (builtins.tryEval (lists.removePrefix [ 1 2 ] [ ])).success;
    expected = false;
  };

  testFoldAttrs = {
    expr =
      foldAttrs (n: a: [ n ] ++ a)
        [ ]
        [
          {
            a = 2;
            b = 7;
          }
          {
            a = 3;
            c = 8;
          }
        ];
    expected = {
      a = [
        2
        3
      ];
      b = [ 7 ];
      c = [ 8 ];
    };
  };

  testListCommonPrefixExample1 = {
    expr = lists.commonPrefix [ 1 2 3 4 5 6 ] [ 1 2 4 8 ];
    expected = [
      1
      2
    ];
  };
  testListCommonPrefixExample2 = {
    expr = lists.commonPrefix [ 1 2 3 ] [ 1 2 3 4 5 ];
    expected = [
      1
      2
      3
    ];
  };
  testListCommonPrefixExample3 = {
    expr = lists.commonPrefix [ 1 2 3 ] [ 4 5 6 ];
    expected = [ ];
  };
  testListCommonPrefixEmpty = {
    expr = lists.commonPrefix [ ] [ 1 2 3 ];
    expected = [ ];
  };
  testListCommonPrefixSame = {
    expr = lists.commonPrefix [ 1 2 3 ] [ 1 2 3 ];
    expected = [
      1
      2
      3
    ];
  };
  testListCommonPrefixLazy = {
    expr = lists.commonPrefix [ 1 ] [ 1 (abort "lib.lists.commonPrefix shouldn't evaluate this") ];
    expected = [ 1 ];
  };
  # This would stack overflow if `commonPrefix` were implemented using recursion
  testListCommonPrefixLong =
    let
      longList = genList (n: n) 100000;
    in
    {
      expr = lists.commonPrefix longList longList;
      expected = longList;
    };

  testSort = {
    expr = sort builtins.lessThan [
      40
      2
      30
      42
    ];
    expected = [
      2
      30
      40
      42
    ];
  };

  testSortOn = {
    expr = sortOn stringLength [
      "aa"
      "b"
      "cccc"
    ];
    expected = [
      "b"
      "aa"
      "cccc"
    ];
  };

  testSortOnEmpty = {
    expr = sortOn (throw "nope") [ ];
    expected = [ ];
  };

  testSortOnIncomparable = {
    expr = map (x: x.f x.ok) (
      sortOn (x: x.ok) [
        {
          ok = 1;
          f = x: x;
        }
        {
          ok = 3;
          f = x: x + 3;
        }
        {
          ok = 2;
          f = x: x;
        }
      ]
    );
    expected = [
      1
      2
      6
    ];
  };

  testReplaceString = {
    expr = replaceString "world" "Nix" "Hello, world!";
    expected = "Hello, Nix!";
  };

  testReplicate = {
    expr = replicate 3 "a";
    expected = [
      "a"
      "a"
      "a"
    ];
  };

  testToIntShouldConvertStringToInt = {
    expr = toInt "27";
    expected = 27;
  };

  testToIntShouldThrowErrorIfItCouldNotConvertToInt = {
    expr = builtins.tryEval (toInt "\"foo\"");
    expected = {
      success = false;
      value = false;
    };
  };

  testHasAttrByPathTrue = {
    expr = hasAttrByPath [ "a" "b" ] {
      a = {
        b = "yey";
      };
    };
    expected = true;
  };

  testHasAttrByPathFalse = {
    expr = hasAttrByPath [ "a" "b" ] {
      a = {
        c = "yey";
      };
    };
    expected = false;
  };

  testHasAttrByPathNonStrict = {
    expr = hasAttrByPath [ ] (throw "do not use");
    expected = true;
  };

  testLongestValidPathPrefix_empty_empty = {
    expr = attrsets.longestValidPathPrefix [ ] { };
    expected = [ ];
  };

  testLongestValidPathPrefix_empty_nonStrict = {
    expr = attrsets.longestValidPathPrefix [ ] (throw "do not use");
    expected = [ ];
  };

  testLongestValidPathPrefix_zero = {
    expr = attrsets.longestValidPathPrefix [ "a" (throw "do not use") ] { d = null; };
    expected = [ ];
  };

  testLongestValidPathPrefix_zero_b = {
    expr = attrsets.longestValidPathPrefix [ "z" "z" ] "remarkably harmonious";
    expected = [ ];
  };

  testLongestValidPathPrefix_one = {
    expr = attrsets.longestValidPathPrefix [ "a" "b" "c" ] { a = null; };
    expected = [ "a" ];
  };

  testLongestValidPathPrefix_two = {
    expr = attrsets.longestValidPathPrefix [ "a" "b" "c" ] { a.b = null; };
    expected = [
      "a"
      "b"
    ];
  };

  testLongestValidPathPrefix_three = {
    expr = attrsets.longestValidPathPrefix [ "a" "b" "c" ] { a.b.c = null; };
    expected = [
      "a"
      "b"
      "c"
    ];
  };

  testLongestValidPathPrefix_three_extra = {
    expr = attrsets.longestValidPathPrefix [ "a" "b" "c" ] { a.b.c.d = throw "nope"; };
    expected = [
      "a"
      "b"
      "c"
    ];
  };

  testFindFirstIndexExample1 = {
    expr = lists.findFirstIndex (x: x > 3) (abort "index found, so a default must not be evaluated") [
      1
      6
      4
    ];
    expected = 1;
  };

  testFindFirstIndexExample2 = {
    expr = lists.findFirstIndex (x: x > 9) "a very specific default" [
      1
      6
      4
    ];
    expected = "a very specific default";
  };

  testFindFirstIndexEmpty = {
    expr = lists.findFirstIndex (abort "when the list is empty, the predicate is not needed") null [ ];
    expected = null;
  };

  testFindFirstIndexSingleMatch = {
    expr = lists.findFirstIndex (x: x == 5) null [ 5 ];
    expected = 0;
  };

  testFindFirstIndexSingleDefault = {
    expr = lists.findFirstIndex (x: false) null [
      (abort "if the predicate doesn't access the value, it must not be evaluated")
    ];
    expected = null;
  };

  testFindFirstIndexNone = {
    expr = builtins.tryEval (
      lists.findFirstIndex (x: x == 2) null [
        1
        (throw "the last element must be evaluated when there's no match")
      ]
    );
    expected = {
      success = false;
      value = false;
    };
  };

  # Makes sure that the implementation doesn't cause a stack overflow
  testFindFirstIndexBig = {
    expr = lists.findFirstIndex (x: x == 1000000) null (range 0 1000000);
    expected = 1000000;
  };

  testFindFirstIndexLazy = {
    expr = lists.findFirstIndex (x: x == 1) null [
      1
      (abort "list elements after the match must not be evaluated")
    ];
    expected = 0;
  };

  testFindFirstExample1 = {
    expr = lists.findFirst (x: x > 3) 7 [
      1
      6
      4
    ];
    expected = 6;
  };

  testFindFirstExample2 = {
    expr = lists.findFirst (x: x > 9) 7 [
      1
      6
      4
    ];
    expected = 7;
  };

  testAllUnique_true = {
    expr = allUnique [
      3
      2
      4
      1
    ];
    expected = true;
  };
  testAllUnique_false = {
    expr = allUnique [
      3
      2
      3
      4
    ];
    expected = false;
  };

  # ATTRSETS

  testConcatMapAttrs = {
    expr =
      concatMapAttrs
        (name: value: {
          ${name} = value;
          ${name + value} = value;
        })
        {
          foo = "bar";
          foobar = "baz";
        };
    expected = {
      foo = "bar";
      foobar = "baz";
      foobarbaz = "baz";
    };
  };

  testFilterAttrs = {
    expr = filterAttrs (n: v: n != "a" && (v.hello or false) == true) {
      a.hello = true;
      b.hello = true;
      c = {
        hello = true;
        world = false;
      };
      d.hello = false;
    };
    expected = {
      b.hello = true;
      c = {
        hello = true;
        world = false;
      };
    };
  };

  # code from example
  testFoldlAttrs = {
    expr = {
      example =
        foldlAttrs
          (acc: name: value: {
            sum = acc.sum + value;
            names = acc.names ++ [ name ];
          })
          {
            sum = 0;
            names = [ ];
          }
          {
            foo = 1;
            bar = 10;
          };
      # should just return the initial value
      emptySet = foldlAttrs (throw "function not needed") 123 { };
      # should just evaluate to the last value
      valuesNotNeeded =
        foldlAttrs
          (
            acc: _name: _v:
            acc
          )
          3
          {
            z = throw "value z not needed";
            a = throw "value a not needed";
          };
      # the accumulator doesnt have to be an attrset it can be as trivial as being just a number or string
      trivialAcc =
        foldlAttrs
          (
            acc: _name: v:
            acc * 10 + v
          )
          1
          {
            z = 1;
            a = 2;
          };
    };
    expected = {
      example = {
        sum = 11;
        names = [
          "bar"
          "foo"
        ];
      };
      emptySet = 123;
      valuesNotNeeded = 3;
      trivialAcc = 121;
    };
  };

  testMergeAttrsListExample1 = {
    expr = attrsets.mergeAttrsList [
      {
        a = 0;
        b = 1;
      }
      {
        c = 2;
        d = 3;
      }
    ];
    expected = {
      a = 0;
      b = 1;
      c = 2;
      d = 3;
    };
  };
  testMergeAttrsListExample2 = {
    expr = attrsets.mergeAttrsList [
      { a = 0; }
      { a = 1; }
    ];
    expected = {
      a = 1;
    };
  };
  testMergeAttrsListExampleMany =
    let
      list = genList (
        n:
        listToAttrs (
          genList (
            m:
            let
              # Integer divide n by two to create duplicate attributes
              str = "halfn${toString (n / 2)}m${toString m}";
            in
            nameValuePair str str
          ) 100
        )
      ) 100;
    in
    {
      expr = attrsets.mergeAttrsList list;
      expected = foldl' mergeAttrs { } list;
    };

  # code from the example
  testRecursiveUpdateUntil = {
    expr =
      recursiveUpdateUntil
        (
          path: l: r:
          path == [ "foo" ]
        )
        {
          # first attribute set
          foo.bar = 1;
          foo.baz = 2;
          bar = 3;
        }
        {
          #second attribute set
          foo.bar = 1;
          foo.quz = 2;
          baz = 4;
        };
    expected = {
      foo.bar = 1; # 'foo.*' from the second set
      foo.quz = 2;
      bar = 3; # 'bar' from the first set
      baz = 4; # 'baz' from the second set
    };
  };

  testMatchAttrsMatchingExact = {
    expr =
      matchAttrs
        {
          cpu = {
            bits = 64;
          };
        }
        {
          cpu = {
            bits = 64;
          };
        };
    expected = true;
  };

  testMatchAttrsMismatch = {
    expr =
      matchAttrs
        {
          cpu = {
            bits = 128;
          };
        }
        {
          cpu = {
            bits = 64;
          };
        };
    expected = false;
  };

  testMatchAttrsMatchingImplicit = {
    expr = matchAttrs { cpu = { }; } {
      cpu = {
        bits = 64;
      };
    };
    expected = true;
  };

  testMatchAttrsMissingAttrs = {
    expr = matchAttrs { cpu = { }; } { };
    expected = false;
  };

  testOverrideExistingEmpty = {
    expr = overrideExisting { } { a = 1; };
    expected = { };
  };

  testOverrideExistingDisjoint = {
    expr = overrideExisting { b = 2; } { a = 1; };
    expected = {
      b = 2;
    };
  };

  testOverrideExistingOverride = {
    expr = overrideExisting {
      a = 3;
      b = 2;
    } { a = 1; };
    expected = {
      a = 1;
      b = 2;
    };
  };

  testListAttrsReverse =
    let
      exampleAttrs = {
        foo = 1;
        bar = "asdf";
        baz = [
          1
          3
          3
          7
        ];
        fnord = null;
      };
      exampleSingletonList = [
        {
          name = "foo";
          value = 1;
        }
      ];
    in
    {
      expr = {
        isReverseToListToAttrs = builtins.listToAttrs (attrsToList exampleAttrs) == exampleAttrs;
        isReverseToAttrsToList =
          attrsToList (builtins.listToAttrs exampleSingletonList) == exampleSingletonList;
        testDuplicatePruningBehaviour = attrsToList (
          builtins.listToAttrs [
            {
              name = "a";
              value = 2;
            }
            {
              name = "a";
              value = 1;
            }
          ]
        );
      };
      expected = {
        isReverseToAttrsToList = true;
        isReverseToListToAttrs = true;
        testDuplicatePruningBehaviour = [
          {
            name = "a";
            value = 2;
          }
        ];
      };
    };

  testAttrsToListsCanDealWithFunctions = testingEval (attrsToList {
    someFunc = a: a + 1;
  });

  # FIXED-POINTS

  testFix = {
    expr = fix (x: {
      a = if x ? a then "a" else "b";
    });
    expected = {
      a = "a";
    };
  };

  testToExtension = {
    expr = [
      (fix (final: {
        a = 0;
        c = final.a;
      }))
      (fix (
        extends
          (toExtension {
            a = 1;
            b = 2;
          })
          (final: {
            a = 0;
            c = final.a;
          })
      ))
      (fix (
        extends
          (toExtension (prev: {
            a = 1;
            b = prev.a;
          }))
          (final: {
            a = 0;
            c = final.a;
          })
      ))
      (fix (
        extends
          (toExtension (
            final: prev: {
              a = 1;
              b = prev.a;
              c = final.a + 1;
            }
          ))
          (final: {
            a = 0;
            c = final.a;
          })
      ))
    ];
    expected = [
      {
        a = 0;
        c = 0;
      }
      {
        a = 1;
        b = 2;
        c = 1;
      }
      {
        a = 1;
        b = 0;
        c = 1;
      }
      {
        a = 1;
        b = 0;
        c = 2;
      }
    ];
  };

  # GENERATORS
  # these tests assume attributes are converted to lists
  # in alphabetical order

  testMkKeyValueDefault = {
    expr = generators.mkKeyValueDefault { } ":" "f:oo" "bar";
    expected = ''f\:oo:bar'';
  };

  testMkValueString = {
    expr =
      let
        vals = {
          int = 42;
          string = ''fo"o'';
          bool = true;
          bool2 = false;
          null = null;
          # float = 42.23; # floats are strange
        };
      in
      mapAttrs (const (generators.mkValueStringDefault { })) vals;
    expected = {
      int = "42";
      string = ''fo"o'';
      bool = "true";
      bool2 = "false";
      null = "null";
      # float = "42.23" true false [ "bar" ] ]'';
    };
  };

  testToKeyValue = {
    expr = generators.toKeyValue { } {
      key = "value";
      "other=key" = "baz";
    };
    expected = ''
      key=value
      other\=key=baz
    '';
  };

  testToINIEmpty = {
    expr = generators.toINI { } { };
    expected = "";
  };

  testToINIEmptySection = {
    expr = generators.toINI { } {
      foo = { };
      bar = { };
    };
    expected = ''
      [bar]

      [foo]
    '';
  };

  testToINIDuplicateKeys = {
    expr = generators.toINI { listsAsDuplicateKeys = true; } {
      foo.bar = true;
      baz.qux = [
        1
        false
      ];
    };
    expected = ''
      [baz]
      qux=1
      qux=false

      [foo]
      bar=true
    '';
  };

  testToINIDefaultEscapes = {
    expr = generators.toINI { } {
      "no [ and ] allowed unescaped" = {
        "and also no = in keys" = 42;
      };
    };
    expected = ''
      [no \[ and \] allowed unescaped]
      and also no \= in keys=42
    '';
  };

  testToINIDefaultFull = {
    expr = generators.toINI { } {
      "section 1" = {
        attribute1 = 5;
        x = "Me-se JarJar Binx";
        # booleans are converted verbatim by default
        boolean = false;
      };
      "foo[]" = {
        "he\\h=he" = "this is okay";
      };
    };
    expected = ''
      [foo\[\]]
      he\h\=he=this is okay

      [section 1]
      attribute1=5
      boolean=false
      x=Me-se JarJar Binx
    '';
  };

  testToINIWithGlobalSectionEmpty = {
    expr = generators.toINIWithGlobalSection { } {
      globalSection = {
      };
      sections = {
      };
    };
    expected = '''';
  };

  testToINIWithGlobalSectionGlobalEmptyIsTheSameAsToINI =
    let
      sections = {
        "section 1" = {
          attribute1 = 5;
          x = "Me-se JarJar Binx";
        };
        "foo" = {
          "he\\h=he" = "this is okay";
        };
      };
    in
    {
      expr = generators.toINIWithGlobalSection { } {
        globalSection = { };
        sections = sections;
      };
      expected = generators.toINI { } sections;
    };

  testToINIWithGlobalSectionFull = {
    expr = generators.toINIWithGlobalSection { } {
      globalSection = {
        foo = "bar";
        test = false;
      };
      sections = {
        "section 1" = {
          attribute1 = 5;
          x = "Me-se JarJar Binx";
        };
        "foo" = {
          "he\\h=he" = "this is okay";
        };
      };
    };
    expected = ''
      foo=bar
      test=false

      [foo]
      he\h\=he=this is okay

      [section 1]
      attribute1=5
      x=Me-se JarJar Binx
    '';
  };

  testToGitINI = {
    expr = generators.toGitINI {
      user = {
        email = "user@example.org";
        name = "John Doe";
        signingKey = "00112233445566778899AABBCCDDEEFF";
      };
      gpg.program = "path-to-gpg";
      tag.gpgSign = true;
      include.path = "~/path/to/config.inc";
      includeIf."gitdif:~/src/dir".path = "~/path/to/conditional.inc";
      extra = {
        boolean = true;
        integer = 38;
        name = "value";
        subsection.value = "test";
      };
    };
    expected = ''
      [extra]
      ${"\t"}boolean = true
      ${"\t"}integer = 38
      ${"\t"}name = "value"

      [extra "subsection"]
      ${"\t"}value = "test"

      [gpg]
      ${"\t"}program = "path-to-gpg"

      [include]
      ${"\t"}path = "~/path/to/config.inc"

      [includeIf "gitdif:~/src/dir"]
      ${"\t"}path = "~/path/to/conditional.inc"

      [tag]
      ${"\t"}gpgSign = true

      [user]
      ${"\t"}email = "user@example.org"
      ${"\t"}name = "John Doe"
      ${"\t"}signingKey = "00112233445566778899AABBCCDDEEFF"
    '';
  };

  # right now only invocation check
  testToJSONSimple =
    let
      val = {
        foobar = [
          "baz"
          1
          2
          3
        ];
      };
    in
    {
      expr = generators.toJSON { } val;
      # trivial implementation
      expected = builtins.toJSON val;
    };

  # right now only invocation check
  testToYAMLSimple =
    let
      val = {
        list = [
          { one = 1; }
          { two = 2; }
        ];
        all = 42;
      };
    in
    {
      expr = generators.toYAML { } val;
      # trivial implementation
      expected = builtins.toJSON val;
    };

  testToPretty =
    let
      deriv = derivation {
        name = "test";
        builder = "/bin/sh";
        system = "aarch64-linux";
      };
    in
    {
      expr = mapAttrs (const (generators.toPretty { multiline = false; })) rec {
        int = 42;
        float = 0.1337;
        bool = true;
        emptystring = "";
        string = "fn\${o}\"r\\d";
        newlinestring = "\n";
        path = /. + "/foo";
        null_ = null;
        function = x: x;
        functionArgs =
          {
            arg ? 4,
            foo,
          }:
          arg;
        list = [
          3
          4
          function
          [ false ]
        ];
        emptylist = [ ];
        attrs = {
          foo = null;
          "foo b/ar" = "baz";
        };
        emptyattrs = { };
        drv = deriv;
      };
      expected = rec {
        int = "42";
        float = "0.1337";
        bool = "true";
        emptystring = ''""'';
        string = ''"fn\''${o}\"r\\d"'';
        newlinestring = "\"\\n\"";
        path = "/foo";
        null_ = "null";
        function = "<function>";
        functionArgs = "<function, args: {arg?, foo}>";
        list = "[ 3 4 ${function} [ false ] ]";
        emptylist = "[ ]";
        attrs = "{ foo = null; \"foo b/ar\" = \"baz\"; }";
        emptyattrs = "{ }";
        drv = "<derivation ${deriv.name}>";
      };
    };

  testToPrettyLimit =
    let
      a.b = 1;
      a.c = a;
    in
    {
      expr = generators.toPretty { } (
        generators.withRecursion {
          throwOnDepthLimit = false;
          depthLimit = 2;
        } a
      );
      expected = "{\n  b = 1;\n  c = {\n    b = \"<unevaluated>\";\n    c = {\n      b = \"<unevaluated>\";\n      c = \"<unevaluated>\";\n    };\n  };\n}";
    };

  testToPrettyLimitThrow =
    let
      a.b = 1;
      a.c = a;
    in
    {
      expr =
        (builtins.tryEval (generators.toPretty { } (generators.withRecursion { depthLimit = 2; } a)))
        .success;
      expected = false;
    };

  testWithRecursionDealsWithFunctors =
    let
      functor = {
        __functor = self: { a, b }: null;
      };
      a = {
        value = "1234";
        b = functor;
        c.d = functor;
      };
    in
    {
      expr = generators.toPretty { } (
        generators.withRecursion {
          depthLimit = 1;
          throwOnDepthLimit = false;
        } a
      );
      expected = "{\n  b = <function, args: {a, b}>;\n  c = {\n    d = \"<unevaluated>\";\n  };\n  value = \"<unevaluated>\";\n}";
    };

  testToPrettyMultiline = {
    expr = mapAttrs (const (generators.toPretty { })) {
      list = [
        3
        4
        [ false ]
      ];
      attrs = {
        foo = null;
        bar.foo = "baz";
      };
      newlinestring = "\n";
      multilinestring = ''
        hello
        ''${there}
        te'''st
      '';
      multilinestring' = ''
        hello
        there
        test'';
    };
    expected = {
      list = ''
        [
          3
          4
          [
            false
          ]
        ]'';
      attrs = ''
        {
          bar = {
            foo = "baz";
          };
          foo = null;
        }'';
      newlinestring = "''\n  \n''";
      multilinestring = ''
        '''
          hello
          '''''${there}
          te''''st
        ''''';
      multilinestring' = ''
        '''
          hello
          there
          test''''';

    };
  };

  testToPrettyAllowPrettyValues = {
    expr = generators.toPretty { allowPrettyValues = true; } {
      __pretty = v: "«" + v + "»";
      val = "foo";
    };
    expected = "«foo»";
  };

  testToPlistUnescaped = {
    expr = mapAttrs (const (generators.toPlist { })) {
      value = {
        nested.values = {
          int = 42;
          float = 0.1337;
          bool = true;
          emptystring = "";
          string = "fn\${o}\"r\\d";
          newlinestring = "\n";
          path = /. + "/foo";
          null_ = null;
          list = [
            3
            4
            "test"
          ];
          emptylist = [ ];
          attrs = {
            foo = null;
            "foo b/ar" = "baz";
          };
          emptyattrs = { };
          "keys are not <escaped>" = "and < neither are string values";
        };
      };
    };
    expected = {
      value = builtins.readFile ./test-to-plist-unescaped-expected.plist;
    };
  };

  testToPlistEscaped = {
    expr = mapAttrs (const (generators.toPlist { escape = true; })) {
      value = {
        nested.values = {
          int = 42;
          float = 0.1337;
          bool = true;
          emptystring = "";
          string = "fn\${o}\"r\\d";
          newlinestring = "\n";
          path = /. + "/foo";
          null_ = null;
          list = [
            3
            4
            "test"
          ];
          emptylist = [ ];
          attrs = {
            foo = null;
            "foo b/ar" = "baz";
          };
          emptyattrs = { };
          "keys are <escaped>" = "and < so are string values";
        };
      };
    };
    expected = {
      value = builtins.readFile ./test-to-plist-escaped-expected.plist;
    };
  };

  testToLuaEmptyAttrSet = {
    expr = generators.toLua { } { };
    expected = ''{}'';
  };

  testToLuaEmptyList = {
    expr = generators.toLua { } [ ];
    expected = ''{}'';
  };

  testToLuaListOfVariousTypes = {
    expr = generators.toLua { } [
      null
      43
      3.14159
      true
    ];
    expected = ''
      {
        nil,
        43,
        3.14159,
        true
      }'';
  };

  testToLuaString = {
    expr = generators.toLua { } ''double-quote (") and single quotes (')'';
    expected = ''"double-quote (\") and single quotes (')"'';
  };

  testToLuaAttrsetWithLuaInline = {
    expr = generators.toLua { } { x = generators.mkLuaInline ''"abc" .. "def"''; };
    expected = ''
      {
        ["x"] = ("abc" .. "def")
      }'';
  };

  testToLuaAttrsetWithSpaceInKey = {
    expr = generators.toLua { } { "some space and double-quote (\")" = 42; };
    expected = ''
      {
        ["some space and double-quote (\")"] = 42
      }'';
  };

  testToLuaWithoutMultiline = {
    expr = generators.toLua { multiline = false; } [
      41
      43
    ];
    expected = ''{ 41, 43 }'';
  };

  testToLuaEmptyBindings = {
    expr = generators.toLua { asBindings = true; } { };
    expected = "";
  };

  testToLuaBindings = {
    expr = generators.toLua { asBindings = true; } {
      x1 = 41;
      _y = {
        a = 43;
      };
    };
    expected = ''
      _y = {
        ["a"] = 43
      }
      x1 = 41
    '';
  };

  testToLuaPartialTableBindings = {
    expr = generators.toLua { asBindings = true; } { "x.y" = 42; };
    expected = ''
      x.y = 42
    '';
  };

  testToLuaIndentedBindings = {
    expr =
      generators.toLua
        {
          asBindings = true;
          indent = "  ";
        }
        {
          x = {
            y = 42;
          };
        };
    expected = "  x = {\n    [\"y\"] = 42\n  }\n";
  };

  testToLuaBindingsWithSpace = testingThrow (
    generators.toLua { asBindings = true; } { "with space" = 42; }
  );

  testToLuaBindingsWithLeadingDigit = testingThrow (
    generators.toLua { asBindings = true; } { "11eleven" = 42; }
  );

  testToLuaBasicExample = {
    expr = generators.toLua { } {
      cmd = [
        "typescript-language-server"
        "--stdio"
      ];
      settings.workspace.library = generators.mkLuaInline ''vim.api.nvim_get_runtime_file("", true)'';
    };
    expected = ''
      {
        ["cmd"] = {
          "typescript-language-server",
          "--stdio"
        },
        ["settings"] = {
          ["workspace"] = {
            ["library"] = (vim.api.nvim_get_runtime_file("", true))
          }
        }
      }'';
  };

  # CLI

  testToGNUCommandLine = {
    expr = cli.toGNUCommandLine { } {
      data = builtins.toJSON { id = 0; };
      X = "PUT";
      retry = 3;
      retry-delay = null;
      url = [
        "https://example.com/foo"
        "https://example.com/bar"
      ];
      silent = false;
      verbose = true;
    };

    expected = [
      "-X"
      "PUT"
      "--data"
      "{\"id\":0}"
      "--retry"
      "3"
      "--url"
      "https://example.com/foo"
      "--url"
      "https://example.com/bar"
      "--verbose"
    ];
  };

  testToGNUCommandLineSeparator = {
    expr = cli.toGNUCommandLine { optionValueSeparator = "="; } {
      data = builtins.toJSON { id = 0; };
      X = "PUT";
      retry = 3;
      retry-delay = null;
      url = [
        "https://example.com/foo"
        "https://example.com/bar"
      ];
      silent = false;
      verbose = true;
    };

    expected = [
      "-X=PUT"
      "--data={\"id\":0}"
      "--retry=3"
      "--url=https://example.com/foo"
      "--url=https://example.com/bar"
      "--verbose"
    ];
  };

  testToGNUCommandLineShell = {
    expr = cli.toGNUCommandLineShell { } {
      data = builtins.toJSON { id = 0; };
      X = "PUT";
      retry = 3;
      retry-delay = null;
      url = [
        "https://example.com/foo"
        "https://example.com/bar"
      ];
      silent = false;
      verbose = true;
    };

    expected = "-X PUT --data '{\"id\":0}' --retry 3 --url https://example.com/foo --url https://example.com/bar --verbose";
  };

  testSanitizeDerivationNameLeadingDots = testSanitizeDerivationName {
    name = "..foo";
    expected = "foo";
  };

  testSanitizeDerivationNameUnicode = testSanitizeDerivationName {
    name = "fö";
    expected = "f-";
  };

  testSanitizeDerivationNameAscii = testSanitizeDerivationName {
    name = " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~";
    expected = "-+--.-0123456789-=-?-ABCDEFGHIJKLMNOPQRSTUVWXYZ-_-abcdefghijklmnopqrstuvwxyz-";
  };

  testSanitizeDerivationNameTooLong = testSanitizeDerivationName {
    name = "This string is loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong";
    expected = "loooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooong";
  };

  testSanitizeDerivationNameTooLongWithInvalid = testSanitizeDerivationName {
    name = "Hello there aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa &&&&&&&&";
    expected = "there-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa-";
  };

  testSanitizeDerivationNameEmpty = testSanitizeDerivationName {
    name = "";
    expected = "unknown";
  };

  # https://github.com/NixOS/nixpkgs/issues/396849
  "test: submodule definitions aren't unchecked when evaluating submodule documentation" = {
    expr =
      let
        module =
          { lib, ... }:
          {
            options.foo = lib.mkOption { type = lib.types.submodule submodule; };
          };

        submodule = {
          options.bar = lib.mkOption { type = lib.types.int; };
          config.submoduleWrong = throw "yikes";
        };

        options = (evalModules { modules = [ module ]; }).options;

        renderableOpts = filter (o: !o.internal) (optionAttrSetToDocList options);
        # Evaluate the whole docs
      in
      builtins.deepSeq renderableOpts
        # Return the locations
        (map (o: o.loc) renderableOpts);
    expected = [
      [
        "_module"
        "args"
      ]
      [ "foo" ]
      [
        "foo"
        "bar"
      ]
    ];
  };

  testFreeformOptions = {
    expr =
      let
        submodule =
          { lib, ... }:
          {
            freeformType = lib.types.attrsOf (
              lib.types.submodule {
                options.bar = lib.mkOption { };
              }
            );
            options.bar = lib.mkOption { };
          };

        module =
          { lib, ... }:
          {
            options.foo = lib.mkOption {
              type = lib.types.submodule submodule;
            };
          };

        options =
          (evalModules {
            modules = [ module ];
          }).options;

        locs = filter (o: !o.internal) (optionAttrSetToDocList options);
      in
      map (o: o.loc) locs;
    expected = [
      [
        "_module"
        "args"
      ]
      [ "foo" ]
      [
        "foo"
        "<name>"
        "bar"
      ]
      [
        "foo"
        "bar"
      ]
    ];
  };

  testAttrsWithName = {
    expr =
      let
        eval = evalModules {
          modules = [
            {
              options = {
                foo = lib.mkOption {
                  type = lib.types.attrsWith {
                    placeholder = "MyCustomPlaceholder";
                    elemType = lib.types.submodule {
                      options.bar = lib.mkOption {
                        type = lib.types.int;
                        default = 42;
                      };
                    };
                  };
                };
              };
            }
          ];
        };
        opt = eval.options.foo;
      in
      (opt.type.getSubOptions opt.loc).bar.loc;
    expected = [
      "foo"
      "<MyCustomPlaceholder>"
      "bar"
    ];
  };

  testShowOptionWithPlaceholder = {
    # <name>, *, should not be escaped. It is used as a placeholder by convention.
    # Other symbols should be escaped. `{}`
    expr = lib.showOption [
      "<name>"
      "<myName>"
      "*"
      "{foo}"
    ];
    expected = "<name>.<myName>.*.\"{foo}\"";
  };

  testCartesianProductOfEmptySet = {
    expr = cartesianProduct { };
    expected = [ { } ];
  };

  testCartesianProductOfOneSet = {
    expr = cartesianProduct {
      a = [
        1
        2
        3
      ];
    };
    expected = [
      { a = 1; }
      { a = 2; }
      { a = 3; }
    ];
  };

  testCartesianProductOfTwoSets = {
    expr = cartesianProduct {
      a = [ 1 ];
      b = [
        10
        20
      ];
    };
    expected = [
      {
        a = 1;
        b = 10;
      }
      {
        a = 1;
        b = 20;
      }
    ];
  };

  testCartesianProductOfTwoSetsWithOneEmpty = {
    expr = cartesianProduct {
      a = [ ];
      b = [
        10
        20
      ];
    };
    expected = [ ];
  };

  testCartesianProductOfThreeSets = {
    expr = cartesianProduct {
      a = [
        1
        2
        3
      ];
      b = [
        10
        20
        30
      ];
      c = [
        100
        200
        300
      ];
    };
    expected = [
      {
        a = 1;
        b = 10;
        c = 100;
      }
      {
        a = 1;
        b = 10;
        c = 200;
      }
      {
        a = 1;
        b = 10;
        c = 300;
      }

      {
        a = 1;
        b = 20;
        c = 100;
      }
      {
        a = 1;
        b = 20;
        c = 200;
      }
      {
        a = 1;
        b = 20;
        c = 300;
      }

      {
        a = 1;
        b = 30;
        c = 100;
      }
      {
        a = 1;
        b = 30;
        c = 200;
      }
      {
        a = 1;
        b = 30;
        c = 300;
      }

      {
        a = 2;
        b = 10;
        c = 100;
      }
      {
        a = 2;
        b = 10;
        c = 200;
      }
      {
        a = 2;
        b = 10;
        c = 300;
      }

      {
        a = 2;
        b = 20;
        c = 100;
      }
      {
        a = 2;
        b = 20;
        c = 200;
      }
      {
        a = 2;
        b = 20;
        c = 300;
      }

      {
        a = 2;
        b = 30;
        c = 100;
      }
      {
        a = 2;
        b = 30;
        c = 200;
      }
      {
        a = 2;
        b = 30;
        c = 300;
      }

      {
        a = 3;
        b = 10;
        c = 100;
      }
      {
        a = 3;
        b = 10;
        c = 200;
      }
      {
        a = 3;
        b = 10;
        c = 300;
      }

      {
        a = 3;
        b = 20;
        c = 100;
      }
      {
        a = 3;
        b = 20;
        c = 200;
      }
      {
        a = 3;
        b = 20;
        c = 300;
      }

      {
        a = 3;
        b = 30;
        c = 100;
      }
      {
        a = 3;
        b = 30;
        c = 200;
      }
      {
        a = 3;
        b = 30;
        c = 300;
      }
    ];
  };

  testMapCartesianProductOfOneSet = {
    expr = mapCartesianProduct ({ a }: a * 2) {
      a = [
        1
        2
        3
      ];
    };
    expected = [
      2
      4
      6
    ];
  };

  testMapCartesianProductOfTwoSets = {
    expr = mapCartesianProduct ({ a, b }: a + b) {
      a = [ 1 ];
      b = [
        10
        20
      ];
    };
    expected = [
      11
      21
    ];
  };

  testMapCartesianProcutOfTwoSetsWithOneEmpty = {
    expr = mapCartesianProduct (x: x.a + x.b) {
      a = [ ];
      b = [
        10
        20
      ];
    };
    expected = [ ];
  };

  testMapCartesianProductOfThreeSets = {
    expr =
      mapCartesianProduct
        (
          {
            a,
            b,
            c,
          }:
          a + b + c
        )
        {
          a = [
            1
            2
            3
          ];
          b = [
            10
            20
            30
          ];
          c = [
            100
            200
            300
          ];
        };
    expected = [
      111
      211
      311
      121
      221
      321
      131
      231
      331
      112
      212
      312
      122
      222
      322
      132
      232
      332
      113
      213
      313
      123
      223
      323
      133
      233
      333
    ];
  };

  # The example from the showAttrPath documentation
  testShowAttrPathExample = {
    expr = showAttrPath [
      "foo"
      "10"
      "bar"
    ];
    expected = "foo.\"10\".bar";
  };

  testShowAttrPathEmpty = {
    expr = showAttrPath [ ];
    expected = "<root attribute path>";
  };

  testShowAttrPathVarious = {
    expr = showAttrPath [
      "."
      "foo"
      "2"
      "a2-b"
      "_bc'de"
    ];
    expected = ''".".foo."2".a2-b._bc'de'';
  };

  testGroupBy = {
    expr = groupBy (n: toString (mod n 5)) (range 0 16);
    expected = {
      "0" = [
        0
        5
        10
        15
      ];
      "1" = [
        1
        6
        11
        16
      ];
      "2" = [
        2
        7
        12
      ];
      "3" = [
        3
        8
        13
      ];
      "4" = [
        4
        9
        14
      ];
    };
  };

  testGroupBy' = {
    expr = groupBy' builtins.add 0 (x: boolToString (x > 2)) [
      5
      1
      2
      3
      4
    ];
    expected = {
      false = 3;
      true = 12;
    };
  };

  # The example from the updateManyAttrsByPath documentation
  testUpdateManyAttrsByPathExample = {
    expr = updateManyAttrsByPath [
      {
        path = [
          "a"
          "b"
        ];
        update = old: { d = old.c; };
      }
      {
        path = [
          "a"
          "b"
          "c"
        ];
        update = old: old + 1;
      }
      {
        path = [
          "x"
          "y"
        ];
        update = old: "xy";
      }
    ] { a.b.c = 0; };
    expected = {
      a = {
        b = {
          d = 1;
        };
      };
      x = {
        y = "xy";
      };
    };
  };

  # If there are no updates, the value is passed through
  testUpdateManyAttrsByPathNone = {
    expr = updateManyAttrsByPath [ ] "something";
    expected = "something";
  };

  # A single update to the root path is just like applying the function directly
  testUpdateManyAttrsByPathSingleIncrement = {
    expr = updateManyAttrsByPath [
      {
        path = [ ];
        update = old: old + 1;
      }
    ] 0;
    expected = 1;
  };

  # Multiple updates can be applied are done in order
  testUpdateManyAttrsByPathMultipleIncrements = {
    expr = updateManyAttrsByPath [
      {
        path = [ ];
        update = old: old + "a";
      }
      {
        path = [ ];
        update = old: old + "b";
      }
      {
        path = [ ];
        update = old: old + "c";
      }
    ] "";
    expected = "abc";
  };

  # If an update doesn't use the value, all previous updates are not evaluated
  testUpdateManyAttrsByPathLazy = {
    expr = updateManyAttrsByPath [
      {
        path = [ ];
        update = old: old + throw "nope";
      }
      {
        path = [ ];
        update = old: "untainted";
      }
    ] (throw "start");
    expected = "untainted";
  };

  # Deeply nested attributes can be updated without affecting others
  testUpdateManyAttrsByPathDeep = {
    expr =
      updateManyAttrsByPath
        [
          {
            path = [
              "a"
              "b"
              "c"
            ];
            update = old: old + 1;
          }
        ]
        {
          a.b.c = 0;

          a.b.z = 0;
          a.y.z = 0;
          x.y.z = 0;
        };
    expected = {
      a.b.c = 1;

      a.b.z = 0;
      a.y.z = 0;
      x.y.z = 0;
    };
  };

  # Nested attributes are updated first
  testUpdateManyAttrsByPathNestedBeforehand = {
    expr =
      updateManyAttrsByPath
        [
          {
            path = [ "a" ];
            update = old: old // { x = old.b; };
          }
          {
            path = [
              "a"
              "b"
            ];
            update = old: old + 1;
          }
        ]
        {
          a.b = 0;
        };
    expected = {
      a.b = 1;
      a.x = 1;
    };
  };

  ## Levenshtein distance functions and co.
  testCommonPrefixLengthEmpty = {
    expr = strings.commonPrefixLength "" "hello";
    expected = 0;
  };

  testCommonPrefixLengthSame = {
    expr = strings.commonPrefixLength "hello" "hello";
    expected = 5;
  };

  testCommonPrefixLengthDiffering = {
    expr = strings.commonPrefixLength "hello" "hey";
    expected = 2;
  };

  testCommonSuffixLengthEmpty = {
    expr = strings.commonSuffixLength "" "hello";
    expected = 0;
  };

  testCommonSuffixLengthSame = {
    expr = strings.commonSuffixLength "hello" "hello";
    expected = 5;
  };

  testCommonSuffixLengthDiffering = {
    expr = strings.commonSuffixLength "test" "rest";
    expected = 3;
  };

  testLevenshteinEmpty = {
    expr = strings.levenshtein "" "";
    expected = 0;
  };

  testLevenshteinOnlyAdd = {
    expr = strings.levenshtein "" "hello there";
    expected = 11;
  };

  testLevenshteinOnlyRemove = {
    expr = strings.levenshtein "hello there" "";
    expected = 11;
  };

  testLevenshteinOnlyTransform = {
    expr = strings.levenshtein "abcdef" "ghijkl";
    expected = 6;
  };

  testLevenshteinMixed = {
    expr = strings.levenshtein "kitchen" "sitting";
    expected = 5;
  };

  testLevenshteinAtMostZeroFalse = {
    expr = strings.levenshteinAtMost 0 "foo" "boo";
    expected = false;
  };

  testLevenshteinAtMostZeroTrue = {
    expr = strings.levenshteinAtMost 0 "foo" "foo";
    expected = true;
  };

  testLevenshteinAtMostOneFalse = {
    expr = strings.levenshteinAtMost 1 "car" "ct";
    expected = false;
  };

  testLevenshteinAtMostOneTrue = {
    expr = strings.levenshteinAtMost 1 "car" "cr";
    expected = true;
  };

  # We test levenshteinAtMost 2 particularly well because it uses a complicated
  # implementation
  testLevenshteinAtMostTwoIsEmpty = {
    expr = strings.levenshteinAtMost 2 "" "";
    expected = true;
  };

  testLevenshteinAtMostTwoIsZero = {
    expr = strings.levenshteinAtMost 2 "abcdef" "abcdef";
    expected = true;
  };

  testLevenshteinAtMostTwoIsOne = {
    expr = strings.levenshteinAtMost 2 "abcdef" "abddef";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff0False = {
    expr = strings.levenshteinAtMost 2 "abcdef" "aczyef";
    expected = false;
  };

  testLevenshteinAtMostTwoDiff0Outer = {
    expr = strings.levenshteinAtMost 2 "abcdef" "zbcdez";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff0DelLeft = {
    expr = strings.levenshteinAtMost 2 "abcdef" "bcdefz";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff0DelRight = {
    expr = strings.levenshteinAtMost 2 "abcdef" "zabcde";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff1False = {
    expr = strings.levenshteinAtMost 2 "abcdef" "bddez";
    expected = false;
  };

  testLevenshteinAtMostTwoDiff1DelLeft = {
    expr = strings.levenshteinAtMost 2 "abcdef" "bcdez";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff1DelRight = {
    expr = strings.levenshteinAtMost 2 "abcdef" "zbcde";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff2False = {
    expr = strings.levenshteinAtMost 2 "hello" "hxo";
    expected = false;
  };

  testLevenshteinAtMostTwoDiff2True = {
    expr = strings.levenshteinAtMost 2 "hello" "heo";
    expected = true;
  };

  testLevenshteinAtMostTwoDiff3 = {
    expr = strings.levenshteinAtMost 2 "hello" "ho";
    expected = false;
  };

  testLevenshteinAtMostThreeFalse = {
    expr = strings.levenshteinAtMost 3 "hello" "Holla!";
    expected = false;
  };

  testLevenshteinAtMostThreeTrue = {
    expr = strings.levenshteinAtMost 3 "hello" "Holla";
    expected = true;
  };

  # DERIVATIONS

  testLazyDerivationIsLazyInDerivationForAttrNames = {
    expr = attrNames (lazyDerivation {
      derivation = throw "not lazy enough";
    });
    # It's ok to add attribute names here when lazyDerivation is improved
    # in accordance with its inline comments.
    expected = [
      "drvPath"
      "meta"
      "name"
      "out"
      "outPath"
      "outputName"
      "outputs"
      "system"
      "type"
    ];
  };

  testLazyDerivationIsLazyInDerivationForPassthruAttr = {
    expr =
      (lazyDerivation {
        derivation = throw "not lazy enough";
        passthru.tests = "whatever is in tests";
      }).tests;
    expected = "whatever is in tests";
  };

  testLazyDerivationIsLazyInDerivationForPassthruAttr2 = {
    # passthru.tests is not a special case. It works for any attr.
    expr =
      (lazyDerivation {
        derivation = throw "not lazy enough";
        passthru.foo = "whatever is in foo";
      }).foo;
    expected = "whatever is in foo";
  };

  testLazyDerivationIsLazyInDerivationForMeta = {
    expr =
      (lazyDerivation {
        derivation = throw "not lazy enough";
        meta = "whatever is in meta";
      }).meta;
    expected = "whatever is in meta";
  };

  testLazyDerivationReturnsDerivationAttrs =
    let
      derivation = {
        type = "derivation";
        outputs = [ "out" ];
        out = "test out";
        outPath = "test outPath";
        outputName = "out";
        drvPath = "test drvPath";
        name = "test name";
        system = "test system";
        meta = "test meta";
      };
    in
    {
      expr = lazyDerivation { inherit derivation; };
      expected = derivation;
    };

  testOptionalDrvAttr =
    let
      mkDerivation =
        args:
        derivation (
          args
          // {
            builder = "builder";
            system = "system";
            __ignoreNulls = true;
          }
        );
    in
    {
      expr =
        (mkDerivation {
          name = "foo";
          x = optionalDrvAttr true 1;
          y = optionalDrvAttr false 1;
        }).drvPath;
      expected =
        (mkDerivation {
          name = "foo";
          x = 1;
        }).drvPath;
    };

  testLazyDerivationMultiOutputReturnsDerivationAttrs =
    let
      derivation = {
        type = "derivation";
        outputs = [
          "out"
          "dev"
        ];
        dev = "test dev";
        out = "test out";
        outPath = "test outPath";
        outputName = "out";
        drvPath = "test drvPath";
        name = "test name";
        system = "test system";
        meta.position = "/hi:23";
      };
    in
    {
      expr = lazyDerivation {
        inherit derivation;
        outputs = [
          "out"
          "dev"
        ];
        passthru.meta.position = "/hi:23";
      };
      expected = derivation;
    };

  testTypeDescriptionInt = {
    expr = (with types; int).description;
    expected = "signed integer";
  };
  testTypeDescriptionIntsPositive = {
    expr = (with types; ints.positive).description;
    expected = "positive integer, meaning >0";
  };
  testTypeDescriptionIntsPositiveOrEnumAuto = {
    expr = (with types; either ints.positive (enum [ "auto" ])).description;
    expected = ''positive integer, meaning >0, or value "auto" (singular enum)'';
  };
  testTypeDescriptionListOfPositive = {
    expr = (with types; listOf ints.positive).description;
    expected = "list of (positive integer, meaning >0)";
  };
  testTypeDescriptionListOfInt = {
    expr = (with types; listOf int).description;
    expected = "list of signed integer";
  };
  testTypeDescriptionListOfListOfInt = {
    expr = (with types; listOf (listOf int)).description;
    expected = "list of list of signed integer";
  };
  testTypeDescriptionListOfEitherStrOrBool = {
    expr = (with types; listOf (either str bool)).description;
    expected = "list of (string or boolean)";
  };
  testTypeDescriptionEitherListOfStrOrBool = {
    expr = (with types; either (listOf bool) str).description;
    expected = "(list of boolean) or string";
  };
  testTypeDescriptionEitherStrOrListOfBool = {
    expr = (with types; either str (listOf bool)).description;
    expected = "string or list of boolean";
  };
  testTypeDescriptionOneOfListOfStrOrBool = {
    expr =
      (
        with types;
        oneOf [
          (listOf bool)
          str
        ]
      ).description;
    expected = "(list of boolean) or string";
  };
  testTypeDescriptionOneOfListOfStrOrBoolOrNumber = {
    expr =
      (
        with types;
        oneOf [
          (listOf bool)
          str
          number
        ]
      ).description;
    expected = "(list of boolean) or string or signed integer or floating point number";
  };
  testTypeDescriptionEitherListOfBoolOrEitherStringOrNumber = {
    expr = (with types; either (listOf bool) (either str number)).description;
    expected = "(list of boolean) or string or signed integer or floating point number";
  };
  testTypeDescriptionEitherEitherListOfBoolOrStringOrNumber = {
    expr = (with types; either (either (listOf bool) str) number).description;
    expected = "(list of boolean) or string or signed integer or floating point number";
  };
  testTypeDescriptionEitherNullOrBoolOrString = {
    expr = (with types; either (nullOr bool) str).description;
    expected = "null or boolean or string";
  };
  testTypeDescriptionEitherListOfEitherBoolOrStrOrInt = {
    expr = (with types; either (listOf (either bool str)) int).description;
    expected = "(list of (boolean or string)) or signed integer";
  };
  testTypeDescriptionEitherIntOrListOrEitherBoolOrStr = {
    expr = (with types; either int (listOf (either bool str))).description;
    expected = "signed integer or list of (boolean or string)";
  };
  testTypeFunctionToPropagateFunctionArgs = {
    expr = lib.functionArgs (
      (types.functionTo types.null).merge
        [ ]
        [
          {
            value =
              {
                a,
                b ? false,
                ...
              }:
              null;
          }
          {
            value =
              {
                b,
                c ? false,
                ...
              }:
              null;
          }
        ]
    );
    expected = {
      a = false;
      b = false;
      c = true;
    };
  };

  # Meta
  testGetExe'Output = {
    expr = getExe' {
      type = "derivation";
      out = "somelonghash";
      bin = "somelonghash";
    } "executable";
    expected = "somelonghash/bin/executable";
  };

  testGetExeOutput = {
    expr = getExe {
      type = "derivation";
      out = "somelonghash";
      bin = "somelonghash";
      meta.mainProgram = "mainProgram";
    };
    expected = "somelonghash/bin/mainProgram";
  };

  testGetExe'FailureFirstArg = testingThrow (getExe' "not a derivation" "executable");

  testGetExe'FailureSecondArg = testingThrow (getExe' { type = "derivation"; } "dir/executable");

  testGetLicenseFromSpdxIdOrExamples = {
    expr = [
      (getLicenseFromSpdxIdOr "MIT" null)
      (getLicenseFromSpdxIdOr "mIt" null)
      (getLicenseFromSpdxIdOr "MY LICENSE" lib.licenses.free)
      (getLicenseFromSpdxIdOr "MY LICENSE" null)
    ];
    expected = [
      lib.licenses.mit
      lib.licenses.mit
      lib.licenses.free
      null
    ];
  };

  testGetLicenseFromSpdxIdOrThrow = testingThrow (
    getLicenseFromSpdxIdOr "MY LICENSE" (throw "No SPDX ID matches MY LICENSE")
  );

  testPlatformMatch = {
    expr = meta.platformMatch { system = "x86_64-linux"; } "x86_64-linux";
    expected = true;
  };

  testPlatformMatchAttrs = {
    expr = meta.platformMatch (systems.elaborate "x86_64-linux") (systems.elaborate "x86_64-linux")
    .parsed;
    expected = true;
  };

  testPlatformMatchNoMatch = {
    expr = meta.platformMatch { system = "x86_64-darwin"; } "x86_64-linux";
    expected = false;
  };

  testPlatformMatchMissingSystem = {
    expr = meta.platformMatch { } "x86_64-linux";
    expected = false;
  };

  testPackagesFromDirectoryRecursive = {
    expr = packagesFromDirectoryRecursive {
      callPackage = path: overrides: import path overrides;
      directory = ./packages-from-directory/plain;
    };
    expected = {
      a = "a";
      b = "b";
      # Note: Other files/directories in `./test-data/c/` are ignored and can be
      # used by `package.nix`.
      c = "c";
      my-namespace = {
        d = "d";
        e = "e";
        f = "f";
        my-sub-namespace = {
          g = "g";
          h = "h";
        };
      };
    };
  };

  # Make sure that passing a string for the `directory` works.
  #
  # See: https://github.com/NixOS/nixpkgs/pull/361424#discussion_r1934813568
  # See: https://github.com/NixOS/nix/issues/9428
  testPackagesFromDirectoryRecursiveStringDirectory = {
    expr = packagesFromDirectoryRecursive {
      callPackage = path: overrides: import path overrides;
      # Do NOT remove the `builtins.toString` call here!!!
      directory = builtins.toString ./packages-from-directory/plain;
    };
    expected = {
      a = "a";
      b = "b";
      # Note: Other files/directories in `./test-data/c/` are ignored and can be
      # used by `package.nix`.
      c = "c";
      my-namespace = {
        d = "d";
        e = "e";
        f = "f";
        my-sub-namespace = {
          g = "g";
          h = "h";
        };
      };
    };
  };

  # Check that `packagesFromDirectoryRecursive` can process a directory with a
  # top-level `package.nix` file into a single package.
  testPackagesFromDirectoryRecursiveTopLevelPackageNix = {
    expr = packagesFromDirectoryRecursive {
      callPackage = path: overrides: import path overrides;
      directory = ./packages-from-directory/plain/c;
    };
    expected = "c";
  };

  testMergeTypesSimple =
    let
      mergedType = types.mergeTypes types.str types.str;
    in
    {
      expr = mergedType.name;
      expected = "str";
    };

  testMergeTypesFail =
    let
      mergedType = types.mergeTypes types.str types.int;
    in
    {
      expr = types.isType "merge-error" mergedType;
      expected = true;
    };

  testMergeTypesEnum =
    let
      enumAB = lib.types.enum [
        "A"
        "B"
      ];
      enumXY = lib.types.enum [
        "X"
        "Y"
      ];
      merged = lib.types.mergeTypes enumAB enumXY; # -> enum [ "A" "B" "X" "Y" ]
    in
    {
      expr = {
        checkA = merged.check "A";
        checkB = merged.check "B";
        checkX = merged.check "X";
        checkY = merged.check "Y";
        checkC = merged.check "C";
      };
      expected = {
        checkA = true;
        checkB = true;
        checkX = true;
        checkY = true;
        checkC = false;
      };
    };

  # Check that `packagesFromDirectoryRecursive` can be used to create scopes
  # for sub-directories
  testPackagesFromDirectoryNestedScopes =
    let
      inherit (lib) makeScope recurseIntoAttrs;
      emptyScope = makeScope lib.callPackageWith (_: { });
    in
    {
      expr =
        lib.filterAttrsRecursive
          (
            name: value:
            !lib.elem name [
              "callPackage"
              "newScope"
              "overrideScope"
              "packages"
            ]
          )
          (packagesFromDirectoryRecursive {
            inherit (emptyScope) callPackage newScope;
            directory = ./packages-from-directory/scope;
          });
      expected = lib.recurseIntoAttrs {
        a = "a";
        b = "b";
        # Note: Other files/directories in `./test-data/c/` are ignored and can be
        # used by `package.nix`.
        c = "c";
        my-namespace = lib.recurseIntoAttrs {
          d = "d";
          e = "e";
          f = "f";
          my-sub-namespace = lib.recurseIntoAttrs {
            g = "g";
            h = "h";
          };
        };
      };
    };

  testFilesystemResolveDefaultNixFile1 = {
    expr = lib.filesystem.resolveDefaultNix ./foo.nix;
    expected = ./foo.nix;
  };

  testFilesystemResolveDefaultNixFile2 = {
    expr = lib.filesystem.resolveDefaultNix ./default.nix;
    expected = ./default.nix;
  };

  testFilesystemResolveDefaultNixDir1 = {
    expr = lib.filesystem.resolveDefaultNix ./.;
    expected = ./default.nix;
  };

  testFilesystemResolveDefaultNixFile1_toString = {
    expr = lib.filesystem.resolveDefaultNix (toString ./foo.nix);
    expected = toString ./foo.nix;
  };

  testFilesystemResolveDefaultNixFile2_toString = {
    expr = lib.filesystem.resolveDefaultNix (toString ./default.nix);
    expected = toString ./default.nix;
  };

  testFilesystemResolveDefaultNixDir1_toString = {
    expr = lib.filesystem.resolveDefaultNix (toString ./.);
    expected = toString ./default.nix;
  };

  testFilesystemResolveDefaultNixDir1_toString2 = {
    expr = lib.filesystem.resolveDefaultNix (toString ./.);
    expected = toString ./. + "/default.nix";
  };

  testFilesystemResolveDefaultNixNonExistent = {
    expr = lib.filesystem.resolveDefaultNix "/non-existent/this/does/not/exist/for/real/please-dont-mess-with-your-local-fs";
    expected = "/non-existent/this/does/not/exist/for/real/please-dont-mess-with-your-local-fs";
  };

  testFilesystemResolveDefaultNixNonExistentDir = {
    expr = lib.filesystem.resolveDefaultNix "/non-existent/this/does/not/exist/for/real/please-dont-mess-with-your-local-fs/";
    expected = "/non-existent/this/does/not/exist/for/real/please-dont-mess-with-your-local-fs/default.nix";
  };

}
</file>

<file path="lib/tests/modules.sh">
#!/usr/bin/env bash

# This script is used to test that the module system is working as expected.
# Executing it runs tests for `lib.modules`, `lib.options` and `lib.types`.
# By default it test the version of nixpkgs which is defined in the NIX_PATH.
#
# Run:
# [nixpkgs]$ lib/tests/modules.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -o errexit -o noclobber -o nounset -o pipefail
shopt -s failglob inherit_errexit

# https://stackoverflow.com/a/246128/6605742
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null && pwd )"

cd "$DIR"/modules

pass=0
fail=0

local-nix-instantiate() {
    nix-instantiate --timeout 1 --eval-only --show-trace --read-write-mode --json "$@"
}

# loc
#   prints the location of the call of to the function that calls it
# loc n
#   prints the location n levels up the call stack
loc() {
    local caller depth
    depth=1
    if [[ $# -gt 0 ]]; then
        depth=$1
    fi
    # ( lineno fnname file ) of the caller
    caller=( $(caller $depth) )
    echo "${caller[2]}:${caller[0]}"
}

line() {
    echo "----------------------------------------"
}
logStartFailure() {
    line
}
logEndFailure() {
    line
    echo
}

logFailure() {
    # bold red
    printf '\033[1;31mTEST FAILED\033[0m at %s\n' "$(loc 2)"
}

evalConfig() {
    local attr=$1
    shift
    local script="import ./default.nix { modules = [ $* ];}"
    local-nix-instantiate -E "$script" -A "$attr"
}

reportFailure() {
    local attr=$1
    shift
    local script="import ./default.nix { modules = [ $* ];}"
    echo "$ nix-instantiate -E '$script' -A '$attr' --eval-only --json"
    evalConfig "$attr" "$@" || true
    ((++fail))
}

checkConfigOutput() {
    local outputContains=$1
    shift
    if evalConfig "$@" 2>/dev/null | grep -E --silent "$outputContains" ; then
        ((++pass))
    else
        logStartFailure
        echo "ACTUAL:"
        reportFailure "$@"
        echo "EXPECTED: result matching '$outputContains'"
        logFailure
        logEndFailure
    fi
}

invertIfUnset() {
    gate="$1"
    shift
    if [[ -n "${!gate:-}" ]]; then
        "$@"
    else
        ! "$@"
    fi
}

globalErrorLogCheck() {
    invertIfUnset "REQUIRE_INFINITE_RECURSION_HINT" \
      grep -i 'if you get an infinite recursion here' \
      <<<"$err" >/dev/null \
      || {
        if [[ -n "${REQUIRE_INFINITE_RECURSION_HINT:-}" ]]; then
            echo "Unexpected infinite recursion hint"
        else
            echo "Expected infinite recursion hint, but none found"
        fi
        return 1
      }
}

checkExpression() {
  local path=$1
  local output
  {
      output="$(local-nix-instantiate --strict "$path" 2>&1)" && ((++pass))
  } || {
      logStartFailure
      echo "$output"
      ((++fail))
      logFailure
      logEndFailure
  }
}

checkConfigError() {
    local errorContains=$1
    local err=""
    shift
    if err="$(evalConfig "$@" 2>&1 >/dev/null)"; then
        logStartFailure
        echo "ACTUAL: exit code 0, output:"
        reportFailure "$@"
        echo "EXPECTED: non-zero exit code"
        logFailure
        logEndFailure
    else
        if ! globalErrorLogCheck "$err"; then
            logStartFailure
            echo "LOG:"
            reportFailure "$@"
            echo "GLOBAL ERROR LOG CHECK FAILED"
            logFailure
            logEndFailure
        fi
        if echo "$err" | grep -zP --silent "$errorContains" ; then
            ((++pass))
        else
            logStartFailure
            echo "ACTUAL:"
            reportFailure "$@"
            echo "EXPECTED: error matching '$errorContains'"
            logFailure
            logEndFailure
        fi
    fi
}

# Shorthand meta attribute does not duplicate the config
checkConfigOutput '^"one two"$' config.result ./shorthand-meta.nix

checkConfigOutput '^true$' config.result ./test-mergeAttrDefinitionsWithPrio.nix

# Check that a module argument is passed, also when a default is available
# (but not needed)
#
# When the default is needed, we currently fail to do what the users expect, as
# we pass our own argument anyway, even if it *turns out* not to exist.
#
# The reason for this is that we don't know at invocation time what is in the
# _module.args option. That value is only available *after* all modules have been
# invoked.
#
# Hypothetically, Nix could help support this by giving access to the default
# values, through a new built-in function.
# However the default values are allowed to depend on other arguments, so those
# would have to be passed in somehow, making this not just a getter but
# something more complicated.
#
# At that point we have to wonder whether the extra complexity is worth the cost.
# Another - subjective - reason not to support it is that default values
# contradict the notion that an option has a single value, where _module.args
# is the option.
checkConfigOutput '^true$' config.result ./module-argument-default.nix

# gvariant
checkConfigOutput '^true$' config.assertion ./gvariant.nix

checkConfigOutput '"ok"' config.result ./specialArgs-lib.nix

# https://github.com/NixOS/nixpkgs/pull/131205
# We currently throw this error already in `config`, but throwing in `config.wrong1` would be acceptable.
checkConfigError 'It seems as if you.re trying to declare an option by placing it into .config. rather than .options.' config.wrong1 ./error-mkOption-in-config.nix
# We currently throw this error already in `config`, but throwing in `config.nest.wrong2` would be acceptable.
checkConfigError 'It seems as if you.re trying to declare an option by placing it into .config. rather than .options.' config.nest.wrong2 ./error-mkOption-in-config.nix
checkConfigError 'The option .sub.wrong2. does not exist. Definition values:' config.sub ./error-mkOption-in-submodule-config.nix
checkConfigError '.*This can happen if you e.g. declared your options in .types.submodule.' config.sub ./error-mkOption-in-submodule-config.nix
checkConfigError '.*A definition for option .bad. is not of type .non-empty .list of .submodule...\.' config.bad ./error-nonEmptyListOf-submodule.nix

# types.attrTag
checkConfigOutput '^true$' config.okChecks ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.syntaxError. is not of type .attribute-tagged union' config.intStrings.syntaxError ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.syntaxError2. is not of type .attribute-tagged union' config.intStrings.syntaxError2 ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.syntaxError3. is not of type .attribute-tagged union' config.intStrings.syntaxError3 ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.syntaxError4. is not of type .attribute-tagged union' config.intStrings.syntaxError4 ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.mergeError. is not of type .attribute-tagged union' config.intStrings.mergeError ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.badTagError. is not of type .attribute-tagged union' config.intStrings.badTagError ./types-attrTag.nix
checkConfigError 'A definition for option .intStrings\.badTagTypeError\.left. is not of type .signed integer.' config.intStrings.badTagTypeError.left ./types-attrTag.nix
checkConfigError 'A definition for option .nested\.right\.left. is not of type .signed integer.' config.nested.right.left ./types-attrTag.nix
checkConfigError 'In attrTag, each tag value must be an option, but tag int was a bare type, not wrapped in mkOption.' config.opt.int ./types-attrTag-wrong-decl.nix

# types.pathInStore
checkConfigOutput '".*/store/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv"' config.pathInStore.ok1 ./types.nix
checkConfigOutput '".*/store/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15"' config.pathInStore.ok2 ./types.nix
checkConfigOutput '".*/store/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash"' config.pathInStore.ok3 ./types.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ""' config.pathInStore.bad1 ./types.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store"' config.pathInStore.bad2 ./types.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store/"' config.pathInStore.bad3 ./types.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store/.links"' config.pathInStore.bad4 ./types.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: "/foo/bar"' config.pathInStore.bad5 ./types.nix

# Check boolean option.
checkConfigOutput '^false$' config.enable ./declare-enable.nix
checkConfigError 'The option .* does not exist. Definition values:\n\s*- In .*: true' config.enable ./define-enable.nix
checkConfigError 'The option .* does not exist. Definition values:\n\s*- In .*' config.enable ./define-enable-throw.nix
checkConfigError 'while evaluating a definition from `.*/define-enable-abort.nix' config.enable ./define-enable-abort.nix
checkConfigError 'while evaluating the error message for definitions for .enable., which is an option that does not exist' config.enable ./define-enable-abort.nix

# Check boolByOr type.
checkConfigOutput '^false$' config.value.falseFalse ./boolByOr.nix
checkConfigOutput '^true$' config.value.trueFalse ./boolByOr.nix
checkConfigOutput '^true$' config.value.falseTrue ./boolByOr.nix
checkConfigOutput '^true$' config.value.trueTrue ./boolByOr.nix

checkConfigOutput '^1$' config.bare-submodule.nested ./declare-bare-submodule.nix ./declare-bare-submodule-nested-option.nix
checkConfigOutput '^2$' config.bare-submodule.deep ./declare-bare-submodule.nix ./declare-bare-submodule-deep-option.nix
checkConfigOutput '^42$' config.bare-submodule.nested ./declare-bare-submodule.nix ./declare-bare-submodule-nested-option.nix ./declare-bare-submodule-deep-option.nix ./define-bare-submodule-values.nix
checkConfigOutput '^420$' config.bare-submodule.deep ./declare-bare-submodule.nix ./declare-bare-submodule-nested-option.nix ./declare-bare-submodule-deep-option.nix ./define-bare-submodule-values.nix
checkConfigOutput '^2$' config.bare-submodule.deep ./declare-bare-submodule.nix ./declare-bare-submodule-deep-option.nix ./define-shorthandOnlyDefinesConfig-true.nix
checkConfigError 'The option .bare-submodule.deep. in .*/declare-bare-submodule-deep-option.nix. is already declared in .*/declare-bare-submodule-deep-option-duplicate.nix' config.bare-submodule.deep ./declare-bare-submodule.nix ./declare-bare-submodule-deep-option.nix  ./declare-bare-submodule-deep-option-duplicate.nix

# Check that strMatching can be merged
checkConfigOutput '^"strMatching.*"$' options.sm.type.name ./strMatching-merge.nix

# Check integer types.
# unsigned
checkConfigOutput '^42$' config.value ./declare-int-unsigned-value.nix ./define-value-int-positive.nix
checkConfigError 'A definition for option .* is not of type.*unsigned integer.*. Definition values:\n\s*- In .*: -23' config.value ./declare-int-unsigned-value.nix ./define-value-int-negative.nix
# positive
checkConfigError 'A definition for option .* is not of type.*positive integer.*. Definition values:\n\s*- In .*: 0' config.value ./declare-int-positive-value.nix ./define-value-int-zero.nix
# between
checkConfigOutput '^42$' config.value ./declare-int-between-value.nix ./define-value-int-positive.nix
checkConfigError 'A definition for option .* is not of type.*between.*-21 and 43.*inclusive.*. Definition values:\n\s*- In .*: -23' config.value ./declare-int-between-value.nix ./define-value-int-negative.nix

# Check either types
# types.either
checkConfigOutput '^42$' config.value ./declare-either.nix ./define-value-int-positive.nix
checkConfigOutput '^"24"$' config.value ./declare-either.nix ./define-value-string.nix
# types.oneOf
checkConfigOutput '^42$' config.value ./declare-oneOf.nix ./define-value-int-positive.nix
checkConfigOutput '^\[\]$' config.value ./declare-oneOf.nix ./define-value-list.nix
checkConfigOutput '^"24"$' config.value ./declare-oneOf.nix ./define-value-string.nix

# Check mkForce without submodules.
set -- config.enable ./declare-enable.nix ./define-enable.nix
checkConfigOutput '^true$' "$@"
checkConfigOutput '^false$' "$@" ./define-force-enable.nix
checkConfigOutput '^false$' "$@" ./define-enable-force.nix

# Check mkForce with option and submodules.
checkConfigError 'attribute .*foo.* .* not found' config.attrsOfSub.foo.enable ./declare-attrsOfSub-any-enable.nix
checkConfigOutput '^false$' config.attrsOfSub.foo.enable ./declare-attrsOfSub-any-enable.nix ./define-attrsOfSub-foo.nix
set -- config.attrsOfSub.foo.enable ./declare-attrsOfSub-any-enable.nix ./define-attrsOfSub-foo-enable.nix
checkConfigOutput '^true$' "$@"
checkConfigOutput '^false$' "$@" ./define-force-attrsOfSub-foo-enable.nix
checkConfigOutput '^false$' "$@" ./define-attrsOfSub-force-foo-enable.nix
checkConfigOutput '^false$' "$@" ./define-attrsOfSub-foo-force-enable.nix
checkConfigOutput '^false$' "$@" ./define-attrsOfSub-foo-enable-force.nix

# Check overriding effect of mkForce on submodule definitions.
checkConfigError 'attribute .*bar.* .* not found' config.attrsOfSub.bar.enable ./declare-attrsOfSub-any-enable.nix ./define-attrsOfSub-foo.nix
checkConfigOutput '^false$' config.attrsOfSub.bar.enable ./declare-attrsOfSub-any-enable.nix ./define-attrsOfSub-foo.nix ./define-attrsOfSub-bar.nix
set -- config.attrsOfSub.bar.enable ./declare-attrsOfSub-any-enable.nix ./define-attrsOfSub-foo.nix ./define-attrsOfSub-bar-enable.nix
checkConfigOutput '^true$' "$@"
checkConfigError 'attribute .*bar.* .* not found' "$@" ./define-force-attrsOfSub-foo-enable.nix
checkConfigError 'attribute .*bar.* .* not found' "$@" ./define-attrsOfSub-force-foo-enable.nix
checkConfigOutput '^true$' "$@" ./define-attrsOfSub-foo-force-enable.nix
checkConfigOutput '^true$' "$@" ./define-attrsOfSub-foo-enable-force.nix

# Check mkIf with submodules.
checkConfigError 'attribute .*foo.* .* not found' config.attrsOfSub.foo.enable ./declare-enable.nix ./declare-attrsOfSub-any-enable.nix
set -- config.attrsOfSub.foo.enable ./declare-enable.nix ./declare-attrsOfSub-any-enable.nix
checkConfigError 'attribute .*foo.* .* not found' "$@" ./define-if-attrsOfSub-foo-enable.nix
checkConfigError 'attribute .*foo.* .* not found' "$@" ./define-attrsOfSub-if-foo-enable.nix
checkConfigError 'attribute .*foo.* .* not found' "$@" ./define-attrsOfSub-foo-if-enable.nix
checkConfigOutput '^false$' "$@" ./define-attrsOfSub-foo-enable-if.nix
checkConfigOutput '^true$' "$@" ./define-enable.nix ./define-if-attrsOfSub-foo-enable.nix
checkConfigOutput '^true$' "$@" ./define-enable.nix ./define-attrsOfSub-if-foo-enable.nix
checkConfigOutput '^true$' "$@" ./define-enable.nix ./define-attrsOfSub-foo-if-enable.nix
checkConfigOutput '^true$' "$@" ./define-enable.nix ./define-attrsOfSub-foo-enable-if.nix

# Check importApply
checkConfigOutput '"abc"' config.value ./importApply.nix
# importApply does not set a key.
# Disabling the function file is not sufficient, because importApply can't reasonably assume that the key is unique.
# e.g. user may call it multiple times with different arguments and expect each of the module to apply.
# While this is excusable for the disabledModules aspect, it is not for the deduplication of modules.
checkConfigOutput '"abc"' config.value ./importApply-disabling.nix

# Check disabledModules with config definitions and option declarations.
set -- config.enable ./define-enable.nix ./declare-enable.nix
checkConfigOutput '^true$' "$@"
checkConfigOutput '^false$' "$@" ./disable-define-enable.nix
checkConfigOutput '^false$' "$@" ./disable-define-enable-string-path.nix
checkConfigError "The option .*enable.* does not exist. Definition values:\n\s*- In .*: true" "$@" ./disable-declare-enable.nix
checkConfigError "attribute .*enable.* in selection path .*config.enable.* not found" "$@" ./disable-define-enable.nix ./disable-declare-enable.nix
checkConfigError "attribute .*enable.* in selection path .*config.enable.* not found" "$@" ./disable-enable-modules.nix

checkConfigOutput '^true$' 'config.positive.enable' ./disable-module-with-key.nix
checkConfigOutput '^false$' 'config.negative.enable' ./disable-module-with-key.nix
checkConfigError 'Module ..*disable-module-bad-key.nix. contains a disabledModules item that is an attribute set, presumably a module, that does not have a .key. attribute. .*' 'config.enable' ./disable-module-bad-key.nix

# Not sure if we want to keep supporting module keys that aren't strings, paths or v?key, but we shouldn't remove support accidentally.
checkConfigOutput '^true$' 'config.positive.enable' ./disable-module-with-toString-key.nix
checkConfigOutput '^false$' 'config.negative.enable' ./disable-module-with-toString-key.nix

# Check _module.args.
set -- config.enable ./declare-enable.nix ./define-enable-with-custom-arg.nix
checkConfigError 'while evaluating the module argument .*custom.* in .*define-enable-with-custom-arg.nix.*:' "$@"
checkConfigOutput '^true$' "$@" ./define-_module-args-custom.nix

# Check that using _module.args on imports cause infinite recursions, with
# the proper error context.
set -- "$@" ./define-_module-args-custom.nix ./import-custom-arg.nix
REQUIRE_INFINITE_RECURSION_HINT=1 checkConfigError 'while evaluating the module argument .*custom.* in .*import-custom-arg.nix.*:' "$@"
REQUIRE_INFINITE_RECURSION_HINT=1 checkConfigError 'infinite recursion encountered' "$@"

# Check _module.check.
set -- config.enable ./declare-enable.nix ./define-enable.nix ./define-attrsOfSub-foo.nix
checkConfigError 'The option .* does not exist. Definition values:\n\s*- In .*' "$@"
checkConfigOutput '^true$' "$@" ./define-module-check.nix

# Check coerced value.
set --
checkConfigOutput '^"42"$' config.value ./declare-coerced-value.nix
checkConfigOutput '^"24"$' config.value ./declare-coerced-value.nix ./define-value-string.nix
checkConfigError 'A definition for option .* is not.*string or signed integer convertible to it.*. Definition values:\n\s*- In .*: \[ \]' config.value ./declare-coerced-value.nix ./define-value-list.nix

# Check coerced option merging.
checkConfigError 'The option .value. in .*/declare-coerced-value.nix. is already declared in .*/declare-coerced-value-no-default.nix.' config.value ./declare-coerced-value.nix ./declare-coerced-value-no-default.nix

# Check coerced value with unsound coercion
checkConfigOutput '^12$' config.value ./declare-coerced-value-unsound.nix
checkConfigError 'A definition for option .* is not of type .*. Definition values:\n\s*- In .*: "1000"' config.value ./declare-coerced-value-unsound.nix ./define-value-string-bigint.nix
checkConfigError 'toInt: Could not convert .* to int' config.value ./declare-coerced-value-unsound.nix ./define-value-string-arbitrary.nix

# Check `graph` attribute
checkExpression './graph/test.nix'

# Check mkAliasOptionModule.
checkConfigOutput '^true$' config.enable ./alias-with-priority.nix
checkConfigOutput '^true$' config.enableAlias ./alias-with-priority.nix
checkConfigOutput '^false$' config.enable ./alias-with-priority-can-override.nix
checkConfigOutput '^false$' config.enableAlias ./alias-with-priority-can-override.nix

# Check mkPackageOption
checkConfigOutput '^"hello"$' config.package.pname ./declare-mkPackageOption.nix
checkConfigOutput '^"hello"$' config.namedPackage.pname ./declare-mkPackageOption.nix
checkConfigOutput '^".*Hello.*"$' options.namedPackage.description ./declare-mkPackageOption.nix
checkConfigOutput '^"literalExpression"$' options.namedPackage.defaultText._type ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.hello"$' options.namedPackage.defaultText.text ./declare-mkPackageOption.nix
checkConfigOutput '^"hello"$' config.namedPackageSingletonDefault.pname ./declare-mkPackageOption.nix
checkConfigOutput '^".*Hello.*"$' options.namedPackageSingletonDefault.description ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.hello"$' options.namedPackageSingletonDefault.defaultText.text ./declare-mkPackageOption.nix
checkConfigOutput '^"hello"$' config.pathPackage.pname ./declare-mkPackageOption.nix
checkConfigOutput '^"literalExpression"$' options.packageWithExample.example._type ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.hello\.override \{ stdenv = pkgs\.clangStdenv; \}"$' options.packageWithExample.example.text ./declare-mkPackageOption.nix
checkConfigOutput '^"literalExpression"$' options.packageWithPathExample.example._type ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.hello"$' options.packageWithPathExample.example.text ./declare-mkPackageOption.nix
checkConfigOutput '^".*Example extra description\..*"$' options.packageWithExtraDescription.description ./declare-mkPackageOption.nix
checkConfigError 'The option .undefinedPackage. was accessed but has no value defined. Try setting the option.' config.undefinedPackage ./declare-mkPackageOption.nix
checkConfigOutput '^null$' config.nullablePackage ./declare-mkPackageOption.nix
checkConfigOutput '^"null or package"$' options.nullablePackage.type.description ./declare-mkPackageOption.nix
checkConfigOutput '^"hello"$' config.nullablePackageWithDefault.pname ./declare-mkPackageOption.nix
checkConfigOutput '^"myPkgs\.hello"$' options.packageWithPkgsText.defaultText.text ./declare-mkPackageOption.nix
checkConfigOutput '^"hello-other"$' options.packageFromOtherSet.default.pname ./declare-mkPackageOption.nix
checkConfigOutput '^"hello"$' config.packageInvalidIdentifier.pname ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.\\"123\\"\.\\"with\\\\\\"quote\\"\.hello"$' options.packageInvalidIdentifier.defaultText.text ./declare-mkPackageOption.nix
checkConfigOutput '^"pkgs\.\\"123\\"\.\\"with\\\\\\"quote\\"\.hello"$' options.packageInvalidIdentifierExample.example.text ./declare-mkPackageOption.nix

# submoduleWith

## specialArgs should work
checkConfigOutput '^"foo"$' config.submodule.foo ./declare-submoduleWith-special.nix

## shorthandOnlyDefines config behaves as expected
checkConfigOutput '^true$' config.submodule.config ./declare-submoduleWith-shorthand.nix ./define-submoduleWith-shorthand.nix
checkConfigError 'is not of type `boolean' config.submodule.config ./declare-submoduleWith-shorthand.nix ./define-submoduleWith-noshorthand.nix
checkConfigError "In module ..*define-submoduleWith-shorthand.nix., you're trying to define a value of type \`bool'\n\s*rather than an attribute set for the option" config.submodule.config ./declare-submoduleWith-noshorthand.nix ./define-submoduleWith-shorthand.nix
checkConfigOutput '^true$' config.submodule.config ./declare-submoduleWith-noshorthand.nix ./define-submoduleWith-noshorthand.nix

## submoduleWith should merge all modules in one swoop
checkConfigOutput '^true$' config.submodule.inner ./declare-submoduleWith-modules.nix
checkConfigOutput '^true$' config.submodule.outer ./declare-submoduleWith-modules.nix
# Should also be able to evaluate the type name (which evaluates freeformType,
# which evaluates all the modules defined by the type)
checkConfigOutput '^"submodule"$' options.submodule.type.description ./declare-submoduleWith-modules.nix

## submodules can be declared using (evalModules {...}).type
checkConfigOutput '^true$' config.submodule.inner ./declare-submodule-via-evalModules.nix
checkConfigOutput '^true$' config.submodule.outer ./declare-submodule-via-evalModules.nix
# Should also be able to evaluate the type name (which evaluates freeformType,
# which evaluates all the modules defined by the type)
checkConfigOutput '^"submodule"$' options.submodule.type.description ./declare-submodule-via-evalModules.nix

## Paths should be allowed as values and work as expected
checkConfigOutput '^true$' config.submodule.enable ./declare-submoduleWith-path.nix

## _prefix module argument is available at import time and contains the prefix
checkConfigOutput '^true$' config.foo.ok ./prefix-module-argument.nix

## deferredModule
# default module is merged into nodes.foo
checkConfigOutput '"beta"' config.nodes.foo.settingsDict.c ./deferred-module.nix
# errors from the default module are reported with accurate location
checkConfigError 'In `the-file-that-contains-the-bad-config.nix, via option default'\'': "bogus"' config.nodes.foo.bottom ./deferred-module.nix
checkConfigError '.*lib/tests/modules/deferred-module-error.nix, via option deferred [(]:anon-1:anon-1:anon-1[)] does not look like a module.' config.result ./deferred-module-error.nix

# Check the file location information is propagated into submodules
checkConfigOutput the-file.nix config.submodule.internalFiles.0 ./submoduleFiles.nix


# Check that disabledModules works recursively and correctly
checkConfigOutput '^true$' config.enable ./disable-recursive/main.nix
checkConfigOutput '^true$' config.enable ./disable-recursive/{main.nix,disable-foo.nix}
checkConfigOutput '^true$' config.enable ./disable-recursive/{main.nix,disable-bar.nix}
checkConfigError 'The option .* does not exist. Definition values:\n\s*- In .*: true' config.enable ./disable-recursive/{main.nix,disable-foo.nix,disable-bar.nix}

# Check that imports can depend on derivations
checkConfigOutput '^true$' config.enable ./import-from-store.nix

# Check that configs can be conditional on option existence
checkConfigOutput '^true$' config.enable ./define-option-dependently.nix ./declare-enable.nix ./declare-int-positive-value.nix
checkConfigOutput '^360$' config.value ./define-option-dependently.nix ./declare-enable.nix ./declare-int-positive-value.nix
checkConfigOutput '^7$' config.value ./define-option-dependently.nix ./declare-int-positive-value.nix
checkConfigOutput '^true$' config.set.enable ./define-option-dependently-nested.nix ./declare-enable-nested.nix ./declare-int-positive-value-nested.nix
checkConfigOutput '^360$' config.set.value ./define-option-dependently-nested.nix ./declare-enable-nested.nix ./declare-int-positive-value-nested.nix
checkConfigOutput '^7$' config.set.value ./define-option-dependently-nested.nix ./declare-int-positive-value-nested.nix

# Check attrsOf and lazyAttrsOf. Only lazyAttrsOf should be lazy, and only
# attrsOf should work with conditional definitions
# In addition, lazyAttrsOf should honor an options emptyValue
checkConfigError "is not lazy" config.isLazy ./declare-attrsOf.nix ./attrsOf-lazy-check.nix
checkConfigOutput '^true$' config.isLazy ./declare-lazyAttrsOf.nix ./attrsOf-lazy-check.nix
checkConfigOutput '^true$' config.conditionalWorks ./declare-attrsOf.nix ./attrsOf-conditional-check.nix
checkConfigOutput '^false$' config.conditionalWorks ./declare-lazyAttrsOf.nix ./attrsOf-conditional-check.nix
checkConfigOutput '^"empty"$' config.value.foo ./declare-lazyAttrsOf.nix ./attrsOf-conditional-check.nix

# Check attrsWith type merging
checkConfigError 'The option `mergedLazyNonLazy'\'' in `.*'\'' is already declared in `.*'\''\.' options.mergedLazyNonLazy ./lazy-attrsWith.nix
checkConfigOutput '^11$' config.lazyResult ./lazy-attrsWith.nix
checkConfigError 'infinite recursion encountered' config.nonLazyResult ./lazy-attrsWith.nix

# AttrsWith placeholder tests
checkConfigOutput '^"mergedName.<id>.nested"$' config.result ./name-merge-attrsWith-1.nix
checkConfigError 'The option .mergedName. in .*\.nix. is already declared in .*\.nix' config.mergedName ./name-merge-attrsWith-2.nix

# Test type.functor.wrapped deprecation warning
# should emit the warning on:
# - merged types
# - non-merged types
# - nestedTypes elemType
# attrsWith
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.attrsWith.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedAttrsWith.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.attrsWith.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedAttrsWith.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
# listOf
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.listOf.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedListOf.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.listOf.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedListOf.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
# unique / uniq
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.unique.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedUnique.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.unique.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedUnique.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
# nullOr
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.nullOr.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedNullOr.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.nullOr.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedNullOr.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
# functionTo
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.functionTo.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedFunctionTo.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.functionTo.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedFunctionTo.type.nestedTypes.elemType.functor.wrapped ./deprecated-wrapped.nix

# coercedTo
# Note: test 'nestedTypes.finalType' and 'nestedTypes.coercedType'
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.coercedTo.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.coercedTo.type.nestedTypes.finalType.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.coercedTo.type.nestedTypes.coercedType.functor.wrapped ./deprecated-wrapped.nix
# either
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.either.type.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedEither.type.functor.wrapped ./deprecated-wrapped.nix

NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.either.type.nestedTypes.left.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.either.type.nestedTypes.right.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedEither.type.nestedTypes.left.functor.wrapped ./deprecated-wrapped.nix
NIX_ABORT_ON_WARN=1 checkConfigError 'The deprecated `.*functor.wrapped` attribute .*is accessed, use `.*nestedTypes.elemType` instead.' options.mergedEither.type.nestedTypes.right.functor.wrapped ./deprecated-wrapped.nix

# Even with multiple assignments, a type error should be thrown if any of them aren't valid
checkConfigError 'A definition for option .* is not of type .*' \
  config.value ./declare-int-unsigned-value.nix ./define-value-list.nix ./define-value-int-positive.nix

## Freeform modules
# Assigning without a declared option should work
checkConfigOutput '^"24"$' config.value ./freeform-attrsOf.nix ./define-value-string.nix
# Shorthand modules interpret `meta` and `class` as config items
checkConfigOutput '^true$' options._module.args.value.result ./freeform-attrsOf.nix ./define-freeform-keywords-shorthand.nix
# No freeform assignments shouldn't make it error
checkConfigOutput '^{}$' config ./freeform-attrsOf.nix
# but only if the type matches
checkConfigError 'A definition for option .* is not of type .*' config.value ./freeform-attrsOf.nix ./define-value-list.nix
# and properties should be applied
checkConfigOutput '^"yes"$' config.value ./freeform-attrsOf.nix ./define-value-string-properties.nix
# Options should still be declarable, and be able to have a type that doesn't match the freeform type
checkConfigOutput '^false$' config.enable ./freeform-attrsOf.nix ./define-value-string.nix ./declare-enable.nix
checkConfigOutput '^"24"$' config.value ./freeform-attrsOf.nix ./define-value-string.nix ./declare-enable.nix
# and this should work too with nested values
checkConfigOutput '^false$' config.nest.foo ./freeform-attrsOf.nix ./freeform-nested.nix
checkConfigOutput '^"bar"$' config.nest.bar ./freeform-attrsOf.nix ./freeform-nested.nix
# Check whether a declared option can depend on an freeform-typed one
checkConfigOutput '^null$' config.foo ./freeform-attrsOf.nix ./freeform-str-dep-unstr.nix
checkConfigOutput '^"24"$' config.foo ./freeform-attrsOf.nix ./freeform-str-dep-unstr.nix ./define-value-string.nix
# Check whether an freeform-typed value can depend on a declared option, this can only work with lazyAttrsOf
REQUIRE_INFINITE_RECURSION_HINT=1 checkConfigError 'infinite recursion encountered' config.foo ./freeform-attrsOf.nix ./freeform-unstr-dep-str.nix
checkConfigError 'The option .* was accessed but has no value defined. Try setting the option.' config.foo ./freeform-lazyAttrsOf.nix ./freeform-unstr-dep-str.nix
checkConfigOutput '^"24"$' config.foo ./freeform-lazyAttrsOf.nix ./freeform-unstr-dep-str.nix ./define-value-string.nix
# submodules in freeformTypes should have their locations annotated
checkConfigOutput '/freeform-submodules.nix"$' config.fooDeclarations.0 ./freeform-submodules.nix
# freeformTypes can get merged using `types.type`, including submodules
checkConfigOutput '^10$' config.free.xxx.foo ./freeform-submodules.nix
checkConfigOutput '^10$' config.free.yyy.bar ./freeform-submodules.nix

## types.anything
# Check that attribute sets are merged recursively
checkConfigOutput '^null$' config.value.foo ./types-anything/nested-attrs.nix
checkConfigOutput '^null$' config.value.l1.foo ./types-anything/nested-attrs.nix
checkConfigOutput '^null$' config.value.l1.l2.foo ./types-anything/nested-attrs.nix
checkConfigOutput '^null$' config.value.l1.l2.l3.foo ./types-anything/nested-attrs.nix
# Attribute sets that are coercible to strings shouldn't be recursed into
checkConfigOutput '^"foo"$' config.value.outPath ./types-anything/attrs-coercible.nix
# Multiple lists aren't concatenated together if their definitions are not equal
checkConfigError 'The option .* has conflicting definition values' config.value ./types-anything/lists.nix
# Check that all equalizable atoms can be used as long as all definitions are equal
checkConfigOutput '^0$' config.value.int ./types-anything/equal-atoms.nix
checkConfigOutput '^false$' config.value.bool ./types-anything/equal-atoms.nix
checkConfigOutput '^""$' config.value.string ./types-anything/equal-atoms.nix
checkConfigOutput '^"/[^"]+"$' config.value.path ./types-anything/equal-atoms.nix
checkConfigOutput '^null$' config.value.null ./types-anything/equal-atoms.nix
checkConfigOutput '^0.1$' config.value.float ./types-anything/equal-atoms.nix
checkConfigOutput '^\[1,"a",{"x":null}\]$' config.value.list ./types-anything/equal-atoms.nix
# Functions can't be merged together
checkConfigError "The option .value.multiple-lambdas.<function body>. has conflicting option types" config.applied.multiple-lambdas ./types-anything/functions.nix
checkConfigOutput '^true$' config.valueIsFunction.single-lambda ./types-anything/functions.nix
checkConfigOutput '^null$' config.applied.merging-lambdas.x ./types-anything/functions.nix
checkConfigOutput '^null$' config.applied.merging-lambdas.y ./types-anything/functions.nix
# Check that all mk* modifiers are applied
checkConfigError 'attribute .* not found' config.value.mkiffalse ./types-anything/mk-mods.nix
checkConfigOutput '^{}$' config.value.mkiftrue ./types-anything/mk-mods.nix
checkConfigOutput '^1$' config.value.mkdefault ./types-anything/mk-mods.nix
checkConfigOutput '^{}$' config.value.mkmerge ./types-anything/mk-mods.nix
checkConfigOutput '^true$' config.value.mkbefore ./types-anything/mk-mods.nix
checkConfigOutput '^1$' config.value.nested.foo ./types-anything/mk-mods.nix
checkConfigOutput '^"baz"$' config.value.nested.bar.baz ./types-anything/mk-mods.nix

## types.functionTo
checkConfigOutput '^"input is input"$' config.result ./functionTo/trivial.nix
checkConfigOutput '^"a b"$' config.result ./functionTo/merging-list.nix
checkConfigError 'A definition for option .fun.<function body>. is not of type .string.. Definition values:\n\s*- In .*wrong-type.nix' config.result ./functionTo/wrong-type.nix
checkConfigOutput '^"b a"$' config.result ./functionTo/list-order.nix
checkConfigOutput '^"a c"$' config.result ./functionTo/merging-attrs.nix
checkConfigOutput '^"a bee"$' config.result ./functionTo/submodule-options.nix
checkConfigOutput '^"fun.<function body>.a fun.<function body>.b"$' config.optionsResult ./functionTo/submodule-options.nix

# moduleType
checkConfigOutput '^"a b"$' config.resultFoo ./declare-variants.nix ./define-variant.nix
checkConfigOutput '^"a b y z"$' config.resultFooBar ./declare-variants.nix ./define-variant.nix
checkConfigOutput '^"a b c"$' config.resultFooFoo ./declare-variants.nix ./define-variant.nix

## emptyValue's
checkConfigOutput "\[\]" config.list.a ./emptyValues.nix
checkConfigOutput "{}" config.attrs.a ./emptyValues.nix
checkConfigOutput "null" config.null.a ./emptyValues.nix
checkConfigOutput "{}" config.submodule.a ./emptyValues.nix
# These types don't have empty values
checkConfigError 'The option .int.a. was accessed but has no value defined. Try setting the option.' config.int.a ./emptyValues.nix
checkConfigError 'The option .nonEmptyList.a. was accessed but has no value defined. Try setting the option.' config.nonEmptyList.a ./emptyValues.nix

# types.unique
#   requires a single definition
checkConfigError 'The option .examples\.merged. is defined multiple times while it.s expected to be unique' config.examples.merged.a ./types-unique.nix
#   user message is printed
checkConfigError 'We require a single definition, because seeing the whole value at once helps us maintain critical invariants of our system.' config.examples.merged.a ./types-unique.nix
#   let the inner merge function check the values (on demand)
checkConfigError 'A definition for option .examples\.badLazyType\.a. is not of type .string.' config.examples.badLazyType.a ./types-unique.nix
#   overriding still works (unlike option uniqueness)
checkConfigOutput '^"bee"$' config.examples.override.b ./types-unique.nix

## types.raw
checkConfigOutput '^true$' config.unprocessedNestingEvaluates.success ./raw.nix
checkConfigOutput "10" config.processedToplevel ./raw.nix
checkConfigError "The option .multiple. is defined multiple times" config.multiple ./raw.nix
checkConfigOutput "bar" config.priorities ./raw.nix

## Option collision
checkConfigError \
  'The option .set. in module .*/declare-set.nix. would be a parent of the following options, but its type .attribute set of signed integer. does not support nested options.\n\s*- option[(]s[)] with prefix .set.enable. in module .*/declare-enable-nested.nix.' \
  config.set \
  ./declare-set.nix ./declare-enable-nested.nix

# Options: accidental use of an option-type instead of option (or other tagged type; unlikely)
checkConfigError 'In module .*/options-type-error-typical.nix: expected an option declaration at option path .result. but got an attribute set with type option-type' config.result ./options-type-error-typical.nix
checkConfigError 'In module .*/options-type-error-typical-nested.nix: expected an option declaration at option path .result.here. but got an attribute set with type option-type' config.result.here ./options-type-error-typical-nested.nix
checkConfigError 'In module .*/options-type-error-configuration.nix: expected an option declaration at option path .result. but got an attribute set with type configuration' config.result ./options-type-error-configuration.nix

# Check that that merging of option collisions doesn't depend on type being set
checkConfigError 'The option .group..*would be a parent of the following options, but its type .<no description>. does not support nested options.\n\s*- option.s. with prefix .group.enable..*' config.group.enable ./merge-typeless-option.nix

# Test that types.optionType merges types correctly
checkConfigOutput '^10$' config.theOption.int ./optionTypeMerging.nix
checkConfigOutput '^"hello"$' config.theOption.str ./optionTypeMerging.nix

# Test that types.optionType correctly annotates option locations
checkConfigError 'The option .theOption.nested. in .other.nix. is already declared in .optionTypeFile.nix.' config.theOption.nested ./optionTypeFile.nix

# Test that types.optionType leaves types untouched as long as they don't need to be merged
checkConfigOutput 'ok' config.freeformItems.foo.bar ./adhoc-freeformType-survives-type-merge.nix

# Test that specifying both functor.wrapped and functor.payload isn't allowed
checkConfigError 'Type foo defines both `functor.payload` and `functor.wrapped` at the same time, which is not supported.' config.result ./default-type-merge-both.nix


# Anonymous submodules don't get nixed by import resolution/deduplication
# because of an `extendModules` bug, issue 168767.
checkConfigOutput '^1$' config.sub.specialisation.value ./extendModules-168767-imports.nix

# Class checks, evalModules
checkConfigOutput '^{}$' config.ok.config ./class-check.nix
checkConfigOutput '"nixos"' config.ok.class ./class-check.nix
checkConfigError 'The module `.*/module-class-is-darwin.nix`.*?expects class "nixos".' config.fail.config ./class-check.nix
checkConfigError 'The module `foo.nix#darwinModules.default`.*?expects class "nixos".' config.fail-anon.config ./class-check.nix

# Class checks, submoduleWith
checkConfigOutput '^{}$' config.sub.nixosOk ./class-check.nix
checkConfigError 'The module `.*/module-class-is-darwin.nix`.*?expects class "nixos".' config.sub.nixosFail.config ./class-check.nix

# submoduleWith type merge with different class
checkConfigError 'A submoduleWith option is declared multiple times with conflicting class values "darwin" and "nixos".' config.sub.mergeFail.config ./class-check.nix

# _type check
checkConfigError 'Expected a module, but found a value of type .*"flake".*, while trying to load a module into .*/module-imports-_type-check.nix' config.ok.config ./module-imports-_type-check.nix
checkConfigOutput '^true$' config.enable ./declare-enable.nix ./define-enable-with-top-level-mkIf.nix
checkConfigError 'Expected a module, but found a value of type .*"configuration".*, while trying to load a module into .*/import-configuration.nix.' config ./import-configuration.nix
checkConfigError 'please only import the modules that make up the configuration' config ./import-configuration.nix
checkConfigError 'Expected a module, but found a value of type "configuration", while trying to load a module into .*/import-error-submodule.nix, while trying to load a module into .*foo.*\.' config.foo ./import-error-submodule.nix

# doRename works when `warnings` does not exist.
checkConfigOutput '^1234$' config.c.d.e ./doRename-basic.nix
# doRename adds a warning.
checkConfigOutput '^"The option `a\.b. defined in `.*/doRename-warnings\.nix. has been renamed to `c\.d\.e.\."$' \
  config.result \
  ./doRename-warnings.nix
checkConfigOutput "^true$" config.result ./doRename-condition.nix ./doRename-condition-enable.nix
checkConfigOutput "^true$" config.result ./doRename-condition.nix ./doRename-condition-no-enable.nix
checkConfigOutput "^true$" config.result ./doRename-condition.nix ./doRename-condition-migrated.nix

# Anonymous modules get deduplicated by key
checkConfigOutput '^"pear"$' config.once.raw ./merge-module-with-key.nix
checkConfigOutput '^"pear\\npear"$' config.twice.raw ./merge-module-with-key.nix

# Declaration positions
# Line should be present for direct options
checkConfigOutput '^14$' options.imported.line14.declarationPositions.0.line ./declaration-positions.nix
checkConfigOutput '/declaration-positions.nix"$' options.imported.line14.declarationPositions.0.file ./declaration-positions.nix
# Generated options may not have line numbers but they will at least get the
# right file
checkConfigOutput '/declaration-positions.nix"$' options.generated.line22.declarationPositions.0.file ./declaration-positions.nix
checkConfigOutput '^null$' options.generated.line22.declarationPositions.0.line ./declaration-positions.nix
# Submodules don't break it
checkConfigOutput '^45$' config.submoduleLine38.submodDeclLine45.0.line ./declaration-positions.nix
checkConfigOutput '/declaration-positions.nix"$' config.submoduleLine38.submodDeclLine45.0.file ./declaration-positions.nix
# New options under freeform submodules get collected into the parent submodule
# (consistent with .declarations behaviour, but weird; notably appears in system.build)
checkConfigOutput '^38|27$' options.submoduleLine38.declarationPositions.0.line ./declaration-positions.nix
checkConfigOutput '^38|27$' options.submoduleLine38.declarationPositions.1.line ./declaration-positions.nix
# nested options work
checkConfigOutput '^34$' options.nested.nestedLine34.declarationPositions.0.line ./declaration-positions.nix

# types.pathWith { inStore = true; }
checkConfigOutput '".*/store/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv"' config.pathInStore.ok1 ./pathWith.nix
checkConfigOutput '".*/store/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15"' config.pathInStore.ok2 ./pathWith.nix
checkConfigOutput '".*/store/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash"' config.pathInStore.ok3 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ""' config.pathInStore.bad1 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store"' config.pathInStore.bad2 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store/"' config.pathInStore.bad3 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: ".*/store/.links"' config.pathInStore.bad4 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path in the Nix store.. Definition values:\n\s*- In .*: "/foo/bar"' config.pathInStore.bad5 ./pathWith.nix

# types.pathWith { inStore = false; }
checkConfigOutput '"/foo/bar"' config.pathNotInStore.ok1 ./pathWith.nix
checkConfigOutput '".*/store"' config.pathNotInStore.ok2 ./pathWith.nix
checkConfigOutput '".*/store/"' config.pathNotInStore.ok3 ./pathWith.nix
checkConfigOutput '""' config.pathNotInStore.ok4 ./pathWith.nix
checkConfigOutput '".*/store/.links"' config.pathNotInStore.ok5 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path not in the Nix store.. Definition values:\n\s*- In .*: ".*/0lz9p8xhf89kb1c1kk6jxrzskaiygnlh-bash-5.2-p15.drv"' config.pathNotInStore.bad1 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path not in the Nix store.. Definition values:\n\s*- In .*: ".*/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15"' config.pathNotInStore.bad2 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path not in the Nix store.. Definition values:\n\s*- In .*: ".*/0fb3ykw9r5hpayd05sr0cizwadzq1d8q-bash-5.2-p15/bin/bash"' config.pathNotInStore.bad3 ./pathWith.nix
checkConfigError 'A definition for option .* is not of type .path not in the Nix store.. Definition values:\n\s*- In .*: .*/pathWith.nix' config.pathNotInStore.bad4 ./pathWith.nix

# types.pathWith { }
checkConfigOutput '"/this/is/absolute"' config.anyPath.ok1 ./pathWith.nix
checkConfigOutput '"./this/is/relative"' config.anyPath.ok2 ./pathWith.nix
checkConfigError 'A definition for option .anyPath.bad1. is not of type .path.' config.anyPath.bad1 ./pathWith.nix

# types.pathWith { absolute = true; }
checkConfigOutput '"/this/is/absolute"' config.absolutePathNotInStore.ok1 ./pathWith.nix
checkConfigError 'A definition for option .absolutePathNotInStore.bad1. is not of type .absolute path not in the Nix store.' config.absolutePathNotInStore.bad1 ./pathWith.nix
checkConfigError 'A definition for option .absolutePathNotInStore.bad2. is not of type .absolute path not in the Nix store.' config.absolutePathNotInStore.bad2 ./pathWith.nix

# types.pathWith failed type merge
checkConfigError 'The option .conflictingPathOptionType. in .*/pathWith.nix. is already declared in .*/pathWith.nix' config.conflictingPathOptionType ./pathWith.nix

# types.pathWith { inStore = true; absolute = false; }
checkConfigError 'In pathWith, inStore means the path must be absolute' config.impossiblePathOptionType ./pathWith.nix

# mkDefinition
# check that mkDefinition 'file' is printed in the error message
checkConfigError 'Cannot merge definitions.*\n\s*- In .file.*\n\s*- In .other.*' config.conflict ./mkDefinition.nix
checkConfigError 'A definition for option .viaOptionDefault. is not of type .boolean.*' config.viaOptionDefault ./mkDefinition.nix
checkConfigOutput '^true$' config.viaConfig ./mkDefinition.nix
checkConfigOutput '^true$' config.mkMerge ./mkDefinition.nix
checkConfigOutput '^true$' config.mkForce ./mkDefinition.nix

# specialArgs._class
checkConfigOutput '"nixos"' config.nixos.config.foo ./specialArgs-class.nix
checkConfigOutput '"bar"' config.conditionalImportAsNixos.config.foo ./specialArgs-class.nix
checkConfigError 'attribute .*bar.* not found' config.conditionalImportAsNixos.config.bar ./specialArgs-class.nix
checkConfigError 'attribute .*foo.* not found' config.conditionalImportAsDarwin.config.foo ./specialArgs-class.nix
checkConfigOutput '"foo"' config.conditionalImportAsDarwin.config.bar ./specialArgs-class.nix
checkConfigOutput '"nixos"' config.sub.nixos.foo ./specialArgs-class.nix
checkConfigOutput '"bar"' config.sub.conditionalImportAsNixos.foo ./specialArgs-class.nix
checkConfigError 'attribute .*bar.* not found' config.sub.conditionalImportAsNixos.bar ./specialArgs-class.nix
checkConfigError 'attribute .*foo.* not found' config.sub.conditionalImportAsDarwin.foo ./specialArgs-class.nix
checkConfigOutput '"foo"' config.sub.conditionalImportAsDarwin.bar ./specialArgs-class.nix

cat <<EOF
====== module tests ======
$pass Pass
$fail Fail
EOF

if [ "$fail" -ne 0 ]; then
    exit 1
fi
exit 0
</file>

<file path="lib/tests/network.sh">
#!/usr/bin/env bash

# Tests lib/network.nix
# Run:
# [nixpkgs]$ lib/tests/network.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -euo pipefail
shopt -s inherit_errexit

if [[ -n "${TEST_LIB:-}" ]]; then
  NIX_PATH=nixpkgs="$(dirname "$TEST_LIB")"
else
  NIX_PATH=nixpkgs="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.."; pwd)"
fi
export NIX_PATH

die() {
  echo >&2 "test case failed: " "$@"
  exit 1
}

tmp="$(mktemp -d)"
clean_up() {
    rm -rf "$tmp"
}
trap clean_up EXIT SIGINT SIGTERM
work="$tmp/work"
mkdir "$work"
cd "$work"

prefixExpression='
  let
    lib = import <nixpkgs/lib>;
    internal = import <nixpkgs/lib/network/internal.nix> {
      inherit lib;
    };
  in
  with lib;
  with lib.network;
'

expectSuccess() {
    local expr=$1
    local expectedResult=$2
    if ! result=$(nix-instantiate --eval --strict --json --show-trace \
        --expr "$prefixExpression ($expr)"); then
        die "$expr failed to evaluate, but it was expected to succeed"
    fi
    if [[ ! "$result" == "$expectedResult" ]]; then
        die "$expr == $result, but $expectedResult was expected"
    fi
}

expectSuccessRegex() {
    local expr=$1
    local expectedResultRegex=$2
    if ! result=$(nix-instantiate --eval --strict --json --show-trace \
        --expr "$prefixExpression ($expr)"); then
        die "$expr failed to evaluate, but it was expected to succeed"
    fi
    if [[ ! "$result" =~ $expectedResultRegex ]]; then
        die "$expr == $result, but $expectedResultRegex was expected"
    fi
}

expectFailure() {
    local expr=$1
    local expectedErrorRegex=$2
    if result=$(nix-instantiate --eval --strict --json --show-trace 2>"$work/stderr" \
        --expr "$prefixExpression ($expr)"); then
        die "$expr evaluated successfully to $result, but it was expected to fail"
    fi
    if [[ ! "$(<"$work/stderr")" =~ $expectedErrorRegex ]]; then
        die "Error was $(<"$work/stderr"), but $expectedErrorRegex was expected"
    fi
}

# Internal functions
expectSuccess '(internal._ipv6.split "0:0:0:0:0:0:0:0").address'                         '[0,0,0,0,0,0,0,0]'
expectSuccess '(internal._ipv6.split "000a:000b:000c:000d:000e:000f:ffff:aaaa").address' '[10,11,12,13,14,15,65535,43690]'
expectSuccess '(internal._ipv6.split "::").address'                                      '[0,0,0,0,0,0,0,0]'
expectSuccess '(internal._ipv6.split "::0000").address'                                  '[0,0,0,0,0,0,0,0]'
expectSuccess '(internal._ipv6.split "::1").address'                                     '[0,0,0,0,0,0,0,1]'
expectSuccess '(internal._ipv6.split "::ffff").address'                                  '[0,0,0,0,0,0,0,65535]'
expectSuccess '(internal._ipv6.split "::000f").address'                                  '[0,0,0,0,0,0,0,15]'
expectSuccess '(internal._ipv6.split "::1:1:1:1:1:1:1").address'                         '[0,1,1,1,1,1,1,1]'
expectSuccess '(internal._ipv6.split "1::").address'                                     '[1,0,0,0,0,0,0,0]'
expectSuccess '(internal._ipv6.split "1:1:1:1:1:1:1::").address'                         '[1,1,1,1,1,1,1,0]'
expectSuccess '(internal._ipv6.split "1:1:1:1::1:1:1").address'                          '[1,1,1,1,0,1,1,1]'
expectSuccess '(internal._ipv6.split "1::1").address'                                    '[1,0,0,0,0,0,0,1]'

expectFailure 'internal._ipv6.split "0:0:0:0:0:0:0:-1"' "contains malformed characters for IPv6 address"
expectFailure 'internal._ipv6.split "::0:"'              "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split ":0::"'              "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "0::0:"'             "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "0:0:"'              "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "0:0:0:0:0:0:0:0:0"' "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "0:0:0:0:0:0:0:0:"'  "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "::0:0:0:0:0:0:0:0"' "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "0::0:0:0:0:0:0:0"'  "is not a valid IPv6 address"
expectFailure 'internal._ipv6.split "::10000"'           "0x10000 is not a valid u16 integer"

expectSuccess '(internal._ipv6.split "::").prefixLength'     '128'
expectSuccess '(internal._ipv6.split "::/1").prefixLength'   '1'
expectSuccess '(internal._ipv6.split "::/128").prefixLength' '128'

expectFailure '(internal._ipv6.split "::/0").prefixLength'   "IPv6 subnet should be in range \[1;128\], got 0"
expectFailure '(internal._ipv6.split "::/129").prefixLength' "IPv6 subnet should be in range \[1;128\], got 129"
expectFailure '(internal._ipv6.split "/::/").prefixLength'   "is not a valid IPv6 address in CIDR notation"

# Library API
expectSuccess 'lib.network.ipv6.fromString "2001:DB8::ffff/64"' '{"address":"2001:db8:0:0:0:0:0:ffff","prefixLength":64}'
expectSuccess 'lib.network.ipv6.fromString "1234:5678:90ab:cdef:fedc:ba09:8765:4321/44"' '{"address":"1234:5678:90ab:cdef:fedc:ba09:8765:4321","prefixLength":44}'

echo >&2 tests ok
</file>

<file path="lib/tests/nix-for-tests.nix">
{
  lib ? pkgs.lib,
  pkgs,
}:

# The aws-sdk-cpp tests are flaky.  Since pull requests to staging
# cause nix to be rebuilt, this means that staging PRs end up
# getting false CI failures due to whatever is flaky in the AWS
# SDK tests.  Since none of our CI needs to (or should be able to)
# contact AWS S3, let's just omit it all from the Nix that runs
# CI.  Bonus: the tests build way faster.
#
# See also: https://github.com/NixOS/nix/issues/7582

builtins.mapAttrs (
  attr: pkg:
  if lib.versionAtLeast pkg.version "2.29pre" then
    pkg.overrideScope (finalScope: prevScope: { aws-sdk-cpp = null; })
  else
    pkg.override { withAWS = false; }
) pkgs.nixVersions
</file>

<file path="lib/tests/release.nix">
{
  # The pkgs used for dependencies for the testing itself
  # Don't test properties of pkgs.lib, but rather the lib in the parent directory
  system ? builtins.currentSystem,
  pkgs ?
    import ../.. {
      inherit system;
      config = {
        permittedInsecurePackages = [ "nix-2.3.18" ];
      };
    }
    // {
      lib = throw "pkgs.lib accessed, but the lib tests should use nixpkgs' lib path directly!";
    },
  # For testing someone may edit impure.nix to return cross pkgs, use `pkgsBuildBuild` directly so everything here works.
  pkgsBB ? pkgs.pkgsBuildBuild,
  nix ? pkgs-nixVersions.stable,
  nixVersions ? [
    pkgs-nixVersions.minimum
    nix
    pkgs-nixVersions.latest
  ],
  pkgs-nixVersions ? import ./nix-for-tests.nix { pkgs = pkgsBB; },
}:

let
  lib = import ../.;
  testWithNix =
    nix:
    import ./test-with-nix.nix {
      inherit lib nix;
      pkgs = pkgsBB;
    };

in
pkgsBB.symlinkJoin {
  name = "nixpkgs-lib-tests";
  paths = map testWithNix nixVersions ++ [
    (import ./maintainers.nix {
      inherit pkgs;
      lib = import ../.;
    })
    (import ./teams.nix {
      inherit pkgs;
      lib = import ../.;
    })
  ];
}
</file>

<file path="lib/tests/sources.sh">
#!/usr/bin/env bash

# Tests lib/sources.nix
# Run:
# [nixpkgs]$ lib/tests/sources.sh
# or:
# [nixpkgs]$ nix-build lib/tests/release.nix

set -euo pipefail
shopt -s inherit_errexit

# Use
#     || die
die() {
  echo >&2 "test case failed: " "$@"
  exit 1
}

if test -n "${TEST_LIB:-}"; then
  NIX_PATH=nixpkgs="$(dirname "$TEST_LIB")"
else
  NIX_PATH=nixpkgs="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.."; pwd)"
fi
export NIX_PATH

work="$(mktemp -d)"
clean_up() {
  rm -rf "$work"
}
trap clean_up EXIT
cd "$work"

# Crudely unquotes a JSON string by just taking everything between the first and the second quote.
# We're only using this for resulting /nix/store paths, which can't contain " anyways,
# nor can they contain any other characters that would need to be escaped specially in JSON
# This way we don't need to add a dependency on e.g. jq
crudeUnquoteJSON() {
    cut -d \" -f2
}

touch {README.md,module.o,foo.bar}

dir="$(nix-instantiate --eval --strict --read-write-mode --json --expr '(with import <nixpkgs/lib>; "${
  cleanSource ./.
}")' | crudeUnquoteJSON)"
(cd "$dir"; find) | sort -f | diff -U10 - <(cat <<EOF
.
./foo.bar
./README.md
EOF
) || die "cleanSource 1"


dir="$(nix-instantiate --eval --strict --read-write-mode --json --expr '(with import <nixpkgs/lib>; "${
  cleanSourceWith { src = '"$work"'; filter = path: type: ! hasSuffix ".bar" path; }
}")' | crudeUnquoteJSON)"
(cd "$dir"; find) | sort -f | diff -U10 - <(cat <<EOF
.
./module.o
./README.md
EOF
) || die "cleanSourceWith 1"

dir="$(nix-instantiate --eval --strict --read-write-mode --json --expr '(with import <nixpkgs/lib>; "${
  cleanSourceWith { src = cleanSource '"$work"'; filter = path: type: ! hasSuffix ".bar" path; }
}")' | crudeUnquoteJSON)"
(cd "$dir"; find) | sort -f | diff -U10 - <(cat <<EOF
.
./README.md
EOF
) || die "cleanSourceWith + cleanSource"

echo >&2 tests ok
</file>

<file path="lib/tests/systems.nix">
# Run:
# [nixpkgs]$ nix-instantiate --eval --strict lib/tests/systems.nix
# Expected output: [], or the failed cases
#
# OfBorg runs (approximately) nix-build lib/tests/release.nix
let
  lib = import ../default.nix;
  mseteq = x: y: {
    expr = lib.sort lib.lessThan x;
    expected = lib.sort lib.lessThan y;
  };

  /*
    Try to convert an elaborated system back to a simple string. If not possible,
    return null. So we have the property:

        sys: _valid_ sys ->
          sys == elaborate (toLosslessStringMaybe sys)

    NOTE: This property is not guaranteed when `sys` was elaborated by a different
          version of Nixpkgs.
  */
  toLosslessStringMaybe =
    sys:
    if lib.isString sys then
      sys
    else if lib.systems.equals sys (lib.systems.elaborate sys.system) then
      sys.system
    else
      null;

in
lib.runTests (
  # We assert that the new algorithmic way of generating these lists matches the
  # way they were hard-coded before.
  #
  # One might think "if we exhaustively test, what's the point of procedurally
  # calculating the lists anyway?". The answer is one can mindlessly update these
  # tests as new platforms become supported, and then just give the diff a quick
  # sanity check before committing :).

  (with lib.systems.doubles; {
    testall = mseteq all (
      linux
      ++ darwin
      ++ freebsd
      ++ openbsd
      ++ netbsd
      ++ illumos
      ++ wasi
      ++ windows
      ++ embedded
      ++ mmix
      ++ js
      ++ genode
      ++ redox
    );

    testarm = mseteq arm [
      "armv5tel-linux"
      "armv6l-linux"
      "armv6l-netbsd"
      "armv6l-none"
      "armv7a-linux"
      "armv7a-netbsd"
      "armv7l-linux"
      "armv7l-netbsd"
      "arm-none"
    ];
    testarmv7 = mseteq armv7 [
      "armv7a-linux"
      "armv7l-linux"
      "armv7a-netbsd"
      "armv7l-netbsd"
    ];
    testi686 = mseteq i686 [
      "i686-linux"
      "i686-freebsd"
      "i686-genode"
      "i686-netbsd"
      "i686-openbsd"
      "i686-cygwin"
      "i686-windows"
      "i686-none"
    ];
    testmips = mseteq mips [
      "mips-none"
      "mips64-none"
      "mips-linux"
      "mips64-linux"
      "mips64el-linux"
      "mipsel-linux"
      "mipsel-netbsd"
    ];
    testmmix = mseteq mmix [ "mmix-mmixware" ];
    testpower = mseteq power [
      "powerpc-netbsd"
      "powerpc-none"
      "powerpc64-linux"
      "powerpc64le-linux"
      "powerpcle-none"
    ];
    testriscv = mseteq riscv [
      "riscv32-linux"
      "riscv64-linux"
      "riscv32-netbsd"
      "riscv64-netbsd"
      "riscv32-none"
      "riscv64-none"
    ];
    testriscv32 = mseteq riscv32 [
      "riscv32-linux"
      "riscv32-netbsd"
      "riscv32-none"
    ];
    testriscv64 = mseteq riscv64 [
      "riscv64-linux"
      "riscv64-netbsd"
      "riscv64-none"
    ];
    tests390x = mseteq s390x [
      "s390x-linux"
      "s390x-none"
    ];
    testx86_64 = mseteq x86_64 [
      "x86_64-linux"
      "x86_64-darwin"
      "x86_64-freebsd"
      "x86_64-genode"
      "x86_64-redox"
      "x86_64-openbsd"
      "x86_64-netbsd"
      "x86_64-cygwin"
      "x86_64-solaris"
      "x86_64-windows"
      "x86_64-none"
    ];

    testcygwin = mseteq cygwin [
      "i686-cygwin"
      "x86_64-cygwin"
    ];
    testdarwin = mseteq darwin [
      "x86_64-darwin"
      "aarch64-darwin"
    ];
    testfreebsd = mseteq freebsd [
      "aarch64-freebsd"
      "i686-freebsd"
      "x86_64-freebsd"
    ];
    testgenode = mseteq genode [
      "aarch64-genode"
      "i686-genode"
      "x86_64-genode"
    ];
    testredox = mseteq redox [ "x86_64-redox" ];
    testgnu = mseteq gnu (
      linux # ++ kfreebsd ++ ...
    );
    testillumos = mseteq illumos [ "x86_64-solaris" ];
    testlinux = mseteq linux [
      "aarch64-linux"
      "armv5tel-linux"
      "armv6l-linux"
      "armv7a-linux"
      "armv7l-linux"
      "i686-linux"
      "loongarch64-linux"
      "m68k-linux"
      "microblaze-linux"
      "microblazeel-linux"
      "mips-linux"
      "mips64-linux"
      "mips64el-linux"
      "mipsel-linux"
      "powerpc64-linux"
      "powerpc64le-linux"
      "riscv32-linux"
      "riscv64-linux"
      "s390-linux"
      "s390x-linux"
      "x86_64-linux"
    ];
    testnetbsd = mseteq netbsd [
      "aarch64-netbsd"
      "armv6l-netbsd"
      "armv7a-netbsd"
      "armv7l-netbsd"
      "i686-netbsd"
      "m68k-netbsd"
      "mipsel-netbsd"
      "powerpc-netbsd"
      "riscv32-netbsd"
      "riscv64-netbsd"
      "x86_64-netbsd"
    ];
    testopenbsd = mseteq openbsd [
      "i686-openbsd"
      "x86_64-openbsd"
    ];
    testwindows = mseteq windows [
      "i686-cygwin"
      "x86_64-cygwin"
      "aarch64-windows"
      "i686-windows"
      "x86_64-windows"
    ];
    testunix = mseteq unix (
      linux ++ darwin ++ freebsd ++ openbsd ++ netbsd ++ illumos ++ cygwin ++ redox
    );
  })

  // {
    test_equals_example_x86_64-linux = {
      expr = lib.systems.equals (lib.systems.elaborate "x86_64-linux") (
        lib.systems.elaborate "x86_64-linux"
      );
      expected = true;
    };

    test_toLosslessStringMaybe_example_x86_64-linux = {
      expr = toLosslessStringMaybe (lib.systems.elaborate "x86_64-linux");
      expected = "x86_64-linux";
    };
    test_toLosslessStringMaybe_fail = {
      expr = toLosslessStringMaybe (lib.systems.elaborate "x86_64-linux" // { something = "extra"; });
      expected = null;
    };
    test_elaborate_config_over_system = {
      expr =
        (lib.systems.elaborate {
          config = "i686-unknown-linux-gnu";
          system = "x86_64-linux";
        }).system;
      expected = "i686-linux";
    };
    test_elaborate_config_over_parsed = {
      expr =
        (lib.systems.elaborate {
          config = "i686-unknown-linux-gnu";
          parsed = (lib.systems.elaborate "x86_64-linux").parsed;
        }).parsed.cpu.arch;
      expected = "i686";
    };
    test_elaborate_system_over_parsed = {
      expr =
        (lib.systems.elaborate {
          system = "i686-linux";
          parsed = (lib.systems.elaborate "x86_64-linux").parsed;
        }).parsed.cpu.arch;
      expected = "i686";
    };
  }

  # Generate test cases to assert that a change in any non-function attribute makes a platform unequal
  //
    lib.concatMapAttrs
      (platformAttrName: origValue: {

        ${"test_equals_unequal_${platformAttrName}"} =
          let
            modified =
              assert origValue != arbitraryValue;
              lib.systems.elaborate "x86_64-linux" // { ${platformAttrName} = arbitraryValue; };
            arbitraryValue = x: "<<modified>>";
          in
          {
            expr = lib.systems.equals (lib.systems.elaborate "x86_64-linux") modified;
            expected =
              {
                # Changes in these attrs are not detectable because they're function.
                # The functions should be derived from the data, so this is not a problem.
                canExecute = null;
                emulator = null;
                emulatorAvailable = null;
                staticEmulatorAvailable = null;
                isCompatible = null;
              } ? ${platformAttrName};
          };

      })
      (
        lib.systems.elaborate "x86_64-linux" # arbitrary choice, just to get all the elaborated attrNames
      )

)
</file>

<file path="lib/tests/teams.nix">
# to run these tests:
# nix-build nixpkgs/lib/tests/teams.nix
# If it builds, all tests passed
{
  pkgs ? import ../.. { },
  lib ? pkgs.lib,
}:

let
  inherit (lib) types;

  teamModule =
    { config, ... }:
    {
      options = {
        shortName = lib.mkOption {
          type = types.str;
        };
        scope = lib.mkOption {
          type = types.str;
        };
        enableFeatureFreezePing = lib.mkOption {
          type = types.bool;
          default = false;
        };
        members = lib.mkOption {
          type = types.listOf (types.submodule (import ./maintainer-module.nix { inherit lib; }));
          default = [ ];
        };
        githubTeams = lib.mkOption {
          type = types.listOf types.str;
          default = [ ];
        };
      };
    };

  checkTeam =
    team: uncheckedAttrs:
    let
      prefix = [
        "lib"
        "maintainer-team"
        team
      ];
      checkedAttrs =
        (lib.modules.evalModules {
          inherit prefix;
          modules = [
            teamModule
            {
              _file = toString ../../maintainers/team-list.nix;
              config = uncheckedAttrs;
            }
          ];
        }).config;
    in
    checkedAttrs;

  checkedTeams = lib.mapAttrs checkTeam lib.teams;
in
pkgs.writeTextDir "maintainer-teams.json" (builtins.toJSON checkedTeams)
</file>

<file path="lib/tests/test-to-plist-escaped-expected.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>nested</key>
	<dict>
		<key>values</key>
		<dict>
			<key>attrs</key>
			<dict>
				<key>foo b/ar</key>
				<string>baz</string>
			</dict>
			<key>bool</key>
			<true/>
			<key>emptyattrs</key>
			<dict>

			</dict>
			<key>emptylist</key>
			<array>

			</array>
			<key>emptystring</key>
			<string></string>
			<key>float</key>
			<real>0.133700</real>
			<key>int</key>
			<integer>42</integer>
			<key>keys are &lt;escaped&gt;</key>
			<string>and &lt; so are string values</string>
			<key>list</key>
			<array>
				<integer>3</integer>
				<integer>4</integer>
				<string>test</string>
			</array>
			<key>newlinestring</key>
			<string>
</string>
			<key>path</key>
			<string>/foo</string>
			<key>string</key>
			<string>fn${o}&quot;r\d</string>
		</dict>
	</dict>
</dict>
</plist>
</file>

<file path="lib/tests/test-to-plist-expected.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>nested</key>
	<dict>
		<key>values</key>
		<dict>
			<key>attrs</key>
			<dict>
				<key>foo b/ar</key>
				<string>baz</string>
			</dict>
			<key>bool</key>
			<true/>
			<key>emptyattrs</key>
			<dict>

			</dict>
			<key>emptylist</key>
			<array>

			</array>
			<key>emptystring</key>
			<string></string>
			<key>float</key>
			<real>0.133700</real>
			<key>int</key>
			<integer>42</integer>
			<key>list</key>
			<array>
				<integer>3</integer>
				<integer>4</integer>
				<string>test</string>
			</array>
			<key>newlinestring</key>
			<string>
</string>
			<key>path</key>
			<string>/foo</string>
			<key>string</key>
			<string>fn${o}"r\d</string>
		</dict>
	</dict>
</dict>
</plist>
</file>

<file path="lib/tests/test-to-plist-unescaped-expected.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>nested</key>
	<dict>
		<key>values</key>
		<dict>
			<key>attrs</key>
			<dict>
				<key>foo b/ar</key>
				<string>baz</string>
			</dict>
			<key>bool</key>
			<true/>
			<key>emptyattrs</key>
			<dict>

			</dict>
			<key>emptylist</key>
			<array>

			</array>
			<key>emptystring</key>
			<string></string>
			<key>float</key>
			<real>0.133700</real>
			<key>int</key>
			<integer>42</integer>
			<key>keys are not <escaped></key>
			<string>and < neither are string values</string>
			<key>list</key>
			<array>
				<integer>3</integer>
				<integer>4</integer>
				<string>test</string>
			</array>
			<key>newlinestring</key>
			<string>
</string>
			<key>path</key>
			<string>/foo</string>
			<key>string</key>
			<string>fn${o}"r\d</string>
		</dict>
	</dict>
</dict>
</plist>
</file>

<file path="lib/tests/test-with-nix.nix">
/**
  Instantiate the library tests for a given Nix version.

  IMPORTANT:
  This is used by the github.com/NixOS/nix CI.
  This is used by Lix's CI (see flake.nix in the Lix repo).

  Try not to change the interface of this file, or if you need to, ping the
  Nix AND Lix maintainers (`nix eval -f . lib.teams.lix`) for help. Thank you!
*/
{
  pkgs,
  lib,
  # Only ever use this nix; see comment at top
  nix,
}:

pkgs.runCommand "nixpkgs-lib-tests-nix-${nix.version}"
  {
    buildInputs = [
      (import ./check-eval.nix)
      (import ./fetchers.nix)
      (import ../path/tests {
        inherit pkgs;
      })
    ];
    nativeBuildInputs = [
      nix
      pkgs.gitMinimal
    ]
    ++ lib.optional pkgs.stdenv.hostPlatform.isLinux pkgs.inotify-tools;
    strictDeps = true;
  }
  ''
    datadir="${nix}/share"
    export TEST_ROOT=$(pwd)/test-tmp
    export HOME=$(mktemp -d)
    export NIX_BUILD_HOOK=
    export NIX_CONF_DIR=$TEST_ROOT/etc
    export NIX_LOCALSTATE_DIR=$TEST_ROOT/var
    export NIX_LOG_DIR=$TEST_ROOT/var/log/nix
    export NIX_STATE_DIR=$TEST_ROOT/var/nix
    export NIX_STORE_DIR=$TEST_ROOT/store
    export PAGER=cat
    cacheDir=$TEST_ROOT/binary-cache

    nix-store --init

    cp -r ${../.} lib
    echo "Running lib/tests/modules.sh"
    bash lib/tests/modules.sh

    echo "Checking lib.version"
    nix-instantiate lib -A version --eval || {
      echo "lib.version does not evaluate when lib is isolated from the rest of the nixpkgs tree"
      exit 1
    }

    echo "Running lib/tests/filesystem.sh"
    TEST_LIB=$PWD/lib bash lib/tests/filesystem.sh

    echo "Running lib/tests/sources.sh"
    TEST_LIB=$PWD/lib bash lib/tests/sources.sh

    echo "Running lib/tests/network.sh"
    TEST_LIB=$PWD/lib bash lib/tests/network.sh

    echo "Running lib/fileset/tests.sh"
    TEST_LIB=$PWD/lib bash lib/fileset/tests.sh

    echo "Running lib/tests/systems.nix"
    [[ $(nix-instantiate --eval --strict lib/tests/systems.nix | tee /dev/stderr) == '[ ]' ]];

    mkdir $out
    echo success > $out/${nix.version}
  ''
</file>

<file path="lib/.version">
25.11
</file>

<file path="lib/ascii-table.nix">
{
  "\t" = 9;
  "\n" = 10;
  "\r" = 13;
  " " = 32;
  "!" = 33;
  "\"" = 34;
  "#" = 35;
  "$" = 36;
  "%" = 37;
  "&" = 38;
  "'" = 39;
  "(" = 40;
  ")" = 41;
  "*" = 42;
  "+" = 43;
  "," = 44;
  "-" = 45;
  "." = 46;
  "/" = 47;
  "0" = 48;
  "1" = 49;
  "2" = 50;
  "3" = 51;
  "4" = 52;
  "5" = 53;
  "6" = 54;
  "7" = 55;
  "8" = 56;
  "9" = 57;
  ":" = 58;
  ";" = 59;
  "<" = 60;
  "=" = 61;
  ">" = 62;
  "?" = 63;
  "@" = 64;
  "A" = 65;
  "B" = 66;
  "C" = 67;
  "D" = 68;
  "E" = 69;
  "F" = 70;
  "G" = 71;
  "H" = 72;
  "I" = 73;
  "J" = 74;
  "K" = 75;
  "L" = 76;
  "M" = 77;
  "N" = 78;
  "O" = 79;
  "P" = 80;
  "Q" = 81;
  "R" = 82;
  "S" = 83;
  "T" = 84;
  "U" = 85;
  "V" = 86;
  "W" = 87;
  "X" = 88;
  "Y" = 89;
  "Z" = 90;
  "[" = 91;
  "\\" = 92;
  "]" = 93;
  "^" = 94;
  "_" = 95;
  "`" = 96;
  "a" = 97;
  "b" = 98;
  "c" = 99;
  "d" = 100;
  "e" = 101;
  "f" = 102;
  "g" = 103;
  "h" = 104;
  "i" = 105;
  "j" = 106;
  "k" = 107;
  "l" = 108;
  "m" = 109;
  "n" = 110;
  "o" = 111;
  "p" = 112;
  "q" = 113;
  "r" = 114;
  "s" = 115;
  "t" = 116;
  "u" = 117;
  "v" = 118;
  "w" = 119;
  "x" = 120;
  "y" = 121;
  "z" = 122;
  "{" = 123;
  "|" = 124;
  "}" = 125;
  "~" = 126;
}
</file>

<file path="lib/asserts.nix">
{ lib }:

let
  inherit (lib.strings)
    concatStringsSep
    ;
  inherit (lib.lists)
    filter
    ;
  inherit (lib.trivial)
    showWarnings
    ;
in
rec {

  /**
    Throw if pred is false, else return pred.
    Intended to be used to augment asserts with helpful error messages.

    # Inputs

    `pred`

    : Predicate that needs to succeed, otherwise `msg` is thrown

    `msg`

    : Message to throw in case `pred` fails

    # Type

    ```
    assertMsg :: Bool -> String -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.asserts.assertMsg` usage example

    ```nix
    assertMsg false "nope"
    stderr> error: nope
    assert assertMsg ("foo" == "bar") "foo is not bar, silly"; ""
    stderr> error: foo is not bar, silly
    ```

    :::
  */
  # TODO(Profpatsch): add tests that check stderr
  assertMsg = pred: msg: pred || builtins.throw msg;

  /**
    Specialized `assertMsg` for checking if `val` is one of the elements
    of the list `xs`. Useful for checking enums.

    # Inputs

    `name`

    : The name of the variable the user entered `val` into, for inclusion in the error message

    `val`

    : The value of what the user provided, to be compared against the values in `xs`

    `xs`

    : The list of valid values

    # Type

    ```
    assertOneOf :: String -> ComparableVal -> List ComparableVal -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.asserts.assertOneOf` usage example

    ```nix
    let sslLibrary = "libressl";
    in assertOneOf "sslLibrary" sslLibrary [ "openssl" "bearssl" ]
    stderr> error: sslLibrary must be one of [
    stderr>   "openssl"
    stderr>   "bearssl"
    stderr> ], but is: "libressl"
    ```

    :::
  */
  assertOneOf =
    name: val: xs:
    assertMsg (lib.elem val xs) "${name} must be one of ${lib.generators.toPretty { } xs}, but is: ${
      lib.generators.toPretty { } val
    }";

  /**
    Specialized `assertMsg` for checking if every one of `vals` is one of the elements
    of the list `xs`. Useful for checking lists of supported attributes.

    # Inputs

    `name`

    : The name of the variable the user entered `val` into, for inclusion in the error message

    `vals`

    : The list of values of what the user provided, to be compared against the values in `xs`

    `xs`

    : The list of valid values

    # Type

    ```
    assertEachOneOf :: String -> List ComparableVal -> List ComparableVal -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.asserts.assertEachOneOf` usage example

    ```nix
    let sslLibraries = [ "libressl" "bearssl" ];
    in assertEachOneOf "sslLibraries" sslLibraries [ "openssl" "bearssl" ]
    stderr> error: each element in sslLibraries must be one of [
    stderr>   "openssl"
    stderr>   "bearssl"
    stderr> ], but is: [
    stderr>   "libressl"
    stderr>   "bearssl"
    stderr> ]
    ```

    :::
  */
  assertEachOneOf =
    name: vals: xs:
    assertMsg (lib.all (val: lib.elem val xs) vals)
      "each element in ${name} must be one of ${lib.generators.toPretty { } xs}, but is: ${
        lib.generators.toPretty { } vals
      }";

  /**
    Wrap a value with logic that throws an error when assertions
    fail and emits any warnings.

    # Inputs

    `assertions`

    : A list of assertions. If any of their `assertion` attrs is `false`, their `message` attrs will be emitted in a `throw`.

    `warnings`

    : A list of strings to emit as warnings. This function does no filtering on this list.

    `val`

    : A value to return, wrapped in `warn`, if a `throw` is not necessary.

    # Type

    ```
    checkAssertWarn :: [ { assertion :: Bool; message :: String } ] -> [ String ] -> Any -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.asserts.checkAssertWarn` usage example
    ```nix
    checkAssertWarn
      [ { assertion = false; message = "Will fail"; } ]
      [ ]
      null
    stderr>        error:
    stderr>        Failed assertions:
    stderr>        - Will fail

    checkAssertWarn
      [ { assertion = true; message = "Will not fail"; } ]
      [ "Will warn" ]
      null
    stderr> evaluation warning: Will warn
    null
    ```

    :::
  */
  checkAssertWarn =
    assertions: warnings: val:
    let
      failedAssertions = map (x: x.message) (filter (x: !x.assertion) assertions);
    in
    if failedAssertions != [ ] then
      throw "\nFailed assertions:\n${concatStringsSep "\n" (map (x: "- ${x}") failedAssertions)}"
    else
      showWarnings warnings val;

}
</file>

<file path="lib/attrsets.nix">
/**
  Operations on attribute sets.
*/
{ lib }:

let
  inherit (builtins) head length;
  inherit (lib.trivial)
    oldestSupportedReleaseIsAtLeast
    mergeAttrs
    warn
    warnIf
    ;
  inherit (lib.strings)
    concatStringsSep
    concatMapStringsSep
    escapeNixIdentifier
    sanitizeDerivationName
    ;
  inherit (lib.lists)
    filter
    foldr
    foldl'
    concatMap
    elemAt
    all
    partition
    groupBy
    take
    foldl
    ;
in

rec {
  inherit (builtins)
    attrNames
    listToAttrs
    hasAttr
    isAttrs
    getAttr
    removeAttrs
    intersectAttrs
    ;

  /**
    Return an attribute from nested attribute sets.

    Nix has an [attribute selection operator `.`](https://nixos.org/manual/nix/stable/language/operators#attribute-selection) which is sufficient for such queries, as long as the number of attributes is static. For example:

    ```nix
    (x.a.b or 6) == attrByPath ["a" "b"] 6 x
    # and
    (x.${f p}."example.com" or 6) == attrByPath [ (f p) "example.com" ] 6 x
    ```

    # Inputs

    `attrPath`

    : A list of strings representing the attribute path to return from `set`

    `default`

    : Default value if `attrPath` does not resolve to an existing value

    `set`

    : The nested attribute set to select values from

    # Type

    ```
    attrByPath :: [String] -> Any -> AttrSet -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.attrByPath` usage example

    ```nix
    x = { a = { b = 3; }; }
    # ["a" "b"] is equivalent to x.a.b
    # 6 is a default value to return if the path does not exist in attrset
    attrByPath ["a" "b"] 6 x
    => 3
    attrByPath ["z" "z"] 6 x
    => 6
    ```

    :::
  */
  attrByPath =
    attrPath: default: set:
    let
      lenAttrPath = length attrPath;
      attrByPath' =
        n: s:
        (
          if n == lenAttrPath then
            s
          else
            (
              let
                attr = elemAt attrPath n;
              in
              if s ? ${attr} then attrByPath' (n + 1) s.${attr} else default
            )
        );
    in
    attrByPath' 0 set;

  /**
    Return if an attribute from nested attribute set exists.

    Nix has a [has attribute operator `?`](https://nixos.org/manual/nix/stable/language/operators#has-attribute), which is sufficient for such queries, as long as the number of attributes is static. For example:

    ```nix
    (x?a.b) == hasAttrByPath ["a" "b"] x
    # and
    (x?${f p}."example.com") == hasAttrByPath [ (f p) "example.com" ] x
    ```

    **Laws**:
     1.  ```nix
         hasAttrByPath [] x == true
         ```

    # Inputs

    `attrPath`

    : A list of strings representing the attribute path to check from `set`

    `e`

    : The nested attribute set to check

    # Type

    ```
    hasAttrByPath :: [String] -> AttrSet -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.hasAttrByPath` usage example

    ```nix
    x = { a = { b = 3; }; }
    hasAttrByPath ["a" "b"] x
    => true
    hasAttrByPath ["z" "z"] x
    => false
    hasAttrByPath [] (throw "no need")
    => true
    ```

    :::
  */
  hasAttrByPath =
    attrPath: e:
    let
      lenAttrPath = length attrPath;
      hasAttrByPath' =
        n: s:
        (
          n == lenAttrPath
          || (
            let
              attr = elemAt attrPath n;
            in
            if s ? ${attr} then hasAttrByPath' (n + 1) s.${attr} else false
          )
        );
    in
    hasAttrByPath' 0 e;

  /**
    Return the longest prefix of an attribute path that refers to an existing attribute in a nesting of attribute sets.

    Can be used after [`mapAttrsRecursiveCond`](#function-library-lib.attrsets.mapAttrsRecursiveCond) to apply a condition,
    although this will evaluate the predicate function on sibling attributes as well.

    Note that the empty attribute path is valid for all values, so this function only throws an exception if any of its inputs does.

    **Laws**:
    1.  ```nix
        attrsets.longestValidPathPrefix [] x == []
        ```

    2.  ```nix
        hasAttrByPath (attrsets.longestValidPathPrefix p x) x == true
        ```

    # Inputs

    `attrPath`

    : A list of strings representing the longest possible path that may be returned.

    `v`

    : The nested attribute set to check.

    # Type

    ```
    attrsets.longestValidPathPrefix :: [String] -> Value -> [String]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.longestValidPathPrefix` usage example

    ```nix
    x = { a = { b = 3; }; }
    attrsets.longestValidPathPrefix ["a" "b" "c"] x
    => ["a" "b"]
    attrsets.longestValidPathPrefix ["a"] x
    => ["a"]
    attrsets.longestValidPathPrefix ["z" "z"] x
    => []
    attrsets.longestValidPathPrefix ["z" "z"] (throw "no need")
    => []
    ```

    :::
  */
  longestValidPathPrefix =
    attrPath: v:
    let
      lenAttrPath = length attrPath;
      getPrefixForSetAtIndex =
        # The nested attribute set to check, if it is an attribute set, which
        # is not a given.
        remainingSet:
        # The index of the attribute we're about to check, as well as
        # the length of the prefix we've already checked.
        remainingPathIndex:

        if remainingPathIndex == lenAttrPath then
          # All previously checked attributes exist, and no attr names left,
          # so we return the whole path.
          attrPath
        else
          let
            attr = elemAt attrPath remainingPathIndex;
          in
          if remainingSet ? ${attr} then
            getPrefixForSetAtIndex remainingSet.${attr} # advance from the set to the attribute value
              (remainingPathIndex + 1) # advance the path
          else
            # The attribute doesn't exist, so we return the prefix up to the
            # previously checked length.
            take remainingPathIndex attrPath;
    in
    getPrefixForSetAtIndex v 0;

  /**
    Create a new attribute set with `value` set at the nested attribute location specified in `attrPath`.

    # Inputs

    `attrPath`

    : A list of strings representing the attribute path to set

    `value`

    : The value to set at the location described by `attrPath`

    # Type

    ```
    setAttrByPath :: [String] -> Any -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.setAttrByPath` usage example

    ```nix
    setAttrByPath ["a" "b"] 3
    => { a = { b = 3; }; }
    ```

    :::
  */
  setAttrByPath =
    attrPath: value:
    let
      len = length attrPath;
      atDepth = n: if n == len then value else { ${elemAt attrPath n} = atDepth (n + 1); };
    in
    atDepth 0;

  /**
    Like `attrByPath`, but without a default value. If it doesn't find the
    path it will throw an error.

    Nix has an [attribute selection operator](https://nixos.org/manual/nix/stable/language/operators#attribute-selection) which is sufficient for such queries, as long as the number of attributes is static. For example:

    ```nix
    x.a.b == getAttrFromPath ["a" "b"] x
    # and
    x.${f p}."example.com" == getAttrFromPath [ (f p) "example.com" ] x
    ```

    # Inputs

    `attrPath`

    : A list of strings representing the attribute path to get from `set`

    `set`

    : The nested attribute set to find the value in.

    # Type

    ```
    getAttrFromPath :: [String] -> AttrSet -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getAttrFromPath` usage example

    ```nix
    x = { a = { b = 3; }; }
    getAttrFromPath ["a" "b"] x
    => 3
    getAttrFromPath ["z" "z"] x
    => error: cannot find attribute `z.z'
    ```

    :::
  */
  getAttrFromPath =
    attrPath: set:
    attrByPath attrPath (abort ("cannot find attribute '" + concatStringsSep "." attrPath + "'")) set;

  /**
    Map each attribute in the given set and merge them into a new attribute set.

    # Inputs

    `f`

    : 1\. Function argument

    `v`

    : 2\. Function argument

    # Type

    ```
    concatMapAttrs :: (String -> a -> AttrSet) -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.concatMapAttrs` usage example

    ```nix
    concatMapAttrs
      (name: value: {
        ${name} = value;
        ${name + value} = value;
      })
      { x = "a"; y = "b"; }
    => { x = "a"; xa = "a"; y = "b"; yb = "b"; }
    ```

    :::
  */
  concatMapAttrs = f: v: foldl' mergeAttrs { } (attrValues (mapAttrs f v));

  /**
    Update or set specific paths of an attribute set.

    Takes a list of updates to apply and an attribute set to apply them to,
    and returns the attribute set with the updates applied. Updates are
    represented as `{ path = ...; update = ...; }` values, where `path` is a
    list of strings representing the attribute path that should be updated,
    and `update` is a function that takes the old value at that attribute path
    as an argument and returns the new
    value it should be.

    Properties:

    - Updates to deeper attribute paths are applied before updates to more
      shallow attribute paths

    - Multiple updates to the same attribute path are applied in the order
      they appear in the update list

    - If any but the last `path` element leads into a value that is not an
      attribute set, an error is thrown

    - If there is an update for an attribute path that doesn't exist,
      accessing the argument in the update function causes an error, but
      intermediate attribute sets are implicitly created as needed

    # Type

    ```
    updateManyAttrsByPath :: [{ path :: [String]; update :: (Any -> Any); }] -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.updateManyAttrsByPath` usage example

    ```nix
    updateManyAttrsByPath [
      {
        path = [ "a" "b" ];
        update = old: { d = old.c; };
      }
      {
        path = [ "a" "b" "c" ];
        update = old: old + 1;
      }
      {
        path = [ "x" "y" ];
        update = old: "xy";
      }
    ] { a.b.c = 0; }
    => { a = { b = { d = 1; }; }; x = { y = "xy"; }; }
    ```

    :::
  */
  updateManyAttrsByPath =
    let
      # When recursing into attributes, instead of updating the `path` of each
      # update using `tail`, which needs to allocate an entirely new list,
      # we just pass a prefix length to use and make sure to only look at the
      # path without the prefix length, so that we can reuse the original list
      # entries.
      go =
        prefixLength: hasValue: value: updates:
        let
          # Splits updates into ones on this level (split.right)
          # And ones on levels further down (split.wrong)
          split = partition (el: length el.path == prefixLength) updates;

          # Groups updates on further down levels into the attributes they modify
          nested = groupBy (el: elemAt el.path prefixLength) split.wrong;

          # Applies only nested modification to the input value
          withNestedMods =
            # Return the value directly if we don't have any nested modifications
            if split.wrong == [ ] then
              if hasValue then
                value
              else
                # Throw an error if there is no value. This `head` call here is
                # safe, but only in this branch since `go` could only be called
                # with `hasValue == false` for nested updates, in which case
                # it's also always called with at least one update
                let
                  updatePath = (head split.right).path;
                in
                throw (
                  "updateManyAttrsByPath: Path '${showAttrPath updatePath}' does "
                  + "not exist in the given value, but the first update to this "
                  + "path tries to access the existing value."
                )
            else
            # If there are nested modifications, try to apply them to the value
            if !hasValue then
              # But if we don't have a value, just use an empty attribute set
              # as the value, but simplify the code a bit
              mapAttrs (name: go (prefixLength + 1) false null) nested
            else if isAttrs value then
              # If we do have a value and it's an attribute set, override it
              # with the nested modifications
              value // mapAttrs (name: go (prefixLength + 1) (value ? ${name}) value.${name}) nested
            else
              # However if it's not an attribute set, we can't apply the nested
              # modifications, throw an error
              let
                updatePath = (head split.wrong).path;
              in
              throw (
                "updateManyAttrsByPath: Path '${showAttrPath updatePath}' needs to "
                + "be updated, but path '${showAttrPath (take prefixLength updatePath)}' "
                + "of the given value is not an attribute set, so we can't "
                + "update an attribute inside of it."
              );

          # We get the final result by applying all the updates on this level
          # after having applied all the nested updates
          # We use foldl instead of foldl' so that in case of multiple updates,
          # intermediate values aren't evaluated if not needed
        in
        foldl (acc: el: el.update acc) withNestedMods split.right;

    in
    updates: value: go 0 true value updates;

  /**
    Return the specified attributes from a set.

    # Inputs

    `nameList`

    : The list of attributes to fetch from `set`. Each attribute name must exist on the attrbitue set

    `set`

    : The set to get attribute values from

    # Type

    ```
    attrVals :: [String] -> AttrSet -> [Any]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.attrVals` usage example

    ```nix
    attrVals ["a" "b" "c"] as
    => [as.a as.b as.c]
    ```

    :::
  */
  attrVals = nameList: set: map (x: set.${x}) nameList;

  /**
    Return the values of all attributes in the given set, sorted by
    attribute name.

    # Type

    ```
    attrValues :: AttrSet -> [Any]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.attrValues` usage example

    ```nix
    attrValues {c = 3; a = 1; b = 2;}
    => [1 2 3]
    ```

    :::
  */
  attrValues = builtins.attrValues;

  /**
    Given a set of attribute names, return the set of the corresponding
    attributes from the given set.

    # Inputs

    `names`

    : A list of attribute names to get out of `set`

    `attrs`

    : The set to get the named attributes from

    # Type

    ```
    getAttrs :: [String] -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getAttrs` usage example

    ```nix
    getAttrs [ "a" "b" ] { a = 1; b = 2; c = 3; }
    => { a = 1; b = 2; }
    ```

    :::
  */
  getAttrs = names: attrs: genAttrs names (name: attrs.${name});

  /**
    Collect each attribute named `attr` from a list of attribute
    sets.  Sets that don't contain the named attribute are ignored.

    # Inputs

    `attr`

    : The attribute name to get out of the sets.

    `list`

    : The list of attribute sets to go through

    # Type

    ```
    catAttrs :: String -> [AttrSet] -> [Any]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.catAttrs` usage example

    ```nix
    catAttrs "a" [{a = 1;} {b = 0;} {a = 2;}]
    => [1 2]
    ```

    :::
  */
  catAttrs = builtins.catAttrs;

  /**
    Filter an attribute set by removing all attributes for which the
    given predicate return false.

    # Inputs

    `pred`

    : Predicate taking an attribute name and an attribute value, which returns `true` to include the attribute, or `false` to exclude the attribute.

    `set`

    : The attribute set to filter

    # Type

    ```
    filterAttrs :: (String -> Any -> Bool) -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.filterAttrs` usage example

    ```nix
    filterAttrs (n: v: n == "foo") { foo = 1; bar = 2; }
    => { foo = 1; }
    ```

    :::
  */
  filterAttrs = pred: set: removeAttrs set (filter (name: !pred name set.${name}) (attrNames set));

  /**
    Filter an attribute set recursively by removing all attributes for
    which the given predicate return false.

    # Inputs

    `pred`

    : Predicate taking an attribute name and an attribute value, which returns `true` to include the attribute, or `false` to exclude the attribute.

    `set`

    : The attribute set to filter

    # Type

    ```
    filterAttrsRecursive :: (String -> Any -> Bool) -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.filterAttrsRecursive` usage example

    ```nix
    filterAttrsRecursive (n: v: v != null) { foo = { bar = null; }; }
    => { foo = {}; }
    ```

    :::
  */
  filterAttrsRecursive =
    pred: set:
    listToAttrs (
      concatMap (
        name:
        let
          v = set.${name};
        in
        if pred name v then
          [
            (nameValuePair name (if isAttrs v then filterAttrsRecursive pred v else v))
          ]
        else
          [ ]
      ) (attrNames set)
    );

  /**
    Like [`lib.lists.foldl'`](#function-library-lib.lists.foldl-prime) but for attribute sets.
    Iterates over every name-value pair in the given attribute set.
    The result of the callback function is often called `acc` for accumulator. It is passed between callbacks from left to right and the final `acc` is the return value of `foldlAttrs`.

    Attention:

    There is a completely different function `lib.foldAttrs`
    which has nothing to do with this function, despite the similar name.

    # Inputs

    `f`

    : 1\. Function argument

    `init`

    : 2\. Function argument

    `set`

    : 3\. Function argument

    # Type

    ```
    foldlAttrs :: ( a -> String -> b -> a ) -> a -> { ... :: b } -> a
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.foldlAttrs` usage example

    ```nix
    foldlAttrs
      (acc: name: value: {
        sum = acc.sum + value;
        names = acc.names ++ [name];
      })
      { sum = 0; names = []; }
      {
        foo = 1;
        bar = 10;
      }
    ->
      {
        sum = 11;
        names = ["bar" "foo"];
      }

    foldlAttrs
      (throw "function not needed")
      123
      {};
    ->
      123

    foldlAttrs
      (acc: _: _: acc)
      3
      { z = throw "value not needed"; a = throw "value not needed"; };
    ->
      3

    The accumulator doesn't have to be an attrset.
    It can be as simple as a number or string.

    foldlAttrs
      (acc: _: v: acc * 10 + v)
      1
      { z = 1; a = 2; };
    ->
      121
    ```

    :::
  */
  foldlAttrs =
    f: init: set:
    foldl' (acc: name: f acc name set.${name}) init (attrNames set);

  /**
    Apply fold functions to values grouped by key.

    # Inputs

    `op`

    : A function, given a value and a collector combines the two.

    `nul`

    : The starting value.

    `list_of_attrs`

    : A list of attribute sets to fold together by key.

    # Type

    ```
    foldAttrs :: (Any -> Any -> Any) -> Any -> [AttrSets] -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.foldAttrs` usage example

    ```nix
    foldAttrs (item: acc: [item] ++ acc) [] [{ a = 2; } { a = 3; }]
    => { a = [ 2 3 ]; }
    ```

    :::
  */
  foldAttrs =
    op: nul: list_of_attrs:
    foldr (
      n: a: foldr (name: o: o // { ${name} = op n.${name} (a.${name} or nul); }) a (attrNames n)
    ) { } list_of_attrs;

  /**
    Recursively collect sets that verify a given predicate named `pred`
    from the set `attrs`. The recursion is stopped when the predicate is
    verified.

    # Inputs

    `pred`

    : Given an attribute's value, determine if recursion should stop.

    `attrs`

    : The attribute set to recursively collect.

    # Type

    ```
    collect :: (AttrSet -> Bool) -> AttrSet -> [x]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.collect` usage example

    ```nix
    collect isList { a = { b = ["b"]; }; c = [1]; }
    => [["b"] [1]]

    collect (x: x ? outPath)
       { a = { outPath = "a/"; }; b = { outPath = "b/"; }; }
    => [{ outPath = "a/"; } { outPath = "b/"; }]
    ```

    :::
  */
  collect =
    pred: attrs:
    if pred attrs then
      [ attrs ]
    else if isAttrs attrs then
      concatMap (collect pred) (attrValues attrs)
    else
      [ ];

  /**
    Return the cartesian product of attribute set value combinations.

    # Inputs

    `attrsOfLists`

    : Attribute set with attributes that are lists of values

    # Type

    ```
    cartesianProduct :: AttrSet -> [AttrSet]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.cartesianProduct` usage example

    ```nix
    cartesianProduct { a = [ 1 2 ]; b = [ 10 20 ]; }
    => [
         { a = 1; b = 10; }
         { a = 1; b = 20; }
         { a = 2; b = 10; }
         { a = 2; b = 20; }
       ]
    ```

    :::
  */
  cartesianProduct =
    attrsOfLists:
    foldl' (
      listOfAttrs: attrName:
      concatMap (
        attrs: map (listValue: attrs // { ${attrName} = listValue; }) attrsOfLists.${attrName}
      ) listOfAttrs
    ) [ { } ] (attrNames attrsOfLists);

  /**
    Return the result of function f applied to the cartesian product of attribute set value combinations.
    Equivalent to using cartesianProduct followed by map.

    # Inputs

    `f`

    : A function, given an attribute set, it returns a new value.

    `attrsOfLists`

    : Attribute set with attributes that are lists of values

    # Type

    ```
    mapCartesianProduct :: (AttrSet -> a) -> AttrSet -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.mapCartesianProduct` usage example

    ```nix
    mapCartesianProduct ({a, b}: "${a}-${b}") { a = [ "1" "2" ]; b = [ "3" "4" ]; }
    => [ "1-3" "1-4" "2-3" "2-4" ]
    ```

    :::
  */
  mapCartesianProduct = f: attrsOfLists: map f (cartesianProduct attrsOfLists);

  /**
    Utility function that creates a `{name, value}` pair as expected by `builtins.listToAttrs`.

    # Inputs

    `name`

    : Attribute name

    `value`

    : Attribute value

    # Type

    ```
    nameValuePair :: String -> Any -> { name :: String; value :: Any; }
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.nameValuePair` usage example

    ```nix
    nameValuePair "some" 6
    => { name = "some"; value = 6; }
    ```

    :::
  */
  nameValuePair = name: value: { inherit name value; };

  /**
    Apply a function to each element in an attribute set, creating a new attribute set.

    # Inputs

    `f`

    : A function that takes an attribute name and its value, and returns the new value for the attribute.

    `attrset`

    : The attribute set to iterate through.

    # Type

    ```
    mapAttrs :: (String -> Any -> Any) -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.mapAttrs` usage example

    ```nix
    mapAttrs (name: value: name + "-" + value)
       { x = "foo"; y = "bar"; }
    => { x = "x-foo"; y = "y-bar"; }
    ```

    :::
  */
  mapAttrs = builtins.mapAttrs;

  /**
    Like `mapAttrs`, but allows the name of each attribute to be
    changed in addition to the value.  The applied function should
    return both the new name and value as a `nameValuePair`.

    # Inputs

    `f`

    : A function, given an attribute's name and value, returns a new `nameValuePair`.

    `set`

    : Attribute set to map over.

    # Type

    ```
    mapAttrs' :: (String -> Any -> { name :: String; value :: Any; }) -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.mapAttrs'` usage example

    ```nix
    mapAttrs' (name: value: nameValuePair ("foo_" + name) ("bar-" + value))
       { x = "a"; y = "b"; }
    => { foo_x = "bar-a"; foo_y = "bar-b"; }
    ```

    :::
  */
  mapAttrs' = f: set: listToAttrs (mapAttrsToList f set);

  /**
    Call a function for each attribute in the given set and return
    the result in a list.

    # Inputs

    `f`

    : A function, given an attribute's name and value, returns a new value.

    `attrs`

    : Attribute set to map over.

    # Type

    ```
    mapAttrsToList :: (String -> a -> b) -> AttrSet -> [b]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.mapAttrsToList` usage example

    ```nix
    mapAttrsToList (name: value: name + value)
       { x = "a"; y = "b"; }
    => [ "xa" "yb" ]
    ```

    :::
  */
  mapAttrsToList = f: attrs: attrValues (mapAttrs f attrs);

  /**
    Deconstruct an attrset to a list of name-value pairs as expected by [`builtins.listToAttrs`](https://nixos.org/manual/nix/stable/language/builtins.html#builtins-listToAttrs).
    Each element of the resulting list is an attribute set with these attributes:
    - `name` (string): The name of the attribute
    - `value` (any): The value of the attribute

    The following is always true:
    ```nix
    builtins.listToAttrs (attrsToList attrs) == attrs
    ```

    :::{.warning}
    The opposite is not always true. In general expect that
    ```nix
    attrsToList (builtins.listToAttrs list) != list
    ```

    This is because the `listToAttrs` removes duplicate names and doesn't preserve the order of the list.
    :::

    # Inputs

    `set`

    : The attribute set to deconstruct.

    # Type

    ```
    attrsToList :: AttrSet -> [ { name :: String; value :: Any; } ]
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.attrsToList` usage example

    ```nix
    attrsToList { foo = 1; bar = "asdf"; }
    => [ { name = "bar"; value = "asdf"; } { name = "foo"; value = 1; } ]
    ```

    :::
  */
  attrsToList = mapAttrsToList nameValuePair;

  /**
    Like `mapAttrs`, except that it recursively applies itself to the *leaf* attributes of a potentially-nested attribute set:
    the second argument of the function will never be an attrset.
    Also, the first argument of the mapping function is a *list* of the attribute names that form the path to the leaf attribute.

    For a function that gives you control over what counts as a leaf, see `mapAttrsRecursiveCond`.

    :::{#map-attrs-recursive-example .example}
    # Map over leaf attributes

    ```nix
    mapAttrsRecursive (path: value: concatStringsSep "-" (path ++ [value]))
      { n = { a = "A"; m = { b = "B"; c = "C"; }; }; d = "D"; }
    ```
    evaluates to
    ```nix
    { n = { a = "n-a-A"; m = { b = "n-m-b-B"; c = "n-m-c-C"; }; }; d = "d-D"; }
    ```
    :::

    # Type
    ```
    mapAttrsRecursive :: ([String] -> a -> b) -> AttrSet -> AttrSet
    ```
  */
  mapAttrsRecursive = f: set: mapAttrsRecursiveCond (as: true) f set;

  /**
    Like `mapAttrsRecursive`, but it takes an additional predicate that tells it whether to recurse into an attribute set.
    If the predicate returns false, `mapAttrsRecursiveCond` does not recurse, but instead applies the mapping function.
    If the predicate returns true, it does recurse, and does not apply the mapping function.

    :::{#map-attrs-recursive-cond-example .example}
    # Map over an leaf attributes defined by a condition

    Map derivations to their `name` attribute.
    Derivatons are identified as attribute sets that contain `{ type = "derivation"; }`.
    ```nix
    mapAttrsRecursiveCond
      (as: !(as ? "type" && as.type == "derivation"))
      (path: x: x.name)
      attrs
    ```
    :::

    # Type
    ```
    mapAttrsRecursiveCond :: (AttrSet -> Bool) -> ([String] -> a -> b) -> AttrSet -> AttrSet
    ```
  */
  mapAttrsRecursiveCond =
    cond: f: set:
    let
      recurse =
        path:
        mapAttrs (
          name: value:
          if isAttrs value && cond value then recurse (path ++ [ name ]) value else f (path ++ [ name ]) value
        );
    in
    recurse [ ] set;

  /**
    Generate an attribute set by mapping a function over a list of
    attribute names.

    # Inputs

    `names`

    : Names of values in the resulting attribute set.

    `f`

    : A function, given the name of the attribute, returns the attribute's value.

    # Type

    ```
    genAttrs :: [ String ] -> (String -> Any) -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.genAttrs` usage example

    ```nix
    genAttrs [ "foo" "bar" ] (name: "x_" + name)
    => { foo = "x_foo"; bar = "x_bar"; }
    ```

    :::
  */
  genAttrs = names: f: listToAttrs (map (n: nameValuePair n (f n)) names);

  /**
    Check whether the argument is a derivation. Any set with
    `{ type = "derivation"; }` counts as a derivation.

    # Inputs

    `value`

    : Value to check.

    # Type

    ```
    isDerivation :: Any -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.isDerivation` usage example

    ```nix
    nixpkgs = import <nixpkgs> {}
    isDerivation nixpkgs.ruby
    => true
    isDerivation "foobar"
    => false
    ```

    :::
  */
  isDerivation = value: value.type or null == "derivation";

  /**
    Converts a store path to a fake derivation.

    # Inputs

    `path`

    : A store path to convert to a derivation.

    # Type

    ```
    toDerivation :: Path -> Derivation
    ```
  */
  toDerivation =
    path:
    let
      path' = builtins.storePath path;
      res = {
        type = "derivation";
        name = sanitizeDerivationName (builtins.substring 33 (-1) (baseNameOf path'));
        outPath = path';
        outputs = [ "out" ];
        out = res;
        outputName = "out";
      };
    in
    res;

  /**
    If `cond` is true, return the attribute set `as`,
    otherwise an empty attribute set.

    # Inputs

    `cond`

    : Condition under which the `as` attribute set is returned.

    `as`

    : The attribute set to return if `cond` is `true`.

    # Type

    ```
    optionalAttrs :: Bool -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.optionalAttrs` usage example

    ```nix
    optionalAttrs (true) { my = "set"; }
    => { my = "set"; }
    optionalAttrs (false) { my = "set"; }
    => { }
    ```

    :::
  */
  optionalAttrs = cond: as: if cond then as else { };

  /**
    Merge sets of attributes and use the function `f` to merge attributes
    values.

    # Inputs

    `names`

    : List of attribute names to zip.

    `f`

    : A function, accepts an attribute name, all the values, and returns a combined value.

    `sets`

    : List of values from the list of attribute sets.

    # Type

    ```
    zipAttrsWithNames :: [ String ] -> (String -> [ Any ] -> Any) -> [ AttrSet ] -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.zipAttrsWithNames` usage example

    ```nix
    zipAttrsWithNames ["a"] (name: vs: vs) [{a = "x";} {a = "y"; b = "z";}]
    => { a = ["x" "y"]; }
    ```

    :::
  */
  zipAttrsWithNames =
    names: f: sets:
    listToAttrs (
      map (name: {
        inherit name;
        value = f name (catAttrs name sets);
      }) names
    );

  /**
    Merge sets of attributes and use the function f to merge attribute values.
    Like `lib.attrsets.zipAttrsWithNames` with all key names are passed for `names`.

    Implementation note: Common names appear multiple times in the list of
    names, hopefully this does not affect the system because the maximal
    laziness avoid computing twice the same expression and `listToAttrs` does
    not care about duplicated attribute names.

    # Type

    ```
    zipAttrsWith :: (String -> [ Any ] -> Any) -> [ AttrSet ] -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.zipAttrsWith` usage example

    ```nix
    zipAttrsWith (name: values: values) [{a = "x";} {a = "y"; b = "z";}]
    => { a = ["x" "y"]; b = ["z"]; }
    ```

    :::
  */
  zipAttrsWith =
    builtins.zipAttrsWith or (f: sets: zipAttrsWithNames (concatMap attrNames sets) f sets);

  /**
    Merge sets of attributes and combine each attribute value in to a list.

    Like `lib.attrsets.zipAttrsWith` with `(name: values: values)` as the function.

    # Type

    ```
    zipAttrs :: [ AttrSet ] -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.zipAttrs` usage example

    ```nix
    zipAttrs [{a = "x";} {a = "y"; b = "z";}]
    => { a = ["x" "y"]; b = ["z"]; }
    ```

    :::
  */
  zipAttrs = zipAttrsWith (name: values: values);

  /**
    Merge a list of attribute sets together using the `//` operator.
    In case of duplicate attributes, values from later list elements take precedence over earlier ones.
    The result is the same as `foldl mergeAttrs { }`, but the performance is better for large inputs.
    For n list elements, each with an attribute set containing m unique attributes, the complexity of this operation is O(nm log n).

    # Inputs

    `list`

    : 1\. Function argument

    # Type

    ```
    mergeAttrsList :: [ Attrs ] -> Attrs
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.mergeAttrsList` usage example

    ```nix
    mergeAttrsList [ { a = 0; b = 1; } { c = 2; d = 3; } ]
    => { a = 0; b = 1; c = 2; d = 3; }
    mergeAttrsList [ { a = 0; } { a = 1; } ]
    => { a = 1; }
    ```

    :::
  */
  mergeAttrsList =
    list:
    let
      # `binaryMerge start end` merges the elements at indices `index` of `list` such that `start <= index < end`
      # Type: Int -> Int -> Attrs
      binaryMerge =
        start: end:
        # assert start < end; # Invariant
        if end - start >= 2 then
          # If there's at least 2 elements, split the range in two, recurse on each part and merge the result
          # The invariant is satisfied because each half will have at least 1 element
          binaryMerge start (start + (end - start) / 2) // binaryMerge (start + (end - start) / 2) end
        else
          # Otherwise there will be exactly 1 element due to the invariant, in which case we just return it directly
          elemAt list start;
    in
    if list == [ ] then
      # Calling binaryMerge as below would not satisfy its invariant
      { }
    else
      binaryMerge 0 (length list);

  /**
    Does the same as the update operator '//' except that attributes are
    merged until the given predicate is verified.  The predicate should
    accept 3 arguments which are the path to reach the attribute, a part of
    the first attribute set and a part of the second attribute set.  When
    the predicate is satisfied, the value of the first attribute set is
    replaced by the value of the second attribute set.

    # Inputs

    `pred`

    : Predicate, taking the path to the current attribute as a list of strings for attribute names, and the two values at that path from the original arguments.

    `lhs`

    : Left attribute set of the merge.

    `rhs`

    : Right attribute set of the merge.

    # Type

    ```
    recursiveUpdateUntil :: ( [ String ] -> AttrSet -> AttrSet -> Bool ) -> AttrSet -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.recursiveUpdateUntil` usage example

    ```nix
    recursiveUpdateUntil (path: l: r: path == ["foo"]) {
      # first attribute set
      foo.bar = 1;
      foo.baz = 2;
      bar = 3;
    } {
      #second attribute set
      foo.bar = 1;
      foo.quz = 2;
      baz = 4;
    }

    => {
      foo.bar = 1; # 'foo.*' from the second set
      foo.quz = 2; #
      bar = 3;     # 'bar' from the first set
      baz = 4;     # 'baz' from the second set
    }
    ```

    :::
  */
  recursiveUpdateUntil =
    pred: lhs: rhs:
    let
      f =
        attrPath:
        zipAttrsWith (
          n: values:
          let
            here = attrPath ++ [ n ];
          in
          if length values == 1 || pred here (elemAt values 1) (head values) then
            head values
          else
            f here values
        );
    in
    f [ ] [ rhs lhs ];

  /**
    A recursive variant of the update operator ‘//’.  The recursion
    stops when one of the attribute values is not an attribute set,
    in which case the right hand side value takes precedence over the
    left hand side value.

    # Inputs

    `lhs`

    : Left attribute set of the merge.

    `rhs`

    : Right attribute set of the merge.

    # Type

    ```
    recursiveUpdate :: AttrSet -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.recursiveUpdate` usage example

    ```nix
    recursiveUpdate {
      boot.loader.grub.enable = true;
      boot.loader.grub.device = "/dev/hda";
    } {
      boot.loader.grub.device = "";
    }

    returns: {
      boot.loader.grub.enable = true;
      boot.loader.grub.device = "";
    }
    ```

    :::
  */
  recursiveUpdate =
    lhs: rhs:
    recursiveUpdateUntil (
      path: lhs: rhs:
      !(isAttrs lhs && isAttrs rhs)
    ) lhs rhs;

  /**
    Recurse into every attribute set of the first argument and check that:
    - Each attribute path also exists in the second argument.
    - If the attribute's value is not a nested attribute set, it must have the same value in the right argument.

    # Inputs

    `pattern`

    : Attribute set structure to match

    `attrs`

    : Attribute set to check

    # Type

    ```
    matchAttrs :: AttrSet -> AttrSet -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.matchAttrs` usage example

    ```nix
    matchAttrs { cpu = {}; } { cpu = { bits = 64; }; }
    => true
    ```

    :::
  */
  matchAttrs =
    pattern: attrs:
    assert isAttrs pattern;
    all (
      # Compare equality between `pattern` & `attrs`.
      attr:
      # Missing attr, not equal.
      attrs ? ${attr}
      && (
        let
          lhs = pattern.${attr};
          rhs = attrs.${attr};
        in
        # If attrset check recursively
        if isAttrs lhs then isAttrs rhs && matchAttrs lhs rhs else lhs == rhs
      )
    ) (attrNames pattern);

  /**
    Override only the attributes that are already present in the old set
    useful for deep-overriding.

    # Inputs

    `old`

    : Original attribute set

    `new`

    : Attribute set with attributes to override in `old`.

    # Type

    ```
    overrideExisting :: AttrSet -> AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.overrideExisting` usage example

    ```nix
    overrideExisting {} { a = 1; }
    => {}
    overrideExisting { b = 2; } { a = 1; }
    => { b = 2; }
    overrideExisting { a = 3; b = 2; } { a = 1; }
    => { a = 1; b = 2; }
    ```

    :::
  */
  overrideExisting = old: new: mapAttrs (name: value: new.${name} or value) old;

  /**
    Turns a list of strings into a human-readable description of those
    strings represented as an attribute path. The result of this function is
    not intended to be machine-readable.
    Create a new attribute set with `value` set at the nested attribute location specified in `attrPath`.

    # Inputs

    `path`

    : Attribute path to render to a string

    # Type

    ```
    showAttrPath :: [String] -> String
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.showAttrPath` usage example

    ```nix
    showAttrPath [ "foo" "10" "bar" ]
    => "foo.\"10\".bar"
    showAttrPath []
    => "<root attribute path>"
    ```

    :::
  */
  showAttrPath =
    path:
    if path == [ ] then "<root attribute path>" else concatMapStringsSep "." escapeNixIdentifier path;

  /**
    Get a package output.
    If no output is found, fallback to `.out` and then to the default.
    The function is idempotent: `getOutput "b" (getOutput "a" p) == getOutput "a" p`.

    # Inputs

    `output`

    : 1\. Function argument

    `pkg`

    : 2\. Function argument

    # Type

    ```
    getOutput :: String -> :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getOutput` usage example

    ```nix
    "${getOutput "dev" pkgs.openssl}"
    => "/nix/store/9rz8gxhzf8sw4kf2j2f1grr49w8zx5vj-openssl-1.0.1r-dev"
    ```

    :::
  */
  getOutput =
    output: pkg:
    if !pkg ? outputSpecified || !pkg.outputSpecified then pkg.${output} or pkg.out or pkg else pkg;

  /**
    Get the first of the `outputs` provided by the package, or the default.
    This function is aligned with `_overrideFirst()` from the `multiple-outputs.sh` setup hook.
    Like `getOutput`, the function is idempotent.

    # Inputs

    `outputs`

    : 1\. Function argument

    `pkg`

    : 2\. Function argument

    # Type

    ```
    getFirstOutput :: [String] -> Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getFirstOutput` usage example

    ```nix
    "${getFirstOutput [ "include" "dev" ] pkgs.openssl}"
    => "/nix/store/00000000000000000000000000000000-openssl-1.0.1r-dev"
    ```

    :::
  */
  getFirstOutput =
    candidates: pkg:
    let
      outputs = builtins.filter (name: hasAttr name pkg) candidates;
      output = builtins.head outputs;
    in
    if pkg.outputSpecified or false || outputs == [ ] then pkg else pkg.${output};

  /**
    Get a package's `bin` output.
    If the output does not exist, fallback to `.out` and then to the default.

    # Inputs

    `pkg`

    : The package whose `bin` output will be retrieved.

    # Type

    ```
    getBin :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getBin` usage example

    ```nix
    "${getBin pkgs.openssl}"
    => "/nix/store/00000000000000000000000000000000-openssl-1.0.1r"
    ```

    :::
  */
  getBin = getOutput "bin";

  /**
    Get a package's `lib` output.
    If the output does not exist, fallback to `.out` and then to the default.

    # Inputs

    `pkg`

    : The package whose `lib` output will be retrieved.

    # Type

    ```
    getLib :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getLib` usage example

    ```nix
    "${getLib pkgs.openssl}"
    => "/nix/store/9rz8gxhzf8sw4kf2j2f1grr49w8zx5vj-openssl-1.0.1r-lib"
    ```

    :::
  */
  getLib = getOutput "lib";

  /**
    Get a package's `static` output.
    If the output does not exist, fallback to `.lib`, then to `.out`, and then to the default.

    # Inputs

    `pkg`

    : The package whose `static` output will be retrieved.

    # Type

    ```
    getStatic :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getStatic` usage example

    ```nix
    "${lib.getStatic pkgs.glibc}"
    => "/nix/store/00000000000000000000000000000000-glibc-2.39-52-static"
    ```

    :::
  */
  getStatic = getFirstOutput [
    "static"
    "lib"
    "out"
  ];

  /**
    Get a package's `dev` output.
    If the output does not exist, fallback to `.out` and then to the default.

    # Inputs

    `pkg`

    : The package whose `dev` output will be retrieved.

    # Type

    ```
    getDev :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getDev` usage example

    ```nix
    "${getDev pkgs.openssl}"
    => "/nix/store/9rz8gxhzf8sw4kf2j2f1grr49w8zx5vj-openssl-1.0.1r-dev"
    ```

    :::
  */
  getDev = getOutput "dev";

  /**
    Get a package's `include` output.
    If the output does not exist, fallback to `.dev`, then to `.out`, and then to the default.

    # Inputs

    `pkg`

    : The package whose `include` output will be retrieved.

    # Type

    ```
    getInclude :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getInclude` usage example

    ```nix
    "${getInclude pkgs.openssl}"
    => "/nix/store/00000000000000000000000000000000-openssl-1.0.1r-dev"
    ```

    :::
  */
  getInclude = getFirstOutput [
    "include"
    "dev"
    "out"
  ];

  /**
    Get a package's `man` output.
    If the output does not exist, fallback to `.out` and then to the default.

    # Inputs

    `pkg`

    : The package whose `man` output will be retrieved.

    # Type

    ```
    getMan :: Derivation -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.getMan` usage example

    ```nix
    "${getMan pkgs.openssl}"
    => "/nix/store/9rz8gxhzf8sw4kf2j2f1grr49w8zx5vj-openssl-1.0.1r-man"
    ```

    :::
  */
  getMan = getOutput "man";

  /**
    Pick the outputs of packages to place in `buildInputs`

    # Inputs

    `pkgs`

    : List of packages.

    # Type

    ```
    chooseDevOutputs :: [Derivation] -> [Derivation]
    ```
  */
  chooseDevOutputs = builtins.map getDev;

  /**
    Make various Nix tools consider the contents of the resulting
    attribute set when looking for what to build, find, etc.

    This function only affects a single attribute set; it does not
    apply itself recursively for nested attribute sets.

    # Inputs

    `attrs`

    : An attribute set to scan for derivations.

    # Type

    ```
    recurseIntoAttrs :: AttrSet -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.attrsets.recurseIntoAttrs` usage example

    ```nix
    { pkgs ? import <nixpkgs> {} }:
    {
      myTools = pkgs.lib.recurseIntoAttrs {
        inherit (pkgs) hello figlet;
      };
    }
    ```

    :::
  */
  recurseIntoAttrs = attrs: attrs // { recurseForDerivations = true; };

  /**
    Undo the effect of recurseIntoAttrs.

    # Inputs

    `attrs`

    : An attribute set to not scan for derivations.

    # Type

    ```
    dontRecurseIntoAttrs :: AttrSet -> AttrSet
    ```
  */
  dontRecurseIntoAttrs = attrs: attrs // { recurseForDerivations = false; };

  /**
    `unionOfDisjoint x y` is equal to `x // y // z` where the
    attrnames in `z` are the intersection of the attrnames in `x` and
    `y`, and all values `assert` with an error message.  This
     operator is commutative, unlike (//).

    # Inputs

    `x`

    : 1\. Function argument

    `y`

    : 2\. Function argument

    # Type

    ```
    unionOfDisjoint :: AttrSet -> AttrSet -> AttrSet
    ```
  */
  unionOfDisjoint =
    x: y:
    let
      intersection = builtins.intersectAttrs x y;
      collisions = lib.concatStringsSep " " (builtins.attrNames intersection);
      mask = builtins.mapAttrs (
        name: value: builtins.throw "unionOfDisjoint: collision on ${name}; complete list: ${collisions}"
      ) intersection;
    in
    (x // y) // mask;

  # DEPRECATED
  zipWithNames = warn "lib.zipWithNames is a deprecated alias of lib.zipAttrsWithNames." zipAttrsWithNames;

  # DEPRECATED
  zip = warn "lib.zip is a deprecated alias of lib.zipAttrsWith." zipAttrsWith;

  # DEPRECATED
  cartesianProductOfSets =
    warnIf (oldestSupportedReleaseIsAtLeast 2405)
      "lib.cartesianProductOfSets is a deprecated alias of lib.cartesianProduct."
      cartesianProduct;
}
</file>

<file path="lib/cli.nix">
{ lib }:

rec {
  /**
    Automatically convert an attribute set to command-line options.

    This helps protect against malformed command lines and also to reduce
    boilerplate related to command-line construction for simple use cases.

    `toGNUCommandLineShell` returns an escaped shell string.

    # Inputs

    `options`

    : How to format the arguments, see `toGNUCommandLine`

    `attrs`

    : The attributes to transform into arguments.

    # Examples
    :::{.example}
    ## `lib.cli.toGNUCommandLineShell` usage example

    ```nix
    cli.toGNUCommandLineShell {} {
      data = builtins.toJSON { id = 0; };
      X = "PUT";
      retry = 3;
      retry-delay = null;
      url = [ "https://example.com/foo" "https://example.com/bar" ];
      silent = false;
      verbose = true;
    }
    => "'-X' 'PUT' '--data' '{\"id\":0}' '--retry' '3' '--url' 'https://example.com/foo' '--url' 'https://example.com/bar' '--verbose'";
    ```

    :::
  */
  toGNUCommandLineShell = options: attrs: lib.escapeShellArgs (toGNUCommandLine options attrs);

  /**
    Automatically convert an attribute set to a list of command-line options.

    `toGNUCommandLine` returns a list of string arguments.

    # Inputs

    `options`

    : How to format the arguments, see below.

    `attrs`

    : The attributes to transform into arguments.

    # Options

    `mkOptionName`

    : How to string-format the option name;
    By default one character is a short option (`-`), more than one characters a long option (`--`).

    `mkBool`

    : How to format a boolean value to a command list;
    By default it’s a flag option (only the option name if true, left out completely if false).

    `mkList`

    : How to format a list value to a command list;
    By default the option name is repeated for each value and `mkOption` is applied to the values themselves.

    `mkOption`

    : How to format any remaining value to a command list;
    On the toplevel, booleans and lists are handled by `mkBool` and `mkList`, though they can still appear as values of a list.
    By default, everything is printed verbatim and complex types are forbidden (lists, attrsets, functions). `null` values are omitted.

    `optionValueSeparator`

    : How to separate an option from its flag;
    By default, there is no separator, so option `-c` and value `5` would become ["-c" "5"].
    This is useful if the command requires equals, for example, `-c=5`.

    # Examples
    :::{.example}
    ## `lib.cli.toGNUCommandLine` usage example

    ```nix
    cli.toGNUCommandLine {} {
      data = builtins.toJSON { id = 0; };
      X = "PUT";
      retry = 3;
      retry-delay = null;
      url = [ "https://example.com/foo" "https://example.com/bar" ];
      silent = false;
      verbose = true;
    }
    => [
      "-X" "PUT"
      "--data" "{\"id\":0}"
      "--retry" "3"
      "--url" "https://example.com/foo"
      "--url" "https://example.com/bar"
      "--verbose"
    ]
    ```

    :::
  */
  toGNUCommandLine =
    {
      mkOptionName ? k: if builtins.stringLength k == 1 then "-${k}" else "--${k}",

      mkBool ? k: v: lib.optional v (mkOptionName k),

      mkList ? k: v: lib.concatMap (mkOption k) v,

      mkOption ?
        k: v:
        if v == null then
          [ ]
        else if optionValueSeparator == null then
          [
            (mkOptionName k)
            (lib.generators.mkValueStringDefault { } v)
          ]
        else
          [ "${mkOptionName k}${optionValueSeparator}${lib.generators.mkValueStringDefault { } v}" ],

      optionValueSeparator ? null,
    }:
    options:
    let
      render =
        k: v:
        if builtins.isBool v then
          mkBool k v
        else if builtins.isList v then
          mkList k v
        else
          mkOption k v;

    in
    builtins.concatLists (lib.mapAttrsToList render options);
}
</file>

<file path="lib/customisation.nix">
{ lib }:

let
  inherit (builtins)
    intersectAttrs
    ;
  inherit (lib)
    functionArgs
    isFunction
    mirrorFunctionArgs
    isAttrs
    setFunctionArgs
    optionalAttrs
    attrNames
    filter
    elemAt
    concatStringsSep
    sortOn
    take
    length
    filterAttrs
    optionalString
    flip
    pathIsDirectory
    head
    pipe
    isDerivation
    listToAttrs
    mapAttrs
    seq
    flatten
    deepSeq
    extends
    toFunction
    id
    ;
  inherit (lib.strings) levenshtein levenshteinAtMost;

in
rec {

  /**
    `overrideDerivation drv f` takes a derivation (i.e., the result
    of a call to the builtin function `derivation`) and returns a new
    derivation in which the attributes of the original are overridden
    according to the function `f`.  The function `f` is called with
    the original derivation attributes.

    `overrideDerivation` allows certain "ad-hoc" customisation
    scenarios (e.g. in ~/.config/nixpkgs/config.nix).  For instance,
    if you want to "patch" the derivation returned by a package
    function in Nixpkgs to build another version than what the
    function itself provides.

    For another application, see build-support/vm, where this
    function is used to build arbitrary derivations inside a QEMU
    virtual machine.

    Note that in order to preserve evaluation errors, the new derivation's
    outPath depends on the old one's, which means that this function cannot
    be used in circular situations when the old derivation also depends on the
    new one.

    You should in general prefer `drv.overrideAttrs` over this function;
    see the nixpkgs manual for more information on overriding.

    # Inputs

    `drv`

    : 1\. Function argument

    `f`

    : 2\. Function argument

    # Type

    ```
    overrideDerivation :: Derivation -> ( Derivation -> AttrSet ) -> Derivation
    ```

    # Examples
    :::{.example}
    ## `lib.customisation.overrideDerivation` usage example

    ```nix
    mySed = overrideDerivation pkgs.gnused (oldAttrs: {
      name = "sed-4.2.2-pre";
      src = fetchurl {
        url = ftp://alpha.gnu.org/gnu/sed/sed-4.2.2-pre.tar.bz2;
        hash = "sha256-MxBJRcM2rYzQYwJ5XKxhXTQByvSg5jZc5cSHEZoB2IY=";
      };
      patches = [];
    });
    ```

    :::
  */
  overrideDerivation =
    drv: f:
    let
      newDrv = derivation (drv.drvAttrs // (f drv));
    in
    flip (extendDerivation (seq drv.drvPath true)) newDrv (
      {
        meta = drv.meta or { };
        passthru = if drv ? passthru then drv.passthru else { };
      }
      // (drv.passthru or { })
      // optionalAttrs (drv ? __spliced) {
        __spliced = { } // (mapAttrs (_: sDrv: overrideDerivation sDrv f) drv.__spliced);
      }
    );

  /**
    `makeOverridable` takes a function from attribute set to attribute set and
    injects `override` attribute which can be used to override arguments of
    the function.

    Please refer to  documentation on [`<pkg>.overrideDerivation`](#sec-pkg-overrideDerivation) to learn about `overrideDerivation` and caveats
    related to its use.

    # Inputs

    `f`

    : 1\. Function argument

    # Type

    ```
    makeOverridable :: (AttrSet -> a) -> AttrSet -> a
    ```

    # Examples
    :::{.example}
    ## `lib.customisation.makeOverridable` usage example

    ```nix
    nix-repl> x = {a, b}: { result = a + b; }

    nix-repl> y = lib.makeOverridable x { a = 1; b = 2; }

    nix-repl> y
    { override = «lambda»; overrideDerivation = «lambda»; result = 3; }

    nix-repl> y.override { a = 10; }
    { override = «lambda»; overrideDerivation = «lambda»; result = 12; }
    ```

    :::
  */
  makeOverridable =
    f:
    let
      # Creates a functor with the same arguments as f
      mirrorArgs = mirrorFunctionArgs f;
    in
    mirrorArgs (
      origArgs:
      let
        result = f origArgs;

        # Changes the original arguments with (potentially a function that returns) a set of new attributes
        overrideWith = newArgs: origArgs // (if isFunction newArgs then newArgs origArgs else newArgs);

        # Re-call the function but with different arguments
        overrideArgs = mirrorArgs (newArgs: makeOverridable f (overrideWith newArgs));
        # Change the result of the function call by applying g to it
        overrideResult = g: makeOverridable (mirrorArgs (args: g (f args))) origArgs;
      in
      if isAttrs result then
        result
        // {
          override = overrideArgs;
          overrideDerivation = fdrv: overrideResult (x: overrideDerivation x fdrv);
          ${if result ? overrideAttrs then "overrideAttrs" else null} =
            fdrv: overrideResult (x: x.overrideAttrs fdrv);
        }
      else if isFunction result then
        # Transform the result into a functor while propagating its arguments
        setFunctionArgs result (functionArgs result)
        // {
          override = overrideArgs;
        }
      else
        result
    );

  /**
    Call the package function in the file `fn` with the required
    arguments automatically.  The function is called with the
    arguments `args`, but any missing arguments are obtained from
    `autoArgs`.  This function is intended to be partially
    parameterised, e.g.,

      ```nix
      callPackage = callPackageWith pkgs;
      pkgs = {
        libfoo = callPackage ./foo.nix { };
        libbar = callPackage ./bar.nix { };
      };
      ```

    If the `libbar` function expects an argument named `libfoo`, it is
    automatically passed as an argument.  Overrides or missing
    arguments can be supplied in `args`, e.g.

      ```nix
      libbar = callPackage ./bar.nix {
        libfoo = null;
        enableX11 = true;
      };
      ```

    <!-- TODO: Apply "Example:" tag to the examples above -->

    # Inputs

    `autoArgs`

    : 1\. Function argument

    `fn`

    : 2\. Function argument

    `args`

    : 3\. Function argument

    # Type

    ```
    callPackageWith :: AttrSet -> ((AttrSet -> a) | Path) -> AttrSet -> a
    ```
  */
  callPackageWith =
    autoArgs: fn: args:
    let
      f = if isFunction fn then fn else import fn;
      fargs = functionArgs f;

      # All arguments that will be passed to the function
      # This includes automatic ones and ones passed explicitly
      allArgs = intersectAttrs fargs autoArgs // args;

      # a list of argument names that the function requires, but
      # wouldn't be passed to it
      missingArgs =
        # Filter out arguments that have a default value
        (
          filterAttrs (name: value: !value)
            # Filter out arguments that would be passed
            (removeAttrs fargs (attrNames allArgs))
        );

      # Get a list of suggested argument names for a given missing one
      getSuggestions =
        arg:
        pipe (autoArgs // args) [
          attrNames
          # Only use ones that are at most 2 edits away. While mork would work,
          # levenshteinAtMost is only fast for 2 or less.
          (filter (levenshteinAtMost 2 arg))
          # Put strings with shorter distance first
          (sortOn (levenshtein arg))
          # Only take the first couple results
          (take 3)
          # Quote all entries
          (map (x: "\"" + x + "\""))
        ];

      prettySuggestions =
        suggestions:
        if suggestions == [ ] then
          ""
        else if length suggestions == 1 then
          ", did you mean ${elemAt suggestions 0}?"
        else
          ", did you mean ${concatStringsSep ", " (lib.init suggestions)} or ${lib.last suggestions}?";

      errorForArg =
        arg:
        let
          loc = builtins.unsafeGetAttrPos arg fargs;
          # loc' can be removed once lib/minver.nix is >2.3.4, since that includes
          # https://github.com/NixOS/nix/pull/3468 which makes loc be non-null
          loc' =
            if loc != null then
              loc.file + ":" + toString loc.line
            else if !isFunction fn then
              toString (lib.filesystem.resolveDefaultNix fn)
            else
              "<unknown location>";
        in
        "Function called without required argument \"${arg}\" at "
        + "${loc'}${prettySuggestions (getSuggestions arg)}";

      # Only show the error for the first missing argument
      error = errorForArg (head (attrNames missingArgs));

    in
    if missingArgs == { } then
      makeOverridable f allArgs
    # This needs to be an abort so it can't be caught with `builtins.tryEval`,
    # which is used by nix-env and ofborg to filter out packages that don't evaluate.
    # This way we're forced to fix such errors in Nixpkgs,
    # which is especially relevant with allowAliases = false
    else
      abort "lib.customisation.callPackageWith: ${error}";

  /**
    Like callPackage, but for a function that returns an attribute
    set of derivations. The override function is added to the
    individual attributes.

    # Inputs

    `autoArgs`

    : 1\. Function argument

    `fn`

    : 2\. Function argument

    `args`

    : 3\. Function argument

    # Type

    ```
    callPackagesWith :: AttrSet -> ((AttrSet -> AttrSet) | Path) -> AttrSet -> AttrSet
    ```
  */
  callPackagesWith =
    autoArgs: fn: args:
    let
      f = if isFunction fn then fn else import fn;
      auto = intersectAttrs (functionArgs f) autoArgs;
      mirrorArgs = mirrorFunctionArgs f;
      origArgs = auto // args;
      pkgs = f origArgs;
      mkAttrOverridable = name: _: makeOverridable (mirrorArgs (newArgs: (f newArgs).${name})) origArgs;
    in
    if isDerivation pkgs then
      throw (
        "function `callPackages` was called on a *single* derivation "
        + ''"${pkgs.name or "<unknown-name>"}";''
        + " did you mean to use `callPackage` instead?"
      )
    else
      mapAttrs mkAttrOverridable pkgs;

  /**
    Add attributes to each output of a derivation without changing
    the derivation itself and check a given condition when evaluating.

    # Inputs

    `condition`

    : 1\. Function argument

    `passthru`

    : 2\. Function argument

    `drv`

    : 3\. Function argument

    # Type

    ```
    extendDerivation :: Bool -> Any -> Derivation -> Derivation
    ```
  */
  extendDerivation =
    condition: passthru: drv:
    let
      outputs = drv.outputs or [ "out" ];

      commonAttrs =
        drv // (listToAttrs outputsList) // ({ all = map (x: x.value) outputsList; }) // passthru;

      outputToAttrListElement = outputName: {
        name = outputName;
        value =
          commonAttrs
          // {
            inherit (drv.${outputName}) type outputName;
            outputSpecified = true;
            drvPath =
              assert condition;
              drv.${outputName}.drvPath;
            outPath =
              assert condition;
              drv.${outputName}.outPath;
          }
          //
            # TODO: give the derivation control over the outputs.
            #       `overrideAttrs` may not be the only attribute that needs
            #       updating when switching outputs.
            optionalAttrs (passthru ? overrideAttrs) {
              # TODO: also add overrideAttrs when overrideAttrs is not custom, e.g. when not splicing.
              overrideAttrs = f: (passthru.overrideAttrs f).${outputName};
            };
      };

      outputsList = map outputToAttrListElement outputs;
    in
    commonAttrs
    // {
      drvPath =
        assert condition;
        drv.drvPath;
      outPath =
        assert condition;
        drv.outPath;
    };

  /**
    Strip a derivation of all non-essential attributes, returning
    only those needed by hydra-eval-jobs. Also strictly evaluate the
    result to ensure that there are no thunks kept alive to prevent
    garbage collection.

    # Inputs

    `drv`

    : 1\. Function argument

    # Type

    ```
    hydraJob :: (Derivation | Null) -> (Derivation | Null)
    ```
  */
  hydraJob =
    drv:
    let
      outputs = drv.outputs or [ "out" ];

      commonAttrs = {
        inherit (drv) name system meta;
        inherit outputs;
      }
      // optionalAttrs (drv._hydraAggregate or false) {
        _hydraAggregate = true;
        constituents = map hydraJob (flatten drv.constituents);
      }
      // (listToAttrs outputsList);

      makeOutput =
        outputName:
        let
          output = drv.${outputName};
        in
        {
          name = outputName;
          value = commonAttrs // {
            outPath = output.outPath;
            drvPath = output.drvPath;
            type = "derivation";
            inherit outputName;
          };
        };

      outputsList = map makeOutput outputs;

      drv' = (head outputsList).value;
    in
    if drv == null then null else deepSeq drv' drv';

  /**
    Make an attribute set (a "scope") from functions that take arguments from that same attribute set.
    See [](#ex-makeScope) for how to use it.

    # Inputs

    1. `newScope` (`AttrSet -> ((AttrSet -> a) | Path) -> AttrSet -> a`)

       A function that takes an attribute set `attrs` and returns what ends up as `callPackage` in the output.

       Typical values are `callPackageWith` or the output attribute `newScope`.

    2. `f` (`AttrSet -> AttrSet`)

       A function that takes an attribute set as returned by `makeScope newScope f` (a "scope") and returns any attribute set.

       This function is used to compute the fixpoint of the resulting scope using `callPackage`.
       Its argument is the lazily evaluated reference to the value of that fixpoint, and is typically called `self` or `final`.

       See [](#ex-makeScope) for how to use it.
       See [](#sec-functions-library-fixedPoints) for details on fixpoint computation.

    # Output

    `makeScope` returns an attribute set of a form called `scope`, which also contains the final attributes produced by `f`:

    ```
    scope :: {
      callPackage :: ((AttrSet -> a) | Path) -> AttrSet -> a
      newScope = AttrSet -> scope
      overrideScope = (scope -> scope -> AttrSet) -> scope
      packages :: AttrSet -> AttrSet
    }
    ```

    - `callPackage` (`((AttrSet -> a) | Path) -> AttrSet -> a`)

      A function that

      1. Takes a function `p`, or a path to a Nix file that contains a function `p`, which takes an attribute set and returns value of arbitrary type `a`,
      2. Takes an attribute set `args` with explicit attributes to pass to `p`,
      3. Calls `f` with attributes from the original attribute set `attrs` passed to `newScope` updated with `args`, i.e. `attrs // args`, if they match the attributes in the argument of `p`.

      All such functions `p` will be called with the same value for `attrs`.

      See [](#ex-makeScope-callPackage) for how to use it.

    - `newScope` (`AttrSet -> scope`)

      Takes an attribute set `attrs` and returns a scope that extends the original scope.

    - `overrideScope` (`(scope -> scope -> AttrSet) -> scope`)

      Takes a function `g` of the form `final: prev: { # attributes }` to act as an overlay on `f`, and returns a new scope with values determined by `extends g f`.
      See [](https://nixos.org/manual/nixpkgs/unstable/#function-library-lib.fixedPoints.extends) for details.

      This allows subsequent modification of the final attribute set in a consistent way, i.e. all functions `p` invoked with `callPackage` will be called with the modified values.

    - `packages` (`AttrSet -> AttrSet`)

      The value of the argument `f` to `makeScope`.

    - final attributes

      The final values returned by `f`.

    # Examples

    :::{#ex-makeScope .example}
    # Create an interdependent package set on top of `pkgs`

    The functions in `foo.nix` and `bar.nix` can depend on each other, in the sense that `foo.nix` can contain a function that expects `bar` as an attribute in its argument.

    ```nix
    let
      pkgs = import <nixpkgs> { };
    in
    pkgs.lib.makeScope pkgs.newScope (self: {
      foo = self.callPackage ./foo.nix { };
      bar = self.callPackage ./bar.nix { };
    })
    ```

    evaluates to

    ```nix
    {
      callPackage = «lambda»;
      newScope = «lambda»;
      overrideScope = «lambda»;
      packages = «lambda»;
      foo = «derivation»;
      bar = «derivation»;
    }
    ```
    :::

    :::{#ex-makeScope-callPackage .example}
    # Using `callPackage` from a scope

    ```nix
    let
      pkgs = import <nixpkgs> { };
      inherit (pkgs) lib;
      scope = lib.makeScope lib.callPackageWith (self: { a = 1; b = 2; });
      three = scope.callPackage ({ a, b }: a + b) { };
      four = scope.callPackage ({ a, b }: a + b) { a = 2; };
    in
    [ three four ]
    ```

    evaluates to

    ```nix
    [ 3 4 ]
    ```
    :::

    # Type

    ```
    makeScope :: (AttrSet -> ((AttrSet -> a) | Path) -> AttrSet -> a) -> (AttrSet -> AttrSet) -> scope
    ```
  */
  makeScope =
    newScope: f:
    let
      self = f self // {
        newScope = scope: newScope (self // scope);
        callPackage = self.newScope { };
        overrideScope = g: makeScope newScope (extends g f);
        packages = f;
      };
    in
    self;

  /**
    backward compatibility with old uncurried form; deprecated

    # Inputs

    `splicePackages`

    : 1\. Function argument

    `newScope`

    : 2\. Function argument

    `otherSplices`

    : 3\. Function argument

    `keep`

    : 4\. Function argument

    `extra`

    : 5\. Function argument

    `f`

    : 6\. Function argument
  */
  makeScopeWithSplicing =
    splicePackages: newScope: otherSplices: keep: extra: f:
    makeScopeWithSplicing' { inherit splicePackages newScope; } {
      inherit
        otherSplices
        keep
        extra
        f
        ;
    };

  /**
    Like makeScope, but aims to support cross compilation. It's still ugly, but
    hopefully it helps a little bit.

    # Type

    ```
    makeScopeWithSplicing' ::
      { splicePackages :: Splice -> AttrSet
      , newScope :: AttrSet -> ((AttrSet -> a) | Path) -> AttrSet -> a
      }
      -> { otherSplices :: Splice, keep :: AttrSet -> AttrSet, extra :: AttrSet -> AttrSet }
      -> AttrSet

    Splice ::
      { pkgsBuildBuild :: AttrSet
      , pkgsBuildHost :: AttrSet
      , pkgsBuildTarget :: AttrSet
      , pkgsHostHost :: AttrSet
      , pkgsHostTarget :: AttrSet
      , pkgsTargetTarget :: AttrSet
      }
    ```
  */
  makeScopeWithSplicing' =
    {
      splicePackages,
      newScope,
    }:
    {
      otherSplices,
      # Attrs from `self` which won't be spliced.
      # Avoid using keep, it's only used for a python hook workaround, added in PR #104201.
      # ex: `keep = (self: { inherit (self) aAttr; })`
      keep ? (_self: { }),
      # Additional attrs to add to the sets `callPackage`.
      # When the package is from a subset (but not a subset within a package IS #211340)
      # within `spliced0` it will be spliced.
      # When using an package outside the set but it's available from `pkgs`, use the package from `pkgs.__splicedPackages`.
      # If the package is not available within the set or in `pkgs`, such as a package in a let binding, it will not be spliced
      # ex:
      # ```
      # nix-repl> darwin.apple_sdk.frameworks.CoreFoundation
      #   «derivation ...CoreFoundation-11.0.0.drv»
      # nix-repl> darwin.CoreFoundation
      #   error: attribute 'CoreFoundation' missing
      # nix-repl> darwin.callPackage ({ CoreFoundation }: CoreFoundation) { }
      #   «derivation ...CoreFoundation-11.0.0.drv»
      # ```
      extra ? (_spliced0: { }),
      f,
    }:
    let
      spliced0 = splicePackages {
        pkgsBuildBuild = otherSplices.selfBuildBuild;
        pkgsBuildHost = otherSplices.selfBuildHost;
        pkgsBuildTarget = otherSplices.selfBuildTarget;
        pkgsHostHost = otherSplices.selfHostHost;
        pkgsHostTarget = self; # Not `otherSplices.selfHostTarget`;
        pkgsTargetTarget = otherSplices.selfTargetTarget;
      };
      spliced = extra spliced0 // spliced0 // keep self;
      self = f self // {
        newScope = scope: newScope (spliced // scope);
        callPackage = newScope spliced; # == self.newScope {};
        # N.B. the other stages of the package set spliced in are *not*
        # overridden.
        overrideScope =
          g:
          (makeScopeWithSplicing' { inherit splicePackages newScope; } {
            inherit otherSplices keep extra;
            f = extends g f;
          });
        packages = f;
      };
    in
    self;

  /**
    Define a `mkDerivation`-like function based on another `mkDerivation`-like function.

    [`stdenv.mkDerivation`](#part-stdenv) gives access to
    its final set of derivation attributes when it is passed a function,
    or when it is passed an overlay-style function in `overrideAttrs`.

    Instead of composing new `stdenv.mkDerivation`-like build helpers
    using normal function composition,
    `extendMkDerivation` makes sure that the returned build helper
    supports such first class recursion like `mkDerivation` does.

    `extendMkDerivation` takes an extra attribute set to configure its behaviour.
    One can optionally specify
    `transformDrv` to specify a function to apply to the result derivation,
    or `inheritFunctionArgs` to decide whether to inherit the `__functionArgs`
    from the base build helper.

    # Inputs

    `extendMkDerivation`-specific configurations
    : `constructDrv`: Base build helper, the `mkDerivation`-like build helper to extend.
    : `excludeDrvArgNames`: Argument names not to pass from the input fixed-point arguments to `constructDrv`. Note: It doesn't apply to the updating arguments returned by `extendDrvArgs`.
    : `extendDrvArgs` : An extension (overlay) of the argument set, like the one taken by [overrideAttrs](#sec-pkg-overrideAttrs) but applied before passing to `constructDrv`.
    : `inheritFunctionArgs`: Whether to inherit `__functionArgs` from the base build helper (default to `true`).
    : `transformDrv`: Function to apply to the result derivation (default to `lib.id`).

    # Type

    ```
    extendMkDerivation ::
      {
        constructDrv :: ((FixedPointArgs | AttrSet) -> a)
        excludeDrvArgNames :: [ String ],
        extendDrvArgs :: (AttrSet -> AttrSet -> AttrSet)
        inheritFunctionArgs :: Bool,
        transformDrv :: a -> a,
      }
      -> (FixedPointArgs | AttrSet) -> a

    FixedPointArgs = AttrSet -> AttrSet
    a = Derivation when defining a build helper
    ```

    # Examples

    :::{.example}
    ## `lib.customisation.extendMkDerivation` usage example
    ```nix-repl
    mkLocalDerivation = lib.extendMkDerivation {
      constructDrv = pkgs.stdenv.mkDerivation;
      excludeDrvArgNames = [ "specialArg" ];
      extendDrvArgs =
        finalAttrs: args@{ preferLocalBuild ? true, allowSubstitute ? false, specialArg ? (_: false), ... }:
        { inherit preferLocalBuild allowSubstitute; passthru = { inherit specialArg; } // args.passthru or { }; };
    }

    mkLocalDerivation.__functionArgs
    => { allowSubstitute = true; preferLocalBuild = true; specialArg = true; }

    mkLocalDerivation { inherit (pkgs.hello) pname version src; specialArg = _: false; }
    => «derivation /nix/store/xirl67m60ahg6jmzicx43a81g635g8z8-hello-2.12.1.drv»

    mkLocalDerivation (finalAttrs: { inherit (pkgs.hello) pname version src; specialArg = _: false; })
    => «derivation /nix/store/xirl67m60ahg6jmzicx43a81g635g8z8-hello-2.12.1.drv»

    (mkLocalDerivation (finalAttrs: { inherit (pkgs.hello) pname version src; passthru = { foo = "a"; bar = "${finalAttrs.passthru.foo}b"; }; })).bar
    => "ab"
    ```
    :::

    :::{.note}
    If `transformDrv` is specified,
    it should take care of existing attributes that perform overriding
    (e.g., [`overrideAttrs`](#sec-pkg-overrideAttrs))
    to ensure that the overriding functionality of the result derivation
    work as expected.
    Modifications that breaks the overriding include
    direct [attribute set update](https://nixos.org/manual/nix/stable/language/operators#update)
    and [`lib.extendDerivation`](#function-library-lib.customisation.extendDerivation).
    :::
  */
  extendMkDerivation =
    let
      extendsWithExclusion =
        excludedNames: g: f: final:
        let
          previous = f final;
        in
        removeAttrs previous excludedNames // g final previous;
    in
    {
      constructDrv,
      excludeDrvArgNames ? [ ],
      extendDrvArgs,
      inheritFunctionArgs ? true,
      transformDrv ? id,
    }:
    setFunctionArgs
      # Adds the fixed-point style support
      (
        fpargs:
        transformDrv (
          constructDrv (extendsWithExclusion excludeDrvArgNames extendDrvArgs (toFunction fpargs))
        )
      )
      # Add __functionArgs
      (
        # Inherit the __functionArgs from the base build helper
        optionalAttrs inheritFunctionArgs (removeAttrs (functionArgs constructDrv) excludeDrvArgNames)
        # Recover the __functionArgs from the derived build helper
        // functionArgs (extendDrvArgs { })
      )
    // {
      inherit
        # Expose to the result build helper.
        constructDrv
        excludeDrvArgNames
        extendDrvArgs
        transformDrv
        ;
    };
}
</file>

<file path="lib/debug.nix">
/**
  Collection of functions useful for debugging
  broken nix expressions.

  * `trace`-like functions take two values, print
    the first to stderr and return the second.
  * `traceVal`-like functions take one argument
    which both printed and returned.
  * `traceSeq`-like functions fully evaluate their
    traced value before printing (not just to “weak
    head normal form” like trace does by default).
  * Functions that end in `-Fn` take an additional
    function as their first argument, which is applied
    to the traced value before it is printed.
*/
{ lib }:
let
  inherit (lib)
    isList
    isAttrs
    substring
    attrValues
    concatLists
    const
    elem
    generators
    id
    mapAttrs
    trace
    ;
in

rec {

  # -- TRACING --

  /**
    Conditionally trace the supplied message, based on a predicate.

    # Inputs

    `pred`

    : Predicate to check

    `msg`

    : Message that should be traced

    `x`

    : Value to return

    # Type

    ```
    traceIf :: bool -> string -> a -> a
    ```

    # Examples
    :::{.example}
    ## `lib.debug.traceIf` usage example

    ```nix
    traceIf true "hello" 3
    trace: hello
    => 3
    ```

    :::
  */
  traceIf =
    pred: msg: x:
    if pred then trace msg x else x;

  /**
    Trace the supplied value after applying a function to it, and
    return the original value.

    # Inputs

    `f`

    : Function to apply

    `x`

    : Value to trace and return

    # Type

    ```
    traceValFn :: (a -> b) -> a -> a
    ```

    # Examples
    :::{.example}
    ## `lib.debug.traceValFn` usage example

    ```nix
    traceValFn (v: "mystring ${v}") "foo"
    trace: mystring foo
    => "foo"
    ```

    :::
  */
  traceValFn = f: x: trace (f x) x;

  /**
    Trace the supplied value and return it.

    # Inputs

    `x`

    : Value to trace and return

    # Type

    ```
    traceVal :: a -> a
    ```

    # Examples
    :::{.example}
    ## `lib.debug.traceVal` usage example

    ```nix
    traceVal 42
    # trace: 42
    => 42
    ```

    :::
  */
  traceVal = traceValFn id;

  /**
    `builtins.trace`, but the value is `builtins.deepSeq`ed first.

    # Inputs

    `x`

    : The value to trace

    `y`

    : The value to return

    # Type

    ```
    traceSeq :: a -> b -> b
    ```

    # Examples
    :::{.example}
    ## `lib.debug.traceSeq` usage example

    ```nix
    trace { a.b.c = 3; } null
    trace: { a = <CODE>; }
    => null
    traceSeq { a.b.c = 3; } null
    trace: { a = { b = { c = 3; }; }; }
    => null
    ```

    :::
  */
  traceSeq = x: y: trace (builtins.deepSeq x x) y;

  /**
    Like `traceSeq`, but only evaluate down to depth n.
    This is very useful because lots of `traceSeq` usages
    lead to an infinite recursion.

    # Inputs

    `depth`

    : 1\. Function argument

    `x`

    : 2\. Function argument

    `y`

    : 3\. Function argument

    # Type

    ```
    traceSeqN :: Int -> a -> b -> b
    ```

    # Examples
    :::{.example}
    ## `lib.debug.traceSeqN` usage example

    ```nix
    traceSeqN 2 { a.b.c = 3; } null
    trace: { a = { b = {…}; }; }
    => null
    ```

    :::
  */
  traceSeqN =
    depth: x: y:
    let
      snip =
        v:
        if isList v then
          noQuotes "[…]" v
        else if isAttrs v then
          noQuotes "{…}" v
        else
          v;
      noQuotes = str: v: {
        __pretty = const str;
        val = v;
      };
      modify =
        n: fn: v:
        if (n == 0) then
          fn v
        else if isList v then
          map (modify (n - 1) fn) v
        else if isAttrs v then
          mapAttrs (const (modify (n - 1) fn)) v
        else
          v;
    in
    trace (generators.toPretty { allowPrettyValues = true; } (modify depth snip x)) y;

  /**
    A combination of `traceVal` and `traceSeq` that applies a
    provided function to the value to be traced after `deepSeq`ing
    it.

    # Inputs

    `f`

    : Function to apply

    `v`

    : Value to trace
  */
  traceValSeqFn = f: v: traceValFn f (builtins.deepSeq v v);

  /**
    A combination of `traceVal` and `traceSeq`.

    # Inputs

    `v`

    : Value to trace
  */
  traceValSeq = traceValSeqFn id;

  /**
    A combination of `traceVal` and `traceSeqN` that applies a
    provided function to the value to be traced.

    # Inputs

    `f`

    : Function to apply

    `depth`

    : 2\. Function argument

    `v`

    : Value to trace
  */
  traceValSeqNFn =
    f: depth: v:
    traceSeqN depth (f v) v;

  /**
    A combination of `traceVal` and `traceSeqN`.

    # Inputs

    `depth`

    : 1\. Function argument

    `v`

    : Value to trace
  */
  traceValSeqN = traceValSeqNFn id;

  /**
    Trace the input and output of a function `f` named `name`,
    both down to `depth`.

    This is useful for adding around a function call,
    to see the before/after of values as they are transformed.

    # Inputs

    `depth`

    : 1\. Function argument

    `name`

    : 2\. Function argument

    `f`

    : 3\. Function argument

    `v`

    : 4\. Function argument

    # Examples
    :::{.example}
    ## `lib.debug.traceFnSeqN` usage example

    ```nix
    traceFnSeqN 2 "id" (x: x) { a.b.c = 3; }
    trace: { fn = "id"; from = { a.b = {…}; }; to = { a.b = {…}; }; }
    => { a.b.c = 3; }
    ```

    :::
  */
  traceFnSeqN =
    depth: name: f: v:
    let
      res = f v;
    in
    lib.traceSeqN (depth + 1) {
      fn = name;
      from = v;
      to = res;
    } res;

  # -- TESTING --

  /**
    Evaluates a set of tests.

    A test is an attribute set `{expr, expected}`,
    denoting an expression and its expected result.

    The result is a `list` of __failed tests__, each represented as
    `{name, expected, result}`,

    - expected
      - What was passed as `expected`
    - result
      - The actual `result` of the test

    Used for regression testing of the functions in lib; see
    tests.nix for more examples.

    Important: Only attributes that start with `test` are executed.

    - If you want to run only a subset of the tests add the attribute `tests = ["testName"];`

    # Inputs

    `tests`

    : Tests to run

    # Type

    ```
    runTests :: {
      tests = [ String ];
      ${testName} :: {
        expr :: a;
        expected :: a;
      };
    }
    ->
    [
      {
        name :: String;
        expected :: a;
        result :: a;
      }
    ]
    ```

    # Examples
    :::{.example}
    ## `lib.debug.runTests` usage example

    ```nix
    runTests {
      testAndOk = {
        expr = lib.and true false;
        expected = false;
      };
      testAndFail = {
        expr = lib.and true false;
        expected = true;
      };
    }
    ->
    [
      {
        name = "testAndFail";
        expected = true;
        result = false;
      }
    ]
    ```

    :::
  */
  runTests =
    tests:
    concatLists (
      attrValues (
        mapAttrs (
          name: test:
          let
            testsToRun = if tests ? tests then tests.tests else [ ];
          in
          if
            (substring 0 4 name == "test" || elem name testsToRun)
            && ((testsToRun == [ ]) || elem name tests.tests)
            && (test.expr != test.expected)

          then
            [
              {
                inherit name;
                expected = test.expected;
                result = test.expr;
              }
            ]
          else
            [ ]
        ) tests
      )
    );

  /**
    Create a test assuming that list elements are `true`.

    # Inputs

    `expr`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `lib.debug.testAllTrue` usage example

    ```nix
    { testX = allTrue [ true ]; }
    ```

    :::
  */
  testAllTrue = expr: {
    inherit expr;
    expected = map (x: true) expr;
  };
}
</file>

<file path="lib/default.nix">
/*
  Library of low-level helper functions for nix expressions.

  Please implement (mostly) exhaustive unit tests
  for new functions in `./tests.nix`.
*/
let

  # A copy of `lib.makeExtensible'` in order to document `extend`.
  # It has been leading to some trouble, so we have to document it specially.
  makeExtensible' =
    rattrs:
    let
      self = rattrs self // {
        /**
          Patch the Nixpkgs library

          A function that applies patches onto the nixpkgs library.
          Usage is discouraged for most scenarios.

          :::{.note}
          The name `extends` is a bit misleading, as it doesn't actually extend the library, but rather patches it.
          It is merely a consequence of being implemented by `makeExtensible`.
          :::

          # Inputs

          - An "extension function" `f` that returns attributes that will be updated in the returned Nixpkgs library.

          # Output

          A patched Nixpkgs library.

          :::{.warning}
          This functionality is intended as an escape hatch for when the provided version of the Nixpkgs library has a flaw.

          If you were to use it to add new functionality, you will run into compatibility and interoperability issues.
          :::
        */
        extend = f: lib.makeExtensible (lib.extends f rattrs);
      };
    in
    self;

  lib = makeExtensible' (
    self:
    let
      callLibs = file: import file { lib = self; };
    in
    {

      # often used, or depending on very little
      trivial = callLibs ./trivial.nix;
      fixedPoints = callLibs ./fixed-points.nix;

      # datatypes
      attrsets = callLibs ./attrsets.nix;
      lists = callLibs ./lists.nix;
      strings = callLibs ./strings.nix;
      stringsWithDeps = callLibs ./strings-with-deps.nix;

      # packaging
      customisation = callLibs ./customisation.nix;
      derivations = callLibs ./derivations.nix;
      maintainers = import ../maintainers/maintainer-list.nix;
      teams = callLibs ../maintainers/team-list.nix;
      meta = callLibs ./meta.nix;
      versions = callLibs ./versions.nix;

      # module system
      modules = callLibs ./modules.nix;
      options = callLibs ./options.nix;
      types = callLibs ./types.nix;

      # constants
      licenses = callLibs ./licenses.nix;
      sourceTypes = callLibs ./source-types.nix;
      systems = callLibs ./systems;

      # serialization
      cli = callLibs ./cli.nix;
      gvariant = callLibs ./gvariant.nix;
      generators = callLibs ./generators.nix;

      # misc
      asserts = callLibs ./asserts.nix;
      debug = callLibs ./debug.nix;
      misc = callLibs ./deprecated/misc.nix;

      # domain-specific
      fetchers = callLibs ./fetchers.nix;

      # Eval-time filesystem handling
      path = callLibs ./path;
      filesystem = callLibs ./filesystem.nix;
      fileset = callLibs ./fileset;
      sources = callLibs ./sources.nix;

      # back-compat aliases
      platforms = self.systems.doubles;

      # linux kernel configuration
      kernel = callLibs ./kernel.nix;

      # network
      network = callLibs ./network;

      # TODO: For consistency, all builtins should also be available from a sub-library;
      # these are the only ones that are currently not
      inherit (builtins)
        addErrorContext
        isPath
        trace
        typeOf
        unsafeGetAttrPos
        ;
      inherit (self.trivial)
        id
        const
        pipe
        concat
        or
        and
        xor
        bitAnd
        bitOr
        bitXor
        bitNot
        boolToString
        mergeAttrs
        flip
        defaultTo
        mapNullable
        inNixShell
        isFloat
        min
        max
        importJSON
        importTOML
        warn
        warnIf
        warnIfNot
        throwIf
        throwIfNot
        checkListOfEnum
        info
        showWarnings
        nixpkgsVersion
        version
        isInOldestRelease
        oldestSupportedReleaseIsAtLeast
        mod
        compare
        splitByAndCompare
        seq
        deepSeq
        lessThan
        add
        sub
        functionArgs
        setFunctionArgs
        isFunction
        toFunction
        mirrorFunctionArgs
        fromHexString
        toHexString
        toBaseDigits
        inPureEvalMode
        isBool
        isInt
        pathExists
        genericClosure
        readFile
        ;
      inherit (self.fixedPoints)
        fix
        fix'
        converge
        extends
        composeExtensions
        composeManyExtensions
        makeExtensible
        makeExtensibleWithCustomName
        toExtension
        ;
      inherit (self.attrsets)
        attrByPath
        hasAttrByPath
        setAttrByPath
        getAttrFromPath
        attrVals
        attrNames
        attrValues
        getAttrs
        catAttrs
        filterAttrs
        filterAttrsRecursive
        foldlAttrs
        foldAttrs
        collect
        nameValuePair
        mapAttrs
        mapAttrs'
        mapAttrsToList
        attrsToList
        concatMapAttrs
        mapAttrsRecursive
        mapAttrsRecursiveCond
        genAttrs
        isDerivation
        toDerivation
        optionalAttrs
        zipAttrsWithNames
        zipAttrsWith
        zipAttrs
        recursiveUpdateUntil
        recursiveUpdate
        matchAttrs
        mergeAttrsList
        overrideExisting
        showAttrPath
        getOutput
        getFirstOutput
        getBin
        getLib
        getStatic
        getDev
        getInclude
        getMan
        chooseDevOutputs
        zipWithNames
        zip
        recurseIntoAttrs
        dontRecurseIntoAttrs
        cartesianProduct
        cartesianProductOfSets
        mapCartesianProduct
        updateManyAttrsByPath
        listToAttrs
        hasAttr
        getAttr
        isAttrs
        intersectAttrs
        removeAttrs
        ;
      inherit (self.lists)
        singleton
        forEach
        map
        foldr
        fold
        foldl
        foldl'
        imap0
        imap1
        filter
        ifilter0
        concatMap
        flatten
        remove
        findSingle
        findFirst
        any
        all
        count
        optional
        optionals
        toList
        range
        replicate
        partition
        zipListsWith
        zipLists
        reverseList
        listDfs
        toposort
        sort
        sortOn
        naturalSort
        compareLists
        take
        takeEnd
        drop
        dropEnd
        sublist
        last
        init
        crossLists
        unique
        allUnique
        intersectLists
        subtractLists
        mutuallyExclusive
        groupBy
        groupBy'
        concatLists
        genList
        length
        head
        tail
        elem
        elemAt
        isList
        ;
      inherit (self.strings)
        concatStrings
        concatMapStrings
        concatImapStrings
        stringLength
        substring
        isString
        replaceString
        replaceStrings
        intersperse
        concatStringsSep
        concatMapStringsSep
        concatMapAttrsStringSep
        concatImapStringsSep
        concatLines
        makeSearchPath
        makeSearchPathOutput
        makeLibraryPath
        makeIncludePath
        makeBinPath
        optionalString
        hasInfix
        hasPrefix
        hasSuffix
        stringToCharacters
        stringAsChars
        escape
        escapeShellArg
        escapeShellArgs
        isStorePath
        isStringLike
        isValidPosixName
        toShellVar
        toShellVars
        trim
        trimWith
        escapeRegex
        escapeURL
        escapeXML
        replaceChars
        lowerChars
        upperChars
        toLower
        toUpper
        toCamelCase
        toSentenceCase
        addContextFrom
        splitString
        splitStringBy
        removePrefix
        removeSuffix
        versionOlder
        versionAtLeast
        getName
        getVersion
        match
        split
        cmakeOptionType
        cmakeBool
        cmakeFeature
        mesonOption
        mesonBool
        mesonEnable
        nameFromURL
        enableFeature
        enableFeatureAs
        withFeature
        withFeatureAs
        fixedWidthString
        fixedWidthNumber
        toInt
        toIntBase10
        readPathsFromFile
        fileContents
        ;
      inherit (self.stringsWithDeps)
        textClosureList
        textClosureMap
        noDepEntry
        fullDepEntry
        packEntry
        stringAfter
        ;
      inherit (self.customisation)
        overrideDerivation
        makeOverridable
        callPackageWith
        callPackagesWith
        extendDerivation
        hydraJob
        makeScope
        makeScopeWithSplicing
        makeScopeWithSplicing'
        extendMkDerivation
        ;
      inherit (self.derivations) lazyDerivation optionalDrvAttr warnOnInstantiate;
      inherit (self.generators) mkLuaInline;
      inherit (self.meta)
        addMetaAttrs
        dontDistribute
        setName
        updateName
        appendToName
        mapDerivationAttrset
        setPrio
        lowPrio
        lowPrioSet
        hiPrio
        hiPrioSet
        licensesSpdx
        getLicenseFromSpdxId
        getLicenseFromSpdxIdOr
        getExe
        getExe'
        ;
      inherit (self.filesystem)
        pathType
        pathIsDirectory
        pathIsRegularFile
        packagesFromDirectoryRecursive
        ;
      inherit (self.sources)
        cleanSourceFilter
        cleanSource
        sourceByRegex
        sourceFilesBySuffices
        commitIdFromGitRepo
        cleanSourceWith
        pathHasContext
        canCleanSource
        pathIsGitRepo
        revOrTag
        repoRevToName
        ;
      inherit (self.modules)
        evalModules
        setDefaultModuleLocation
        unifyModuleSyntax
        applyModuleArgsIfFunction
        mergeModules
        mergeModules'
        mergeOptionDecls
        mergeDefinitions
        pushDownProperties
        dischargeProperties
        filterOverrides
        sortProperties
        fixupOptionType
        mkIf
        mkAssert
        mkDefinition
        mkMerge
        mkOverride
        mkOptionDefault
        mkDefault
        mkImageMediaOverride
        mkForce
        mkVMOverride
        mkFixStrictness
        mkOrder
        mkBefore
        mkAfter
        mkAliasDefinitions
        mkAliasAndWrapDefinitions
        fixMergeModules
        mkRemovedOptionModule
        mkRenamedOptionModule
        mkRenamedOptionModuleWith
        mkMergedOptionModule
        mkChangedOptionModule
        mkAliasOptionModule
        mkDerivedConfig
        doRename
        mkAliasOptionModuleMD
        ;
      evalOptionValue = lib.warn "External use of `lib.evalOptionValue` is deprecated. If your use case isn't covered by non-deprecated functions, we'd like to know more and perhaps support your use case well, instead of providing access to these low level functions. In this case please open an issue in https://github.com/nixos/nixpkgs/issues/." self.modules.evalOptionValue;
      inherit (self.options)
        isOption
        mkEnableOption
        mkSinkUndeclaredOptions
        mergeDefaultOption
        mergeOneOption
        mergeEqualOption
        mergeUniqueOption
        getValues
        getFiles
        optionAttrSetToDocList
        optionAttrSetToDocList'
        scrubOptionValue
        literalExpression
        literalExample
        showOption
        showOptionWithDefLocs
        showFiles
        unknownModule
        mkOption
        mkPackageOption
        mkPackageOptionMD
        literalMD
        ;
      inherit (self.types)
        isType
        setType
        defaultTypeMerge
        defaultFunctor
        isOptionType
        mkOptionType
        ;
      inherit (self.asserts)
        assertMsg
        assertOneOf
        ;
      inherit (self.debug)
        traceIf
        traceVal
        traceValFn
        traceSeq
        traceSeqN
        traceValSeq
        traceValSeqFn
        traceValSeqN
        traceValSeqNFn
        traceFnSeqN
        runTests
        testAllTrue
        ;
      inherit (self.misc)
        maybeEnv
        defaultMergeArg
        defaultMerge
        foldArgs
        maybeAttrNullable
        maybeAttr
        ifEnable
        checkFlag
        getValue
        checkReqs
        uniqList
        uniqListExt
        condConcat
        lazyGenericClosure
        innerModifySumArgs
        modifySumArgs
        innerClosePropagation
        closePropagation
        mapAttrsFlatten
        nvs
        setAttr
        setAttrMerge
        mergeAttrsWithFunc
        mergeAttrsConcatenateValues
        mergeAttrsNoOverride
        mergeAttrByFunc
        mergeAttrsByFuncDefaults
        mergeAttrsByFuncDefaultsClean
        mergeAttrBy
        fakeHash
        fakeSha256
        fakeSha512
        nixType
        imap
        ;
      inherit (self.versions)
        splitVersion
        ;
    }
  );
in
lib
</file>

<file path="lib/deprecated.nix">
{ lib }:

let
  inherit (lib)
    and
    any
    attrByPath
    attrNames
    compare
    concat
    concatMap
    elem
    filter
    foldl
    foldr
    genericClosure
    head
    imap1
    init
    isAttrs
    isFunction
    isInt
    isList
    lists
    listToAttrs
    mapAttrs
    mergeAttrs
    meta
    nameValuePair
    tail
    toList
    ;

  inherit (lib.attrsets) removeAttrs;

  # returns default if env var is not set
  maybeEnv = name: default:
    let value = builtins.getEnv name; in
    if value == "" then default else value;

  defaultMergeArg = x : y: if builtins.isAttrs y then
    y
  else
    (y x);
  defaultMerge = x: y: x // (defaultMergeArg x y);
  foldArgs = merger: f: init: x:
    let arg = (merger init (defaultMergeArg init x));
        # now add the function with composed args already applied to the final attrs
        base = (setAttrMerge "passthru" {} (f arg)
                        ( z: z // {
                            function = foldArgs merger f arg;
                            args = (attrByPath ["passthru" "args"] {} z) // x;
                          } ));
        withStdOverrides = base // {
          override = base.passthru.function;
        };
        in
          withStdOverrides;


  # shortcut for attrByPath ["name"] default attrs
  maybeAttrNullable = maybeAttr;

  # shortcut for attrByPath ["name"] default attrs
  maybeAttr = name: default: attrs: attrs.${name} or default;


  # Return the second argument if the first one is true or the empty version
  # of the second argument.
  ifEnable = cond: val:
    if cond then val
    else if builtins.isList val then []
    else if builtins.isAttrs val then {}
    # else if builtins.isString val then ""
    else if val == true || val == false then false
    else null;


  # Return true only if there is an attribute and it is true.
  checkFlag = attrSet: name:
        if name == "true" then true else
        if name == "false" then false else
        if (elem name (attrByPath ["flags"] [] attrSet)) then true else
        attrByPath [name] false attrSet ;


  # Input : attrSet, [ [name default] ... ], name
  # Output : its value or default.
  getValue = attrSet: argList: name:
  ( attrByPath [name] (if checkFlag attrSet name then true else
        if argList == [] then null else
        let x = builtins.head argList; in
                if (head x) == name then
                        (head (tail x))
                else (getValue attrSet
                        (tail argList) name)) attrSet );


  # Input : attrSet, [[name default] ...], [ [flagname reqs..] ... ]
  # Output : are reqs satisfied? It's asserted.
  checkReqs = attrSet: argList: condList:
  (
    foldr and true
      (map (x: let name = (head x); in

        ((checkFlag attrSet name) ->
        (foldr and true
        (map (y: let val=(getValue attrSet argList y); in
                (val!=null) && (val!=false))
        (tail x))))) condList));


  # This function has O(n^2) performance.
  uniqList = { inputList, acc ? [] }:
    let go = xs: acc:
             if xs == []
             then []
             else let x = head xs;
                      y = if elem x acc then [] else [x];
                  in y ++ go (tail xs) (y ++ acc);
    in go inputList acc;

  uniqListExt = { inputList,
                  outputList ? [],
                  getter ? (x: x),
                  compare ? (x: y: x==y) }:
        if inputList == [] then outputList else
        let x = head inputList;
            isX = y: (compare (getter y) (getter x));
            newOutputList = outputList ++
                (if any isX outputList then [] else [x]);
        in uniqListExt { outputList = newOutputList;
                         inputList = (tail inputList);
                         inherit getter compare;
                       };

  condConcat = name: list: checker:
        if list == [] then name else
        if checker (head list) then
                condConcat
                        (name + (head (tail list)))
                        (tail (tail list))
                        checker
        else condConcat
                name (tail (tail list)) checker;

  lazyGenericClosure = {startSet, operator}:
    let
      work = list: doneKeys: result:
        if list == [] then
          result
        else
          let x = head list; key = x.key; in
          if elem key doneKeys then
            work (tail list) doneKeys result
          else
            work (tail list ++ operator x) ([key] ++ doneKeys) ([x] ++ result);
    in
      work startSet [] [];

  innerModifySumArgs = f: x: a: b: if b == null then (f a b) // x else
        innerModifySumArgs f x (a // b);
  modifySumArgs = f: x: innerModifySumArgs f x {};


  innerClosePropagation = acc: xs:
    if xs == []
    then acc
    else let y  = head xs;
             ys = tail xs;
         in if ! isAttrs y
            then innerClosePropagation acc ys
            else let acc' = [y] ++ acc;
                 in innerClosePropagation
                      acc'
                      (uniqList { inputList = (maybeAttrNullable "propagatedBuildInputs" [] y)
                                           ++ (maybeAttrNullable "propagatedNativeBuildInputs" [] y)
                                           ++ ys;
                                  acc = acc';
                                }
                      );

  closePropagationSlow = list: (uniqList {inputList = (innerClosePropagation [] list);});

  # This is an optimisation of closePropagation which avoids the O(n^2) behavior
  # Using a list of derivations, it generates the full closure of the propagatedXXXBuildInputs
  # The ordering / sorting / comparison is done based on the `outPath`
  # attribute of each derivation.
  # On some benchmarks, it performs up to 15 times faster than closePropagation.
  # See https://github.com/NixOS/nixpkgs/pull/194391 for details.
  closePropagationFast = list:
    builtins.map (x: x.val) (builtins.genericClosure {
      startSet = builtins.map (x: {
        key = x.outPath;
        val = x;
      }) (builtins.filter (x: x != null) list);
      operator = item:
        if !builtins.isAttrs item.val then
          [ ]
        else
          builtins.concatMap (x:
            if x != null then [{
              key = x.outPath;
              val = x;
            }] else
              [ ]) ((item.val.propagatedBuildInputs or [ ])
                ++ (item.val.propagatedNativeBuildInputs or [ ]));
    });

  closePropagation = if builtins ? genericClosure
    then closePropagationFast
    else closePropagationSlow;

  # calls a function (f attr value ) for each record item. returns a list
  mapAttrsFlatten = f: r: map (attr: f attr r.${attr}) (attrNames r);

  # attribute set containing one attribute
  nvs = name: value: listToAttrs [ (nameValuePair name value) ];
  # adds / replaces an attribute of an attribute set
  setAttr = set: name: v: set // (nvs name v);

  # setAttrMerge (similar to mergeAttrsWithFunc but only merges the values of a particular name)
  # setAttrMerge "a" [] { a = [2];} (x: x ++ [3]) -> { a = [2 3]; }
  # setAttrMerge "a" [] {         } (x: x ++ [3]) -> { a = [  3]; }
  setAttrMerge = name: default: attrs: f:
    setAttr attrs name (f (maybeAttr name default attrs));

  # Using f = a: b = b the result is similar to //
  # merge attributes with custom function handling the case that the attribute
  # exists in both sets
  mergeAttrsWithFunc = f: set1: set2:
    foldr (n: set: if set ? ${n}
                        then setAttr set n (f set.${n} set2.${n})
                        else set )
           (set2 // set1) (attrNames set2);

  # merging two attribute set concatenating the values of same attribute names
  # eg { a = 7; } {  a = [ 2 3 ]; } becomes { a = [ 7 2 3 ]; }
  mergeAttrsConcatenateValues = mergeAttrsWithFunc ( a: b: (toList a) ++ (toList b) );

  # merges attributes using //, if a name exists in both attributes
  # an error will be triggered unless its listed in mergeLists
  # so you can mergeAttrsNoOverride { buildInputs = [a]; } { buildInputs = [a]; } {} to get
  # { buildInputs = [a b]; }
  # merging buildPhase doesn't really make sense. The cases will be rare where appending /prefixing will fit your needs?
  # in these cases the first buildPhase will override the second one
  # ! deprecated, use mergeAttrByFunc instead
  mergeAttrsNoOverride = { mergeLists ? ["buildInputs" "propagatedBuildInputs"],
                           overrideSnd ? [ "buildPhase" ]
                         }: attrs1: attrs2:
    foldr (n: set:
        setAttr set n ( if set ? ${n}
            then # merge
              if elem n mergeLists # attribute contains list, merge them by concatenating
                then attrs2.${n} ++ attrs1.${n}
              else if elem n overrideSnd
                then attrs1.${n}
              else throw "error mergeAttrsNoOverride, attribute ${n} given in both attributes - no merge func defined"
            else attrs2.${n} # add attribute not existing in attr1
           )) attrs1 (attrNames attrs2);


  # example usage:
  # mergeAttrByFunc  {
  #   inherit mergeAttrBy; # defined below
  #   buildInputs = [ a b ];
  # } {
  #  buildInputs = [ c d ];
  # };
  # will result in
  # { mergeAttrsBy = [...]; buildInputs = [ a b c d ]; }
  # is used by defaultOverridableDelayableArgs and can be used when composing using
  # foldArgs, composedArgsAndFun or applyAndFun. Example: composableDerivation in all-packages.nix
  mergeAttrByFunc = x: y:
    let
          mergeAttrBy2 = { mergeAttrBy = mergeAttrs; }
                      // (maybeAttr "mergeAttrBy" {} x)
                      // (maybeAttr "mergeAttrBy" {} y); in
    foldr mergeAttrs {} [
      x y
      (mapAttrs ( a: v: # merge special names using given functions
          if x ? ${a}
             then if y ? ${a}
               then v x.${a} y.${a} # both have attr, use merge func
               else x.${a} # only x has attr
             else y.${a} # only y has attr)
          ) (removeAttrs mergeAttrBy2
                         # don't merge attrs which are neither in x nor y
                         (filter (a: ! x ? ${a} && ! y ? ${a})
                                 (attrNames mergeAttrBy2))
            )
      )
    ];
  mergeAttrsByFuncDefaults = foldl mergeAttrByFunc { inherit mergeAttrBy; };
  mergeAttrsByFuncDefaultsClean = list: removeAttrs (mergeAttrsByFuncDefaults list) ["mergeAttrBy"];

  # sane defaults (same name as attr name so that inherit can be used)
  mergeAttrBy = # { buildInputs = concatList; [...]; passthru = mergeAttr; [..]; }
    listToAttrs (map (n: nameValuePair n concat)
      [ "nativeBuildInputs" "buildInputs" "propagatedBuildInputs" "configureFlags" "prePhases" "postAll" "patches" ])
    // listToAttrs (map (n: nameValuePair n mergeAttrs) [ "passthru" "meta" "cfg" "flags" ])
    // listToAttrs (map (n: nameValuePair n (a: b: "${a}\n${b}") ) [ "preConfigure" "postInstall" ])
  ;

  nixType = x:
      if isAttrs x then
          if x ? outPath then "derivation"
          else "attrs"
      else if isFunction x then "function"
      else if isList x then "list"
      else if x == true then "bool"
      else if x == false then "bool"
      else if x == null then "null"
      else if isInt x then "int"
      else "string";

  /**
    # Deprecated

    For historical reasons, imap has an index starting at 1.

    But for consistency with the rest of the library we want an index
    starting at zero.
  */
  imap = imap1;

  # Fake hashes. Can be used as hash placeholders, when computing hash ahead isn't trivial
  fakeHash = "sha256-AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=";
  fakeSha256 = "0000000000000000000000000000000000000000000000000000000000000000";
  fakeSha512 = "00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000";

in

# Everything in this attrset is the public interface of the file.
{
  inherit
    checkFlag
    checkReqs
    closePropagation
    closePropagationFast
    closePropagationSlow
    condConcat
    defaultMerge
    defaultMergeArg
    fakeHash
    fakeSha256
    fakeSha512
    foldArgs
    getValue
    ifEnable
    imap
    innerClosePropagation
    innerModifySumArgs
    lazyGenericClosure
    mapAttrsFlatten
    maybeAttr
    maybeAttrNullable
    maybeEnv
    mergeAttrBy
    mergeAttrByFunc
    mergeAttrsByFuncDefaults
    mergeAttrsByFuncDefaultsClean
    mergeAttrsConcatenateValues
    mergeAttrsNoOverride
    mergeAttrsWithFunc
    modifySumArgs
    nixType
    nvs
    setAttr
    setAttrMerge
    uniqList
    uniqListExt
    ;
}
</file>

<file path="lib/derivations.nix">
{ lib }:

let
  inherit (lib)
    genAttrs
    isString
    mapAttrs
    removeAttrs
    throwIfNot
    ;

  showMaybeAttrPosPre =
    prefix: attrName: v:
    let
      pos = builtins.unsafeGetAttrPos attrName v;
    in
    if pos == null then "" else "${prefix}${pos.file}:${toString pos.line}:${toString pos.column}";

  showMaybePackagePosPre =
    prefix: pkg:
    if pkg ? meta.position && isString pkg.meta.position then "${prefix}${pkg.meta.position}" else "";
in
{
  /**
    Restrict a derivation to a predictable set of attribute names, so
    that the returned attrset is not strict in the actual derivation,
    saving a lot of computation when the derivation is non-trivial.

    This is useful in situations where a derivation might only be used for its
    passthru attributes, improving evaluation performance.

    The returned attribute set is lazy in `derivation`. Specifically, this
    means that the derivation will not be evaluated in at least the
    situations below.

    For illustration and/or testing, we define derivation such that its
    evaluation is very noticeable.

        let derivation = throw "This won't be evaluated.";

    In the following expressions, `derivation` will _not_ be evaluated:

        (lazyDerivation { inherit derivation; }).type

        attrNames (lazyDerivation { inherit derivation; })

        (lazyDerivation { inherit derivation; } // { foo = true; }).foo

        (lazyDerivation { inherit derivation; meta.foo = true; }).meta

    In these expressions, `derivation` _will_ be evaluated:

        "${lazyDerivation { inherit derivation }}"

        (lazyDerivation { inherit derivation }).outPath

        (lazyDerivation { inherit derivation }).meta

    And the following expressions are not valid, because the refer to
    implementation details and/or attributes that may not be present on
    some derivations:

        (lazyDerivation { inherit derivation }).buildInputs

        (lazyDerivation { inherit derivation }).passthru

        (lazyDerivation { inherit derivation }).pythonPath

    # Inputs

    Takes an attribute set with the following attributes

    `derivation`
    : The derivation to be wrapped.

    `meta`
    : Optional meta attribute.

      While this function is primarily about derivations, it can improve
      the `meta` package attribute, which is usually specified through
      `mkDerivation`.

    `passthru`
    : Optional extra values to add to the returned attrset.

      This can be used for adding package attributes, such as `tests`.

    `outputs`
    : Optional list of assumed outputs. Default: ["out"]

      This must match the set of outputs that the returned derivation has.
      You must use this when the derivation has multiple outputs.
  */
  lazyDerivation =
    args@{
      derivation,
      meta ? null,
      passthru ? { },
      outputs ? [ "out" ],
    }:
    let
      # These checks are strict in `drv` and some `drv` attributes, but the
      # attrset spine returned by lazyDerivation does not depend on it.
      # Instead, the individual derivation attributes do depend on it.
      checked =
        throwIfNot (derivation.type or null == "derivation") "lazyDerivation: input must be a derivation."
          throwIfNot
          # NOTE: Technically we could require our outputs to be a subset of the
          # actual ones, or even leave them unchecked and fail on a lazy basis.
          # However, consider the case where an output is added in the underlying
          # derivation, such as dev. lazyDerivation would remove it and cause it
          # to fail as a buildInputs item, without any indication as to what
          # happened. Hence the more stringent condition. We could consider
          # adding a flag to control this behavior if there's a valid case for it,
          # but the documentation must have a note like this.
          (derivation.outputs == outputs)
          ''
            lib.lazyDerivation: The derivation ${derivation.name or "<unknown>"} has outputs that don't match the assumed outputs.

            Assumed outputs passed to lazyDerivation${showMaybeAttrPosPre ",\n    at " "outputs" args}:
                ${lib.generators.toPretty { multiline = false; } outputs};

            Actual outputs of the derivation${showMaybePackagePosPre ",\n    defined at " derivation}:
                ${lib.generators.toPretty { multiline = false; } derivation.outputs}

            If the outputs are known ahead of evaluating the derivation,
            then update the lazyDerivation call to match the actual outputs, in the same order.
            If lazyDerivation is passed a literal value, just change it to the actual outputs.
            As a result it will work as before / as intended.

            Otherwise, when the outputs are dynamic and can't be known ahead of time, it won't
            be possible to add laziness, but lib.lazyDerivation may still be useful for trimming
            the attributes.
            If you want to keep trimming the attributes, make sure that the package is in a
            variable (don't evaluate it twice!) and pass the variable and its outputs attribute
            to lib.lazyDerivation. This largely defeats laziness, but keeps the trimming.
            If none of the above works for you, replace the lib.lazyDerivation call by the
            expression in the derivation argument.
          ''
          derivation;
    in
    {
      # Hardcoded `type`
      #
      # `lazyDerivation` requires its `derivation` argument to be a derivation,
      # so if it is not, that is a programming error by the caller and not
      # something that `lazyDerivation` consumers should be able to correct
      # for after the fact.
      # So, to improve laziness, we assume correctness here and check it only
      # when actual derivation values are accessed later.
      type = "derivation";

      # A fixed set of derivation values, so that `lazyDerivation` can return
      # its attrset before evaluating `derivation`.
      # This must only list attributes that are available on _all_ derivations.
      inherit (checked)
        outPath
        outputName
        drvPath
        name
        system
        ;
      inherit outputs;

      # The meta attribute can either be taken from the derivation, or if the
      # `lazyDerivation` caller knew a shortcut, be taken from there.
      meta = args.meta or checked.meta;
    }
    // genAttrs outputs (outputName: checked.${outputName})
    // passthru;

  /**
    Conditionally set a derivation attribute.

    Because `mkDerivation` sets `__ignoreNulls = true`, a derivation
    attribute set to `null` will not impact the derivation output hash.
    Thus, this function passes through its `value` argument if the `cond`
    is `true`, but returns `null` if not.

    # Inputs

    `cond`

    : Condition

    `value`

    : Attribute value

    # Type

    ```
    optionalDrvAttr :: Bool -> a -> a | Null
    ```

    # Examples
    :::{.example}
    ## `lib.derivations.optionalDrvAttr` usage example

    ```nix
    (stdenv.mkDerivation {
      name = "foo";
      x = optionalDrvAttr true 1;
      y = optionalDrvAttr false 1;
    }).drvPath == (stdenv.mkDerivation {
      name = "foo";
      x = 1;
    }).drvPath
    => true
    ```

    :::
  */
  optionalDrvAttr = cond: value: if cond then value else null;

  /**
    Wrap a derivation such that instantiating it produces a warning.

    All attributes will be wrapped with `lib.warn` except from `.meta`, `.name`,
    and `.type` which are used by `nix search`, and `.outputName` which avoids
    double warnings with `nix-instantiate` and `nix-build`.

    # Inputs

    `msg`
    : The warning message to emit (via `lib.warn`).

    `drv`
    : The derivation to wrap.

    # Examples
    :::{.example}
    ## `lib.derivations.warnOnInstantiate` usage example

    ```nix
    {
      myPackage = warnOnInstantiate "myPackage has been renamed to my-package" my-package;
    }
    ```

    :::
  */
  warnOnInstantiate =
    msg: drv:
    let
      drvToWrap = removeAttrs drv [
        "meta"
        "name"
        "type"
        "outputName"
      ];
    in
    drv // mapAttrs (_: lib.warn msg) drvToWrap;
}
</file>

<file path="lib/fetchers.nix">
# snippets that can be shared by multiple fetchers (pkgs/build-support)
{ lib }:
let
  commonH = hashTypes: rec {
    hashNames = [ "hash" ] ++ hashTypes;
    hashSet = lib.genAttrs hashNames (lib.const { });
  };

  fakeH = {
    hash = lib.fakeHash;
    sha256 = lib.fakeSha256;
    sha512 = lib.fakeSha512;
  };
in
rec {

  proxyImpureEnvVars = [
    # We borrow these environment variables from the caller to allow
    # easy proxy configuration.  This is impure, but a fixed-output
    # derivation like fetchurl is allowed to do so since its result is
    # by definition pure.
    "http_proxy"
    "https_proxy"
    "ftp_proxy"
    "all_proxy"
    "no_proxy"
    "HTTP_PROXY"
    "HTTPS_PROXY"
    "FTP_PROXY"
    "ALL_PROXY"
    "NO_PROXY"

    # https proxies typically need to inject custom root CAs too
    "NIX_SSL_CERT_FILE"
  ];

  /**
    Converts an attrset containing one of `hash`, `sha256` or `sha512`,
    into one containing `outputHash{,Algo}` as accepted by `mkDerivation`.

    An appropriate “fake hash” is substituted when the hash value is `""`,
    as is the [convention for fetchers](#sec-pkgs-fetchers-updating-source-hashes-fakehash-method).

    All other attributes in the set remain as-is.

    # Example

    ```nix
    normalizeHash { } { hash = ""; foo = "bar"; }
    =>
    {
      outputHash = lib.fakeHash;
      outputHashAlgo = null;
      foo = "bar";
    }
    ```

    ```nix
    normalizeHash { } { sha256 = lib.fakeSha256; }
    =>
    {
      outputHash = lib.fakeSha256;
      outputHashAlgo = "sha256";
    }
    ```

    ```nix
    normalizeHash { } { sha512 = lib.fakeSha512; }
    =>
    {
      outputHash = lib.fakeSha512;
      outputHashAlgo = "sha512";
    }
    ```

    # Type
    ```
    normalizeHash :: { hashTypes :: List String, required :: Bool } -> AttrSet -> AttrSet
    ```

    # Arguments

    hashTypes
    : the set of attribute names accepted as hash inputs, in addition to `hash`

    required
    : whether to throw if no hash was present in the input; otherwise returns the original input, unmodified
  */
  normalizeHash =
    {
      hashTypes ? [ "sha256" ],
      required ? true,
    }:
    let
      inherit (lib)
        concatMapStringsSep
        head
        tail
        throwIf
        ;
      inherit (lib.attrsets)
        attrsToList
        intersectAttrs
        removeAttrs
        optionalAttrs
        ;

      inherit (commonH hashTypes) hashNames hashSet;
    in
    args:
    if args ? "outputHash" then
      args
    else
      let
        # The argument hash, as a {name, value} pair
        h =
          # All hashes passed in arguments (possibly 0 or >1) as a list of {name, value} pairs
          let
            hashesAsNVPairs = attrsToList (intersectAttrs hashSet args);
          in
          if hashesAsNVPairs == [ ] then
            throwIf required "fetcher called without `hash`" null
          else if tail hashesAsNVPairs != [ ] then
            throw "fetcher called with mutually-incompatible arguments: ${
              concatMapStringsSep ", " (a: a.name) hashesAsNVPairs
            }"
          else
            head hashesAsNVPairs;
      in
      removeAttrs args hashNames
      // (optionalAttrs (h != null) {
        outputHashAlgo = if h.name == "hash" then null else h.name;
        outputHash =
          if h.value == "" then
            fakeH.${h.name} or (throw "no “fake hash” defined for ${h.name}")
          else
            h.value;
      });

  /**
    Wraps a function which accepts `outputHash{,Algo}` into one which accepts `hash` or `sha{256,512}`

    # Example
    ```nix
    withNormalizedHash { hashTypes = [ "sha256" "sha512" ]; } (
      { outputHash, outputHashAlgo, ... }:
      ...
    )
    ```
    is a function which accepts one of `hash`, `sha256`, or `sha512` (or the original's `outputHash` and `outputHashAlgo`).

    Its `functionArgs` metadata only lists `hash` as a parameter, optional iff. `outputHash` was an optional parameter of
    the original function.  `sha256`, `sha512`, `outputHash`, or `outputHashAlgo` are not mentioned in the `functionArgs`
    metadata.

    # Type
    ```
    withNormalizedHash :: { hashTypes :: List String } -> (AttrSet -> T) -> (AttrSet -> T)
    ```

    # Arguments

    hashTypes
    : the set of attribute names accepted as hash inputs, in addition to `hash`
    : they must correspond to a valid value for `outputHashAlgo`, currently one of: `md5`, `sha1`, `sha256`, or `sha512`.

    f
    : the function to be wrapped

    ::: {.note}
    In nixpkgs, `mkDerivation` rejects MD5 `outputHash`es, and SHA-1 is being deprecated.

    As such, there is no reason to add `md5` to `hashTypes`, and
    `sha1` should only ever be included for backwards compatibility.
    :::

    # Output

    `withNormalizedHash { inherit hashTypes; } f` is functionally equivalent to
    ```nix
    args: f (normalizeHash {
      inherit hashTypes;
      required = !(lib.functionArgs f).outputHash;
    } args)
    ```

    However, `withNormalizedHash` preserves `functionArgs` metadata insofar as possible,
    and is implemented somewhat more efficiently.
  */
  withNormalizedHash =
    {
      hashTypes ? [ "sha256" ],
    }:
    fetcher:
    let
      inherit (lib.attrsets) intersectAttrs removeAttrs;
      inherit (lib.trivial) functionArgs setFunctionArgs;

      inherit (commonH hashTypes) hashSet;
      fArgs = functionArgs fetcher;

      normalize = normalizeHash {
        inherit hashTypes;
        required = !fArgs.outputHash;
      };
    in
    # The o.g. fetcher must *only* accept outputHash and outputHashAlgo
    assert fArgs ? outputHash && fArgs ? outputHashAlgo;
    assert intersectAttrs fArgs hashSet == { };

    setFunctionArgs (args: fetcher (normalize args)) (
      removeAttrs fArgs [
        "outputHash"
        "outputHashAlgo"
      ]
      // {
        hash = fArgs.outputHash;
      }
    );
}
</file>

<file path="lib/filesystem.nix">
/**
  Functions for querying information about the filesystem
  without copying any files to the Nix store.
*/
{ lib }:

# Tested in lib/tests/filesystem.sh
let
  inherit (builtins)
    readDir
    pathExists
    toString
    ;

  inherit (lib.filesystem)
    pathIsDirectory
    pathIsRegularFile
    pathType
    packagesFromDirectoryRecursive
    ;

  inherit (lib.strings)
    hasSuffix
    ;
in

{

  /**
    The type of a path. The path needs to exist and be accessible.
    The result is either "directory" for a directory, "regular" for a regular file, "symlink" for a symlink, or "unknown" for anything else.

    # Inputs

    path

    : The path to query

    # Type

    ```
    pathType :: Path -> String
    ```

    # Examples
    :::{.example}
    ## `lib.filesystem.pathType` usage example

    ```nix
    pathType /.
    => "directory"

    pathType /some/file.nix
    => "regular"
    ```

    :::
  */
  pathType =
    builtins.readFileType or
    # Nix <2.14 compatibility shim
    (
      path:
      if
        !pathExists path
      # Fail irrecoverably to mimic the historic behavior of this function and
      # the new builtins.readFileType
      then
        abort "lib.filesystem.pathType: Path ${toString path} does not exist."
      # The filesystem root is the only path where `dirOf / == /` and
      # `baseNameOf /` is not valid. We can detect this and directly return
      # "directory", since we know the filesystem root can't be anything else.
      else if dirOf path == path then
        "directory"
      else
        (readDir (dirOf path)).${baseNameOf path}
    );

  /**
    Whether a path exists and is a directory.

    # Inputs

    `path`

    : 1\. Function argument

    # Type

    ```
    pathIsDirectory :: Path -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.filesystem.pathIsDirectory` usage example

    ```nix
    pathIsDirectory /.
    => true

    pathIsDirectory /this/does/not/exist
    => false

    pathIsDirectory /some/file.nix
    => false
    ```

    :::
  */
  pathIsDirectory = path: pathExists path && pathType path == "directory";

  /**
    Whether a path exists and is a regular file, meaning not a symlink or any other special file type.

    # Inputs

    `path`

    : 1\. Function argument

    # Type

    ```
    pathIsRegularFile :: Path -> Bool
    ```

    # Examples
    :::{.example}
    ## `lib.filesystem.pathIsRegularFile` usage example

    ```nix
    pathIsRegularFile /.
    => false

    pathIsRegularFile /this/does/not/exist
    => false

    pathIsRegularFile /some/file.nix
    => true
    ```

    :::
  */
  pathIsRegularFile = path: pathExists path && pathType path == "regular";

  /**
    A map of all haskell packages defined in the given path,
    identified by having a cabal file with the same name as the
    directory itself.

    # Inputs

    `root`

    : The directory within to search

    # Type

    ```
    Path -> Map String Path
    ```
  */
  haskellPathsInDir =
    root:
    let
      # Files in the root
      root-files = builtins.attrNames (builtins.readDir root);
      # Files with their full paths
      root-files-with-paths = map (file: {
        name = file;
        value = root + "/${file}";
      }) root-files;
      # Subdirectories of the root with a cabal file.
      cabal-subdirs = builtins.filter (
        { name, value }: builtins.pathExists (value + "/${name}.cabal")
      ) root-files-with-paths;
    in
    builtins.listToAttrs cabal-subdirs;
  /**
    Find the first directory containing a file matching 'pattern'
    upward from a given 'file'.
    Returns 'null' if no directories contain a file matching 'pattern'.

    # Inputs

    `pattern`

    : The pattern to search for

    `file`

    : The file to start searching upward from

    # Type

    ```
    RegExp -> Path -> Nullable { path : Path; matches : [ MatchResults ]; }
    ```
  */
  locateDominatingFile =
    pattern: file:
    let
      go =
        path:
        let
          files = builtins.attrNames (builtins.readDir path);
          matches = builtins.filter (match: match != null) (map (builtins.match pattern) files);
        in
        if builtins.length matches != 0 then
          { inherit path matches; }
        else if path == /. then
          null
        else
          go (dirOf path);
      parent = dirOf file;
      isDir =
        let
          base = baseNameOf file;
          type = (builtins.readDir parent).${base} or null;
        in
        file == /. || type == "directory";
    in
    go (if isDir then file else parent);

  /**
    Given a directory, return a flattened list of all files within it recursively.

    # Inputs

    `dir`

    : The path to recursively list

    # Type

    ```
    Path -> [ Path ]
    ```
  */
  listFilesRecursive =
    dir:
    lib.flatten (
      lib.mapAttrsToList (
        name: type:
        if type == "directory" then
          lib.filesystem.listFilesRecursive (dir + "/${name}")
        else
          dir + "/${name}"
      ) (builtins.readDir dir)
    );

  /**
    Transform a directory tree containing package files suitable for
    `callPackage` into a matching nested attribute set of derivations.

    For a directory tree like this:

    ```
    my-packages
    ├── a.nix
    ├── b.nix
    ├── c
    │  ├── my-extra-feature.patch
    │  ├── package.nix
    │  └── support-definitions.nix
    └── my-namespace
       ├── d.nix
       ├── e.nix
       └── f
          └── package.nix
    ```

    `packagesFromDirectoryRecursive` will produce an attribute set like this:

    ```nix
    # packagesFromDirectoryRecursive {
    #   callPackage = pkgs.callPackage;
    #   directory = ./my-packages;
    # }
    {
      a = pkgs.callPackage ./my-packages/a.nix { };
      b = pkgs.callPackage ./my-packages/b.nix { };
      c = pkgs.callPackage ./my-packages/c/package.nix { };
      my-namespace = {
        d = pkgs.callPackage ./my-packages/my-namespace/d.nix { };
        e = pkgs.callPackage ./my-packages/my-namespace/e.nix { };
        f = pkgs.callPackage ./my-packages/my-namespace/f/package.nix { };
      };
    }
    ```

    In particular:
    - If the input directory contains a `package.nix` file, then
      `callPackage <directory>/package.nix { }` is returned.
    - Otherwise, the input directory's contents are listed and transformed into
      an attribute set.
      - If a regular file's name has the `.nix` extension, it is turned into attribute
        where:
        - The attribute name is the file name without the `.nix` extension
        - The attribute value is `callPackage <file path> { }`
      - Directories are turned into an attribute where:
        - The attribute name is the name of the directory
        - The attribute value is the result of calling
          `packagesFromDirectoryRecursive { ... }` on the directory.

        As a result, directories with no `.nix` files (including empty
        directories) will be transformed into empty attribute sets.
      - Other files are ignored, including symbolic links to directories and to regular `.nix`
        files; this is because nixlang code cannot distinguish the type of a link's target.

    # Type

    ```
    packagesFromDirectoryRecursive :: {
      callPackage :: Path -> {} -> a,
      newScope? :: AttrSet -> scope,
      directory :: Path,
    } -> AttrSet
    ```

    # Inputs

    `callPackage`
    : The function used to convert a Nix file's path into a leaf of the attribute set.
      It is typically the `callPackage` function, taken from either `pkgs` or a new scope corresponding to the `directory`.

    `newScope`
    : If present, this function is used when recursing into a directory, to generate a new scope.
      The arguments are updated with the scope's `callPackage` and `newScope` functions, so packages can require
      anything in their scope, or in an ancestor of their scope.

    `directory`
    : The directory to read package files from.

    # Examples
    :::{.example}
    ## Basic use of `lib.packagesFromDirectoryRecursive`

    ```nix
    packagesFromDirectoryRecursive {
      inherit (pkgs) callPackage;
      directory = ./my-packages;
    }
    => { ... }
    ```

    In this case, `callPackage` will only search `pkgs` for a file's input parameters.
    In other words, a file cannot refer to another file in the directory in its input parameters.
    :::

    ::::{.example}
    ## Create a scope for the nix files found in a directory
    ```nix
    packagesFromDirectoryRecursive {
      inherit (pkgs) callPackage newScope;
      directory = ./my-packages;
    }
    => { ... }
    ```

    For example, take the following directory structure:
    ```
    my-packages
    ├── a.nix    → { b }: assert b ? b1; ...
    └── b
       ├── b1.nix  → { a }: ...
       └── b2.nix
    ```

    Here, `b1.nix` can specify `{ a }` as a parameter, which `callPackage` will resolve as expected.
    Likewise, `a.nix` receive an attrset corresponding to the contents of the `b` directory.

    :::{.note}
    `a.nix` cannot directly take as inputs packages defined in a child directory, such as `b1`.
    :::
    ::::
  */
  packagesFromDirectoryRecursive =
    let
      inherit (lib)
        concatMapAttrs
        id
        makeScope
        recurseIntoAttrs
        removeSuffix
        ;

      # Generate an attrset corresponding to a given directory.
      # This function is outside `packagesFromDirectoryRecursive`'s lambda expression,
      #  to prevent accidentally using its parameters.
      processDir =
        { callPackage, directory, ... }@args:
        concatMapAttrs (
          name: type:
          # for each directory entry
          let
            path = directory + "/${name}";
          in
          if type == "directory" then
            {
              # recurse into directories
              "${name}" = packagesFromDirectoryRecursive (
                args
                // {
                  directory = path;
                }
              );
            }
          else if type == "regular" && hasSuffix ".nix" name then
            {
              # call .nix files
              "${removeSuffix ".nix" name}" = callPackage path { };
            }
          else if type == "regular" then
            {
              # ignore non-nix files
            }
          else
            throw ''
              lib.filesystem.packagesFromDirectoryRecursive: Unsupported file type ${type} at path ${toString path}
            ''
        ) (builtins.readDir directory);
    in
    {
      callPackage,
      newScope ? throw "lib.packagesFromDirectoryRecursive: newScope wasn't passed in args",
      directory,
    }@args:
    let
      defaultPath = directory + "/package.nix";
    in
    if pathExists defaultPath then
      # if `${directory}/package.nix` exists, call it directly
      callPackage defaultPath { }
    else if args ? newScope then
      # Create a new scope and mark it `recurseForDerivations`.
      # This lets the packages refer to each other.
      # See:
      #  [lib.makeScope](https://nixos.org/manual/nixpkgs/unstable/#function-library-lib.customisation.makeScope) and
      #  [lib.recurseIntoAttrs](https://nixos.org/manual/nixpkgs/unstable/#function-library-lib.customisation.makeScope)
      recurseIntoAttrs (
        makeScope newScope (
          self:
          # generate the attrset representing the directory, using the new scope's `callPackage` and `newScope`
          processDir (
            args
            // {
              inherit (self) callPackage newScope;
            }
          )
        )
      )
    else
      processDir args;

  /**
    Append `/default.nix` if the passed path is a directory.

    # Type

    ```
    resolveDefaultNix :: (Path | String) -> (Path | String)
    ```

    # Inputs

    A single argument which can be a [path](https://nix.dev/manual/nix/stable/language/types#type-path) value or a string containing an absolute path.

    # Output

    If the input refers to a directory that exists, the output is that same path with `/default.nix` appended.
    Furthermore, if the input is a string that ends with `/`, `default.nix` is appended to it.
    Otherwise, the input is returned unchanged.

    # Examples
    :::{.example}
    ## `lib.filesystem.resolveDefaultNix` usage example

    This expression checks whether `a` and `b` refer to the same locally available Nix file path.

    ```nix
    resolveDefaultNix a == resolveDefaultNix b
    ```

    For instance, if `a` is `/some/dir` and `b` is `/some/dir/default.nix`, and `/some/dir/` exists, the expression evaluates to `true`, despite `a` and `b` being different references to the same Nix file.
  */
  resolveDefaultNix =
    v:
    if pathIsDirectory v then
      v + "/default.nix"
    else if lib.isString v && hasSuffix "/" v then
      # A path ending in `/` can only refer to a directory, so we take the hint, even if we can't verify the validity of the path's `/` assertion.
      # A `/` is already present, so we don't add another one.
      v + "default.nix"
    else
      v;
}
</file>

<file path="lib/fixed-points.nix">
{ lib, ... }:
rec {
  /**
    `fix f` computes the fixed point of the given function `f`. In other words, the return value is `x` in `x = f x`.

    `f` must be a lazy function.
    This means that `x` must be a value that can be partially evaluated,
    such as an attribute set, a list, or a function.
    This way, `f` can use one part of `x` to compute another part.

    **Relation to syntactic recursion**

    This section explains `fix` by refactoring from syntactic recursion to a call of `fix` instead.

    For context, Nix lets you define attributes in terms of other attributes syntactically using the [`rec { }` syntax](https://nixos.org/manual/nix/stable/language/constructs.html#recursive-sets).

    ```nix
    nix-repl> rec {
      foo = "foo";
      bar = "bar";
      foobar = foo + bar;
    }
    { bar = "bar"; foo = "foo"; foobar = "foobar"; }
    ```

    This is convenient when constructing a value to pass to a function for example,
    but an equivalent effect can be achieved with the `let` binding syntax:

    ```nix
    nix-repl> let self = {
      foo = "foo";
      bar = "bar";
      foobar = self.foo + self.bar;
    }; in self
    { bar = "bar"; foo = "foo"; foobar = "foobar"; }
    ```

    But in general you can get more reuse out of `let` bindings by refactoring them to a function.

    ```nix
    nix-repl> f = self: {
      foo = "foo";
      bar = "bar";
      foobar = self.foo + self.bar;
    }
    ```

    This is where `fix` comes in, it contains the syntactic recursion that's not in `f` anymore.

    ```nix
    nix-repl> fix = f:
      let self = f self; in self;
    ```

    By applying `fix` we get the final result.

    ```nix
    nix-repl> fix f
    { bar = "bar"; foo = "foo"; foobar = "foobar"; }
    ```

    Such a refactored `f` using `fix` is not useful by itself.
    See [`extends`](#function-library-lib.fixedPoints.extends) for an example use case.
    There `self` is also often called `final`.

    # Inputs

    `f`

    : 1\. Function argument

    # Type

    ```
    fix :: (a -> a) -> a
    ```

    # Examples
    :::{.example}
    ## `lib.fixedPoints.fix` usage example

    ```nix
    fix (self: { foo = "foo"; bar = "bar"; foobar = self.foo + self.bar; })
    => { bar = "bar"; foo = "foo"; foobar = "foobar"; }

    fix (self: [ 1 2 (elemAt self 0 + elemAt self 1) ])
    => [ 1 2 3 ]
    ```

    :::
  */
  fix =
    f:
    let
      x = f x;
    in
    x;

  /**
    A variant of `fix` that records the original recursive attribute set in the
    result, in an attribute named `__unfix__`.

    This is useful in combination with the `extends` function to
    implement deep overriding.

    # Inputs

    `f`

    : 1\. Function argument
  */
  fix' =
    f:
    let
      x = f x // {
        __unfix__ = f;
      };
    in
    x;

  /**
    Return the fixpoint that `f` converges to when called iteratively, starting
    with the input `x`.

    ```
    nix-repl> converge (x: x / 2) 16
    0
    ```

    # Inputs

    `f`

    : 1\. Function argument

    `x`

    : 2\. Function argument

    # Type

    ```
    (a -> a) -> a -> a
    ```
  */
  converge =
    f: x:
    let
      x' = f x;
    in
    if x' == x then x else converge f x';

  /**
    Extend a function using an overlay.

    Overlays allow modifying and extending fixed-point functions, specifically ones returning attribute sets.
    A fixed-point function is a function which is intended to be evaluated by passing the result of itself as the argument.
    This is possible due to Nix's lazy evaluation.

    A fixed-point function returning an attribute set has the form

    ```nix
    final: {
      # attributes
    }
    ```

    where `final` refers to the lazily evaluated attribute set returned by the fixed-point function.

    An overlay to such a fixed-point function has the form

    ```nix
    final: prev: {
      # attributes
    }
    ```

    where `prev` refers to the result of the original function to `final`, and `final` is the result of the composition of the overlay and the original function.

    Applying an overlay is done with `extends`:

    ```nix
    let
      f = final: {
        # attributes
      };
      overlay = final: prev: {
        # attributes
      };
    in extends overlay f;
    ```

    To get the value of `final`, use `lib.fix`:

    ```nix
    let
      f = final: {
        # attributes
      };
      overlay = final: prev: {
        # attributes
      };
      g = extends overlay f;
    in fix g
    ```

    :::{.note}
    The argument to the given fixed-point function after applying an overlay will *not* refer to its own return value, but rather to the value after evaluating the overlay function.

    The given fixed-point function is called with a separate argument than if it was evaluated with `lib.fix`.
    :::

    :::{.example}

    # Extend a fixed-point function with an overlay

    Define a fixed-point function `f` that expects its own output as the argument `final`:

    ```nix-repl
    f = final: {
      # Constant value a
      a = 1;

      # b depends on the final value of a, available as final.a
      b = final.a + 2;
    }
    ```

    Evaluate this using [`lib.fix`](#function-library-lib.fixedPoints.fix) to get the final result:

    ```nix-repl
    fix f
    => { a = 1; b = 3; }
    ```

    An overlay represents a modification or extension of such a fixed-point function.
    Here's an example of an overlay:

    ```nix-repl
    overlay = final: prev: {
      # Modify the previous value of a, available as prev.a
      a = prev.a + 10;

      # Extend the attribute set with c, letting it depend on the final values of a and b
      c = final.a + final.b;
    }
    ```

    Use `extends overlay f` to apply the overlay to the fixed-point function `f`.
    This produces a new fixed-point function `g` with the combined behavior of `f` and `overlay`:

    ```nix-repl
    g = extends overlay f
    ```

    The result is a function, so we can't print it directly, but it's the same as:

    ```nix-repl
    g' = final: {
      # The constant from f, but changed with the overlay
      a = 1 + 10;

      # Unchanged from f
      b = final.a + 2;

      # Extended in the overlay
      c = final.a + final.b;
    }
    ```

    Evaluate this using [`lib.fix`](#function-library-lib.fixedPoints.fix) again to get the final result:

    ```nix-repl
    fix g
    => { a = 11; b = 13; c = 24; }
    ```
    :::

    # Inputs

    `overlay`

    : The overlay to apply to the fixed-point function

    `f`

    : The fixed-point function

    # Type

    ```
    extends :: (Attrs -> Attrs -> Attrs) # The overlay to apply to the fixed-point function
            -> (Attrs -> Attrs) # A fixed-point function
            -> (Attrs -> Attrs) # The resulting fixed-point function
    ```

    # Examples
    :::{.example}
    ## `lib.fixedPoints.extends` usage example

    ```nix
    f = final: { a = 1; b = final.a + 2; }

    fix f
    => { a = 1; b = 3; }

    fix (extends (final: prev: { a = prev.a + 10; }) f)
    => { a = 11; b = 13; }

    fix (extends (final: prev: { b = final.a + 5; }) f)
    => { a = 1; b = 6; }

    fix (extends (final: prev: { c = final.a + final.b; }) f)
    => { a = 1; b = 3; c = 4; }
    ```

    :::
  */
  extends =
    overlay: f:
    # The result should be thought of as a function, the argument of that function is not an argument to `extends` itself
    (
      final:
      let
        prev = f final;
      in
      prev // overlay final prev
    );

  /**
    Compose two overlay functions and return a single overlay function that combines them.
    For more details see: [composeManyExtensions](#function-library-lib.fixedPoints.composeManyExtensions).
  */
  composeExtensions =
    f: g: final: prev:
    let
      fApplied = f final prev;
      prev' = prev // fApplied;
    in
    fApplied // g final prev';

  /**
    Composes a list of [`overlays`](#chap-overlays) and returns a single overlay function that combines them.

    :::{.note}
    The result is produced by using the update operator `//`.
    This means nested values of previous overlays are not merged recursively.
    In other words, previously defined attributes are replaced, ignoring the previous value, unless referenced by the overlay; for example `final: prev: { foo = final.foo + 1; }`.
    :::

    # Inputs

    `extensions`

    : A list of overlay functions
      :::{.note}
      The order of the overlays in the list is important.
      :::

    : Each overlay function takes two arguments, by convention `final` and `prev`, and returns an attribute set.
      - `final` is the result of the fixed-point function, with all overlays applied.
      - `prev` is the result of the previous overlay function(s).

    # Type

    ```
    # Pseudo code
    let
      #               final      prev
      #                 ↓          ↓
      OverlayFn = { ... } -> { ... } -> { ... };
    in
      composeManyExtensions :: ListOf OverlayFn -> OverlayFn
    ```

    # Examples
    :::{.example}
    ## `lib.fixedPoints.composeManyExtensions` usage example

    ```nix
    let
      # The "original function" that is extended by the overlays.
      # Note that it doesn't have prev: as argument since no overlay function precedes it.
      original = final: { a = 1; };

      # Each overlay function has 'final' and 'prev' as arguments.
      overlayA = final: prev: { b = final.c; c = 3; };
      overlayB = final: prev: { c = 10; x = prev.c or 5; };

      extensions = composeManyExtensions [ overlayA overlayB ];

      # Calculate the fixed point of all composed overlays.
      fixedpoint = lib.fix (lib.extends extensions original );

    in fixedpoint
    =>
    {
      a = 1;
      b = 10;
      c = 10;
      x = 3;
    }
    ```
    :::
  */
  composeManyExtensions = lib.foldr (x: y: composeExtensions x y) (final: prev: { });

  /**
    Create an overridable, recursive attribute set. For example:

    ```
    nix-repl> obj = makeExtensible (final: { })

    nix-repl> obj
    { __unfix__ = «lambda»; extend = «lambda»; }

    nix-repl> obj = obj.extend (final: prev: { foo = "foo"; })

    nix-repl> obj
    { __unfix__ = «lambda»; extend = «lambda»; foo = "foo"; }

    nix-repl> obj = obj.extend (final: prev: { foo = prev.foo + " + "; bar = "bar"; foobar = final.foo + final.bar; })

    nix-repl> obj
    { __unfix__ = «lambda»; bar = "bar"; extend = «lambda»; foo = "foo + "; foobar = "foo + bar"; }
    ```
  */
  makeExtensible = makeExtensibleWithCustomName "extend";

  /**
    Same as `makeExtensible` but the name of the extending attribute is
    customized.

    # Inputs

    `extenderName`

    : 1\. Function argument

    `rattrs`

    : 2\. Function argument
  */
  makeExtensibleWithCustomName =
    extenderName: rattrs:
    fix' (
      self:
      (rattrs self)
      // {
        ${extenderName} = f: makeExtensibleWithCustomName extenderName (extends f rattrs);
      }
    );

  /**
    Convert to an extending function (overlay).

    `toExtension` is the `toFunction` for extending functions (a.k.a. extensions or overlays).
    It converts a non-function or a single-argument function to an extending function,
    while returning a two-argument function as-is.

    That is, it takes a value of the shape `x`, `prev: x`, or `final: prev: x`,
    and returns `final: prev: x`, assuming `x` is not a function.

    This function takes care of the input to `stdenv.mkDerivation`'s
    `overrideAttrs` function.
    It bridges the gap between `<pkg>.overrideAttrs`
    before and after the overlay-style support.

    # Inputs

    `f`
    : The function or value to convert to an extending function.

    # Type

    ```
    toExtension ::
      b' -> Any -> Any -> b'
    or
    toExtension ::
      (a -> b') -> Any -> a -> b'
    or
    toExtension ::
      (a -> a -> b) -> a -> a -> b
    where b' = ! Callable

    Set a = b = b' = AttrSet & ! Callable to make toExtension return an extending function.
    ```

    # Examples
    :::{.example}
    ## `lib.fixedPoints.toExtension` usage example

    ```nix
    fix (final: { a = 0; c = final.a; })
    => { a = 0; c = 0; };

    fix (extends (toExtension { a = 1; b = 2; }) (final: { a = 0; c = final.a; }))
    => { a = 1; b = 2; c = 1; };

    fix (extends (toExtension (prev: { a = 1; b = prev.a; })) (final: { a = 0; c = final.a; }))
    => { a = 1; b = 0; c = 1; };

    fix (extends (toExtension (final: prev: { a = 1; b = prev.a; c = final.a + 1 })) (final: { a = 0; c = final.a; }))
    => { a = 1; b = 0; c = 2; };
    ```
    :::
  */
  toExtension =
    f:
    if lib.isFunction f then
      final: prev:
      let
        fPrev = f prev;
      in
      if lib.isFunction fPrev then
        # f is (final: prev: { ... })
        f final prev
      else
        # f is (prev: { ... })
        fPrev
    else
      # f is not a function; probably { ... }
      final: prev: f;
}
</file>

<file path="lib/flake-version-info.nix">
# This function produces a lib overlay to be used by the nixpkgs
# & nixpkgs/lib flakes to provide meaningful values for
# `lib.trivial.version` et al..
#
# Internal and subject to change, don't use this anywhere else!
# Instead, consider using a public interface, such as this flake here
# in this directory, `lib/`, or use the nixpkgs flake, which applies
# this logic for you in its `lib` output attribute.

self: # from the flake

finalLib: prevLib: # lib overlay

{
  trivial = prevLib.trivial // {
    versionSuffix = ".${
      finalLib.substring 0 8 (self.lastModifiedDate or "19700101")
    }.${self.shortRev or "dirty"}";
    revisionWithDefault = default: self.rev or default;
  };
}
</file>

<file path="lib/flake.nix">
{
  description = "Library of low-level helper functions for nix expressions.";

  outputs =
    { self }:
    let
      lib0 = import ./.;
    in
    {
      lib = lib0.extend (import ./flake-version-info.nix self);
    };
}
</file>

<file path="lib/flakes.nix">
{ lib }:

rec {

  /* imports a flake.nix without acknowledging its lock file, useful for
    referencing subflakes from a parent flake. The second argument allows
    specifying the inputs of this flake.

    Example:
      callLocklessFlake {
        path = ./directoryContainingFlake;
        inputs = { inherit nixpkgs; };
      }
  */
  callLocklessFlake = { path, inputs ? { } }:
    let
      self = { outPath = path; } //
        ((import (path + "/flake.nix")).outputs (inputs // { self = self; }));
    in
    self;

}
</file>

<file path="lib/generators.nix">
/**
  Functions that generate widespread file
  formats from nix data structures.

  They all follow a similar interface:

  ```nix
  generator { config-attrs } data
  ```

  `config-attrs` are “holes” in the generators
  with sensible default implementations that
  can be overwritten. The default implementations
  are mostly generators themselves, called with
  their respective default values; they can be reused.

  Tests can be found in ./tests/misc.nix

  Further Documentation can be found [here](#sec-generators).
*/
{ lib }:

let
  inherit (lib)
    addErrorContext
    assertMsg
    attrNames
    concatLists
    concatMapStringsSep
    concatStrings
    concatStringsSep
    const
    elem
    escape
    filter
    flatten
    foldl
    functionArgs # Note: not the builtin; considers `__functor` in attrsets.
    gvariant
    hasInfix
    head
    id
    init
    isAttrs
    isBool
    isDerivation
    isFloat
    isFunction # Note: not the builtin; considers `__functor` in attrsets.
    isInt
    isList
    isPath
    isString
    last
    length
    mapAttrs
    mapAttrsToList
    optionals
    recursiveUpdate
    replaceStrings
    reverseList
    splitString
    tail
    toList
    ;

  inherit (lib.strings)
    escapeNixIdentifier
    floatToString
    match
    split
    toJSON
    typeOf
    escapeXML
    ;

  ## -- HELPER FUNCTIONS & DEFAULTS --
in
rec {
  /**
    Convert a value to a sensible default string representation.
    The builtin `toString` function has some strange defaults,
    suitable for bash scripts but not much else.

    # Inputs

    Options
    : Empty set, there may be configuration options in the future

    `v`
    : 2\. Function argument
  */
  mkValueStringDefault =
    { }:
    v:
    let
      err = t: v: abort ("generators.mkValueStringDefault: " + "${t} not supported: ${toPretty { } v}");
    in
    if isInt v then
      toString v
    # convert derivations to store paths
    else if isDerivation v then
      toString v
    # we default to not quoting strings
    else if isString v then
      v
    # isString returns "1", which is not a good default
    else if true == v then
      "true"
    # here it returns to "", which is even less of a good default
    else if false == v then
      "false"
    else if null == v then
      "null"
    # if you have lists you probably want to replace this
    else if isList v then
      err "lists" v
    # same as for lists, might want to replace
    else if isAttrs v then
      err "attrsets" v
    # functions can’t be printed of course
    else if isFunction v then
      err "functions" v
    # Floats currently can't be converted to precise strings,
    # condition warning on nix version once this isn't a problem anymore
    # See https://github.com/NixOS/nix/pull/3480
    else if isFloat v then
      floatToString v
    else
      err "this value is" (toString v);

  /**
    Generate a line of key k and value v, separated by
    character sep. If sep appears in k, it is escaped.
    Helper for synaxes with different separators.

    mkValueString specifies how values should be formatted.

    ```nix
    mkKeyValueDefault {} ":" "f:oo" "bar"
    > "f\:oo:bar"
    ```

    # Inputs

    Structured function argument
    : mkValueString (optional, default: `mkValueStringDefault {}`)
      : Function to convert values to strings

    `sep`

    : 2\. Function argument

    `k`

    : 3\. Function argument

    `v`

    : 4\. Function argument
  */
  mkKeyValueDefault =
    {
      mkValueString ? mkValueStringDefault { },
    }:
    sep: k: v:
    "${escape [ sep ] k}${sep}${mkValueString v}";

  ## -- FILE FORMAT GENERATORS --

  /**
    Generate a key-value-style config file from an attrset.

    # Inputs

    Structured function argument

    : mkKeyValue (optional, default: `mkKeyValueDefault {} "="`)
      : format a setting line from key and value

    : listsAsDuplicateKeys (optional, default: `false`)
      : allow lists as values for duplicate keys

    : indent (optional, default: `""`)
      : Initial indentation level
  */
  toKeyValue =
    {
      mkKeyValue ? mkKeyValueDefault { } "=",
      listsAsDuplicateKeys ? false,
      indent ? "",
    }:
    let
      mkLine = k: v: indent + mkKeyValue k v + "\n";
      mkLines =
        if listsAsDuplicateKeys then
          k: v: map (mkLine k) (if isList v then v else [ v ])
        else
          k: v: [ (mkLine k v) ];
    in
    attrs: concatStrings (concatLists (mapAttrsToList mkLines attrs));

  /**
    Generate an INI-style config file from an
    attrset of sections to an attrset of key-value pairs.

    # Inputs

    Structured function argument

    : mkSectionName (optional, default: `(name: escape [ "[" "]" ] name)`)
      : apply transformations (e.g. escapes) to section names

    : mkKeyValue (optional, default: `{} "="`)
      : format a setting line from key and value

    : listsAsDuplicateKeys (optional, default: `false`)
      : allow lists as values for duplicate keys

    # Examples
    :::{.example}
    ## `lib.generators.toINI` usage example

    ```nix
    generators.toINI {} {
      foo = { hi = "${pkgs.hello}"; ciao = "bar"; };
      baz = { "also, integers" = 42; };
    }

    > [baz]
    > also, integers=42
    >
    > [foo]
    > ciao=bar
    > hi=/nix/store/y93qql1p5ggfnaqjjqhxcw0vqw95rlz0-hello-2.10
    ```

    The mk* configuration attributes can generically change
    the way sections and key-value strings are generated.

    For more examples see the test cases in ./tests/misc.nix.

    :::
  */
  toINI =
    {
      mkSectionName ? (name: escape [ "[" "]" ] name),
      mkKeyValue ? mkKeyValueDefault { } "=",
      listsAsDuplicateKeys ? false,
    }:
    attrsOfAttrs:
    let
      # map function to string for each key val
      mapAttrsToStringsSep =
        sep: mapFn: attrs:
        concatStringsSep sep (mapAttrsToList mapFn attrs);
      mkSection =
        sectName: sectValues:
        ''
          [${mkSectionName sectName}]
        ''
        + toKeyValue { inherit mkKeyValue listsAsDuplicateKeys; } sectValues;
    in
    # map input to ini sections
    mapAttrsToStringsSep "\n" mkSection attrsOfAttrs;

  /**
    Generate an INI-style config file from an attrset
    specifying the global section (no header), and an
    attrset of sections to an attrset of key-value pairs.

    # Inputs

    1\. Structured function argument

    : mkSectionName (optional, default: `(name: escape [ "[" "]" ] name)`)
      : apply transformations (e.g. escapes) to section names

    : mkKeyValue (optional, default: `{} "="`)
      : format a setting line from key and value

    : listsAsDuplicateKeys (optional, default: `false`)
      : allow lists as values for duplicate keys

    2\. Structured function argument

    : globalSection (required)
      : global section key-value pairs

    : sections (optional, default: `{}`)
      : attrset of sections to key-value pairs

    # Examples
    :::{.example}
    ## `lib.generators.toINIWithGlobalSection` usage example

    ```nix
    generators.toINIWithGlobalSection {} {
      globalSection = {
        someGlobalKey = "hi";
      };
      sections = {
        foo = { hi = "${pkgs.hello}"; ciao = "bar"; };
        baz = { "also, integers" = 42; };
    }

    > someGlobalKey=hi
    >
    > [baz]
    > also, integers=42
    >
    > [foo]
    > ciao=bar
    > hi=/nix/store/y93qql1p5ggfnaqjjqhxcw0vqw95rlz0-hello-2.10
    ```

    The mk* configuration attributes can generically change
    the way sections and key-value strings are generated.

    For more examples see the test cases in ./tests/misc.nix.

    :::

    If you don’t need a global section, you can also use
    `generators.toINI` directly, which only takes
    the part in `sections`.
  */
  toINIWithGlobalSection =
    {
      mkSectionName ? (name: escape [ "[" "]" ] name),
      mkKeyValue ? mkKeyValueDefault { } "=",
      listsAsDuplicateKeys ? false,
    }:
    {
      globalSection,
      sections ? { },
    }:
    (
      if globalSection == { } then
        ""
      else
        (toKeyValue { inherit mkKeyValue listsAsDuplicateKeys; } globalSection) + "\n"
    )
    + (toINI { inherit mkSectionName mkKeyValue listsAsDuplicateKeys; } sections);

  /**
    Generate a git-config file from an attrset.

    It has two major differences from the regular INI format:

    1. values are indented with tabs
    2. sections can have sub-sections

    Further: https://git-scm.com/docs/git-config#EXAMPLES

    # Examples
    :::{.example}
    ## `lib.generators.toGitINI` usage example

    ```nix
    generators.toGitINI {
      url."ssh://git@github.com/".insteadOf = "https://github.com";
      user.name = "edolstra";
    }

    > [url "ssh://git@github.com/"]
    >   insteadOf = "https://github.com"
    >
    > [user]
    >   name = "edolstra"
    ```

    :::

    # Inputs

    `attrs`

    : Key-value pairs to be converted to a git-config file.
      See: https://git-scm.com/docs/git-config#_variables for possible values.
  */
  toGitINI =
    attrs:
    let
      mkSectionName =
        name:
        let
          containsQuote = hasInfix ''"'' name;
          sections = splitString "." name;
          section = head sections;
          subsections = tail sections;
          subsection = concatStringsSep "." subsections;
        in
        if containsQuote || subsections == [ ] then name else ''${section} "${subsection}"'';

      mkValueString =
        v:
        let
          escapedV = ''"${replaceStrings [ "\n" "	" ''"'' "\\" ] [ "\\n" "\\t" ''\"'' "\\\\" ] v}"'';
        in
        mkValueStringDefault { } (if isString v then escapedV else v);

      # generation for multiple ini values
      mkKeyValue =
        k: v:
        let
          mkKeyValue = mkKeyValueDefault { inherit mkValueString; } " = " k;
        in
        concatStringsSep "\n" (map (kv: "\t" + mkKeyValue kv) (toList v));

      # converts { a.b.c = 5; } to { "a.b".c = 5; } for toINI
      gitFlattenAttrs =
        let
          recurse =
            path: value:
            if isAttrs value && !isDerivation value then
              mapAttrsToList (name: value: recurse ([ name ] ++ path) value) value
            else if length path > 1 then
              {
                ${concatStringsSep "." (reverseList (tail path))}.${head path} = value;
              }
            else
              {
                ${head path} = value;
              };
        in
        attrs: foldl recursiveUpdate { } (flatten (recurse [ ] attrs));

      toINI_ = toINI { inherit mkKeyValue mkSectionName; };
    in
    toINI_ (gitFlattenAttrs attrs);

  /**
    mkKeyValueDefault wrapper that handles dconf INI quirks.
    The main differences of the format is that it requires strings to be quoted.
  */
  mkDconfKeyValue = mkKeyValueDefault { mkValueString = v: toString (gvariant.mkValue v); } "=";

  /**
    Generates INI in dconf keyfile style. See https://help.gnome.org/admin/system-admin-guide/stable/dconf-keyfiles.html.en
    for details.
  */
  toDconfINI = toINI { mkKeyValue = mkDconfKeyValue; };

  /**
    Recurses through a `Value` limited to a certain depth. (`depthLimit`)

    If the depth is exceeded, an error is thrown, unless `throwOnDepthLimit` is set to `false`.

    # Inputs

    Structured function argument

    : depthLimit (required)
      : If this option is not null, the given value will stop evaluating at a certain depth

    : throwOnDepthLimit (optional, default: `true`)
      : If this option is true, an error will be thrown, if a certain given depth is exceeded

    Value
    : The value to be evaluated recursively
  */
  withRecursion =
    {
      depthLimit,
      throwOnDepthLimit ? true,
    }:
    assert isInt depthLimit;
    let
      specialAttrs = [
        "__functor"
        "__functionArgs"
        "__toString"
        "__pretty"
      ];
      stepIntoAttr = evalNext: name: if elem name specialAttrs then id else evalNext;
      transform =
        depth:
        if depthLimit != null && depth > depthLimit then
          if throwOnDepthLimit then
            throw "Exceeded maximum eval-depth limit of ${toString depthLimit} while trying to evaluate with `generators.withRecursion'!"
          else
            const "<unevaluated>"
        else
          id;
      mapAny =
        depth: v:
        let
          evalNext = x: mapAny (depth + 1) (transform (depth + 1) x);
        in
        if isAttrs v then
          mapAttrs (stepIntoAttr evalNext) v
        else if isList v then
          map evalNext v
        else
          transform (depth + 1) v;
    in
    mapAny 0;

  /**
    Pretty print a value, akin to `builtins.trace`.

    Should probably be a builtin as well.

    The pretty-printed string should be suitable for rendering default values
    in the NixOS manual. In particular, it should be as close to a valid Nix expression
    as possible.

    # Inputs

    Structured function argument
    : allowPrettyValues
      : If this option is true, attrsets like { __pretty = fn; val = …; }
        will use fn to convert val to a pretty printed representation.
        (This means fn is type Val -> String.)
    : multiline
      : If this option is true, the output is indented with newlines for attribute sets and lists
    : indent
      : Initial indentation level

    Value
    : The value to be pretty printed
  */
  toPretty =
    {
      allowPrettyValues ? false,
      multiline ? true,
      indent ? "",
    }:
    let
      go =
        indent: v:
        let
          introSpace = if multiline then "\n${indent}  " else " ";
          outroSpace = if multiline then "\n${indent}" else " ";
        in
        if isInt v then
          toString v
        # toString loses precision on floats, so we use toJSON instead. This isn't perfect
        # as the resulting string may not parse back as a float (e.g. 42, 1e-06), but for
        # pretty-printing purposes this is acceptable.
        else if isFloat v then
          builtins.toJSON v
        else if isString v then
          let
            lines = filter (v: !isList v) (split "\n" v);
            escapeSingleline = escape [
              "\\"
              "\""
              "\${"
            ];
            escapeMultiline = replaceStrings [ "\${" "''" ] [ "''\${" "'''" ];
            singlelineResult = "\"" + concatStringsSep "\\n" (map escapeSingleline lines) + "\"";
            multilineResult =
              let
                escapedLines = map escapeMultiline lines;
                # The last line gets a special treatment: if it's empty, '' is on its own line at the "outer"
                # indentation level. Otherwise, '' is appended to the last line.
                lastLine = last escapedLines;
              in
              "''"
              + introSpace
              + concatStringsSep introSpace (init escapedLines)
              + (if lastLine == "" then outroSpace else introSpace + lastLine)
              + "''";
          in
          if multiline && length lines > 1 then multilineResult else singlelineResult
        else if true == v then
          "true"
        else if false == v then
          "false"
        else if null == v then
          "null"
        else if isPath v then
          toString v
        else if isList v then
          if v == [ ] then
            "[ ]"
          else
            "[" + introSpace + concatMapStringsSep introSpace (go (indent + "  ")) v + outroSpace + "]"
        else if isFunction v then
          let
            fna = functionArgs v;
            showFnas = concatStringsSep ", " (
              mapAttrsToList (name: hasDefVal: if hasDefVal then name + "?" else name) fna
            );
          in
          if fna == { } then "<function>" else "<function, args: {${showFnas}}>"
        else if isAttrs v then
          # apply pretty values if allowed
          if allowPrettyValues && v ? __pretty && v ? val then
            v.__pretty v.val
          else if v == { } then
            "{ }"
          else if v ? type && v.type == "derivation" then
            "<derivation ${v.name or "???"}>"
          else
            "{"
            + introSpace
            + concatStringsSep introSpace (
              mapAttrsToList (
                name: value:
                "${escapeNixIdentifier name} = ${
                  addErrorContext "while evaluating an attribute `${name}`" (go (indent + "  ") value)
                };"
              ) v
            )
            + outroSpace
            + "}"
        else
          abort "generators.toPretty: should never happen (v = ${v})";
    in
    go indent;

  /**
    Translate a simple Nix expression to [Plist notation](https://en.wikipedia.org/wiki/Property_list).

    # Inputs

    Structured function argument

    : escape (optional, default: `false`)
      : If this option is true, XML special characters are escaped in string values and keys

    Value
      : The value to be converted to Plist
  */
  toPlist =
    {
      escape ? false,
    }:
    v:
    let
      expr =
        ind: x:
        if x == null then
          ""
        else if isBool x then
          bool ind x
        else if isInt x then
          int ind x
        else if isString x then
          str ind x
        else if isList x then
          list ind x
        else if isAttrs x then
          attrs ind x
        else if isPath x then
          str ind (toString x)
        else if isFloat x then
          float ind x
        else
          abort "generators.toPlist: should never happen (v = ${v})";

      literal = ind: x: ind + x;

      maybeEscapeXML = if escape then escapeXML else x: x;

      bool = ind: x: literal ind (if x then "<true/>" else "<false/>");
      int = ind: x: literal ind "<integer>${toString x}</integer>";
      str = ind: x: literal ind "<string>${maybeEscapeXML x}</string>";
      key = ind: x: literal ind "<key>${maybeEscapeXML x}</key>";
      float = ind: x: literal ind "<real>${toString x}</real>";

      indent = ind: expr "\t${ind}";

      item = ind: concatMapStringsSep "\n" (indent ind);

      list =
        ind: x:
        concatStringsSep "\n" [
          (literal ind "<array>")
          (item ind x)
          (literal ind "</array>")
        ];

      attrs =
        ind: x:
        concatStringsSep "\n" [
          (literal ind "<dict>")
          (attr ind x)
          (literal ind "</dict>")
        ];

      attr =
        let
          attrFilter = name: value: name != "_module" && value != null;
        in
        ind: x:
        concatStringsSep "\n" (
          flatten (
            mapAttrsToList (
              name: value:
              optionals (attrFilter name value) [
                (key "\t${ind}" name)
                (expr "\t${ind}" value)
              ]
            ) x
          )
        );

    in
    # TODO: As discussed in #356502, deprecated functionality should be removed sometime after 25.11.
    lib.warnIf (!escape && lib.oldestSupportedReleaseIsAtLeast 2505)
      "Using `lib.generators.toPlist` without `escape = true` is deprecated"
      ''
        <?xml version="1.0" encoding="UTF-8"?>
        <!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
        <plist version="1.0">
        ${expr "" v}
        </plist>'';

  /**
    Translate a simple Nix expression to Dhall notation.

    Note that integers are translated to Integer and never
    the Natural type.

    # Inputs

    Options

    : Empty set, there may be configuration options in the future

    Value

    : The value to be converted to Dhall
  */
  toDhall =
    { }@args:
    v:
    let
      concatItems = concatStringsSep ", ";
    in
    if isAttrs v then
      "{ ${concatItems (mapAttrsToList (key: value: "${key} = ${toDhall args value}") v)} }"
    else if isList v then
      "[ ${concatItems (map (toDhall args) v)} ]"
    else if isInt v then
      "${if v < 0 then "" else "+"}${toString v}"
    else if isBool v then
      (if v then "True" else "False")
    else if isFunction v then
      abort "generators.toDhall: cannot convert a function to Dhall"
    else if v == null then
      abort "generators.toDhall: cannot convert a null to Dhall"
    else
      toJSON v;

  /**
    Translate a simple Nix expression to Lua representation with occasional
    Lua-inlines that can be constructed by mkLuaInline function.

    Configuration:

    * multiline - by default is true which results in indented block-like view.
    * indent - initial indent.
    * asBindings - by default generate single value, but with this use attrset to set global vars.

    Attention:

    Regardless of multiline parameter there is no trailing newline.

    # Inputs

    Structured function argument

    : multiline (optional, default: `true`)
      : If this option is true, the output is indented with newlines for attribute sets and lists
    : indent (optional, default: `""`)
      : Initial indentation level
    : asBindings (optional, default: `false`)
      : Interpret as variable bindings

    Value

    : The value to be converted to Lua

    # Type

    ```
    toLua :: AttrSet -> Any -> String
    ```

    # Examples
    :::{.example}
    ## `lib.generators.toLua` usage example

    ```nix
    generators.toLua {}
      {
        cmd = [ "typescript-language-server" "--stdio" ];
        settings.workspace.library = mkLuaInline ''vim.api.nvim_get_runtime_file("", true)'';
      }
    ->
     {
       ["cmd"] = {
         "typescript-language-server",
         "--stdio"
       },
       ["settings"] = {
         ["workspace"] = {
           ["library"] = (vim.api.nvim_get_runtime_file("", true))
         }
       }
     }
    ```

    :::
  */
  toLua =
    {
      multiline ? true,
      indent ? "",
      asBindings ? false,
    }@args:
    v:
    let
      innerIndent = "${indent}  ";
      introSpace = if multiline then "\n${innerIndent}" else " ";
      outroSpace = if multiline then "\n${indent}" else " ";
      innerArgs = args // {
        indent = if asBindings then indent else innerIndent;
        asBindings = false;
      };
      concatItems = concatStringsSep ",${introSpace}";
      isLuaInline =
        {
          _type ? null,
          ...
        }:
        _type == "lua-inline";

      generatedBindings =
        assert assertMsg (badVarNames == [ ]) "Bad Lua var names: ${toPretty { } badVarNames}";
        concatStrings (mapAttrsToList (key: value: "${indent}${key} = ${toLua innerArgs value}\n") v);

      # https://en.wikibooks.org/wiki/Lua_Programming/variable#Variable_names
      matchVarName = match "[[:alpha:]_][[:alnum:]_]*(\\.[[:alpha:]_][[:alnum:]_]*)*";
      badVarNames = filter (name: matchVarName name == null) (attrNames v);
    in
    if asBindings then
      generatedBindings
    else if v == null then
      "nil"
    else if isInt v || isFloat v || isString v || isBool v then
      toJSON v
    else if isPath v || isDerivation v then
      toJSON "${v}"
    else if isList v then
      (
        if v == [ ] then
          "{}"
        else
          "{${introSpace}${concatItems (map (value: "${toLua innerArgs value}") v)}${outroSpace}}"
      )
    else if isAttrs v then
      (
        if isLuaInline v then
          "(${v.expr})"
        else if v == { } then
          "{}"
        else
          "{${introSpace}${
            concatItems (mapAttrsToList (key: value: "[${toJSON key}] = ${toLua innerArgs value}") v)
          }${outroSpace}}"
      )
    else
      abort "generators.toLua: type ${typeOf v} is unsupported";

  /**
    Mark string as Lua expression to be inlined when processed by toLua.

    # Inputs

    `expr`

    : 1\. Function argument

    # Type

    ```
    mkLuaInline :: String -> AttrSet
    ```
  */
  mkLuaInline = expr: {
    _type = "lua-inline";
    inherit expr;
  };
}
// {
  /**
    Generates JSON from an arbitrary (non-function) value.
    For more information see the documentation of the builtin.

    # Inputs

    Options

    : Empty set, there may be configuration options in the future

    Value

    : The value to be converted to JSON
  */
  toJSON = { }: lib.strings.toJSON;

  /**
    YAML has been a strict superset of JSON since 1.2, so we
    use toJSON. Before it only had a few differences referring
    to implicit typing rules, so it should work with older
    parsers as well.

    # Inputs

    Options

    : Empty set, there may be configuration options in the future

    Value

    : The value to be converted to YAML
  */
  toYAML = { }: lib.strings.toJSON;
}
</file>

<file path="lib/gvariant.nix">
/**
  A partial and basic implementation of GVariant formatted strings.
  See [GVariant Format Strings](https://docs.gtk.org/glib/gvariant-format-strings.html) for details.

  :::{.warning}
  This API is not considered fully stable and it might therefore
  change in backwards incompatible ways without prior notice.
  :::
*/

# This file is based on https://github.com/nix-community/home-manager
# Copyright (c) 2017-2022 Home Manager contributors
{ lib }:

let
  inherit (lib)
    concatMapStringsSep
    concatStrings
    escape
    head
    replaceString
    ;

  mkPrimitive = t: v: {
    _type = "gvariant";
    type = t;
    value = v;
    __toString = self: "@${self.type} ${toString self.value}"; # https://docs.gtk.org/glib/gvariant-text.html
  };

  type = {
    arrayOf = t: "a${t}";
    maybeOf = t: "m${t}";
    tupleOf = ts: "(${concatStrings ts})";
    dictionaryEntryOf = nameType: valueType: "{${nameType}${valueType}}";
    string = "s";
    boolean = "b";
    uchar = "y";
    int16 = "n";
    uint16 = "q";
    int32 = "i";
    uint32 = "u";
    int64 = "x";
    uint64 = "t";
    double = "d";
    variant = "v";
  };

in
rec {

  inherit type;

  /**
    Check if a value is a GVariant value

    # Inputs

    `v`

    : value to check

    # Type

    ```
    isGVariant :: Any -> Bool
    ```
  */
  isGVariant = v: v._type or "" == "gvariant";

  intConstructors = [
    {
      name = "mkInt32";
      type = type.int32;
      min = -2147483648;
      max = 2147483647;
    }
    {
      name = "mkUint32";
      type = type.uint32;
      min = 0;
      max = 4294967295;
    }
    {
      name = "mkInt64";
      type = type.int64;
      # Nix does not support such large numbers.
      min = null;
      max = null;
    }
    {
      name = "mkUint64";
      type = type.uint64;
      min = 0;
      # Nix does not support such large numbers.
      max = null;
    }
    {
      name = "mkInt16";
      type = type.int16;
      min = -32768;
      max = 32767;
    }
    {
      name = "mkUint16";
      type = type.uint16;
      min = 0;
      max = 65535;
    }
    {
      name = "mkUchar";
      type = type.uchar;
      min = 0;
      max = 255;
    }
  ];

  /**
    Returns the GVariant value that most closely matches the given Nix value.
    If no GVariant value can be found unambiguously then error is thrown.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkValue :: Any -> gvariant
    ```
  */
  mkValue =
    v:
    if builtins.isBool v then
      mkBoolean v
    else if builtins.isFloat v then
      mkDouble v
    else if builtins.isString v then
      mkString v
    else if builtins.isList v then
      mkArray v
    else if isGVariant v then
      v
    else if builtins.isInt v then
      let
        validConstructors = builtins.filter (
          { min, max, ... }: (min == null || min <= v) && (max == null || v <= max)
        ) intConstructors;
      in
      throw ''
        The GVariant type for number “${builtins.toString v}” is unclear.
        Please wrap the value with one of the following, depending on the value type in GSettings schema:

        ${lib.concatMapStringsSep "\n" (
          { name, type, ... }: "- `lib.gvariant.${name}` for `${type}`"
        ) validConstructors}
      ''
    else if builtins.isAttrs v then
      throw "Cannot construct GVariant value from an attribute set. If you want to construct a dictionary, you will need to create an array containing items constructed with `lib.gvariant.mkDictionaryEntry`."
    else
      throw "The GVariant type of “${builtins.typeOf v}” can't be inferred.";

  /**
    Returns the GVariant array from the given type of the elements and a Nix list.

    # Inputs

    `elems`

    : 1\. Function argument

    # Type

    ```
    mkArray :: [Any] -> gvariant
    ```

    # Examples
    :::{.example}
    ## `lib.gvariant.mkArray` usage example

    ```nix
    # Creating a string array
    lib.gvariant.mkArray [ "a" "b" "c" ]
    ```

    :::
  */
  mkArray =
    elems:
    let
      vs = map mkValue (lib.throwIf (elems == [ ]) "Please create empty array with mkEmptyArray." elems);
      elemType = lib.throwIfNot (lib.all (t: (head vs).type == t) (
        map (v: v.type) vs
      )) "Elements in a list should have same type." (head vs).type;
    in
    mkPrimitive (type.arrayOf elemType) vs
    // {
      __toString = self: "@${self.type} [${concatMapStringsSep "," toString self.value}]";
    };

  /**
    Returns the GVariant array from the given empty Nix list.

    # Inputs

    `elemType`

    : 1\. Function argument

    # Type

    ```
    mkEmptyArray :: gvariant.type -> gvariant
    ```

    # Examples
    :::{.example}
    ## `lib.gvariant.mkEmptyArray` usage example

    ```nix
    # Creating an empty string array
    lib.gvariant.mkEmptyArray (lib.gvariant.type.string)
    ```

    :::
  */
  mkEmptyArray =
    elemType:
    mkPrimitive (type.arrayOf elemType) [ ]
    // {
      __toString = self: "@${self.type} []";
    };

  /**
    Returns the GVariant variant from the given Nix value. Variants are containers
    of different GVariant type.

    # Inputs

    `elem`

    : 1\. Function argument

    # Type

    ```
    mkVariant :: Any -> gvariant
    ```

    # Examples
    :::{.example}
    ## `lib.gvariant.mkVariant` usage example

    ```nix
    lib.gvariant.mkArray [
      (lib.gvariant.mkVariant "a string")
      (lib.gvariant.mkVariant (lib.gvariant.mkInt32 1))
    ]
    ```

    :::
  */
  mkVariant =
    elem:
    let
      gvarElem = mkValue elem;
    in
    mkPrimitive type.variant gvarElem
    // {
      __toString = self: "<${toString self.value}>";
    };

  /**
    Returns the GVariant dictionary entry from the given key and value.

    # Inputs

    `name`

    : The key of the entry

    `value`

    : The value of the entry

    # Type

    ```
    mkDictionaryEntry :: String -> Any -> gvariant
    ```

    # Examples
    :::{.example}
    ## `lib.gvariant.mkDictionaryEntry` usage example

    ```nix
    # A dictionary describing an Epiphany’s search provider
    [
      (lib.gvariant.mkDictionaryEntry "url" (lib.gvariant.mkVariant "https://duckduckgo.com/?q=%s&t=epiphany"))
      (lib.gvariant.mkDictionaryEntry "bang" (lib.gvariant.mkVariant "!d"))
      (lib.gvariant.mkDictionaryEntry "name" (lib.gvariant.mkVariant "DuckDuckGo"))
    ]
    ```

    :::
  */
  mkDictionaryEntry =
    name: value:
    let
      name' = mkValue name;
      value' = mkValue value;
      dictionaryType = type.dictionaryEntryOf name'.type value'.type;
    in
    mkPrimitive dictionaryType { inherit name value; }
    // {
      __toString = self: "@${self.type} {${name'},${value'}}";
    };

  /**
    Returns the GVariant maybe from the given element type.

    # Inputs

    `elemType`

    : 1\. Function argument

    `elem`

    : 2\. Function argument

    # Type

    ```
    mkMaybe :: gvariant.type -> Any -> gvariant
    ```
  */
  mkMaybe =
    elemType: elem:
    mkPrimitive (type.maybeOf elemType) elem
    // {
      __toString =
        self: if self.value == null then "@${self.type} nothing" else "just ${toString self.value}";
    };

  /**
    Returns the GVariant nothing from the given element type.

    # Inputs

    `elemType`

    : 1\. Function argument

    # Type

    ```
    mkNothing :: gvariant.type -> gvariant
    ```
  */
  mkNothing = elemType: mkMaybe elemType null;

  /**
    Returns the GVariant just from the given Nix value.

    # Inputs

    `elem`

    : 1\. Function argument

    # Type

    ```
    mkJust :: Any -> gvariant
    ```
  */
  mkJust =
    elem:
    let
      gvarElem = mkValue elem;
    in
    mkMaybe gvarElem.type gvarElem;

  /**
    Returns the GVariant tuple from the given Nix list.

    # Inputs

    `elems`

    : 1\. Function argument

    # Type

    ```
    mkTuple :: [Any] -> gvariant
    ```
  */
  mkTuple =
    elems:
    let
      gvarElems = map mkValue elems;
      tupleType = type.tupleOf (map (e: e.type) gvarElems);
    in
    mkPrimitive tupleType gvarElems
    // {
      __toString = self: "@${self.type} (${concatMapStringsSep "," toString self.value})";
    };

  /**
    Returns the GVariant boolean from the given Nix bool value.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkBoolean :: Bool -> gvariant
    ```
  */
  mkBoolean =
    v:
    mkPrimitive type.boolean v
    // {
      __toString = self: if self.value then "true" else "false";
    };

  /**
    Returns the GVariant string from the given Nix string value.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkString :: String -> gvariant
    ```
  */
  mkString =
    v:
    let
      sanitize = s: replaceString "\n" "\\n" (escape [ "'" "\\" ] s);
    in
    mkPrimitive type.string v
    // {
      __toString = self: "'${sanitize self.value}'";
    };

  /**
    Returns the GVariant object path from the given Nix string value.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkObjectpath :: String -> gvariant
    ```
  */
  mkObjectpath =
    v:
    mkPrimitive type.string v
    // {
      __toString = self: "objectpath '${escape [ "'" ] self.value}'";
    };

  /**
    Returns the GVariant uchar from the given Nix int value.

    # Type

    ```
    mkUchar :: Int -> gvariant
    ```
  */
  mkUchar = mkPrimitive type.uchar;

  /**
    Returns the GVariant int16 from the given Nix int value.

    # Type

    ```
    mkInt16 :: Int -> gvariant
    ```
  */
  mkInt16 = mkPrimitive type.int16;

  /**
    Returns the GVariant uint16 from the given Nix int value.

    # Type

    ```
    mkUint16 :: Int -> gvariant
    ```
  */
  mkUint16 = mkPrimitive type.uint16;

  /**
    Returns the GVariant int32 from the given Nix int value.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkInt32 :: Int -> gvariant
    ```
  */
  mkInt32 =
    v:
    mkPrimitive type.int32 v
    // {
      __toString = self: toString self.value;
    };

  /**
    Returns the GVariant uint32 from the given Nix int value.

    # Type

    ```
    mkUint32 :: Int -> gvariant
    ```
  */
  mkUint32 = mkPrimitive type.uint32;

  /**
    Returns the GVariant int64 from the given Nix int value.

    # Type

    ```
    mkInt64 :: Int -> gvariant
    ```
  */
  mkInt64 = mkPrimitive type.int64;

  /**
    Returns the GVariant uint64 from the given Nix int value.

    # Type

    ```
    mkUint64 :: Int -> gvariant
    ```
  */
  mkUint64 = mkPrimitive type.uint64;

  /**
    Returns the GVariant double from the given Nix float value.

    # Inputs

    `v`

    : 1\. Function argument

    # Type

    ```
    mkDouble :: Float -> gvariant
    ```
  */
  mkDouble =
    v:
    mkPrimitive type.double v
    // {
      __toString = self: toString self.value;
    };
}
</file>

<file path="lib/kernel.nix">
{ lib }:

let
  inherit (lib) mkIf versionAtLeast versionOlder;
in
{

  # Keeping these around in case we decide to change this horrible implementation :)
  option = x: x // { optional = true; };

  yes = {
    tristate = "y";
    optional = false;
  };
  no = {
    tristate = "n";
    optional = false;
  };
  module = {
    tristate = "m";
    optional = false;
  };
  unset = {
    tristate = null;
    optional = false;
  };
  freeform = x: {
    freeform = x;
    optional = false;
  };

  #  Common patterns/legacy used in common-config/hardened/config.nix
  whenHelpers = version: {
    whenAtLeast = ver: mkIf (versionAtLeast version ver);
    whenOlder = ver: mkIf (versionOlder version ver);
    # range is (inclusive, exclusive)
    whenBetween = verLow: verHigh: mkIf (versionAtLeast version verLow && versionOlder version verHigh);
  };

}
</file>

<file path="lib/licenses.nix">
{ lib }:
let
  inherit (lib) optionalAttrs;

  mkLicense =
    lname:
    {
      shortName ? lname,
      # Most of our licenses are Free, explicitly declare unfree additions as such!
      free ? true,
      deprecated ? false,
      spdxId ? null,
      url ? null,
      fullName ? null,
      redistributable ? free,
    }@attrs:
    {
      inherit
        shortName
        free
        deprecated
        redistributable
        ;
    }
    // optionalAttrs (attrs ? spdxId) {
      inherit spdxId;
      url = "https://spdx.org/licenses/${spdxId}.html";
    }
    // optionalAttrs (attrs ? url) {
      inherit url;
    }
    // optionalAttrs (attrs ? fullName) {
      inherit fullName;
    };

in
lib.mapAttrs mkLicense (
  {
    /**
      License identifiers from spdx.org where possible.
      If you cannot find your license here, then look for a similar license or
      add it to this list. The URL mentioned above is a good source for inspiration.
    */

    abstyles = {
      spdxId = "Abstyles";
      fullName = "Abstyles License";
    };

    acsl14 = {
      fullName = "Anti-Capitalist Software License v1.4";
      url = "https://anticapitalist.software/";
      /**
        restrictions on corporations apply for both use and redistribution
      */
      free = false;
      redistributable = false;
    };

    activision = {
      # https://doomwiki.org/wiki/Raven_source_code_licensing
      fullName = "Activision EULA";
      url = "https://www.doomworld.com/eternity/activision_eula.txt";
      free = false;
    };

    afl20 = {
      spdxId = "AFL-2.0";
      fullName = "Academic Free License v2.0";
    };

    afl21 = {
      spdxId = "AFL-2.1";
      fullName = "Academic Free License v2.1";
    };

    afl3 = {
      spdxId = "AFL-3.0";
      fullName = "Academic Free License v3.0";
    };

    agpl3Only = {
      spdxId = "AGPL-3.0-only";
      fullName = "GNU Affero General Public License v3.0 only";
    };

    agpl3Plus = {
      spdxId = "AGPL-3.0-or-later";
      fullName = "GNU Affero General Public License v3.0 or later";
    };

    aladdin = {
      spdxId = "Aladdin";
      fullName = "Aladdin Free Public License";
      free = false;
    };

    amazonsl = {
      fullName = "Amazon Software License";
      url = "https://aws.amazon.com/asl/";
      free = false;
    };

    amd = {
      fullName = "AMD License Agreement";
      url = "https://developer.amd.com/amd-license-agreement/";
      free = false;
    };

    aml = {
      spdxId = "AML";
      fullName = "Apple MIT License";
    };

    ampas = {
      spdxId = "AMPAS";
      fullName = "Academy of Motion Picture Arts and Sciences BSD";
    };

    aom = {
      fullName = "Alliance for Open Media Patent License 1.0";
      url = "https://aomedia.org/license/patent-license/";
    };

    apple-psl10 = {
      spdxId = "APSL-1.0";
      fullName = "Apple Public Source License 1.0";
    };

    apple-psl20 = {
      spdxId = "APSL-2.0";
      fullName = "Apple Public Source License 2.0";
    };

    arphicpl = {
      spdxId = "Arphic-1999";
      fullName = "Arphic Public License";
    };

    artistic1 = {
      spdxId = "Artistic-1.0";
      fullName = "Artistic License 1.0";
    };

    artistic1-cl8 = {
      spdxId = "Artistic-1.0-cl8";
      fullName = "Artistic License 1.0 w/clause 8";
    };

    artistic2 = {
      spdxId = "Artistic-2.0";
      fullName = "Artistic License 2.0";
    };

    asl20 = {
      spdxId = "Apache-2.0";
      fullName = "Apache License 2.0";
    };

    bitstreamVera = {
      spdxId = "Bitstream-Vera";
      fullName = "Bitstream Vera Font License";
    };

    bitTorrent10 = {
      spdxId = "BitTorrent-1.0";
      fullName = " BitTorrent Open Source License v1.0";
    };

    bitTorrent11 = {
      spdxId = "BitTorrent-1.1";
      fullName = " BitTorrent Open Source License v1.1";
    };

    bola11 = {
      url = "https://blitiri.com.ar/p/bola/";
      fullName = "Buena Onda License Agreement 1.1";
    };

    boost = {
      spdxId = "BSL-1.0";
      fullName = "Boost Software License 1.0";
    };

    beerware = {
      spdxId = "Beerware";
      fullName = "Beerware License";
    };

    blueOak100 = {
      spdxId = "BlueOak-1.0.0";
      fullName = "Blue Oak Model License 1.0.0";
    };

    bsd0 = {
      spdxId = "0BSD";
      fullName = "BSD Zero Clause License";
    };

    bsd1 = {
      spdxId = "BSD-1-Clause";
      fullName = "BSD 1-Clause License";
    };

    bsd2 = {
      spdxId = "BSD-2-Clause";
      fullName = ''BSD 2-clause "Simplified" License'';
    };

    bsd2Patent = {
      spdxId = "BSD-2-Clause-Patent";
      fullName = "BSD-2-Clause Plus Patent License";
    };

    bsd2WithViews = {
      spdxId = "BSD-2-Clause-Views";
      fullName = "BSD 2-Clause with views sentence";
    };

    bsd3 = {
      spdxId = "BSD-3-Clause";
      fullName = ''BSD 3-clause "New" or "Revised" License'';
    };

    bsd3Clear = {
      spdxId = "BSD-3-Clause-Clear";
      fullName = "BSD 3-Clause Clear License";
    };

    bsd3Lbnl = {
      spdxId = "BSD-3-Clause-LBNL";
      fullName = "Lawrence Berkeley National Labs BSD variant license";
    };

    bsd3TheodoreTso = {
      fullName = "BSD 3 Clause Theodore Tso Variant";
      # TODO: if the license gets accepted to spdx then
      #   add spdxId
      # else
      #   remove license
      #   && replace all references with bsd3
      # https://tools.spdx.org/app/license_requests/442/
      # https://github.com/spdx/license-list-XML/issues/2702
    };

    bsdAxisNoDisclaimerUnmodified = {
      fullName = "BSD-Axis without Warranty Disclaimer with Unmodified requirement";
      url = "https://scancode-licensedb.aboutcode.org/bsd-no-disclaimer-unmodified.html";
    };

    bsdOriginal = {
      spdxId = "BSD-4-Clause";
      fullName = ''BSD 4-clause "Original" or "Old" License'';
    };

    bsdOriginalShortened = {
      spdxId = "BSD-4-Clause-Shortened";
      fullName = "BSD 4 Clause Shortened";
    };

    bsdOriginalUC = {
      spdxId = "BSD-4-Clause-UC";
      fullName = "BSD 4-Clause University of California-Specific";
    };

    bsdProtection = {
      spdxId = "BSD-Protection";
      fullName = "BSD Protection License";
    };

    bsdSourceCode = {
      spdxId = "BSD-Source-Code";
      fullName = "BSD Source Code Attribution";
    };

    bsl11 = {
      spdxId = "BUSL-1.1";
      fullName = "Business Source License 1.1";
      free = false;
      redistributable = true;
    };

    caossl = {
      fullName = "Computer Associates Open Source Licence Version 1.0";
      url = "http://jxplorer.org/licence.html";
    };

    cal10 = {
      spdxId = "CAL-1.0";
      fullName = "Cryptographic Autonomy License version 1.0 (CAL-1.0)";
    };

    caldera = {
      spdxId = "Caldera";
      fullName = "Caldera License";
    };

    capec = {
      fullName = "Common Attack Pattern Enumeration and Classification";
      url = "https://capec.mitre.org/about/termsofuse.html";
    };

    clArtistic = {
      spdxId = "ClArtistic";
      fullName = "Clarified Artistic License";
    };

    cc0 = {
      spdxId = "CC0-1.0";
      fullName = "Creative Commons Zero v1.0 Universal";
    };

    cc-by-nc-nd-30 = {
      spdxId = "CC-BY-NC-ND-3.0";
      fullName = "Creative Commons Attribution Non Commercial No Derivative Works 3.0 Unported";
      free = false;
    };

    cc-by-nc-nd-40 = {
      spdxId = "CC-BY-NC-ND-4.0";
      fullName = "Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International";
      free = false;
    };

    cc-by-nc-sa-20 = {
      spdxId = "CC-BY-NC-SA-2.0";
      fullName = "Creative Commons Attribution Non Commercial Share Alike 2.0";
      free = false;
    };

    cc-by-nc-sa-25 = {
      spdxId = "CC-BY-NC-SA-2.5";
      fullName = "Creative Commons Attribution Non Commercial Share Alike 2.5";
      free = false;
    };

    cc-by-nc-sa-30 = {
      spdxId = "CC-BY-NC-SA-3.0";
      fullName = "Creative Commons Attribution Non Commercial Share Alike 3.0";
      free = false;
    };

    cc-by-nc-sa-40 = {
      spdxId = "CC-BY-NC-SA-4.0";
      fullName = "Creative Commons Attribution Non Commercial Share Alike 4.0";
      free = false;
    };

    cc-by-nc-30 = {
      spdxId = "CC-BY-NC-3.0";
      fullName = "Creative Commons Attribution Non Commercial 3.0 Unported";
      free = false;
    };

    cc-by-nc-40 = {
      spdxId = "CC-BY-NC-4.0";
      fullName = "Creative Commons Attribution Non Commercial 4.0 International";
      free = false;
    };

    cc-by-nd-30 = {
      spdxId = "CC-BY-ND-3.0";
      fullName = "Creative Commons Attribution-No Derivative Works v3.00";
      free = false;
    };

    cc-by-nd-40 = {
      spdxId = "CC-BY-ND-4.0";
      fullName = "Creative Commons Attribution-No Derivative Works v4.0";
      free = false;
    };

    cc-by-sa-10 = {
      spdxId = "CC-BY-SA-1.0";
      fullName = "Creative Commons Attribution Share Alike 1.0";
    };

    cc-by-sa-20 = {
      spdxId = "CC-BY-SA-2.0";
      fullName = "Creative Commons Attribution Share Alike 2.0";
    };

    cc-by-sa-25 = {
      spdxId = "CC-BY-SA-2.5";
      fullName = "Creative Commons Attribution Share Alike 2.5";
    };

    cc-by-10 = {
      spdxId = "CC-BY-1.0";
      fullName = "Creative Commons Attribution 1.0";
    };

    cc-by-20 = {
      spdxId = "CC-BY-2.0";
      fullName = "Creative Commons Attribution 2.0";
    };

    cc-by-30 = {
      spdxId = "CC-BY-3.0";
      fullName = "Creative Commons Attribution 3.0";
    };

    cc-by-sa-30 = {
      spdxId = "CC-BY-SA-3.0";
      fullName = "Creative Commons Attribution Share Alike 3.0";
    };

    cc-by-40 = {
      spdxId = "CC-BY-4.0";
      fullName = "Creative Commons Attribution 4.0";
    };

    cc-by-sa-40 = {
      spdxId = "CC-BY-SA-4.0";
      fullName = "Creative Commons Attribution Share Alike 4.0";
    };

    cc-sa-10 = {
      shortName = "CC-SA-1.0";
      fullName = "Creative Commons Share Alike 1.0";
      url = "https://creativecommons.org/licenses/sa/1.0";
    };

    cddl = {
      spdxId = "CDDL-1.0";
      fullName = "Common Development and Distribution License 1.0";
    };

    cecill20 = {
      spdxId = "CECILL-2.0";
      fullName = "CeCILL Free Software License Agreement v2.0";
    };

    cecill21 = {
      spdxId = "CECILL-2.1";
      fullName = "CeCILL Free Software License Agreement v2.1";
    };

    cecill-b = {
      spdxId = "CECILL-B";
      fullName = "CeCILL-B Free Software License Agreement";
    };

    cecill-c = {
      spdxId = "CECILL-C";
      fullName = "CeCILL-C Free Software License Agreement";
    };

    cockroachdb-community-license = {
      fullName = "CockroachDB Community License Agreement";
      url = "https://www.cockroachlabs.com/cockroachdb-community-license/";
      free = false;
    };

    cpal10 = {
      spdxId = "CPAL-1.0";
      fullName = "Common Public Attribution License 1.0";
    };

    commons-clause = {
      fullName = "Commons Clause License";
      url = "https://commonsclause.com/";
      free = false;
    };

    cpl10 = {
      spdxId = "CPL-1.0";
      fullName = "Common Public License 1.0";
    };

    cronyx = {
      spdxId = "Cronyx";
      fullName = "Cronyx License";
    };

    curl = {
      spdxId = "curl";
      fullName = "curl License";
    };

    doc = {
      spdxId = "DOC";
      fullName = "DOC License";
    };

    drl10 = {
      spdxId = "DRL-1.0";
      fullName = "Detection Rule License 1.0";
    };

    dtoa = {
      spdxId = "dtoa";
      fullName = "dtoa License";
    };

    eapl = {
      fullName = "EPSON AVASYS PUBLIC LICENSE";
      url = "https://avasys.jp/hp/menu000000700/hpg000000603.htm";
      free = false;
    };

    ecl20 = {
      fullName = "Educational Community License, Version 2.0";
      shortName = "ECL 2.0";
      spdxId = "ECL-2.0";
    };

    efl10 = {
      spdxId = "EFL-1.0";
      fullName = "Eiffel Forum License v1.0";
    };

    efl20 = {
      spdxId = "EFL-2.0";
      fullName = "Eiffel Forum License v2.0";
    };

    elastic20 = {
      spdxId = "Elastic-2.0";
      fullName = "Elastic License 2.0";
      free = false;
    };

    epl10 = {
      spdxId = "EPL-1.0";
      fullName = "Eclipse Public License 1.0";
    };

    epl20 = {
      spdxId = "EPL-2.0";
      fullName = "Eclipse Public License 2.0";
    };

    epson = {
      fullName = "Seiko Epson Corporation Software License Agreement for Linux";
      url = "https://download.ebz.epson.net/dsc/du/02/eula/global/LINUX_EN.html";
      free = false;
    };

    eupl11 = {
      spdxId = "EUPL-1.1";
      fullName = "European Union Public License 1.1";
    };

    eupl12 = {
      spdxId = "EUPL-1.2";
      fullName = "European Union Public License 1.2";
    };

    fdl11Only = {
      spdxId = "GFDL-1.1-only";
      fullName = "GNU Free Documentation License v1.1 only";
    };

    fdl11Plus = {
      spdxId = "GFDL-1.1-or-later";
      fullName = "GNU Free Documentation License v1.1 or later";
    };

    fdl12Only = {
      spdxId = "GFDL-1.2-only";
      fullName = "GNU Free Documentation License v1.2 only";
    };

    fdl12Plus = {
      spdxId = "GFDL-1.2-or-later";
      fullName = "GNU Free Documentation License v1.2 or later";
    };

    fdl13Only = {
      spdxId = "GFDL-1.3-only";
      fullName = "GNU Free Documentation License v1.3 only";
    };

    fdl13Plus = {
      spdxId = "GFDL-1.3-or-later";
      fullName = "GNU Free Documentation License v1.3 or later";
    };

    ffsl = {
      fullName = "Floodgap Free Software License";
      url = "https://www.floodgap.com/software/ffsl/license.html";
      free = false;
    };

    fraunhofer-fdk = {
      fullName = "Fraunhofer FDK AAC Codec Library";
      spdxId = "FDK-AAC";
    };

    free = {
      fullName = "Unspecified free software license";
    };

    fsl11Mit = {
      fullName = "Functional Source License, Version 1.1, MIT Future License";
      url = "https://fsl.software/FSL-1.1-MIT.template.md";
      free = false;
      redistributable = true;
    };

    fsl11Asl20 = {
      fullName = "Functional Source License, Version 1.1, Apache 2.0 Future License";
      url = "https://fsl.software/FSL-1.1-Apache-2.0.template.md";
      free = false;
      redistributable = true;
    };

    ftl = {
      spdxId = "FTL";
      fullName = "Freetype Project License";
    };

    g4sl = {
      fullName = "Geant4 Software License";
      url = "https://geant4.web.cern.ch/geant4/license/LICENSE.html";
    };

    geogebra = {
      fullName = "GeoGebra Non-Commercial License Agreement";
      url = "https://www.geogebra.org/license";
      free = false;
    };

    generaluser = {
      fullName = "GeneralUser GS License v2.0";
      url = "https://www.schristiancollins.com/generaluser.php"; # license included in sources
    };

    gfl = {
      fullName = "GUST Font License";
      url = "https://www.gust.org.pl/projects/e-foundry/licenses/GUST-FONT-LICENSE.txt";
    };

    gfsl = {
      fullName = "GUST Font Source License";
      url = "https://www.gust.org.pl/projects/e-foundry/licenses/GUST-FONT-SOURCE-LICENSE.txt";
    };

    gpl1Only = {
      spdxId = "GPL-1.0-only";
      fullName = "GNU General Public License v1.0 only";
    };

    gpl1Plus = {
      spdxId = "GPL-1.0-or-later";
      fullName = "GNU General Public License v1.0 or later";
    };

    gpl2Only = {
      spdxId = "GPL-2.0-only";
      fullName = "GNU General Public License v2.0 only";
    };

    gpl2Classpath = {
      spdxId = "GPL-2.0-with-classpath-exception";
      fullName = "GNU General Public License v2.0 only (with Classpath exception)";
    };

    gpl2ClasspathPlus = {
      fullName = "GNU General Public License v2.0 or later (with Classpath exception)";
      url = "https://fedoraproject.org/wiki/Licensing/GPL_Classpath_Exception";
    };

    gpl2UBDLPlus = {
      fullName = "GNU General Public License v3.0 or later (with UBDL exception)";
      url = "https://spdx.org/licenses/UBDL-exception.html";
    };

    gpl2Oss = {
      fullName = "GNU General Public License version 2 only (with OSI approved licenses linking exception)";
      url = "https://www.mysql.com/about/legal/licensing/foss-exception";
    };

    gpl2Plus = {
      spdxId = "GPL-2.0-or-later";
      fullName = "GNU General Public License v2.0 or later";
    };

    gpl3Only = {
      spdxId = "GPL-3.0-only";
      fullName = "GNU General Public License v3.0 only";
    };

    gpl3Plus = {
      spdxId = "GPL-3.0-or-later";
      fullName = "GNU General Public License v3.0 or later";
    };

    gpl3ClasspathPlus = {
      fullName = "GNU General Public License v3.0 or later (with Classpath exception)";
      url = "https://fedoraproject.org/wiki/Licensing/GPL_Classpath_Exception";
    };

    giftware = {
      spdxId = "Giftware";
      fullName = "Giftware License";
    };

    hpnd = {
      spdxId = "HPND";
      fullName = "Historic Permission Notice and Disclaimer";
    };

    hpndDifferentDisclaimer = {
      fullName = "HPND with different disclaimer";
      url = "https://gitlab.freedesktop.org/xorg/proto/xorgproto/-/blob/1914233e662d23ffb3812b80fadd0bbd064ad91c/COPYING-x11proto#L69-88";
      # TODO: if the license gets accepted to spdx then
      #   add spdxId
      # else
      #   remove license
      #   && replace reference with whatever this license is supposed to be then
      # https://tools.spdx.org/app/license_requests/456
      # https://github.com/spdx/license-list-xml/issues/2753
    };

    hpndSellVariant = {
      fullName = "Historical Permission Notice and Disclaimer - sell variant";
      spdxId = "HPND-sell-variant";
    };

    hpndUc = {
      spdxId = "HPND-UC";
      fullName = "Historical Permission Notice and Disclaimer - University of California variant";
    };

    # Intel's license, seems free
    iasl = {
      spdxId = "Intel-ACPI";
      fullName = "Intel ACPI Software License Agreement";
    };

    icu = {
      spdxId = "ICU";
      fullName = "ICU";
    };

    ijg = {
      spdxId = "IJG";
      fullName = "Independent JPEG Group License";
    };

    imagemagick = {
      fullName = "ImageMagick License";
      spdxId = "ImageMagick";
    };

    imlib2 = {
      spdxId = "Imlib2";
      fullName = "Imlib2 License";
    };

    info-zip = {
      spdxId = "Info-ZIP";
      fullName = "Info-ZIP License";
    };

    inria-compcert = {
      fullName = "INRIA Non-Commercial License Agreement for the CompCert verified compiler";
      url = "https://compcert.org/doc/LICENSE.txt";
      free = false;
    };

    inria-icesl = {
      fullName = "End User License Agreement for IceSL Software";
      url = "https://icesl.loria.fr/assets/pdf/EULA_IceSL_binary.pdf";
      free = false;
    };

    inria-zelus = {
      fullName = "INRIA Non-Commercial License Agreement for the Zélus compiler";
      url = "https://github.com/INRIA/zelus/raw/829f2b97cba93b0543a9ca0272269e6b8fdad356/LICENSE";
      free = false;
    };

    ipa = {
      spdxId = "IPA";
      fullName = "IPA Font License";
    };

    ipl10 = {
      spdxId = "IPL-1.0";
      fullName = "IBM Public License v1.0";
    };

    isc = {
      spdxId = "ISC";
      fullName = "ISC License";
    };

    databricks = {
      fullName = "Databricks License";
      url = "https://www.databricks.com/legal/db-license";
      free = false;
    };

    databricks-dbx = {
      fullName = "DataBricks eXtensions aka dbx License";
      url = "https://github.com/databrickslabs/dbx/blob/743b579a4ac44531f764c6e522dbe5a81a7dc0e4/LICENSE";
      free = false;
      redistributable = false;
    };

    databricks-license = {
      fullName = "Databricks License";
      url = "https://www.databricks.com/legal/db-license";
      free = false;
    };

    fair = {
      fullName = "Fair License";
      spdxId = "Fair";
      free = true;
    };

    fairsource09 = {
      fullName = "Fair Source License, version 0.9";
      url = "https://fair.io/v0.9.txt";
      free = false;
      redistributable = true;
    };

    hl3 = {
      fullName = "Hippocratic License v3.0";
      url = "https://firstdonoharm.dev/version/3/0/core.txt";
      free = false;
      redistributable = true;
    };

    issl = {
      fullName = "Intel Simplified Software License";
      url = "https://software.intel.com/en-us/license/intel-simplified-software-license";
      free = false;
    };

    knuth = {
      fullName = "Knuth CTAN License";
      spdxId = "Knuth-CTAN";
    };

    lal12 = {
      spdxId = "LAL-1.2";
      fullName = "Licence Art Libre 1.2";
    };

    lal13 = {
      spdxId = "LAL-1.3";
      fullName = "Licence Art Libre 1.3";
    };

    lens = {
      fullName = "Lens Terms of Service Agreement";
      url = "https://k8slens.dev/legal/tos";
      free = false;
    };

    lgpl2Only = {
      spdxId = "LGPL-2.0-only";
      fullName = "GNU Library General Public License v2 only";
    };

    lgpl2Plus = {
      spdxId = "LGPL-2.0-or-later";
      fullName = "GNU Library General Public License v2 or later";
    };

    lgpl21Only = {
      spdxId = "LGPL-2.1-only";
      fullName = "GNU Lesser General Public License v2.1 only";
    };

    lgpl21Plus = {
      spdxId = "LGPL-2.1-or-later";
      fullName = "GNU Lesser General Public License v2.1 or later";
    };

    lgpl3Only = {
      spdxId = "LGPL-3.0-only";
      fullName = "GNU Lesser General Public License v3.0 only";
    };

    lgpl3Plus = {
      spdxId = "LGPL-3.0-or-later";
      fullName = "GNU Lesser General Public License v3.0 or later";
    };

    lgpllr = {
      spdxId = "LGPLLR";
      fullName = "Lesser General Public License For Linguistic Resources";
    };

    libpng = {
      spdxId = "Libpng";
      fullName = "libpng License";
    };

    libpng2 = {
      spdxId = "libpng-2.0"; # Used since libpng 1.6.36.
      fullName = "PNG Reference Library version 2";
    };

    libtiff = {
      spdxId = "libtiff";
      fullName = "libtiff License";
    };

    llgpl21 = {
      fullName = "Lisp LGPL; GNU Lesser General Public License version 2.1 with Franz Inc. preamble for clarification of LGPL terms in context of Lisp";
      url = "https://opensource.franz.com/preamble.html";
    };

    llvm-exception = {
      spdxId = "LLVM-exception";
      fullName = "LLVM Exception"; # LLVM exceptions to the Apache 2.0 License
    };

    lppl1 = {
      spdxId = "LPPL-1.0";
      fullName = "LaTeX Project Public License v1.0";
    };

    lppl12 = {
      spdxId = "LPPL-1.2";
      fullName = "LaTeX Project Public License v1.2";
    };

    lppl13a = {
      spdxId = "LPPL-1.3a";
      fullName = "LaTeX Project Public License v1.3a";
    };

    lppl13c = {
      spdxId = "LPPL-1.3c";
      fullName = "LaTeX Project Public License v1.3c";
    };

    lpl-102 = {
      spdxId = "LPL-1.02";
      fullName = "Lucent Public License v1.02";
    };

    miros = {
      spdxId = "MirOS";
      fullName = "MirOS License";
    };

    mit = {
      spdxId = "MIT";
      fullName = "MIT License";
    };

    mit-cmu = {
      spdxId = "MIT-CMU";
      fullName = "CMU License";
    };

    mit-feh = {
      spdxId = "MIT-feh";
      fullName = "feh License";
    };

    mit-modern = {
      # Also known as Zsh license
      spdxId = "MIT-Modern-Variant";
      fullName = "MIT License Modern Variant";
    };

    mitAdvertising = {
      spdxId = "MIT-advertising";
      fullName = "Enlightenment License (e16)";
    };

    mit0 = {
      spdxId = "MIT-0";
      fullName = "MIT No Attribution";
    };

    mitOpenGroup = {
      spdxId = "MIT-open-group";
      fullName = "MIT Open Group variant";
    };

    mpl10 = {
      spdxId = "MPL-1.0";
      fullName = "Mozilla Public License 1.0";
    };

    mpl11 = {
      spdxId = "MPL-1.1";
      fullName = "Mozilla Public License 1.1";
    };

    mpl20 = {
      spdxId = "MPL-2.0";
      fullName = "Mozilla Public License 2.0";
    };

    mplus = {
      spdxId = "mplus";
      fullName = "M+ Font License";
    };

    mspl = {
      spdxId = "MS-PL";
      fullName = "Microsoft Public License";
    };

    mulan-psl2 = {
      spdxId = "MulanPSL-2.0";
      fullName = "Mulan Permissive Software License, Version 2";
    };

    naist-2003 = {
      spdxId = "NAIST-2003";
      fullName = "Nara Institute of Science and Technology License (2003)";
    };

    nasa13 = {
      spdxId = "NASA-1.3";
      fullName = "NASA Open Source Agreement 1.3";
      free = false;
    };

    ncbiPd = {
      spdxId = "NCBI-PD";
      fullName = "NCBI Public Domain Notice";
      # Due to United States copyright law, anything with this "license" does not have a copyright in the
      # jurisdiction of the United States. However, other jurisdictions may assign the United States
      # government copyright to the work, and the license explicitly states that in such a case, no license
      # is granted. This is nonfree and nonredistributable in most jurisdictions other than the United States.
      free = false;
      redistributable = false;
    };

    ncsa = {
      spdxId = "NCSA";
      fullName = "University of Illinois/NCSA Open Source License";
    };

    ncul1 = {
      spdxId = "NCUL1";
      fullName = "Netdata Cloud UI License v1.0";
      free = false;
      redistributable = true; # Only if used in Netdata products.
    };

    nistSoftware = {
      spdxId = "NIST-Software";
      fullName = "NIST Software License";
    };

    nlpl = {
      spdxId = "NLPL";
      fullName = "No Limit Public License";
    };

    nposl3 = {
      spdxId = "NPOSL-3.0";
      fullName = "Non-Profit Open Software License 3.0";
    };

    nvidiaCuda = {
      shortName = "CUDA EULA";
      fullName = "CUDA Toolkit End User License Agreement (EULA)";
      url = "https://docs.nvidia.com/cuda/eula/index.html#cuda-toolkit-supplement-license-agreement";
      free = false;
    };

    nvidiaCudaRedist = {
      shortName = "CUDA EULA";
      fullName = "CUDA Toolkit End User License Agreement (EULA)";
      url = "https://docs.nvidia.com/cuda/eula/index.html#cuda-toolkit-supplement-license-agreement";
      free = false;
      redistributable = true;
    };

    obsidian = {
      fullName = "Obsidian End User Agreement";
      url = "https://obsidian.md/eula";
      free = false;
    };

    ocamlLgplLinkingException = {
      spdxId = "OCaml-LGPL-linking-exception";
      fullName = "OCaml LGPL Linking Exception";
    };

    ocamlpro_nc = {
      fullName = "OCamlPro Non Commercial license version 1";
      url = "https://alt-ergo.ocamlpro.com/http/alt-ergo-2.2.0/OCamlPro-Non-Commercial-License.pdf";
      free = false;
    };

    odbl = {
      spdxId = "ODbL-1.0";
      fullName = "Open Data Commons Open Database License v1.0";
    };

    ofl = {
      spdxId = "OFL-1.1";
      fullName = "SIL Open Font License 1.1";
    };

    oml = {
      spdxId = "OML";
      fullName = "Open Market License";
    };

    openldap = {
      spdxId = "OLDAP-2.8";
      fullName = "Open LDAP Public License v2.8";
    };

    openssl = {
      spdxId = "OpenSSL";
      fullName = "OpenSSL License";
    };

    opubl = {
      spdxId = "OPUBL-1.0";
      fullName = "Open Publication License v1.0";
    };

    osl2 = {
      spdxId = "OSL-2.0";
      fullName = "Open Software License 2.0";
    };

    osl21 = {
      spdxId = "OSL-2.1";
      fullName = "Open Software License 2.1";
    };

    osl3 = {
      spdxId = "OSL-3.0";
      fullName = "Open Software License 3.0";
    };

    parity70 = {
      spdxId = "Parity-7.0.0";
      fullName = "Parity Public License 7.0.0";
    };

    php301 = {
      spdxId = "PHP-3.01";
      fullName = "PHP License v3.01";
    };

    postgresql = {
      spdxId = "PostgreSQL";
      fullName = "PostgreSQL License";
    };

    postman = {
      fullName = "Postman EULA";
      url = "https://www.getpostman.com/licenses/postman_base_app";
      free = false;
    };

    psfl = {
      spdxId = "Python-2.0";
      fullName = "Python Software Foundation License version 2";
    };

    publicDomain = {
      fullName = "Public Domain";
    };

    purdueBsd = {
      fullName = "Purdue BSD-Style License"; # also known as lsof license
      url = "https://enterprise.dejacode.com/licenses/public/purdue-bsd";
    };

    prosperity30 = {
      fullName = "Prosperity-3.0.0";
      free = false;
      url = "https://prosperitylicense.com/versions/3.0.0.html";
    };

    qhull = {
      spdxId = "Qhull";
      fullName = "Qhull License";
    };

    qpl = {
      spdxId = "QPL-1.0";
      fullName = "Q Public License 1.0";
    };

    qwt = {
      fullName = "Qwt License, Version 1.0";
      url = "https://qwt.sourceforge.io/qwtlicense.html";
    };

    radiance = {
      fullName = "The Radiance Software License, Version 2.0";
      url = "https://github.com/LBNL-ETA/Radiance/blob/master/License.txt";
    };

    ruby = {
      spdxId = "Ruby";
      fullName = "Ruby License";
    };

    sendmail = {
      spdxId = "Sendmail";
      fullName = "Sendmail License";
    };

    sfl = {
      fullName = "Source First License 1.1";
      url = "https://gitlab.futo.org/videostreaming/grayjay/-/blob/master/LICENSE.md";
      free = false;
      redistributable = true;
    };

    sgi-b-20 = {
      spdxId = "SGI-B-2.0";
      fullName = "SGI Free Software License B v2.0";
    };

    # Gentoo seems to treat it as a license:
    # https://gitweb.gentoo.org/repo/gentoo.git/tree/licenses/SGMLUG?id=7d999af4a47bf55e53e54713d98d145f935935c1
    sgmlug = {
      fullName = "SGML UG SGML Parser Materials license";
    };

    sleepycat = {
      spdxId = "Sleepycat";
      fullName = "Sleepycat License";
    };

    smail = {
      shortName = "smail";
      fullName = "SMAIL General Public License";
      url = "https://sources.debian.org/copyright/license/debianutils/4.9.1/";
    };

    smlnj = {
      spdxId = "SMLNJ";
      fullName = "Standard ML of New Jersey License";
    };

    sspl = {
      shortName = "SSPL";
      fullName = "Server Side Public License";
      url = "https://www.mongodb.com/licensing/server-side-public-license";
      free = false;
      # NOTE Debatable.
      # The license a slightly modified AGPL but still considered unfree by the
      # OSI for what seem like political reasons
      redistributable = true; # Definitely redistributable though, it's an AGPL derivative
    };

    stk = {
      shortName = "stk";
      fullName = "Synthesis Tool Kit 4.3";
      url = "https://github.com/thestk/stk/blob/master/LICENSE";
    };

    sudo = {
      shortName = "sudo";
      fullName = "Sudo License (ISC-style)";
      url = "https://www.sudo.ws/about/license/";
    };

    sustainableUse = {
      shortName = "sustainable";
      fullName = "Sustainable Use License";
      url = "https://github.com/n8n-io/n8n/blob/master/LICENSE.md";
      free = false;
      redistributable = false; # only free to redistribute "for non-commercial purposes"
    };

    teamspeak = {
      fullName = "Teamspeak client license";
      url = "https://www.teamspeak.com/en/privacy-and-terms/";
      free = false;
      redistributable = true; # we got a permit to redistribute it:
      # License issues:
      # Date: Mon, 10 Dec 2007 19:55:16 -0500
      # From: TeamSpeak Sales <sales@tritoncia.com>
      # To: 'Marc Weber' <marco-oweber@gmx.de>
      # Subject: RE: teamspeak on nix?
      #
      # Yes, that would be fine.  As long as you are not renting servers or selling
      # TeamSpeak then you are more than welcome to distribute it.
      #
      # Thank you,
      #
      # TeamSpeak Sales Team
      # ________________________________
      # e-Mail: sales@tritoncia.com
      # TeamSpeak: http://www.TeamSpeak.com
      # Account Login: https://sales.TritonCIA.com/users
      #
      #
      #
      # -----Original Message-----
      # From: Marc Weber [mailto:marco-oweber@gmx.de]
      # Sent: Monday, December 10, 2007 5:03 PM
      # To: sales@tritoncia.com
      # Subject: teamspeak on nix?
      #
      # Hello,
      #
      # nix is very young software distribution system (http://nix.cs.uu.nl/)
      # I'd like to ask wether you permit us to add teamspeak (server/ client?)
      #
      # Sincerly
      # Marc Weber (small nix contributor)
    };

    tsl = {
      shortName = "TSL";
      fullName = "Timescale License Agreegment";
      url = "https://github.com/timescale/timescaledb/blob/main/tsl/LICENSE-TIMESCALE";
      free = false;
    };

    tcltk = {
      spdxId = "TCL";
      fullName = "TCL/TK License";
    };

    tost = {
      fullName = "Tomorrow Open Source Technology License 1.0";
      url = "https://github.com/PixarAnimationStudios/OpenUSD/blob/release/LICENSE.txt";
    };

    ucd = {
      fullName = "Unicode Character Database License";
      url = "https://fedoraproject.org/wiki/Licensing:UCD";
    };

    ufl = {
      spdxId = "Ubuntu-font-1.0";
      fullName = "Ubuntu Font License 1.0";
    };

    unfree = {
      fullName = "Unfree";
      free = false;
    };

    unfreeRedistributable = {
      fullName = "Unfree redistributable";
      free = false;
      redistributable = true;
    };

    unfreeRedistributableFirmware = {
      fullName = "Unfree redistributable firmware";
      redistributable = true;
      # Note: we currently consider these "free" for inclusion in the
      # channel and NixOS images.
    };

    unicode-30 = {
      spdxId = "Unicode-3.0";
      fullName = "Unicode License v3";
    };

    unicode-dfs-2015 = {
      spdxId = "Unicode-DFS-2015";
      fullName = "Unicode License Agreement - Data Files and Software (2015)";
    };

    unicode-dfs-2016 = {
      spdxId = "Unicode-DFS-2016";
      fullName = "Unicode License Agreement - Data Files and Software (2016)";
    };

    unicodeTOU = {
      spdxId = "Unicode-TOU";
      fullName = "Unicode Terms of Use";
    };

    unlicense = {
      spdxId = "Unlicense";
      fullName = "The Unlicense";
    };

    upl = {
      spdxId = "UPL-1.0";
      fullName = "Universal Permissive License";
    };

    vim = {
      spdxId = "Vim";
      fullName = "Vim License";
    };

    virtualbox-puel = {
      fullName = "Oracle VM VirtualBox Extension Pack Personal Use and Evaluation License (PUEL)";
      url = "https://www.virtualbox.org/wiki/VirtualBox_PUEL";
      free = false;
    };

    vol-sl = {
      fullName = "Volatility Software License, Version 1.0";
      url = "https://www.volatilityfoundation.org/license/vsl-v1.0";
    };

    vsl10 = {
      spdxId = "VSL-1.0";
      fullName = "Vovida Software License v1.0";
    };

    watcom = {
      spdxId = "Watcom-1.0";
      fullName = "Sybase Open Watcom Public License 1.0";
      # Despite being OSI‐approved, this licence is not considered FOSS
      # by Debian, Fedora, or the FSF, due to an onerous restriction that
      # requires publication of even privately‐deployed modifications.
      # This violates the FSF’s freedom 3 and Debian’s “desert island
      # test” and “dissident test”.
      #
      # See: <https://en.wikipedia.org/wiki/Sybase_Open_Watcom_Public_License>
      free = false;
      redistributable = true;
    };

    w3c = {
      spdxId = "W3C";
      fullName = "W3C Software Notice and License";
    };

    wadalab = {
      fullName = "Wadalab Font License";
      url = "https://fedoraproject.org/wiki/Licensing:Wadalab?rd=Licensing/Wadalab";
    };

    wtfpl = {
      spdxId = "WTFPL";
      fullName = "Do What The F*ck You Want To Public License";
    };

    wxWindows = {
      spdxId = "wxWindows";
      fullName = "wxWindows Library Licence, Version 3.1";
    };

    x11 = {
      spdxId = "X11";
      fullName = "X11 License";
    };

    xfig = {
      spdxId = "Xfig";
      fullName = "xfig";
    };

    xinetd = {
      spdxId = "xinetd";
      fullName = "xinetd License";
    };

    xskat = {
      spdxId = "XSkat";
      fullName = "XSkat License";
    };

    zlib = {
      spdxId = "Zlib";
      fullName = "zlib License";
    };

    zpl20 = {
      spdxId = "ZPL-2.0";
      fullName = "Zope Public License 2.0";
    };

    zpl21 = {
      spdxId = "ZPL-2.1";
      fullName = "Zope Public License 2.1";
    };

  }
  // {
    # TODO: remove legacy aliases
    apsl10 = {
      # deprecated for consistency with `apple-psl20`; use `apple-psl10`
      spdxId = "APSL-1.0";
      fullName = "Apple Public Source License 1.0";
      deprecated = true;
    };
    apsl20 = {
      # deprecated due to confusion with Apache-2.0; use `apple-psl20`
      spdxId = "APSL-2.0";
      fullName = "Apple Public Source License 2.0";
      deprecated = true;
    };
    gpl2 = {
      spdxId = "GPL-2.0";
      fullName = "GNU General Public License v2.0";
      deprecated = true;
    };
    gpl3 = {
      spdxId = "GPL-3.0";
      fullName = "GNU General Public License v3.0";
      deprecated = true;
    };
    lgpl2 = {
      spdxId = "LGPL-2.0";
      fullName = "GNU Library General Public License v2";
      deprecated = true;
    };
    lgpl21 = {
      spdxId = "LGPL-2.1";
      fullName = "GNU Lesser General Public License v2.1";
      deprecated = true;
    };
    lgpl3 = {
      spdxId = "LGPL-3.0";
      fullName = "GNU Lesser General Public License v3.0";
      deprecated = true;
    };
  }
)
</file>

<file path="lib/lists.nix">
/**
  General list operations.
*/
{ lib }:
let
  inherit (lib.strings) toInt;
  inherit (lib.trivial)
    compare
    min
    id
    warn
    pipe
    ;
  inherit (lib.attrsets) mapAttrs;
  inherit (lib) max;
in
rec {

  inherit (builtins)
    head
    tail
    length
    isList
    elemAt
    concatLists
    filter
    elem
    genList
    map
    ;

  /**
    Create a list consisting of a single element. `singleton x` is
    sometimes more convenient with respect to indentation than `[x]`
    when x spans multiple lines.

    # Inputs

    `x`

    : 1\. Function argument

    # Type

    ```
    singleton :: a -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.singleton` usage example

    ```nix
    singleton "foo"
    => [ "foo" ]
    ```

    :::
  */
  singleton = x: [ x ];

  /**
    Apply the function to each element in the list.
    Same as `map`, but arguments flipped.

    # Inputs

    `xs`

    : 1\. Function argument

    `f`

    : 2\. Function argument

    # Type

    ```
    forEach :: [a] -> (a -> b) -> [b]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.forEach` usage example

    ```nix
    forEach [ 1 2 ] (x:
      toString x
    )
    => [ "1" "2" ]
    ```

    :::
  */
  forEach = xs: f: map f xs;

  /**
    “right fold” a binary function `op` between successive elements of
    `list` with `nul` as the starting value, i.e.,
    `foldr op nul [x_1 x_2 ... x_n] == op x_1 (op x_2 ... (op x_n nul))`.

    # Inputs

    `op`

    : 1\. Function argument

    `nul`

    : 2\. Function argument

    `list`

    : 3\. Function argument

    # Type

    ```
    foldr :: (a -> b -> b) -> b -> [a] -> b
    ```

    # Examples
    :::{.example}
    ## `lib.lists.foldr` usage example

    ```nix
    concat = foldr (a: b: a + b) "z"
    concat [ "a" "b" "c" ]
    => "abcz"
    # different types
    strange = foldr (int: str: toString (int + 1) + str) "a"
    strange [ 1 2 3 4 ]
    => "2345a"
    ```

    :::
  */
  foldr =
    op: nul: list:
    let
      len = length list;
      fold' = n: if n == len then nul else op (elemAt list n) (fold' (n + 1));
    in
    fold' 0;

  /**
    `fold` is an alias of `foldr` for historic reasons
  */
  # FIXME(Profpatsch): deprecate?
  fold = foldr;

  /**
    “left fold”, like `foldr`, but from the left:

    `foldl op nul [x_1 x_2 ... x_n] == op (... (op (op nul x_1) x_2) ... x_n)`.

    # Inputs

    `op`

    : 1\. Function argument

    `nul`

    : 2\. Function argument

    `list`

    : 3\. Function argument

    # Type

    ```
    foldl :: (b -> a -> b) -> b -> [a] -> b
    ```

    # Examples
    :::{.example}
    ## `lib.lists.foldl` usage example

    ```nix
    lconcat = foldl (a: b: a + b) "z"
    lconcat [ "a" "b" "c" ]
    => "zabc"
    # different types
    lstrange = foldl (str: int: str + toString (int + 1)) "a"
    lstrange [ 1 2 3 4 ]
    => "a2345"
    ```

    :::
  */
  foldl =
    op: nul: list:
    let
      foldl' = n: if n == -1 then nul else op (foldl' (n - 1)) (elemAt list n);
    in
    foldl' (length list - 1);

  /**
    Reduce a list by applying a binary operator from left to right,
    starting with an initial accumulator.

    Before each application of the operator, the accumulator value is evaluated.
    This behavior makes this function stricter than [`foldl`](#function-library-lib.lists.foldl).

    Unlike [`builtins.foldl'`](https://nixos.org/manual/nix/unstable/language/builtins.html#builtins-foldl'),
    the initial accumulator argument is evaluated before the first iteration.

    A call like

    ```nix
    foldl' op acc₀ [ x₀ x₁ x₂ ... xₙ₋₁ xₙ ]
    ```

    is (denotationally) equivalent to the following,
    but with the added benefit that `foldl'` itself will never overflow the stack.

    ```nix
    let
      acc₁   = builtins.seq acc₀   (op acc₀   x₀  );
      acc₂   = builtins.seq acc₁   (op acc₁   x₁  );
      acc₃   = builtins.seq acc₂   (op acc₂   x₂  );
      ...
      accₙ   = builtins.seq accₙ₋₁ (op accₙ₋₁ xₙ₋₁);
      accₙ₊₁ = builtins.seq accₙ   (op accₙ   xₙ  );
    in
    accₙ₊₁

    # Or ignoring builtins.seq
    op (op (... (op (op (op acc₀ x₀) x₁) x₂) ...) xₙ₋₁) xₙ
    ```

    # Inputs

    `op`

    : The binary operation to run, where the two arguments are:

    1. `acc`: The current accumulator value: Either the initial one for the first iteration, or the result of the previous iteration
    2. `x`: The corresponding list element for this iteration

    `acc`

    : The initial accumulator value.

      The accumulator value is evaluated in any case before the first iteration starts.

      To avoid evaluation even before the `list` argument is given an eta expansion can be used:

      ```nix
      list: lib.foldl' op acc list
      ```

    `list`

    : The list to fold

    # Type

    ```
    foldl' :: (acc -> x -> acc) -> acc -> [x] -> acc
    ```

    # Examples
    :::{.example}
    ## `lib.lists.foldl'` usage example

    ```nix
    foldl' (acc: x: acc + x) 0 [1 2 3]
    => 6
    ```

    :::
  */
  foldl' =
    op: acc:
    # The builtin `foldl'` is a bit lazier than one might expect.
    # See https://github.com/NixOS/nix/pull/7158.
    # In particular, the initial accumulator value is not forced before the first iteration starts.
    builtins.seq acc (builtins.foldl' op acc);

  /**
    Map with index starting from 0

    # Inputs

    `f`

    : 1\. Function argument

    `list`

    : 2\. Function argument

    # Type

    ```
    imap0 :: (int -> a -> b) -> [a] -> [b]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.imap0` usage example

    ```nix
    imap0 (i: v: "${v}-${toString i}") ["a" "b"]
    => [ "a-0" "b-1" ]
    ```

    :::
  */
  imap0 = f: list: genList (n: f n (elemAt list n)) (length list);

  /**
    Map with index starting from 1

    # Inputs

    `f`

    : 1\. Function argument

    `list`

    : 2\. Function argument

    # Type

    ```
    imap1 :: (int -> a -> b) -> [a] -> [b]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.imap1` usage example

    ```nix
    imap1 (i: v: "${v}-${toString i}") ["a" "b"]
    => [ "a-1" "b-2" ]
    ```

    :::
  */
  imap1 = f: list: genList (n: f (n + 1) (elemAt list n)) (length list);

  /**
    Filter a list for elements that satisfy a predicate function.
    The predicate function is called with both the index and value for each element.
    It must return `true`/`false` to include/exclude a given element in the result.
    This function is strict in the result of the predicate function for each element.
    This function has O(n) complexity.

    Also see [`builtins.filter`](https://nixos.org/manual/nix/stable/language/builtins.html#builtins-filter) (available as `lib.lists.filter`),
    which can be used instead when the index isn't needed.

    # Inputs

    `ipred`

    : The predicate function, it takes two arguments:
      - 1. (int): the index of the element.
      - 2. (a): the value of the element.

      It must return `true`/`false` to include/exclude a given element from the result.

    `list`

    : The list to filter using the predicate.

    # Type
    ```
    ifilter0 :: (int -> a -> bool) -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.ifilter0` usage example

    ```nix
    ifilter0 (i: v: i == 0 || v > 2) [ 1 2 3 ]
    => [ 1 3 ]
    ```
    :::
  */
  ifilter0 =
    ipred: input:
    map (idx: elemAt input idx) (
      filter (idx: ipred idx (elemAt input idx)) (genList (x: x) (length input))
    );

  /**
    Map and concatenate the result.

    # Type

    ```
    concatMap :: (a -> [b]) -> [a] -> [b]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.concatMap` usage example

    ```nix
    concatMap (x: [x] ++ ["z"]) ["a" "b"]
    => [ "a" "z" "b" "z" ]
    ```

    :::
  */
  concatMap = builtins.concatMap;

  /**
    Flatten the argument into a single list; that is, nested lists are
    spliced into the top-level lists.

    # Inputs

    `x`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.flatten` usage example

    ```nix
    flatten [1 [2 [3] 4] 5]
    => [1 2 3 4 5]
    flatten 1
    => [1]
    ```

    :::
  */
  flatten = x: if isList x then concatMap (y: flatten y) x else [ x ];

  /**
    Remove elements equal to 'e' from a list.  Useful for buildInputs.

    # Inputs

    `e`

    : Element to remove from `list`

    `list`

    : The list

    # Type

    ```
    remove :: a -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.remove` usage example

    ```nix
    remove 3 [ 1 3 4 3 ]
    => [ 1 4 ]
    ```

    :::
  */
  remove = e: filter (x: x != e);

  /**
    Find the sole element in the list matching the specified
    predicate.

    Returns `default` if no such element exists, or
    `multiple` if there are multiple matching elements.

    # Inputs

    `pred`

    : Predicate

    `default`

    : Default value to return if element was not found.

    `multiple`

    : Default value to return if more than one element was found

    `list`

    : Input list

    # Type

    ```
    findSingle :: (a -> bool) -> a -> a -> [a] -> a
    ```

    # Examples
    :::{.example}
    ## `lib.lists.findSingle` usage example

    ```nix
    findSingle (x: x == 3) "none" "multiple" [ 1 3 3 ]
    => "multiple"
    findSingle (x: x == 3) "none" "multiple" [ 1 3 ]
    => 3
    findSingle (x: x == 3) "none" "multiple" [ 1 9 ]
    => "none"
    ```

    :::
  */
  findSingle =
    pred: default: multiple: list:
    let
      found = filter pred list;
      len = length found;
    in
    if len == 0 then
      default
    else if len != 1 then
      multiple
    else
      head found;

  /**
    Find the first index in the list matching the specified
    predicate or return `default` if no such element exists.

    # Inputs

    `pred`

    : Predicate

    `default`

    : Default value to return

    `list`

    : Input list

    # Type

    ```
    findFirstIndex :: (a -> Bool) -> b -> [a] -> (Int | b)
    ```

    # Examples
    :::{.example}
    ## `lib.lists.findFirstIndex` usage example

    ```nix
    findFirstIndex (x: x > 3) null [ 0 6 4 ]
    => 1
    findFirstIndex (x: x > 9) null [ 0 6 4 ]
    => null
    ```

    :::
  */
  findFirstIndex =
    pred: default: list:
    let
      # A naive recursive implementation would be much simpler, but
      # would also overflow the evaluator stack. We use `foldl'` as a workaround
      # because it reuses the same stack space, evaluating the function for one
      # element after another. We can't return early, so this means that we
      # sacrifice early cutoff, but that appears to be an acceptable cost. A
      # clever scheme with "exponential search" is possible, but appears over-
      # engineered for now. See https://github.com/NixOS/nixpkgs/pull/235267

      # Invariant:
      # - if index < 0 then el == elemAt list (- index - 1) and all elements before el didn't satisfy pred
      # - if index >= 0 then pred (elemAt list index) and all elements before (elemAt list index) didn't satisfy pred
      #
      # We start with index -1 and the 0'th element of the list, which satisfies the invariant
      resultIndex = foldl' (
        index: el:
        if index < 0 then
          # No match yet before the current index, we need to check the element
          if pred el then
            # We have a match! Turn it into the actual index to prevent future iterations from modifying it
            -index - 1
          else
            # Still no match, update the index to the next element (we're counting down, so minus one)
            index - 1
        else
          # There's already a match, propagate the index without evaluating anything
          index
      ) (-1) list;
    in
    if resultIndex < 0 then default else resultIndex;

  /**
    Find the first element in the list matching the specified
    predicate or return `default` if no such element exists.

    # Inputs

    `pred`

    : Predicate

    `default`

    : Default value to return

    `list`

    : Input list

    # Type

    ```
    findFirst :: (a -> bool) -> a -> [a] -> a
    ```

    # Examples
    :::{.example}
    ## `lib.lists.findFirst` usage example

    ```nix
    findFirst (x: x > 3) 7 [ 1 6 4 ]
    => 6
    findFirst (x: x > 9) 7 [ 1 6 4 ]
    => 7
    ```

    :::
  */
  findFirst =
    pred: default: list:
    let
      index = findFirstIndex pred null list;
    in
    if index == null then default else elemAt list index;

  /**
    Return true if function `pred` returns true for at least one
    element of `list`.

    # Inputs

    `pred`

    : Predicate

    `list`

    : Input list

    # Type

    ```
    any :: (a -> bool) -> [a] -> bool
    ```

    # Examples
    :::{.example}
    ## `lib.lists.any` usage example

    ```nix
    any isString [ 1 "a" { } ]
    => true
    any isString [ 1 { } ]
    => false
    ```

    :::
  */
  any = builtins.any;

  /**
    Return true if function `pred` returns true for all elements of
    `list`.

    # Inputs

    `pred`

    : Predicate

    `list`

    : Input list

    # Type

    ```
    all :: (a -> bool) -> [a] -> bool
    ```

    # Examples
    :::{.example}
    ## `lib.lists.all` usage example

    ```nix
    all (x: x < 3) [ 1 2 ]
    => true
    all (x: x < 3) [ 1 2 3 ]
    => false
    ```

    :::
  */
  all = builtins.all;

  /**
    Count how many elements of `list` match the supplied predicate
    function.

    # Inputs

    `pred`

    : Predicate

    # Type

    ```
    count :: (a -> bool) -> [a] -> int
    ```

    # Examples
    :::{.example}
    ## `lib.lists.count` usage example

    ```nix
    count (x: x == 3) [ 3 2 3 4 6 ]
    => 2
    ```

    :::
  */
  count = pred: foldl' (c: x: if pred x then c + 1 else c) 0;

  /**
    Return a singleton list or an empty list, depending on a boolean
    value.  Useful when building lists with optional elements
    (e.g. `++ optional (system == "i686-linux") firefox`).

    # Inputs

    `cond`

    : 1\. Function argument

    `elem`

    : 2\. Function argument

    # Type

    ```
    optional :: bool -> a -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.optional` usage example

    ```nix
    optional true "foo"
    => [ "foo" ]
    optional false "foo"
    => [ ]
    ```

    :::
  */
  optional = cond: elem: if cond then [ elem ] else [ ];

  /**
    Return a list or an empty list, depending on a boolean value.

    # Inputs

    `cond`

    : Condition

    `elems`

    : List to return if condition is true

    # Type

    ```
    optionals :: bool -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.optionals` usage example

    ```nix
    optionals true [ 2 3 ]
    => [ 2 3 ]
    optionals false [ 2 3 ]
    => [ ]
    ```

    :::
  */
  optionals = cond: elems: if cond then elems else [ ];

  /**
    If argument is a list, return it; else, wrap it in a singleton
    list. If you're using this, you should almost certainly
    reconsider if there isn't a more "well-typed" approach.

    # Inputs

    `x`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.toList` usage example

    ```nix
    toList [ 1 2 ]
    => [ 1 2 ]
    toList "hi"
    => [ "hi "]
    ```

    :::
  */
  toList = x: if isList x then x else [ x ];

  /**
    Return a list of integers from `first` up to and including `last`.

    # Inputs

    `first`

    : First integer in the range

    `last`

    : Last integer in the range

    # Type

    ```
    range :: int -> int -> [int]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.range` usage example

    ```nix
    range 2 4
    => [ 2 3 4 ]
    range 3 2
    => [ ]
    ```

    :::
  */
  range = first: last: if first > last then [ ] else genList (n: first + n) (last - first + 1);

  /**
    Return a list with `n` copies of an element.

    # Inputs

    `n`

    : 1\. Function argument

    `elem`

    : 2\. Function argument

    # Type

    ```
    replicate :: int -> a -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.replicate` usage example

    ```nix
    replicate 3 "a"
    => [ "a" "a" "a" ]
    replicate 2 true
    => [ true true ]
    ```

    :::
  */
  replicate = n: elem: genList (_: elem) n;

  /**
    Splits the elements of a list in two lists, `right` and
    `wrong`, depending on the evaluation of a predicate.

    # Inputs

    `pred`

    : Predicate

    `list`

    : Input list

    # Type

    ```
    (a -> bool) -> [a] -> { right :: [a]; wrong :: [a]; }
    ```

    # Examples
    :::{.example}
    ## `lib.lists.partition` usage example

    ```nix
    partition (x: x > 2) [ 5 1 2 3 4 ]
    => { right = [ 5 3 4 ]; wrong = [ 1 2 ]; }
    ```

    :::
  */
  partition = builtins.partition;

  /**
    Splits the elements of a list into many lists, using the return value of a predicate.
    Predicate should return a string which becomes keys of attrset `groupBy` returns.
    `groupBy'` allows to customise the combining function and initial value

    # Inputs

    `op`

    : 1\. Function argument

    `nul`

    : 2\. Function argument

    `pred`

    : 3\. Function argument

    `lst`

    : 4\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.groupBy'` usage example

    ```nix
    groupBy (x: boolToString (x > 2)) [ 5 1 2 3 4 ]
    => { true = [ 5 3 4 ]; false = [ 1 2 ]; }
    groupBy (x: x.name) [ {name = "icewm"; script = "icewm &";}
                          {name = "xfce";  script = "xfce4-session &";}
                          {name = "icewm"; script = "icewmbg &";}
                          {name = "mate";  script = "gnome-session &";}
                        ]
    => { icewm = [ { name = "icewm"; script = "icewm &"; }
                   { name = "icewm"; script = "icewmbg &"; } ];
         mate  = [ { name = "mate";  script = "gnome-session &"; } ];
         xfce  = [ { name = "xfce";  script = "xfce4-session &"; } ];
       }

    groupBy' builtins.add 0 (x: boolToString (x > 2)) [ 5 1 2 3 4 ]
    => { true = 12; false = 3; }
    ```

    :::
  */
  groupBy' =
    op: nul: pred: lst:
    mapAttrs (name: foldl op nul) (groupBy pred lst);

  groupBy =
    builtins.groupBy or (
      pred:
      foldl' (
        r: e:
        let
          key = pred e;
        in
        r // { ${key} = (r.${key} or [ ]) ++ [ e ]; }
      ) { }
    );

  /**
    Merges two lists of the same size together. If the sizes aren't the same
    the merging stops at the shortest. How both lists are merged is defined
    by the first argument.

    # Inputs

    `f`

    : Function to zip elements of both lists

    `fst`

    : First list

    `snd`

    : Second list

    # Type

    ```
    zipListsWith :: (a -> b -> c) -> [a] -> [b] -> [c]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.zipListsWith` usage example

    ```nix
    zipListsWith (a: b: a + b) ["h" "l"] ["e" "o"]
    => ["he" "lo"]
    ```

    :::
  */
  zipListsWith =
    f: fst: snd:
    genList (n: f (elemAt fst n) (elemAt snd n)) (min (length fst) (length snd));

  /**
    Merges two lists of the same size together. If the sizes aren't the same
    the merging stops at the shortest.

    # Inputs

    `fst`

    : First list

    `snd`

    : Second list

    # Type

    ```
    zipLists :: [a] -> [b] -> [{ fst :: a; snd :: b; }]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.zipLists` usage example

    ```nix
    zipLists [ 1 2 ] [ "a" "b" ]
    => [ { fst = 1; snd = "a"; } { fst = 2; snd = "b"; } ]
    ```

    :::
  */
  zipLists = zipListsWith (fst: snd: { inherit fst snd; });

  /**
    Reverse the order of the elements of a list.

    # Inputs

    `xs`

    : 1\. Function argument

    # Type

    ```
    reverseList :: [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.reverseList` usage example

    ```nix
    reverseList [ "b" "o" "j" ]
    => [ "j" "o" "b" ]
    ```

    :::
  */
  reverseList =
    xs:
    let
      l = length xs;
    in
    genList (n: elemAt xs (l - n - 1)) l;

  /**
    Depth-First Search (DFS) for lists `list != []`.

    `before a b == true` means that `b` depends on `a` (there's an
    edge from `b` to `a`).

    # Inputs

    `stopOnCycles`

    : 1\. Function argument

    `before`

    : 2\. Function argument

    `list`

    : 3\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.listDfs` usage example

    ```nix
    listDfs true hasPrefix [ "/home/user" "other" "/" "/home" ]
      == { minimal = "/";                  # minimal element
           visited = [ "/home/user" ];     # seen elements (in reverse order)
           rest    = [ "/home" "other" ];  # everything else
         }

    listDfs true hasPrefix [ "/home/user" "other" "/" "/home" "/" ]
      == { cycle   = "/";                  # cycle encountered at this element
           loops   = [ "/" ];              # and continues to these elements
           visited = [ "/" "/home/user" ]; # elements leading to the cycle (in reverse order)
           rest    = [ "/home" "other" ];  # everything else
    ```

    :::
  */
  listDfs =
    stopOnCycles: before: list:
    let
      dfs' =
        us: visited: rest:
        let
          c = filter (x: before x us) visited;
          b = partition (x: before x us) rest;
        in
        if stopOnCycles && (length c > 0) then
          {
            cycle = us;
            loops = c;
            inherit visited rest;
          }
        else if length b.right == 0 then
          # nothing is before us
          {
            minimal = us;
            inherit visited rest;
          }
        else
          # grab the first one before us and continue
          dfs' (head b.right) ([ us ] ++ visited) (tail b.right ++ b.wrong);
    in
    dfs' (head list) [ ] (tail list);

  /**
    Sort a list based on a partial ordering using DFS. This
    implementation is O(N^2), if your ordering is linear, use `sort`
    instead.

    `before a b == true` means that `b` should be after `a`
    in the result.

    # Inputs

    `before`

    : 1\. Function argument

    `list`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.toposort` usage example

    ```nix
    toposort hasPrefix [ "/home/user" "other" "/" "/home" ]
      == { result = [ "/" "/home" "/home/user" "other" ]; }

    toposort hasPrefix [ "/home/user" "other" "/" "/home" "/" ]
      == { cycle = [ "/home/user" "/" "/" ]; # path leading to a cycle
           loops = [ "/" ]; }                # loops back to these elements

    toposort hasPrefix [ "other" "/home/user" "/home" "/" ]
      == { result = [ "other" "/" "/home" "/home/user" ]; }

    toposort (a: b: a < b) [ 3 2 1 ] == { result = [ 1 2 3 ]; }
    ```

    :::
  */
  toposort =
    before: list:
    let
      dfsthis = listDfs true before list;
      toporest = toposort before (dfsthis.visited ++ dfsthis.rest);
    in
    if length list < 2 then
      # finish
      { result = list; }
    else if dfsthis ? cycle then
      # there's a cycle, starting from the current vertex, return it
      {
        cycle = reverseList ([ dfsthis.cycle ] ++ dfsthis.visited);
        inherit (dfsthis) loops;
      }
    else if toporest ? cycle then
      # there's a cycle somewhere else in the graph, return it
      toporest
    # Slow, but short. Can be made a bit faster with an explicit stack.
    else
      # there are no cycles
      { result = [ dfsthis.minimal ] ++ toporest.result; };

  /**
    Sort a list based on a comparator function which compares two
    elements and returns true if the first argument is strictly below
    the second argument.  The returned list is sorted in an increasing
    order.  The implementation does a quick-sort.

    See also [`sortOn`](#function-library-lib.lists.sortOn), which applies the
    default comparison on a function-derived property, and may be more efficient.

    # Inputs

    `comparator`

    : 1\. Function argument

    `list`

    : 2\. Function argument

    # Type

    ```
    sort :: (a -> a -> Bool) -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.sort` usage example

    ```nix
    sort (p: q: p < q) [ 5 3 7 ]
    => [ 3 5 7 ]
    ```

    :::
  */
  sort = builtins.sort;

  /**
    Sort a list based on the default comparison of a derived property `b`.

    The items are returned in `b`-increasing order.

    **Performance**:

    The passed function `f` is only evaluated once per item,
    unlike an unprepared [`sort`](#function-library-lib.lists.sort) using
    `f p < f q`.

    **Laws**:
    ```nix
    sortOn f == sort (p: q: f p < f q)
    ```

    # Inputs

    `f`

    : 1\. Function argument

    `list`

    : 2\. Function argument

    # Type

    ```
    sortOn :: (a -> b) -> [a] -> [a], for comparable b
    ```

    # Examples
    :::{.example}
    ## `lib.lists.sortOn` usage example

    ```nix
    sortOn stringLength [ "aa" "b" "cccc" ]
    => [ "b" "aa" "cccc" ]
    ```

    :::
  */
  sortOn =
    f: list:
    let
      # Heterogenous list as pair may be ugly, but requires minimal allocations.
      pairs = map (x: [
        (f x)
        x
      ]) list;
    in
    map (x: builtins.elemAt x 1) (
      sort
        # Compare the first element of the pairs
        # Do not factor out the `<`, to avoid calls in hot code; duplicate instead.
        (a: b: head a < head b)
        pairs
    );

  /**
    Compare two lists element-by-element with a comparison function `cmp`.

    List elements are compared pairwise in order by the provided comparison function `cmp`,
    the first non-equal pair of elements determines the result.

    :::{.note}
    The `<` operator can also be used to compare lists using a boolean condition. (e.g. `[1 2] < [1 3]` is `true`).
    See also [language operators](https://nix.dev/manual/nix/stable/language/operators#comparison) for more information.
    :::

    # Inputs

    `cmp`

    : The comparison function `a: b: ...` must return:
      - `0` if `a` and `b` are equal
      - `1` if `a` is greater than `b`
      - `-1` if `a` is less than `b`

      See [lib.compare](#function-library-lib.trivial.compare) for a an example implementation.

    `a`

    : The first list

    `b`

    : The second list

    # Examples
    :::{.example}
    ## `lib.lists.compareLists` usage examples

    ```nix
    compareLists lib.compare [] []
    => 0
    compareLists lib.compare [] [ "a" ]
    => -1
    compareLists lib.compare [ "a" ] []
    => 1
    compareLists lib.compare [ "a" "b" ] [ "a" "c" ]
    => -1
    ```

    :::
  */
  compareLists =
    cmp: a: b:
    if a == [ ] then
      if b == [ ] then 0 else -1
    else if b == [ ] then
      1
    else
      let
        rel = cmp (head a) (head b);
      in
      if rel == 0 then compareLists cmp (tail a) (tail b) else rel;

  /**
    Sort list using "Natural sorting".
    Numeric portions of strings are sorted in numeric order.

    # Inputs

    `lst`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `lib.lists.naturalSort` usage example

    ```nix
    naturalSort ["disk11" "disk8" "disk100" "disk9"]
    => ["disk8" "disk9" "disk11" "disk100"]
    naturalSort ["10.46.133.149" "10.5.16.62" "10.54.16.25"]
    => ["10.5.16.62" "10.46.133.149" "10.54.16.25"]
    naturalSort ["v0.2" "v0.15" "v0.0.9"]
    => [ "v0.0.9" "v0.2" "v0.15" ]
    ```

    :::
  */
  naturalSort =
    lst:
    let
      vectorise = s: map (x: if isList x then toInt (head x) else x) (builtins.split "(0|[1-9][0-9]*)" s);
      prepared = map (x: [
        (vectorise x)
        x
      ]) lst; # remember vectorised version for O(n) regex splits
      less = a: b: (compareLists compare (head a) (head b)) < 0;
    in
    map (x: elemAt x 1) (sort less prepared);

  /**
    Return the first (at most) N elements of a list.

    # Inputs

    `count`

    : Number of elements to take

    `list`

    : Input list

    # Type

    ```
    take :: int -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.take` usage example

    ```nix
    take 2 [ "a" "b" "c" "d" ]
    => [ "a" "b" ]
    take 2 [ ]
    => [ ]
    ```

    :::
  */
  take = count: sublist 0 count;

  /**
    Return the last (at most) N elements of a list.

    # Inputs

    `count`

    : Maximum number of elements to pick

    `list`

    : Input list

    # Type

    ```
    takeEnd :: int -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.takeEnd` usage example

    ```nix
    takeEnd 2 [ "a" "b" "c" "d" ]
    => [ "c" "d" ]
    takeEnd 2 [ ]
    => [ ]
    ```

    :::
  */
  takeEnd = n: xs: drop (max 0 (length xs - n)) xs;

  /**
    Remove the first (at most) N elements of a list.

    # Inputs

    `count`

    : Number of elements to drop

    `list`

    : Input list

    # Type

    ```
    drop :: int -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.drop` usage example

    ```nix
    drop 2 [ "a" "b" "c" "d" ]
    => [ "c" "d" ]
    drop 2 [ ]
    => [ ]
    ```

    :::
  */
  drop = count: list: sublist count (length list) list;

  /**
    Remove the last (at most) N elements of a list.

    # Inputs

    `count`

    : Number of elements to drop

    `list`

    : Input list

    # Type

    ```
    dropEnd :: Int -> [a] -> [a]
    ```

    # Examples

    :::{.example}
    ## `lib.lists.dropEnd` usage example

    ```nix
      dropEnd 2 [ "a" "b" "c" "d" ]
      => [ "a" "b" ]
      dropEnd 2 [ ]
      => [ ]
    ```
    :::
  */
  dropEnd = n: xs: take (max 0 (length xs - n)) xs;

  /**
    Whether the first list is a prefix of the second list.

    # Inputs

    `list1`

    : 1\. Function argument

    `list2`

    : 2\. Function argument

    # Type

    ```
    hasPrefix :: [a] -> [a] -> bool
    ```

    # Examples
    :::{.example}
    ## `lib.lists.hasPrefix` usage example

    ```nix
    hasPrefix [ 1 2 ] [ 1 2 3 4 ]
    => true
    hasPrefix [ 0 1 ] [ 1 2 3 4 ]
    => false
    ```

    :::
  */
  hasPrefix = list1: list2: take (length list1) list2 == list1;

  /**
    Remove the first list as a prefix from the second list.
    Error if the first list isn't a prefix of the second list.

    # Inputs

    `list1`

    : 1\. Function argument

    `list2`

    : 2\. Function argument

    # Type

    ```
    removePrefix :: [a] -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.removePrefix` usage example

    ```nix
    removePrefix [ 1 2 ] [ 1 2 3 4 ]
    => [ 3 4 ]
    removePrefix [ 0 1 ] [ 1 2 3 4 ]
    => <error>
    ```

    :::
  */
  removePrefix =
    list1: list2:
    if hasPrefix list1 list2 then
      drop (length list1) list2
    else
      throw "lib.lists.removePrefix: First argument is not a list prefix of the second argument";

  /**
    Return a list consisting of at most `count` elements of `list`,
    starting at index `start`.

    # Inputs

    `start`

    : Index at which to start the sublist

    `count`

    : Number of elements to take

    `list`

    : Input list

    # Type

    ```
    sublist :: int -> int -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.sublist` usage example

    ```nix
    sublist 1 3 [ "a" "b" "c" "d" "e" ]
    => [ "b" "c" "d" ]
    sublist 1 3 [ ]
    => [ ]
    ```

    :::
  */
  sublist =
    start: count: list:
    let
      len = length list;
    in
    genList (n: elemAt list (n + start)) (
      if start >= len then
        0
      else if start + count > len then
        len - start
      else
        count
    );

  /**
    The common prefix of two lists.

    # Inputs

    `list1`

    : 1\. Function argument

    `list2`

    : 2\. Function argument

    # Type

    ```
    commonPrefix :: [a] -> [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.commonPrefix` usage example

    ```nix
    commonPrefix [ 1 2 3 4 5 6 ] [ 1 2 4 8 ]
    => [ 1 2 ]
    commonPrefix [ 1 2 3 ] [ 1 2 3 4 5 ]
    => [ 1 2 3 ]
    commonPrefix [ 1 2 3 ] [ 4 5 6 ]
    => [ ]
    ```

    :::
  */
  commonPrefix =
    list1: list2:
    let
      # Zip the lists together into a list of booleans whether each element matches
      matchings = zipListsWith (fst: snd: fst != snd) list1 list2;
      # Find the first index where the elements don't match,
      # which will then also be the length of the common prefix.
      # If all elements match, we fall back to the length of the zipped list,
      # which is the same as the length of the smaller list.
      commonPrefixLength = findFirstIndex id (length matchings) matchings;
    in
    take commonPrefixLength list1;

  /**
    Return the last element of a list.

    This function throws an error if the list is empty.

    # Inputs

    `list`

    : 1\. Function argument

    # Type

    ```
    last :: [a] -> a
    ```

    # Examples
    :::{.example}
    ## `lib.lists.last` usage example

    ```nix
    last [ 1 2 3 ]
    => 3
    ```

    :::
  */
  last =
    list:
    assert lib.assertMsg (list != [ ]) "lists.last: list must not be empty!";
    elemAt list (length list - 1);

  /**
    Return all elements but the last.

    This function throws an error if the list is empty.

    # Inputs

    `list`

    : 1\. Function argument

    # Type

    ```
    init :: [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.init` usage example

    ```nix
    init [ 1 2 3 ]
    => [ 1 2 ]
    ```

    :::
  */
  init =
    list:
    assert lib.assertMsg (list != [ ]) "lists.init: list must not be empty!";
    take (length list - 1) list;

  /**
    Return the image of the cross product of some lists by a function.

    # Examples
    :::{.example}
    ## `lib.lists.crossLists` usage example

    ```nix
    crossLists (x: y: "${toString x}${toString y}") [[1 2] [3 4]]
    => [ "13" "14" "23" "24" ]
    ```

    The following function call is equivalent to the one deprecated above:

    ```nix
    mapCartesianProduct (x: "${toString x.a}${toString x.b}") { a = [1 2]; b = [3 4]; }
    => [ "13" "14" "23" "24" ]
    ```
    :::
  */
  crossLists = warn ''
    lib.crossLists is deprecated, use lib.mapCartesianProduct instead.

    For example, the following function call:

    nix-repl> lib.crossLists (x: y: x+y) [[1 2] [3 4]]
    [ 4 5 5 6 ]

    Can now be replaced by the following one:

    nix-repl> lib.mapCartesianProduct ({x,y}: x+y) { x = [1 2]; y = [3 4]; }
    [ 4 5 5 6 ]
  '' (f: foldl (fs: args: concatMap (f: map f args) fs) [ f ]);

  /**
    Remove duplicate elements from the `list`. O(n^2) complexity.

    # Inputs

    `list`

    : Input list

    # Type

    ```
    unique :: [a] -> [a]
    ```

    # Examples
    :::{.example}
    ## `lib.lists.unique` usage example

    ```nix
    unique [ 3 2 3 4 ]
    => [ 3 2 4 ]
    ```

    :::
  */
  unique = foldl' (acc: e: if elem e acc then acc else acc ++ [ e ]) [ ];

  /**
    Check if list contains only unique elements. O(n^2) complexity.

    # Inputs

    `list`

    : 1\. Function argument

    # Type

    ```
    allUnique :: [a] -> bool
    ```

    # Examples
    :::{.example}
    ## `lib.lists.allUnique` usage example

    ```nix
    allUnique [ 3 2 3 4 ]
    => false
    allUnique [ 3 2 4 1 ]
    => true
    ```

    :::
  */
  allUnique = list: (length (unique list) == length list);

  /**
    Intersects list 'list1' and another list (`list2`).

    O(nm) complexity.

    # Inputs

    `list1`

    : First list

    `list2`

    : Second list

    # Examples
    :::{.example}
    ## `lib.lists.intersectLists` usage example

    ```nix
    intersectLists [ 1 2 3 ] [ 6 3 2 ]
    => [ 3 2 ]
    ```

    :::
  */
  intersectLists = e: filter (x: elem x e);

  /**
    Subtracts list 'e' from another list (`list2`).

    O(nm) complexity.

    # Inputs

    `e`

    : First list

    `list2`

    : Second list

    # Examples
    :::{.example}
    ## `lib.lists.subtractLists` usage example

    ```nix
    subtractLists [ 3 2 ] [ 1 2 3 4 5 3 ]
    => [ 1 4 5 ]
    ```

    :::
  */
  subtractLists = e: filter (x: !(elem x e));

  /**
    Test if two lists have no common element.
    It should be slightly more efficient than (intersectLists a b == [])

    # Inputs

    `a`

    : 1\. Function argument

    `b`

    : 2\. Function argument
  */
  mutuallyExclusive = a: b: length a == 0 || !(any (x: elem x a) b);

}
</file>

<file path="lib/meta.nix">
/**
  Some functions for manipulating meta attributes, as well as the
  name attribute.
*/

{ lib }:

let
  inherit (lib)
    matchAttrs
    any
    all
    isDerivation
    getBin
    assertMsg
    ;
  inherit (lib.attrsets) mapAttrs' filterAttrs;
  inherit (builtins) isString match typeOf;

in
rec {

  /**
    Add to or override the meta attributes of the given
    derivation.

    # Inputs

    `newAttrs`

    : 1\. Function argument

    `drv`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `lib.meta.addMetaAttrs` usage example

    ```nix
    addMetaAttrs {description = "Bla blah";} somePkg
    ```

    :::
  */
  addMetaAttrs = newAttrs: drv: drv // { meta = (drv.meta or { }) // newAttrs; };

  /**
    Disable Hydra builds of given derivation.

    # Inputs

    `drv`

    : 1\. Function argument
  */
  dontDistribute = drv: addMetaAttrs { hydraPlatforms = [ ]; } drv;

  /**
    Change the [symbolic name of a derivation](https://nixos.org/manual/nix/stable/language/derivations.html#attr-name).

    :::{.warning}
    Dependent derivations will be rebuilt when the symbolic name is changed.
    :::

    # Inputs

    `name`

    : 1\. Function argument

    `drv`

    : 2\. Function argument
  */
  setName = name: drv: drv // { inherit name; };

  /**
    Like `setName`, but takes the previous name as an argument.

    # Inputs

    `updater`

    : 1\. Function argument

    `drv`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `lib.meta.updateName` usage example

    ```nix
    updateName (oldName: oldName + "-experimental") somePkg
    ```

    :::
  */
  updateName = updater: drv: drv // { name = updater (drv.name); };

  /**
    Append a suffix to the name of a package (before the version
    part).

    # Inputs

    `suffix`

    : 1\. Function argument
  */
  appendToName =
    suffix:
    updateName (
      name:
      let
        x = builtins.parseDrvName name;
      in
      "${x.name}-${suffix}-${x.version}"
    );

  /**
    Apply a function to each derivation and only to derivations in an attrset.

    # Inputs

    `f`

    : 1\. Function argument

    `set`

    : 2\. Function argument
  */
  mapDerivationAttrset =
    f: set: lib.mapAttrs (name: pkg: if lib.isDerivation pkg then (f pkg) else pkg) set;

  /**
    The default priority of packages in Nix. See `defaultPriority` in [`src/nix/profile.cc`](https://github.com/NixOS/nix/blob/master/src/nix/profile.cc#L47).
  */
  defaultPriority = 5;

  /**
    Set the nix-env priority of the package. Note that higher values are lower priority, and vice versa.

    # Inputs

    `priority`
    : 1\. The priority to set.

    `drv`
    : 2\. Function argument
  */
  setPrio = priority: addMetaAttrs { inherit priority; };

  /**
    Decrease the nix-env priority of the package, i.e., other
    versions/variants of the package will be preferred.

    # Inputs

    `drv`

    : 1\. Function argument
  */
  lowPrio = setPrio 10;

  /**
    Apply lowPrio to an attrset with derivations.

    # Inputs

    `set`

    : 1\. Function argument
  */
  lowPrioSet = set: mapDerivationAttrset lowPrio set;

  /**
    Increase the nix-env priority of the package, i.e., this
    version/variant of the package will be preferred.

    # Inputs

    `drv`

    : 1\. Function argument
  */
  hiPrio = setPrio (-10);

  /**
    Apply hiPrio to an attrset with derivations.

    # Inputs

    `set`

    : 1\. Function argument
  */
  hiPrioSet = set: mapDerivationAttrset hiPrio set;

  /**
    Check to see if a platform is matched by the given `meta.platforms`
    element.

    A `meta.platform` pattern is either

    1. (legacy) a system string.

    2. (modern) a pattern for the entire platform structure (see `lib.systems.inspect.platformPatterns`).

    3. (modern) a pattern for the platform `parsed` field (see `lib.systems.inspect.patterns`).

    We can inject these into a pattern for the whole of a structured platform,
    and then match that.

    # Inputs

    `platform`

    : 1\. Function argument

    `elem`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `lib.meta.platformMatch` usage example

    ```nix
    lib.meta.platformMatch { system = "aarch64-darwin"; } "aarch64-darwin"
    => true
    ```

    :::
  */
  platformMatch =
    platform: elem:
    (
      # Check with simple string comparison if elem was a string.
      #
      # The majority of comparisons done with this function will be against meta.platforms
      # which contains a simple platform string.
      #
      # Avoiding an attrset allocation results in significant  performance gains (~2-30) across the board in OfBorg
      # because this is a hot path for nixpkgs.
      if isString elem then
        platform ? system && elem == platform.system
      else
        matchAttrs (
          # Normalize platform attrset.
          if elem ? parsed then elem else { parsed = elem; }
        ) platform
    );

  /**
    Check if a package is available on a given platform.

    A package is available on a platform if both

    1. One of `meta.platforms` pattern matches the given
        platform, or `meta.platforms` is not present.

    2. None of `meta.badPlatforms` pattern matches the given platform.

    # Inputs

    `platform`

    : 1\. Function argument

    `pkg`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `lib.meta.availableOn` usage example

    ```nix
    lib.meta.availableOn { system = "aarch64-darwin"; } pkg.zsh
    => true
    ```

    :::
  */
  availableOn =
    platform: pkg:
    ((!pkg ? meta.platforms) || any (platformMatch platform) pkg.meta.platforms)
    && all (elem: !platformMatch platform elem) (pkg.meta.badPlatforms or [ ]);

  /**
    Mapping of SPDX ID to the attributes in lib.licenses.

    For SPDX IDs, see https://spdx.org/licenses.
    Note that some SPDX licenses might be missing.

    # Examples
    :::{.example}
    ## `lib.meta.licensesSpdx` usage example

    ```nix
    lib.licensesSpdx.MIT == lib.licenses.mit
    => true
    lib.licensesSpdx."MY LICENSE"
    => error: attribute 'MY LICENSE' missing
    ```

    :::
  */
  licensesSpdx = mapAttrs' (_key: license: {
    name = license.spdxId;
    value = license;
  }) (filterAttrs (_key: license: license ? spdxId) lib.licenses);

  /**
    Get the corresponding attribute in lib.licenses from the SPDX ID
    or warn and fallback to `{ shortName = <license string>; }`.

    For SPDX IDs, see https://spdx.org/licenses.
    Note that some SPDX licenses might be missing.

    # Type

    ```
    getLicenseFromSpdxId :: str -> AttrSet
    ```

    # Examples
    :::{.example}
    ## `lib.meta.getLicenseFromSpdxId` usage example

    ```nix
    lib.getLicenseFromSpdxId "MIT" == lib.licenses.mit
    => true
    lib.getLicenseFromSpdxId "mIt" == lib.licenses.mit
    => true
    lib.getLicenseFromSpdxId "MY LICENSE"
    => trace: warning: getLicenseFromSpdxId: No license matches the given SPDX ID: MY LICENSE
    => { shortName = "MY LICENSE"; }
    ```

    :::
  */
  getLicenseFromSpdxId =
    licstr:
    getLicenseFromSpdxIdOr licstr (
      lib.warn "getLicenseFromSpdxId: No license matches the given SPDX ID: ${licstr}" {
        shortName = licstr;
      }
    );

  /**
    Get the corresponding attribute in lib.licenses from the SPDX ID
    or fallback to the given default value.

    For SPDX IDs, see https://spdx.org/licenses.
    Note that some SPDX licenses might be missing.

    # Inputs

    `licstr`
    : 1\. SPDX ID string to find a matching license

    `default`
    : 2\. Fallback value when a match is not found

    # Type

    ```
    getLicenseFromSpdxIdOr :: str -> Any -> Any
    ```

    # Examples
    :::{.example}
    ## `lib.meta.getLicenseFromSpdxIdOr` usage example

    ```nix
    lib.getLicenseFromSpdxIdOr "MIT" null == lib.licenses.mit
    => true
    lib.getLicenseFromSpdxId "mIt" null == lib.licenses.mit
    => true
    lib.getLicenseFromSpdxIdOr "MY LICENSE" lib.licenses.free == lib.licenses.free
    => true
    lib.getLicenseFromSpdxIdOr "MY LICENSE" null
    => null
    lib.getLicenseFromSpdxIdOr "MY LICENSE" (builtins.throw "No SPDX ID matches MY LICENSE")
    => error: No SPDX ID matches MY LICENSE
    ```
    :::
  */
  getLicenseFromSpdxIdOr =
    let
      lowercaseLicenses = lib.mapAttrs' (name: value: {
        name = lib.toLower name;
        inherit value;
      }) licensesSpdx;
    in
    licstr: default: lowercaseLicenses.${lib.toLower licstr} or default;

  /**
    Get the path to the main program of a package based on meta.mainProgram

    # Inputs

    `x`

    : 1\. Function argument

    # Type

    ```
    getExe :: package -> string
    ```

    # Examples
    :::{.example}
    ## `lib.meta.getExe` usage example

    ```nix
    getExe pkgs.hello
    => "/nix/store/g124820p9hlv4lj8qplzxw1c44dxaw1k-hello-2.12/bin/hello"
    getExe pkgs.mustache-go
    => "/nix/store/am9ml4f4ywvivxnkiaqwr0hyxka1xjsf-mustache-go-1.3.0/bin/mustache"
    ```

    :::
  */
  getExe =
    x:
    getExe' x (
      x.meta.mainProgram or (
        # This could be turned into an error when 23.05 is at end of life
        lib.warn
          "getExe: Package ${
            lib.strings.escapeNixIdentifier x.meta.name or x.pname or x.name
          } does not have the meta.mainProgram attribute. We'll assume that the main program has the same name for now, but this behavior is deprecated, because it leads to surprising errors when the assumption does not hold. If the package has a main program, please set `meta.mainProgram` in its definition to make this warning go away. Otherwise, if the package does not have a main program, or if you don't control its definition, use getExe' to specify the name to the program, such as lib.getExe' foo \"bar\"."
          lib.getName
          x
      )
    );

  /**
    Get the path of a program of a derivation.

    # Inputs

    `x`

    : 1\. Function argument

    `y`

    : 2\. Function argument

    # Type

    ```
    getExe' :: derivation -> string -> string
    ```

    # Examples
    :::{.example}
    ## `lib.meta.getExe'` usage example

    ```nix
    getExe' pkgs.hello "hello"
    => "/nix/store/g124820p9hlv4lj8qplzxw1c44dxaw1k-hello-2.12/bin/hello"
    getExe' pkgs.imagemagick "convert"
    => "/nix/store/5rs48jamq7k6sal98ymj9l4k2bnwq515-imagemagick-7.1.1-15/bin/convert"
    ```

    :::
  */
  getExe' =
    x: y:
    assert assertMsg (isDerivation x)
      "lib.meta.getExe': The first argument is of type ${typeOf x}, but it should be a derivation instead.";
    assert assertMsg (isString y)
      "lib.meta.getExe': The second argument is of type ${typeOf y}, but it should be a string instead.";
    assert assertMsg (match ".*/.*" y == null)
      "lib.meta.getExe': The second argument \"${y}\" is a nested path with a \"/\" character, but it should just be the name of the executable instead.";
    "${getBin x}/bin/${y}";
}
</file>

<file path="lib/minver.nix">
# Expose the minimum required version for evaluating Nixpkgs
"2.3.17"
</file>

<file path="lib/modules.nix">
{ lib }:

let
  inherit (lib)
    addErrorContext
    all
    any
    attrByPath
    attrNames
    catAttrs
    concatLists
    concatMap
    concatStringsSep
    elem
    filter
    foldl'
    functionArgs
    getAttrFromPath
    genericClosure
    head
    id
    imap1
    isAttrs
    isBool
    isFunction
    oldestSupportedReleaseIsAtLeast
    isList
    isString
    length
    mapAttrs
    mapAttrsToList
    mapAttrsRecursiveCond
    min
    optional
    optionalAttrs
    optionalString
    recursiveUpdate
    reverseList
    sort
    seq
    setAttrByPath
    substring
    throwIfNot
    trace
    typeOf
    types
    unsafeGetAttrPos
    warn
    warnIf
    zipAttrs
    zipAttrsWith
    ;
  inherit (lib.options)
    isOption
    mkOption
    showDefs
    showFiles
    showOption
    unknownModule
    ;
  inherit (lib.strings)
    isConvertibleWithToString
    ;

  showDeclPrefix =
    loc: decl: prefix:
    " - option(s) with prefix `${showOption (loc ++ [ prefix ])}' in module `${decl._file}'";
  showRawDecls =
    loc: decls:
    concatStringsSep "\n" (
      sort (a: b: a < b) (concatMap (decl: map (showDeclPrefix loc decl) (attrNames decl.options)) decls)
    );

  /**
    See https://nixos.org/manual/nixpkgs/unstable/#module-system-lib-evalModules
    or file://./../doc/module-system/module-system.chapter.md

    !!! Please think twice before adding to this argument list! The more
    that is specified here instead of in the modules themselves the harder
    it is to transparently move a set of modules to be a submodule of another
    config (as the proper arguments need to be replicated at each call to
    evalModules) and the less declarative the module set is.
  */
  evalModules =
    evalModulesArgs@{
      modules,
      prefix ? [ ],
      # This should only be used for special arguments that need to be evaluated
      # when resolving module structure (like in imports). For everything else,
      # there's _module.args. If specialArgs.modulesPath is defined it will be
      # used as the base path for disabledModules.
      specialArgs ? { },
      # `class`:
      # A nominal type for modules. When set and non-null, this adds a check to
      # make sure that only compatible modules are imported.
      class ? null,
      # This would be remove in the future, Prefer _module.args option instead.
      args ? { },
      # This would be remove in the future, Prefer _module.check option instead.
      check ? true,
    }:
    let
      withWarnings =
        x:
        warnIf (evalModulesArgs ? args)
          "The args argument to evalModules is deprecated. Please set config._module.args instead."
          warnIf
          (evalModulesArgs ? check)
          "The check argument to evalModules is deprecated. Please set config._module.check instead."
          x;

      legacyModules =
        optional (evalModulesArgs ? args) {
          config = {
            _module.args = args;
          };
        }
        ++ optional (evalModulesArgs ? check) {
          config = {
            _module.check = mkDefault check;
          };
        };
      regularModules = modules ++ legacyModules;

      # This internal module declare internal options under the `_module'
      # attribute.  These options are fragile, as they are used by the
      # module system to change the interpretation of modules.
      #
      # When extended with extendModules or moduleType, a fresh instance of
      # this module is used, to avoid conflicts and allow chaining of
      # extendModules.
      internalModule = rec {
        _file = "lib/modules.nix";

        key = _file;

        options = {
          _module.args = mkOption {
            # Because things like `mkIf` are entirely useless for
            # `_module.args` (because there's no way modules can check which
            # arguments were passed), we'll use `lazyAttrsOf` which drops
            # support for that, in turn it's lazy in its values. This means e.g.
            # a `_module.args.pkgs = import (fetchTarball { ... }) {}` won't
            # start a download when `pkgs` wasn't evaluated.
            type = types.lazyAttrsOf types.raw;
            # Only render documentation once at the root of the option tree,
            # not for all individual submodules.
            # Allow merging option decls to make this internal regardless.
            ${
              if prefix == [ ] then
                null # unset => visible
              else
                "internal"
            } =
              true;
            # TODO: Change the type of this option to a submodule with a
            # freeformType, so that individual arguments can be documented
            # separately
            description = ''
              Additional arguments passed to each module in addition to ones
              like `lib`, `config`,
              and `pkgs`, `modulesPath`.

              This option is also available to all submodules. Submodules do not
              inherit args from their parent module, nor do they provide args to
              their parent module or sibling submodules. The sole exception to
              this is the argument `name` which is provided by
              parent modules to a submodule and contains the attribute name
              the submodule is bound to, or a unique generated name if it is
              not bound to an attribute.

              Some arguments are already passed by default, of which the
              following *cannot* be changed with this option:
              - {var}`lib`: The nixpkgs library.
              - {var}`config`: The results of all options after merging the values from all modules together.
              - {var}`options`: The options declared in all modules.
              - {var}`specialArgs`: The `specialArgs` argument passed to `evalModules`.
              - All attributes of {var}`specialArgs`

                Whereas option values can generally depend on other option values
                thanks to laziness, this does not apply to `imports`, which
                must be computed statically before anything else.

                For this reason, callers of the module system can provide `specialArgs`
                which are available during import resolution.

                For NixOS, `specialArgs` includes
                {var}`modulesPath`, which allows you to import
                extra modules from the nixpkgs package tree without having to
                somehow make the module aware of the location of the
                `nixpkgs` or NixOS directories.
                ```
                { modulesPath, ... }: {
                  imports = [
                    (modulesPath + "/profiles/minimal.nix")
                  ];
                }
                ```

              For NixOS, the default value for this option includes at least this argument:
              - {var}`pkgs`: The nixpkgs package set according to
                the {option}`nixpkgs.pkgs` option.
            '';
          };

          _module.check = mkOption {
            type = types.bool;
            internal = true;
            default = true;
            description = "Whether to check whether all option definitions have matching declarations.";
          };

          _module.freeformType = mkOption {
            type = types.nullOr types.optionType;
            internal = true;
            default = null;
            description = ''
              If set, merge all definitions that don't have an associated option
              together using this type. The result then gets combined with the
              values of all declared options to produce the final `
              config` value.

              If this is `null`, definitions without an option
              will throw an error unless {option}`_module.check` is
              turned off.
            '';
          };

          _module.specialArgs = mkOption {
            readOnly = true;
            internal = true;
            description = ''
              Externally provided module arguments that can't be modified from
              within a configuration, but can be used in module imports.
            '';
          };
        };

        config = {
          _module.args = {
            inherit extendModules;
            moduleType = type;
          };
          _module.specialArgs = specialArgs;
        };
      };

      # This function takes an empty attrset as an argument.
      # It could theoretically be replaced with its body,
      # but such a binding is avoided to allow for earlier grabage collection.
      doCollect =
        { }:
        collectModules class (specialArgs.modulesPath or "") (regularModules ++ [ internalModule ]) (
          {
            inherit
              lib
              options
              specialArgs
              ;
            _class = class;
            _prefix = prefix;
            config = addErrorContext "if you get an infinite recursion here, you probably reference `config` in `imports`. If you are trying to achieve a conditional import behavior dependent on `config`, consider importing unconditionally, and using `mkEnableOption` and `mkIf` to control its effect." config;
          }
          // specialArgs
        );

      merged = mergeModules prefix (reverseList (doCollect { }).modules);

      options = merged.matchedOptions;

      config =
        let

          # For definitions that have an associated option
          declaredConfig = mapAttrsRecursiveCond (v: !isOption v) (_: v: v.value) options;

          # If freeformType is set, this is for definitions that don't have an associated option
          freeformConfig =
            let
              defs = map (def: {
                file = def.file;
                value = setAttrByPath def.prefix def.value;
              }) merged.unmatchedDefns;
            in
            if defs == [ ] then { } else declaredConfig._module.freeformType.merge prefix defs;

        in
        if declaredConfig._module.freeformType == null then
          declaredConfig
        # Because all definitions that had an associated option ended in
        # declaredConfig, freeformConfig can only contain the non-option
        # paths, meaning recursiveUpdate will never override any value
        else
          recursiveUpdate freeformConfig declaredConfig;

      checkUnmatched =
        if config._module.check && config._module.freeformType == null && merged.unmatchedDefns != [ ] then
          let
            firstDef = head merged.unmatchedDefns;
            baseMsg =
              let
                optText = showOption (prefix ++ firstDef.prefix);
                defText =
                  addErrorContext
                    "while evaluating the error message for definitions for `${optText}', which is an option that does not exist"
                    (addErrorContext "while evaluating a definition from `${firstDef.file}'" (showDefs [ firstDef ]));
              in
              "The option `${optText}' does not exist. Definition values:${defText}";
          in
          if
            attrNames options == [ "_module" ]
          # No options were declared at all (`_module` is built in)
          # but we do have unmatched definitions, and no freeformType (earlier conditions)
          then
            let
              optionName = showOption prefix;
            in
            if optionName == "" then
              throw ''
                ${baseMsg}

                It seems as if you're trying to declare an option by placing it into `config' rather than `options'!
              ''
            else
              throw ''
                ${baseMsg}

                However there are no options defined in `${showOption prefix}'. Are you sure you've
                declared your options properly? This can happen if you e.g. declared your options in `types.submodule'
                under `config' rather than `options'.
              ''
          else
            throw baseMsg
        else
          null;

      checked = seq checkUnmatched;

      extendModules =
        extendArgs@{
          modules ? [ ],
          specialArgs ? { },
          prefix ? [ ],
        }:
        evalModules (
          evalModulesArgs
          // {
            modules = regularModules ++ modules;
            specialArgs = evalModulesArgs.specialArgs or { } // specialArgs;
            prefix = extendArgs.prefix or evalModulesArgs.prefix or [ ];
          }
        );

      type = types.submoduleWith {
        inherit modules specialArgs class;
      };

      result = withWarnings {
        _type = "configuration";
        options = checked options;
        config = checked (removeAttrs config [ "_module" ]);
        _module = checked (config._module);
        inherit (doCollect { }) graph;
        inherit extendModules type class;
      };
    in
    result;

  # collectModules :: (class: String) -> (modulesPath: String) -> (modules: [ Module ]) -> (args: Attrs) -> ModulesTree
  #
  # Collects all modules recursively through `import` statements, filtering out
  # all modules in disabledModules.
  collectModules =
    class:
    let

      # Like unifyModuleSyntax, but also imports paths and calls functions if necessary
      loadModule =
        args: fallbackFile: fallbackKey: m:
        if isFunction m then
          unifyModuleSyntax fallbackFile fallbackKey (applyModuleArgs fallbackKey m args)
        else if isAttrs m then
          if m._type or "module" == "module" then
            unifyModuleSyntax fallbackFile fallbackKey m
          else if m._type == "if" || m._type == "override" then
            loadModule args fallbackFile fallbackKey { config = m; }
          else
            throw (
              messages.not_a_module {
                inherit fallbackFile;
                value = m;
                _type = m._type;
                expectedClass = class;
                prefix = args._prefix;
              }
            )
        else if isList m then
          let
            defs = [
              {
                file = fallbackFile;
                value = m;
              }
            ];
          in
          throw "Module imports can't be nested lists. Perhaps you meant to remove one level of lists? Definitions: ${showDefs defs}"
        else
          unifyModuleSyntax (toString m) (toString m) (
            applyModuleArgsIfFunction (toString m) (import m) args
          );

      checkModule =
        if class != null then
          m:
          if m._class == null || m._class == class then
            m
          else
            throw ''
              The module `${m._file or m.key}` (class: ${lib.strings.escapeNixString m._class}) cannot be imported into a module evaluation that expects class ${lib.strings.escapeNixString class}.

              Help:
              - Ensure that you are importing the correct module.
              - Verify that the module's `_class`, ${lib.strings.escapeNixString m._class} matches the expected `class` ${lib.strings.escapeNixString class}.
              - If you are using a custom class, make sure it is correctly defined and used consistently across your modules.
            ''
        else
          m: m;

      # isDisabled :: String -> [ { disabled, file } ] -> StructuredModule -> bool
      #
      # Figures out whether a `StructuredModule` is disabled.
      isDisabled =
        modulesPath: disabledList:
        let
          moduleKey =
            file: m:
            if isString m then
              if substring 0 1 m == "/" then m else toString modulesPath + "/" + m

            else if isConvertibleWithToString m then
              if m ? key && m.key != toString m then
                throw "Module `${file}` contains a disabledModules item that is an attribute set that can be converted to a string (${toString m}) but also has a `.key` attribute (${m.key}) with a different value. This makes it ambiguous which module should be disabled."
              else
                toString m

            else if m ? key then
              m.key

            else if isAttrs m then
              throw "Module `${file}` contains a disabledModules item that is an attribute set, presumably a module, that does not have a `key` attribute. This means that the module system doesn't have any means to identify the module that should be disabled. Make sure that you've put the correct value in disabledModules: a string path relative to modulesPath, a path value, or an attribute set with a `key` attribute."
            else
              throw "Each disabledModules item must be a path, string, or a attribute set with a key attribute, or a value supported by toString. However, one of the disabledModules items in `${toString file}` is none of that, but is of type ${typeOf m}.";

          disabledKeys = concatMap ({ file, disabled }: map (moduleKey file) disabled) disabledList;
        in
        structuredModule: elem structuredModule.key disabledKeys;

      /**
        Collects all modules recursively into a `[ StructuredModule ]` and a list of disabled modules:

          {
            disabled = [ <list of disabled modules> ];
            # All modules of the main module list
            modules = [
              {
                key = <key1>;
                module = <module for key1>;
                # All modules imported by the module for key1
                modules = [
                  {
                    key = <key1-1>;
                    module = <module for key1-1>;
                    # All modules imported by the module for key1-1
                    modules = [ ... ];
                  }
                  ...
                ];
              }
              ...
            ];
          }
      */
      collectStructuredModules =
        let
          collectResults = modules: {
            disabled = concatLists (catAttrs "disabled" modules);
            inherit modules;
          };
        in
        parentFile: parentKey: initialModules: args:
        collectResults (
          imap1 (
            n: x:
            let
              module = checkModule (loadModule args parentFile "${parentKey}:anon-${toString n}" x);
              collectedImports = collectStructuredModules module._file module.key module.imports args;
            in
            {
              key = module.key;
              module = module;
              modules = collectedImports.modules;
              disabled =
                (
                  if module.disabledModules != [ ] then
                    [
                      {
                        file = module._file;
                        disabled = module.disabledModules;
                      }
                    ]
                  else
                    [ ]
                )
                ++ collectedImports.disabled;
            }
          ) initialModules
        );

      # filterModules :: String -> { disabled, modules } -> [ Module ]
      #
      # Filters a structure as emitted by collectStructuredModules by removing all disabled
      # modules recursively. It returns the final list of unique-by-key modules
      filterModules =
        modulesPath:
        { disabled, modules }:
        let
          keyFilter = filter (attrs: !isDisabled modulesPath disabled attrs);
        in
        map (attrs: attrs.module) (genericClosure {
          startSet = keyFilter modules;
          operator = attrs: keyFilter attrs.modules;
        });

      toGraph =
        modulesPath:
        { disabled, modules }:
        let
          isDisabledModule = isDisabled modulesPath disabled;

          toModuleGraph = structuredModule: {
            disabled = isDisabledModule structuredModule;
            inherit (structuredModule) key;
            file = structuredModule.module._file;
            imports = map toModuleGraph structuredModule.modules;
          };
        in
        map toModuleGraph (filter (x: x.key != "lib/modules.nix") modules);
    in
    modulesPath: initialModules: args: {
      modules = filterModules modulesPath (collectStructuredModules unknownModule "" initialModules args);
      graph = toGraph modulesPath (collectStructuredModules unknownModule "" initialModules args);
    };

  /**
    Wrap a module with a default location for reporting errors.

    # Inputs

    `file`

    : 1\. Function argument

    `m`

    : 2\. Function argument
  */
  setDefaultModuleLocation = file: m: {
    _file = file;
    imports = [ m ];
  };

  /**
    Massage a module into canonical form, that is, a set consisting
    of ‘options’, ‘config’ and ‘imports’ attributes.

    # Inputs

    `file`

    : 1\. Function argument

    `key`

    : 2\. Function argument

    `m`

    : 3\. Function argument
  */
  unifyModuleSyntax =
    file: key: m:
    let
      addMeta =
        config:
        if m ? meta then
          mkMerge [
            config
            { meta = m.meta; }
          ]
        else
          config;
      addFreeformType =
        config:
        if m ? freeformType then
          mkMerge [
            config
            { _module.freeformType = m.freeformType; }
          ]
        else
          config;
    in
    if m ? config || m ? options then
      let
        badAttrs = removeAttrs m [
          "_class"
          "_file"
          "key"
          "disabledModules"
          "imports"
          "options"
          "config"
          "meta"
          "freeformType"
        ];
      in
      if badAttrs != { } then
        throw "Module `${key}' has an unsupported attribute `${head (attrNames badAttrs)}'. This is caused by introducing a top-level `config' or `options' attribute. Add configuration attributes immediately on the top level instead, or move all of them (namely: ${toString (attrNames badAttrs)}) into the explicit `config' attribute."
      else
        {
          _file = toString m._file or file;
          _class = m._class or null;
          key = toString m.key or key;
          disabledModules = m.disabledModules or [ ];
          imports = m.imports or [ ];
          options = m.options or { };
          config = addFreeformType (addMeta (m.config or { }));
        }
    else
      # shorthand syntax
      throwIfNot (isAttrs m) "module ${file} (${key}) does not look like a module." {
        _file = toString m._file or file;
        _class = m._class or null;
        key = toString m.key or key;
        disabledModules = m.disabledModules or [ ];
        imports = m.require or [ ] ++ m.imports or [ ];
        options = { };
        config = addFreeformType (
          removeAttrs m [
            "_class"
            "_file"
            "key"
            "disabledModules"
            "require"
            "imports"
            "freeformType"
          ]
        );
      };

  applyModuleArgsIfFunction =
    key: f: args@{ config, ... }: if isFunction f then applyModuleArgs key f args else f;

  applyModuleArgs =
    key: f:
    args@{ config, ... }:
    let
      # Module arguments are resolved in a strict manner when attribute set
      # deconstruction is used.  As the arguments are now defined with the
      # config._module.args option, the strictness used on the attribute
      # set argument would cause an infinite loop, if the result of the
      # option is given as argument.
      #
      # To work-around the strictness issue on the deconstruction of the
      # attributes set argument, we create a new attribute set which is
      # constructed to satisfy the expected set of attributes.  Thus calling
      # a module will resolve strictly the attributes used as argument but
      # not their values.  The values are forwarding the result of the
      # evaluation of the option.
      context = name: ''while evaluating the module argument `${name}' in "${key}":'';
      extraArgs = mapAttrs (
        name: _:
        addErrorContext (context name) (
          args.${name} or (addErrorContext
            "noting that argument `${name}` is not externally provided, so querying `_module.args` instead, requiring `config`"
            config._module.args.${name}
          )
        )
      ) (functionArgs f);

      # Note: we append in the opposite order such that we can add an error
      # context on the explicit arguments of "args" too. This update
      # operator is used to make the "args@{ ... }: with args.lib;" notation
      # works.
    in
    f (args // extraArgs);

  /**
    Merge a list of modules.  This will recurse over the option
    declarations in all modules, combining them into a single set.
    At the same time, for each option declaration, it will merge the
    corresponding option definitions in all machines, returning them
    in the ‘value’ attribute of each option.

    This returns a set like
      {
        # A recursive set of options along with their final values
        matchedOptions = {
          foo = { _type = "option"; value = "option value of foo"; ... };
          bar.baz = { _type = "option"; value = "option value of bar.baz"; ... };
          ...
        };
        # A list of definitions that weren't matched by any option
        unmatchedDefns = [
          { file = "file.nix"; prefix = [ "qux" ]; value = "qux"; }
          ...
        ];
      }

    # Inputs

    `prefix`

    : 1\. Function argument

    `modules`

    : 2\. Function argument
  */
  mergeModules =
    prefix: modules:
    mergeModules' prefix modules (
      concatMap (
        m:
        map (config: {
          file = m._file;
          inherit config;
        }) (pushDownProperties m.config)
      ) modules
    );

  mergeModules' =
    prefix: modules: configs:
    let
      # an attrset 'name' => list of submodules that declare ‘name’.
      declsByName = zipAttrsWith (n: v: v) (
        map (
          module:
          let
            subtree = module.options;
          in
          if !(isAttrs subtree) then
            throw ''
              An option declaration for `${concatStringsSep "." prefix}' has type
              `${typeOf subtree}' rather than an attribute set.
              Did you mean to define this outside of `options'?
            ''
          else
            mapAttrs (n: option: {
              inherit (module) _file;
              pos = unsafeGetAttrPos n subtree;
              options = option;
            }) subtree
        ) modules
      );

      # The root of any module definition must be an attrset.
      checkedConfigs =
        assert all (
          c:
          # TODO: I have my doubts that this error would occur when option definitions are not matched.
          #       The implementation of this check used to be tied to a superficially similar check for
          #       options, so maybe that's why this is here.
          isAttrs c.config
          || throw ''
            In module `${c.file}', you're trying to define a value of type `${typeOf c.config}'
            rather than an attribute set for the option
            `${concatStringsSep "." prefix}'!

            This usually happens if `${concatStringsSep "." prefix}' has option
            definitions inside that are not matched. Please check how to properly define
            this option by e.g. referring to `man 5 configuration.nix'!
          ''
        ) configs;
        configs;

      # an attrset 'name' => list of submodules that define ‘name’.
      pushedDownDefinitionsByName = zipAttrsWith (n: concatLists) (
        map (
          module:
          mapAttrs (
            n: value:
            map (config: {
              inherit (module) file;
              inherit config;
            }) (pushDownProperties value)
          ) module.config
        ) checkedConfigs
      );
      # extract the definitions for each loc
      rawDefinitionsByName = zipAttrsWith (n: v: v) (
        map (
          module:
          mapAttrs (n: value: {
            inherit (module) file;
            inherit value;
          }) module.config
        ) checkedConfigs
      );

      # Convert an option tree decl to a submodule option decl
      optionTreeToOption =
        decl:
        if isOption decl.options then
          decl
        else
          decl
          // {
            options = mkOption {
              type = types.submoduleWith {
                modules = [ { options = decl.options; } ];
                # `null` is not intended for use by modules. It is an internal
                # value that means "whatever the user has declared elsewhere".
                # This might become obsolete with https://github.com/NixOS/nixpkgs/issues/162398
                shorthandOnlyDefinesConfig = null;
              };
            };
          };

      resultsByName = mapAttrs (
        name: decls:
        # We're descending into attribute ‘name’.
        let
          loc = prefix ++ [ name ];
          defns = pushedDownDefinitionsByName.${name} or [ ];
          defns' = rawDefinitionsByName.${name} or [ ];
          optionDecls = filter (
            m:
            m.options ? _type
            && (m.options._type == "option" || throwDeclarationTypeError loc m.options._type m._file)
          ) decls;
        in
        if length optionDecls == length decls then
          let
            opt = fixupOptionType loc (mergeOptionDecls loc decls);
          in
          {
            matchedOptions = evalOptionValue loc opt defns';
            unmatchedDefns = [ ];
          }
        else if optionDecls != [ ] then
          if
            all (x: x.options.type.name or null == "submodule") optionDecls
          # Raw options can only be merged into submodules. Merging into
          # attrsets might be nice, but ambiguous. Suppose we have
          # attrset as a `attrsOf submodule`. User declares option
          # attrset.foo.bar, this could mean:
          #  a. option `bar` is only available in `attrset.foo`
          #  b. option `foo.bar` is available in all `attrset.*`
          #  c. reject and require "<name>" as a reminder that it behaves like (b).
          #  d. magically combine (a) and (c).
          # All of the above are merely syntax sugar though.
          then
            let
              opt = fixupOptionType loc (mergeOptionDecls loc (map optionTreeToOption decls));
            in
            {
              matchedOptions = evalOptionValue loc opt defns';
              unmatchedDefns = [ ];
            }
          else
            let
              nonOptions = filter (m: !isOption m.options) decls;
            in
            throw "The option `${showOption loc}' in module `${(head optionDecls)._file}' would be a parent of the following options, but its type `${
              (head optionDecls).options.type.description or "<no description>"
            }' does not support nested options.\n${showRawDecls loc nonOptions}"
        else
          mergeModules' loc decls defns
      ) declsByName;

      matchedOptions = mapAttrs (n: v: v.matchedOptions) resultsByName;

      # an attrset 'name' => list of unmatched definitions for 'name'
      unmatchedDefnsByName =
        # Propagate all unmatched definitions from nested option sets
        mapAttrs (n: v: v.unmatchedDefns) resultsByName
        # Plus the definitions for the current prefix that don't have a matching option
        // removeAttrs rawDefinitionsByName (attrNames matchedOptions);
    in
    {
      inherit matchedOptions;

      # Transforms unmatchedDefnsByName into a list of definitions
      unmatchedDefns =
        if configs == [ ] then
          # When no config values exist, there can be no unmatched config, so
          # we short circuit and avoid evaluating more _options_ than necessary.
          [ ]
        else
          concatLists (
            mapAttrsToList (
              name: defs:
              map (
                def:
                def
                // {
                  # Set this so we know when the definition first left unmatched territory
                  prefix = [ name ] ++ (def.prefix or [ ]);
                }
              ) defs
            ) unmatchedDefnsByName
          );
    };

  throwDeclarationTypeError =
    loc: actualTag: file:
    let
      name = lib.strings.escapeNixIdentifier (lib.lists.last loc);
      path = showOption loc;
      depth = length loc;

      paragraphs = [
        "In module ${file}: expected an option declaration at option path `${path}` but got an attribute set with type ${actualTag}"
      ]
      ++ optional (actualTag == "option-type") ''
        When declaring an option, you must wrap the type in a `mkOption` call. It should look somewhat like:
            ${comment}
            ${name} = lib.mkOption {
              description = ...;
              type = <the type you wrote for ${name}>;
              ...
            };
      '';

      # Ideally we'd know the exact syntax they used, but short of that,
      # we can only reliably repeat the last. However, we repeat the
      # full path in a non-misleading way here, in case they overlook
      # the start of the message. Examples attract attention.
      comment = optionalString (depth > 1) "\n    # ${showOption loc}";
    in
    throw (concatStringsSep "\n\n" paragraphs);

  /**
    Merge multiple option declarations into a single declaration.  In
    general, there should be only one declaration of each option.
    The exception is the ‘options’ attribute, which specifies
    sub-options.  These can be specified multiple times to allow one
    module to add sub-options to an option declared somewhere else
    (e.g. multiple modules define sub-options for ‘fileSystems’).

    'loc' is the list of attribute names where the option is located.

    'opts' is a list of modules.  Each module has an options attribute which
    correspond to the definition of 'loc' in 'opt.file'.

    # Inputs

    `loc`

    : 1\. Function argument

    `opts`

    : 2\. Function argument
  */
  mergeOptionDecls =
    loc: opts:
    foldl'
      (
        res: opt:
        let
          t = res.type;
          t' = opt.options.type;
          mergedType = t.typeMerge t'.functor;
          typesMergeable = mergedType != null;

          # TODO: Remove this when all downstream reliances of internals: 'functor.wrapped' are sufficiently migrated.
          # A function that adds the deprecated wrapped message to a type.
          addDeprecatedWrapped =
            t:
            t
            // {
              functor = t.functor // {
                wrapped = t.functor.wrappedDeprecationMessage {
                  inherit loc;
                };
              };
            };

          typeSet =
            if opt.options ? type then
              if res ? type then
                if typesMergeable then
                  {
                    type =
                      if mergedType ? functor.wrappedDeprecationMessage then
                        addDeprecatedWrapped mergedType
                      else
                        mergedType;
                  }
                else
                  # Keep in sync with the same error below!
                  throw
                    "The option `${showOption loc}' in `${opt._file}' is already declared in ${showFiles res.declarations}."
              else if opt.options.type ? functor.wrappedDeprecationMessage then
                { type = addDeprecatedWrapped opt.options.type; }
              else
                { }
            else
              { };

          bothHave = k: opt.options ? ${k} && res ? ${k};
        in
        if bothHave "default" || bothHave "example" || bothHave "description" || bothHave "apply" then
          # Keep in sync with the same error above!
          throw
            "The option `${showOption loc}' in `${opt._file}' is already declared in ${showFiles res.declarations}."
        else
          let
            getSubModules = opt.options.type.getSubModules or null;
            submodules =
              if getSubModules != null then
                map (setDefaultModuleLocation opt._file) getSubModules ++ res.options
              else
                res.options;
          in
          opt.options
          // res
          // {
            declarations = res.declarations ++ [ opt._file ];
            # In the case of modules that are generated dynamically, we won't
            # have exact declaration lines; fall back to just the file being
            # evaluated.
            declarationPositions =
              res.declarationPositions
              ++ (
                if opt.pos != null then
                  [ opt.pos ]
                else
                  [
                    {
                      file = opt._file;
                      line = null;
                      column = null;
                    }
                  ]
              );
            options = submodules;
          }
          // typeSet
      )
      {
        inherit loc;
        declarations = [ ];
        declarationPositions = [ ];
        options = [ ];
      }
      opts;

  /**
    Merge all the definitions of an option to produce the final
    config value.

    # Inputs

    `loc`

    : 1\. Function argument

    `opt`

    : 2\. Function argument

    `defs`

    : 3\. Function argument
  */
  evalOptionValue =
    loc: opt: defs:
    let
      # Add in the default value for this option, if any.
      defs' =
        (optional (opt ? default) {
          file = head opt.declarations;
          value = mkOptionDefault opt.default;
        })
        ++ defs;

      # Handle properties, check types, and merge everything together.
      res =
        if opt.readOnly or false && length defs' > 1 then
          let
            # For a better error message, evaluate all readOnly definitions as
            # if they were the only definition.
            separateDefs = map (
              def:
              def
              // {
                value = (mergeDefinitions loc opt.type [ def ]).mergedValue;
              }
            ) defs';
          in
          throw "The option `${showOption loc}' is read-only, but it's set multiple times. Definition values:${showDefs separateDefs}"
        else
          mergeDefinitions loc opt.type defs';

      # Apply the 'apply' function to the merged value. This allows options to
      # yield a value computed from the definitions
      value = if opt ? apply then opt.apply res.mergedValue else res.mergedValue;

      warnDeprecation =
        warnIf (opt.type.deprecationMessage != null)
          "The type `types.${opt.type.name}' of option `${showOption loc}' defined in ${showFiles opt.declarations} is deprecated. ${opt.type.deprecationMessage}";

    in
    warnDeprecation opt
    // {
      value = addErrorContext "while evaluating the option `${showOption loc}':" value;
      inherit (res.defsFinal') highestPrio;
      definitions = map (def: def.value) res.defsFinal;
      files = map (def: def.file) res.defsFinal;
      definitionsWithLocations = res.defsFinal;
      inherit (res) isDefined;
      # This allows options to be correctly displayed using `${options.path.to.it}`
      __toString = _: showOption loc;
    };

  # Merge definitions of a value of a given type.
  mergeDefinitions = loc: type: defs: rec {
    defsFinal' =
      let
        # Process mkMerge and mkIf properties.
        defs' = concatMap (
          m:
          map (
            value:
            if value._type or null == "definition" then
              value
            else
              {
                inherit (m) file;
                inherit value;
              }
          ) (addErrorContext "while evaluating definitions from `${m.file}':" (dischargeProperties m.value))
        ) defs;

        # Process mkOverride properties.
        defs'' = filterOverrides' defs';

        # Sort mkOrder properties.
        defs''' =
          # Avoid sorting if we don't have to.
          if any (def: def.value._type or "" == "order") defs''.values then
            sortProperties defs''.values
          else
            defs''.values;
      in
      {
        values = defs''';
        inherit (defs'') highestPrio;
      };
    defsFinal = defsFinal'.values;

    # Type-check the remaining definitions, and merge them. Or throw if no definitions.
    mergedValue =
      if isDefined then
        if all (def: type.check def.value) defsFinal then
          type.merge loc defsFinal
        else
          let
            allInvalid = filter (def: !type.check def.value) defsFinal;
          in
          throw "A definition for option `${showOption loc}' is not of type `${type.description}'. Definition values:${showDefs allInvalid}"
      else
        # (nixos-option detects this specific error message and gives it special
        # handling.  If changed here, please change it there too.)
        throw
          "The option `${showOption loc}' was accessed but has no value defined. Try setting the option.";

    isDefined = defsFinal != [ ];

    optionalValue = if isDefined then { value = mergedValue; } else { };
  };

  /**
    Given a config set, expand mkMerge properties, and push down the
    other properties into the children.  The result is a list of
    config sets that do not have properties at top-level.  For
    example,

      mkMerge [ { boot = set1; } (mkIf cond { boot = set2; services = set3; }) ]

    is transformed into

      [ { boot = set1; } { boot = mkIf cond set2; services = mkIf cond set3; } ].

    This transform is the critical step that allows mkIf conditions
    to refer to the full configuration without creating an infinite
    recursion.

    # Inputs

    `cfg`

    : 1\. Function argument
  */
  pushDownProperties =
    cfg:
    if cfg._type or "" == "merge" then
      concatMap pushDownProperties cfg.contents
    else if cfg._type or "" == "if" then
      map (mapAttrs (n: v: mkIf cfg.condition v)) (pushDownProperties cfg.content)
    else if cfg._type or "" == "override" then
      map (mapAttrs (n: v: mkOverride cfg.priority v)) (pushDownProperties cfg.content)
    # FIXME: handle mkOrder?
    else
      [ cfg ];

  /**
    Given a config value, expand mkMerge properties, and discharge
    any mkIf conditions.  That is, this is the place where mkIf
    conditions are actually evaluated.  The result is a list of
    config values.  For example, ‘mkIf false x’ yields ‘[]’,
    ‘mkIf true x’ yields ‘[x]’, and

      mkMerge [ 1 (mkIf true 2) (mkIf true (mkIf false 3)) ]

    yields ‘[ 1 2 ]’.

    # Inputs

    `def`

    : 1\. Function argument
  */
  dischargeProperties =
    def:
    if def._type or "" == "merge" then
      concatMap dischargeProperties def.contents
    else if def._type or "" == "if" then
      if isBool def.condition then
        if def.condition then dischargeProperties def.content else [ ]
      else
        throw "‘mkIf’ called with a non-Boolean condition"
    else
      [ def ];

  /**
    Given a list of config values, process the mkOverride properties,
    that is, return the values that have the highest (that is,
    numerically lowest) priority, and strip the mkOverride
    properties.  For example,

      [ { file = "/1"; value = mkOverride 10 "a"; }
        { file = "/2"; value = mkOverride 20 "b"; }
        { file = "/3"; value = "z"; }
        { file = "/4"; value = mkOverride 10 "d"; }
      ]

    yields

      [ { file = "/1"; value = "a"; }
        { file = "/4"; value = "d"; }
      ]

    Note that "z" has the default priority 100.

    # Inputs

    `defs`

    : 1\. Function argument
  */
  filterOverrides = defs: (filterOverrides' defs).values;

  filterOverrides' =
    defs:
    let
      getPrio =
        def: if def.value._type or "" == "override" then def.value.priority else defaultOverridePriority;
      highestPrio = foldl' (prio: def: min (getPrio def) prio) 9999 defs;
      strip =
        def: if def.value._type or "" == "override" then def // { value = def.value.content; } else def;
    in
    {
      values = concatMap (def: if getPrio def == highestPrio then [ (strip def) ] else [ ]) defs;
      inherit highestPrio;
    };

  /**
    Sort a list of properties.  The sort priority of a property is
    defaultOrderPriority by default, but can be overridden by wrapping the property
    using mkOrder.

    # Inputs

    `defs`

    : 1\. Function argument
  */
  sortProperties =
    defs:
    let
      strip =
        def:
        if def.value._type or "" == "order" then
          def
          // {
            value = def.value.content;
            inherit (def.value) priority;
          }
        else
          def;
      defs' = map strip defs;
      compare = a: b: (a.priority or defaultOrderPriority) < (b.priority or defaultOrderPriority);
    in
    sort compare defs';

  # This calls substSubModules, whose entire purpose is only to ensure that
  # option declarations in submodules have accurate position information.
  # TODO: Merge this into mergeOptionDecls
  fixupOptionType =
    loc: opt:
    if opt.type.getSubModules or null == null then
      opt // { type = opt.type or types.unspecified; }
    else
      opt
      // {
        type = opt.type.substSubModules opt.options;
        options = [ ];
      };

  /**
    Merge an option's definitions in a way that preserves the priority of the
    individual attributes in the option value.

    This does not account for all option semantics, such as readOnly.

    # Inputs

    `opt`

    : 1\. Function argument

    # Type

    ```
    option -> attrsOf { highestPrio, value }
    ```
  */
  mergeAttrDefinitionsWithPrio =
    opt:
    let
      defsByAttr = zipAttrs (
        concatLists (
          concatMap (
            { value, ... }@def:
            map (mapAttrsToList (
              k: value: {
                ${k} = def // {
                  inherit value;
                };
              }
            )) (pushDownProperties value)
          ) opt.definitionsWithLocations
        )
      );
    in
    assert opt.type.name == "attrsOf" || opt.type.name == "lazyAttrsOf";
    mapAttrs (
      k: v:
      let
        merging = mergeDefinitions (opt.loc ++ [ k ]) opt.type.nestedTypes.elemType v;
      in
      {
        value = merging.mergedValue;
        inherit (merging.defsFinal') highestPrio;
      }
    ) defsByAttr;

  /**
    Properties.

    # Inputs

    `condition`

    : 1\. Function argument

    `content`

    : 2\. Function argument
  */

  mkIf = condition: content: {
    _type = "if";
    inherit condition content;
  };

  mkAssert =
    assertion: message: content:
    mkIf (if assertion then true else throw "\nFailed assertion: ${message}") content;

  mkMerge = contents: {
    _type = "merge";
    inherit contents;
  };

  /**
    Return a definition with file location information.
  */
  mkDefinition = args@{ file, value, ... }: args // { _type = "definition"; };

  mkOverride = priority: content: {
    _type = "override";
    inherit priority content;
  };

  mkOptionDefault = mkOverride 1500; # priority of option defaults
  mkDefault = mkOverride 1000; # used in config sections of non-user modules to set a default
  defaultOverridePriority = 100;
  mkImageMediaOverride = mkOverride 60; # image media profiles can be derived by inclusion into host config, hence needing to override host config, but do allow user to mkForce
  mkForce = mkOverride 50;
  mkVMOverride = mkOverride 10; # used by ‘nixos-rebuild build-vm’

  defaultPriority =
    warnIf (oldestSupportedReleaseIsAtLeast 2305)
      "lib.modules.defaultPriority is deprecated, please use lib.modules.defaultOverridePriority instead."
      defaultOverridePriority;

  mkFixStrictness = warn "lib.mkFixStrictness has no effect and will be removed. It returns its argument unmodified, so you can just remove any calls." id;

  mkOrder = priority: content: {
    _type = "order";
    inherit priority content;
  };

  mkBefore = mkOrder 500;
  defaultOrderPriority = 1000;
  mkAfter = mkOrder 1500;

  # Convenient property used to transfer all definitions and their
  # properties from one option to another. This property is useful for
  # renaming options, and also for including properties from another module
  # system, including sub-modules.
  #
  #   { config, options, ... }:
  #
  #   {
  #     # 'bar' might not always be defined in the current module-set.
  #     config.foo.enable = mkAliasDefinitions (options.bar.enable or {});
  #
  #     # 'barbaz' has to be defined in the current module-set.
  #     config.foobar.paths = mkAliasDefinitions options.barbaz.paths;
  #   }
  #
  # Note, this is different than taking the value of the option and using it
  # as a definition, as the new definition will not keep the mkOverride /
  # mkDefault properties of the previous option.
  #
  mkAliasDefinitions = mkAliasAndWrapDefinitions id;
  mkAliasAndWrapDefinitions = wrap: option: mkAliasIfDef option (wrap (mkMerge option.definitions));

  # Similar to mkAliasAndWrapDefinitions but copies over the priority from the
  # option as well.
  #
  # If a priority is not set, it assumes a priority of defaultOverridePriority.
  mkAliasAndWrapDefsWithPriority =
    wrap: option:
    let
      prio = option.highestPrio or defaultOverridePriority;
      defsWithPrio = map (mkOverride prio) option.definitions;
    in
    mkAliasIfDef option (wrap (mkMerge defsWithPrio));

  mkAliasIfDef = option: mkIf (isOption option && option.isDefined);

  /**
    Compatibility.

    # Inputs

    `modules`

    : 1\. Function argument

    `args`

    : 2\. Function argument
  */
  fixMergeModules =
    modules: args:
    evalModules {
      inherit modules args;
      check = false;
    };

  /**
    Return a module that causes a warning to be shown if the
    specified option is defined. For example,

      mkRemovedOptionModule [ "boot" "loader" "grub" "bootDevice" ] "<replacement instructions>"

    causes a assertion if the user defines boot.loader.grub.bootDevice.

    replacementInstructions is a string that provides instructions on
    how to achieve the same functionality without the removed option,
    or alternatively a reasoning why the functionality is not needed.
    replacementInstructions SHOULD be provided!

    # Inputs

    `optionName`

    : 1\. Function argument

    `replacementInstructions`

    : 2\. Function argument
  */
  mkRemovedOptionModule =
    optionName: replacementInstructions:
    { options, ... }:
    {
      options = setAttrByPath optionName (mkOption {
        visible = false;
        apply =
          x:
          throw "The option `${showOption optionName}' can no longer be used since it's been removed. ${replacementInstructions}";
      });
      config.assertions =
        let
          opt = getAttrFromPath optionName options;
        in
        [
          {
            assertion = !opt.isDefined;
            message = ''
              The option definition `${showOption optionName}' in ${showFiles opt.files} no longer has any effect; please remove it.
              ${replacementInstructions}
            '';
          }
        ];
    };

  /**
    Return a module that causes a warning to be shown if the
    specified "from" option is defined; the defined value is however
    forwarded to the "to" option. This can be used to rename options
    while providing backward compatibility. For example,

      mkRenamedOptionModule [ "boot" "copyKernels" ] [ "boot" "loader" "grub" "copyKernels" ]

    forwards any definitions of boot.copyKernels to
    boot.loader.grub.copyKernels while printing a warning.

    This also copies over the priority from the aliased option to the
    non-aliased option.

    # Inputs

    `from`

    : 1\. Function argument

    `to`

    : 2\. Function argument
  */
  mkRenamedOptionModule =
    from: to:
    doRename {
      inherit from to;
      visible = false;
      warn = true;
      use = trace "Obsolete option `${showOption from}' is used. It was renamed to `${showOption to}'.";
    };

  mkRenamedOptionModuleWith =
    {
      /**
        Old option path as list of strings.
      */
      from,
      /**
        New option path as list of strings.
      */
      to,

      /**
        Release number of the first release that contains the rename, ignoring backports.
        Set it to the upcoming release, matching the nixpkgs/.version file.
      */
      sinceRelease,

    }:
    doRename {
      inherit from to;
      visible = false;
      warn = oldestSupportedReleaseIsAtLeast sinceRelease;
      use = warnIf (oldestSupportedReleaseIsAtLeast sinceRelease) "Obsolete option `${showOption from}' is used. It was renamed to `${showOption to}'.";
    };

  /**
    Return a module that causes a warning to be shown if any of the "from"
    option is defined; the defined values can be used in the "mergeFn" to set
    the "to" value.
    This function can be used to merge multiple options into one that has a
    different type.

    "mergeFn" takes the module "config" as a parameter and must return a value
    of "to" option type.

      mkMergedOptionModule
        [ [ "a" "b" "c" ]
          [ "d" "e" "f" ] ]
        [ "x" "y" "z" ]
        (config:
          let value = p: getAttrFromPath p config;
          in
          if      (value [ "a" "b" "c" ]) == true then "foo"
          else if (value [ "d" "e" "f" ]) == true then "bar"
          else "baz")

    - options.a.b.c is a removed boolean option
    - options.d.e.f is a removed boolean option
    - options.x.y.z is a new str option that combines a.b.c and d.e.f
      functionality

    This show a warning if any a.b.c or d.e.f is set, and set the value of
    x.y.z to the result of the merge function

    # Inputs

    `from`

    : 1\. Function argument

    `to`

    : 2\. Function argument

    `mergeFn`

    : 3\. Function argument
  */
  mkMergedOptionModule =
    from: to: mergeFn:
    { config, options, ... }:
    {
      options = foldl' recursiveUpdate { } (
        map (
          path:
          setAttrByPath path (mkOption {
            visible = false;
            # To use the value in mergeFn without triggering errors
            default = "_mkMergedOptionModule";
          })
        ) from
      );

      config = {
        warnings = filter (x: x != "") (
          map (
            f:
            let
              val = getAttrFromPath f config;
              opt = getAttrFromPath f options;
            in
            optionalString (val != "_mkMergedOptionModule")
              "The option `${showOption f}' defined in ${showFiles opt.files} has been changed to `${showOption to}' that has a different type. Please read `${showOption to}' documentation and update your configuration accordingly."
          ) from
        );
      }
      // setAttrByPath to (
        mkMerge (
          optional (any (f: (getAttrFromPath f config) != "_mkMergedOptionModule") from) (mergeFn config)
        )
      );
    };

  /**
    Single "from" version of mkMergedOptionModule.
    Return a module that causes a warning to be shown if the "from" option is
    defined; the defined value can be used in the "mergeFn" to set the "to"
    value.
    This function can be used to change an option into another that has a
    different type.

    "mergeFn" takes the module "config" as a parameter and must return a value of
    "to" option type.

      mkChangedOptionModule [ "a" "b" "c" ] [ "x" "y" "z" ]
        (config:
          let value = getAttrFromPath [ "a" "b" "c" ] config;
          in
          if   value > 100 then "high"
          else "normal")

    - options.a.b.c is a removed int option
    - options.x.y.z is a new str option that supersedes a.b.c

    This show a warning if a.b.c is set, and set the value of x.y.z to the
    result of the change function

    # Inputs

    `from`

    : 1\. Function argument

    `to`

    : 2\. Function argument

    `changeFn`

    : 3\. Function argument
  */
  mkChangedOptionModule =
    from: to: changeFn:
    mkMergedOptionModule [ from ] to changeFn;

  /**
    Like ‘mkRenamedOptionModule’, but doesn't show a warning.

    # Inputs

    `from`

    : 1\. Function argument

    `to`

    : 2\. Function argument
  */
  mkAliasOptionModule =
    from: to:
    doRename {
      inherit from to;
      visible = true;
      warn = false;
      use = id;
    };

  /**
    Transitional version of mkAliasOptionModule that uses MD docs.

    This function is no longer necessary and merely an alias of `mkAliasOptionModule`.
  */
  mkAliasOptionModuleMD = mkAliasOptionModule;

  /**
    mkDerivedConfig : Option a -> (a -> Definition b) -> Definition b

    Create config definitions with the same priority as the definition of another option.
    This should be used for option definitions where one option sets the value of another as a convenience.
    For instance a config file could be set with a `text` or `source` option, where text translates to a `source`
    value using `mkDerivedConfig options.text (pkgs.writeText "filename.conf")`.

    It takes care of setting the right priority using `mkOverride`.

    # Inputs

    `opt`

    : 1\. Function argument

    `f`

    : 2\. Function argument
  */
  # TODO: make the module system error message include information about `opt` in
  # error messages about conflicts. E.g. introduce a variation of `mkOverride` which
  # adds extra location context to the definition object. This will allow context to be added
  # to all messages that report option locations "this value was derived from <full option name>
  # which was defined in <locations>". It can provide a trace of options that contributed
  # to definitions.
  mkDerivedConfig = opt: f: mkOverride (opt.highestPrio or defaultOverridePriority) (f opt.value);

  /**
    Return a module that help declares an option that has been renamed.
    When a value is defined for the old option, it is forwarded to the `to` option.
  */
  doRename =
    {
      # List of strings representing the attribute path of the old option.
      from,
      # List of strings representing the attribute path of the new option.
      to,
      # Boolean, whether the old option is to be included in documentation.
      visible,
      # Whether to warn when a value is defined for the old option.
      # NOTE: This requires the NixOS assertions module to be imported, so
      #        - this generally does not work in submodules
      #        - this may or may not work outside NixOS
      warn,
      # A function that is applied to the option value, to form the value
      # of the old `from` option.
      #
      # For example, the identity function can be passed, to return the option value unchanged.
      # ```nix
      # use = x: x;
      # ```
      #
      # To add a warning, you can pass the partially applied `warn` function.
      # ```nix
      # use = lib.warn "Obsolete option `${opt.old}' is used. Use `${opt.to}' instead.";
      # ```
      use,
      # Legacy option, enabled by default: whether to preserve the priority of definitions in `old`.
      withPriority ? true,
      # A boolean that defines the `mkIf` condition for `to`.
      # If the condition evaluates to `true`, and the `to` path points into an
      # `attrsOf (submodule ...)`, then `doRename` would cause an empty module to
      # be created, even if the `from` option is undefined.
      # By setting this to an expression that may return `false`, you can inhibit
      # this undesired behavior.
      #
      # Example:
      #
      # ```nix
      # { config, lib, ... }:
      # let
      #   inherit (lib) mkOption mkEnableOption types doRename;
      # in
      # {
      #   options = {
      #
      #     # Old service
      #     services.foo.enable = mkEnableOption "foo";
      #
      #     # New multi-instance service
      #     services.foos = mkOption {
      #       type = types.attrsOf (types.submodule …);
      #     };
      #   };
      #   imports = [
      #     (doRename {
      #       from = [ "services" "foo" "bar" ];
      #       to = [ "services" "foos" "" "bar" ];
      #       visible = true;
      #       warn = false;
      #       use = x: x;
      #       withPriority = true;
      #       # Only define services.foos."" if needed. (It's not just about `bar`)
      #       condition = config.services.foo.enable;
      #     })
      #   ];
      # }
      # ```
      condition ? true,
    }:
    { config, options, ... }:
    let
      fromOpt = getAttrFromPath from options;
      toOf = attrByPath to (abort "Renaming error: option `${showOption to}' does not exist.");
      toType =
        let
          opt = attrByPath to { } options;
        in
        opt.type or (types.submodule { });
    in
    {
      options = setAttrByPath from (
        mkOption {
          inherit visible;
          description = "Alias of {option}`${showOption to}`.";
          apply = x: use (toOf config);
        }
        // optionalAttrs (toType != null) {
          type = toType;
        }
      );
      config = mkIf condition (mkMerge [
        (optionalAttrs (options ? warnings) {
          warnings =
            optional (warn && fromOpt.isDefined)
              "The option `${showOption from}' defined in ${showFiles fromOpt.files} has been renamed to `${showOption to}'.";
        })
        (
          if withPriority then
            mkAliasAndWrapDefsWithPriority (setAttrByPath to) fromOpt
          else
            mkAliasAndWrapDefinitions (setAttrByPath to) fromOpt
        )
      ]);
    };

  /**
    `importApply file arg :: Path -> a -> Module`,  where `import file :: a -> Module`

    `importApply` imports a Nix expression file much like the module system would,
    after passing an extra positional argument to the function in the file.

    This function should be used when declaring a module in a file that refers to
    values from a different scope, such as that in a flake.

    It solves the problems of alternative solutions:

    - While `importApply file arg` is _mostly_ equivalent to
      `import file arg`, the latter returns a module without a location,
      as `import` only returns the contained expression. This leads to worse
      error messages.

    - Using `specialArgs` to provide arguments to all modules. This effectively
      creates an incomplete module, and requires the user of the module to
      manually pass the `specialArgs` to the configuration, which is error-prone,
      verbose, and unnecessary.

    The nix file must contain a function that returns a module.
    A module may itself be a function, so the file is often a function with two
    positional arguments instead of one. See the example below.

    This function does not add support for deduplication and `disabledModules`,
    although that could be achieved by wrapping the returned module and setting
    the `key` module attribute.
    The reason for this omission is that the file path is not guaranteed to be
    a unique identifier for the module, as two instances of the module may
    reference different `arg`s in their closures.

    Example

        # lib.nix
        imports = [
          (lib.modules.importApply ./module.nix { bar = bar; })
        ];

        # module.nix
        { bar }:
        { lib, config, ... }:
        {
          options = ...;
          config = ... bar ...;
        }
  */
  importApply =
    modulePath: staticArg: lib.setDefaultModuleLocation modulePath (import modulePath staticArg);

  /**
    Use this function to import a JSON file as NixOS configuration.

    modules.importJSON :: path -> attrs

    # Inputs

    `file`

    : 1\. Function argument
  */
  importJSON = file: {
    _file = file;
    config = lib.importJSON file;
  };

  /**
    Use this function to import a TOML file as NixOS configuration.

    modules.importTOML :: path -> attrs

    # Inputs

    `file`

    : 1\. Function argument
  */
  importTOML = file: {
    _file = file;
    config = lib.importTOML file;
  };

  private =
    mapAttrs
      (
        k:
        warn "External use of `lib.modules.${k}` is deprecated. If your use case isn't covered by non-deprecated functions, we'd like to know more and perhaps support your use case well, instead of providing access to these low level functions. In this case please open an issue in https://github.com/nixos/nixpkgs/issues/."
      )
      {
        inherit
          applyModuleArgsIfFunction
          dischargeProperties
          mergeModules
          mergeModules'
          pushDownProperties
          unifyModuleSyntax
          ;
        collectModules = collectModules null;
      };

  /**
    Error messages produced by the module system.

    We factor these out to improve the flow when reading the code.

    Functions in `messages` that produce error messages are spelled in
    lower_snake_case. This goes against the convention in order to make the
    error message implementation more readable, and to visually distinguish
    them from other functions in the module system.
  */
  messages =
    let
      inherit (lib.strings) concatMapStringsSep escapeNixString trim;
      /**
        "" or ", in file FOO"
      */
      into_fallback_file_maybe =
        file:
        optionalString (
          file != null && file != unknownModule
        ) ", while trying to load a module into ${toString file}";

      into_prefix_maybe =
        prefix:
        optionalString (prefix != [ ]) ", while trying to load a module into ${code (showOption prefix)}";

      /**
        Format text with one line break between each list item.
      */
      lines = concatMapStringsSep "\n" trim;

      /**
        Format text with two line break between each list item.
      */
      paragraphs = concatMapStringsSep "\n\n" trim;

      /**
        ```
        optionalMatch
          { foo = "Foo result";
            bar = "Bar result";
          } "foo"
          ==  [ "Foo result" ]

        optionalMatch { foo = "Foo"; } "baz"  ==  [ ]

        optionalMatch { foo = "Foo"; } true   ==  [ ]
        ```
      */
      optionalMatch =
        cases: value: if isString value && cases ? ${value} then [ cases.${value} ] else [ ];

      # esc = builtins.fromJSON "\"\\u001b\"";
      esc = builtins.fromJSON "\"\\u001b\"";
      # Bold purple for warnings
      warn = s: "${esc}[1;35m${s}${esc}[0m";
      # Bold green for suggestions
      good = s: "${esc}[1;32m${s}${esc}[0m";
      # Bold, default color for code
      code = s: "${esc}[1m${s}${esc}[0m";

    in
    {

      /**
        When load a value with a (wrong) _type as a module
      */
      not_a_module =
        {
          fallbackFile,
          value,
          _type,
          expectedClass ? null,
          prefix,
        }:
        paragraphs (
          [
            ''
              Expected a module, but found a value of type ${warn (escapeNixString _type)}${into_fallback_file_maybe fallbackFile}${into_prefix_maybe prefix}.
              A module is typically loaded by adding it to the ${code "imports = [ ... ];"} attribute of an existing module, or in the ${code "modules = [ ... ];"} argument of various functions.
              Please make sure that each of the list items is a module, and not a different kind of value.
            ''
          ]
          ++ (optionalMatch {
            "configuration" = trim ''
              If you really mean to import this configuration, instead please only import the modules that make up the configuration.
              You may have to create a `let` binding, file or attribute to give yourself access to the relevant modules.
              While loading a configuration into the module system is a very sensible idea, it can not be done cleanly in practice.
            '';
            # ^^ Extended explanation: That's because a finalized configuration is more than just a set of modules. For instance, it has its own `specialArgs` that, by the nature of `specialArgs` can't be loaded through `imports` or the the `modules` argument. So instead, we have to ask you to extract the relevant modules and use those instead. This way, we keep the module system comparatively simple, and hopefully avoid a bad surprise down the line.

            "flake" = lines (
              [
                (trim ''
                  Perhaps you forgot to select an attribute name?
                  Instead of, for example,
                      ${warn "inputs.someflake"}
                  you need to write something like
                      ${warn "inputs.someflake"}${
                        if expectedClass == null then
                          good ".modules.someApp.default"
                        else
                          good ".modules.${expectedClass}.default"

                      }
                '')
              ]
              ++ optionalMatch {
                # We'll add no more than 5 custom suggestions here.
                # Please switch to `.modules.${class}` in your Module System application.
                "nixos" = trim ''
                  or
                      ${warn "inputs.someflake"}${good ".nixosModules.default"}
                '';
                "darwin" = trim ''
                  or
                      ${warn "inputs.someflake"}${good ".darwinModules.default"}
                '';
              } expectedClass
            );
          } _type)
        );
    };

in
private
// {
  # NOTE: not all of these functions are necessarily public interfaces; some
  #       are just needed by types.nix, but are not meant to be consumed
  #       externally.
  inherit
    defaultOrderPriority
    defaultOverridePriority
    defaultPriority
    doRename
    evalModules
    evalOptionValue # for use by lib.types
    filterOverrides
    filterOverrides'
    fixMergeModules
    fixupOptionType # should be private?
    importApply
    importJSON
    importTOML
    mergeDefinitions
    mergeAttrDefinitionsWithPrio
    mergeOptionDecls # should be private?
    mkAfter
    mkAliasAndWrapDefinitions
    mkAliasAndWrapDefsWithPriority
    mkAliasDefinitions
    mkAliasIfDef
    mkAliasOptionModule
    mkAliasOptionModuleMD
    mkAssert
    mkBefore
    mkChangedOptionModule
    mkDefault
    mkDefinition
    mkDerivedConfig
    mkFixStrictness
    mkForce
    mkIf
    mkImageMediaOverride
    mkMerge
    mkMergedOptionModule
    mkOptionDefault
    mkOrder
    mkOverride
    mkRemovedOptionModule
    mkRenamedOptionModule
    mkRenamedOptionModuleWith
    mkVMOverride
    setDefaultModuleLocation
    sortProperties
    ;
}
</file>

<file path="lib/options.nix">
/**
  Module System option handling.
*/
{ lib }:

let
  inherit (lib)
    all
    collect
    concatLists
    concatMap
    concatMapStringsSep
    filter
    foldl'
    head
    tail
    isAttrs
    isBool
    isDerivation
    isFunction
    isInt
    isList
    isString
    length
    mapAttrs
    optional
    optionals
    take
    ;
  inherit (lib.attrsets)
    attrByPath
    optionalAttrs
    showAttrPath
    ;
  inherit (lib.strings)
    concatMapStrings
    concatStringsSep
    ;
  inherit (lib.types)
    mkOptionType
    ;
  inherit (lib.lists)
    last
    toList
    ;
  prioritySuggestion = ''
    Use `lib.mkForce value` or `lib.mkDefault value` to change the priority on any of these definitions.
  '';
in
rec {

  /**
    Returns true when the given argument `a` is an option

    # Inputs

    `a`
    : Any value to check whether it is an option

    # Examples
    :::{.example}
    ## `lib.options.isOption` usage example

    ```nix
    isOption 1             // => false
    isOption (mkOption {}) // => true
    ```

    :::

    # Type

    ```
    isOption :: a -> Bool
    ```
  */
  isOption = lib.isType "option";

  /**
    Creates an Option attribute set. mkOption accepts an attribute set with the following keys:

    # Inputs

    Structured attribute set
    : Attribute set containing none or some of the following attributes.

      `default`
      : Optional default value used when no definition is given in the configuration.

      `defaultText`
      : Substitute for documenting the `default`, if evaluating the default value during documentation rendering is not possible.
      : Can be any nix value that evaluates.
      : Usage with `lib.literalMD` or `lib.literalExpression` is supported

      `example`
      : Optional example value used in the manual.
      : Can be any nix value that evaluates.
      : Usage with `lib.literalMD` or `lib.literalExpression` is supported

      `description`
      : Optional string describing the option. This is required if option documentation is generated.

      `relatedPackages`
      : Optional related packages used in the manual (see `genRelatedPackages` in `../nixos/lib/make-options-doc/default.nix`).

      `type`
      : Optional option type, providing type-checking and value merging.

      `apply`
      : Optional function that converts the option value to something else.

      `internal`
      : Optional boolean indicating whether the option is for NixOS developers only.

      `visible`
      : Optional boolean indicating whether the option shows up in the manual. Default: true. Use false to hide the option and any sub-options from submodules. Use "shallow" to hide only sub-options.

      `readOnly`
      : Optional boolean indicating whether the option can be set only once.

      `...` (any other attribute)
      : Any other attribute is passed through to the resulting option attribute set.

    # Examples
    :::{.example}
    ## `lib.options.mkOption` usage example

    ```nix
    mkOption { }  // => { _type = "option"; }
    mkOption { default = "foo"; } // => { _type = "option"; default = "foo"; }
    ```

    :::
  */
  mkOption =
    {
      default ? null,
      defaultText ? null,
      example ? null,
      description ? null,
      relatedPackages ? null,
      type ? null,
      apply ? null,
      internal ? null,
      visible ? null,
      readOnly ? null,
    }@attrs:
    attrs // { _type = "option"; };

  /**
    Creates an option declaration with a default value of ´false´, and can be defined to ´true´.

    # Inputs

    `name`

    : Name for the created option

    # Examples
    :::{.example}
    ## `lib.options.mkEnableOption` usage example

    ```nix
    # module
    let
      eval = lib.evalModules {
        modules = [
          {
            options.foo.enable = mkEnableOption "foo";

            config.foo.enable = true;
          }
        ];
      };
    in
    eval.config
    => { foo.enable = true; }
    ```

    :::
  */
  mkEnableOption =
    name:
    mkOption {
      default = false;
      example = true;
      description = "Whether to enable ${name}.";
      type = lib.types.bool;
    };

  /**
    Creates an Option attribute set for an option that specifies the
    package a module should use for some purpose.

    The package is specified in the third argument under `default` as a list of strings
    representing its attribute path in nixpkgs (or another package set).
    Because of this, you need to pass nixpkgs itself (usually `pkgs` in a module;
    alternatively to nixpkgs itself, another package set) as the first argument.

    If you pass another package set you should set the `pkgsText` option.
    This option is used to display the expression for the package set. It is `"pkgs"` by default.
    If your expression is complex you should parenthesize it, as the `pkgsText` argument
    is usually immediately followed by an attribute lookup (`.`).

    The second argument may be either a string or a list of strings.
    It provides the display name of the package in the description of the generated option
    (using only the last element if the passed value is a list)
    and serves as the fallback value for the `default` argument.

    To include extra information in the description, pass `extraDescription` to
    append arbitrary text to the generated description.

    You can also pass an `example` value, either a literal string or an attribute path.

    The `default` argument can be omitted if the provided name is
    an attribute of pkgs (if `name` is a string) or a valid attribute path in pkgs (if `name` is a list).
    You can also set `default` to just a string in which case it is interpreted as an attribute name
    (a singleton attribute path, if you will).

    If you wish to explicitly provide no default, pass `null` as `default`.

    If you want users to be able to set no package, pass `nullable = true`.
    In this mode a `default = null` will not be interpreted as no default and is interpreted literally.

    # Inputs

    `pkgs`

    : Package set (an instantiation of nixpkgs such as pkgs in modules or another package set)

    `name`

    : Name for the package, shown in option description

    Structured function argument
    : Attribute set containing the following attributes.

      `nullable`
      : Optional whether the package can be null, for example to disable installing a package altogether. Default: `false`

      `default`
      : Optional attribute path where the default package is located. Default: `name`
        If omitted will be copied from `name`

      `example`
      : Optional string or an attribute path to use as an example. Default: `null`

      `extraDescription`
      : Optional additional text to include in the option description. Default: `""`

      `pkgsText`
      : Optional representation of the package set passed as pkgs. Default: `"pkgs"`

    # Type

    ```
    mkPackageOption :: pkgs -> (string|[string]) -> { nullable? :: bool, default? :: string|[string], example? :: null|string|[string], extraDescription? :: string, pkgsText? :: string } -> option
    ```

    # Examples
    :::{.example}
    ## `lib.options.mkPackageOption` usage example

    ```nix
    mkPackageOption pkgs "hello" { }
    => { ...; default = pkgs.hello; defaultText = literalExpression "pkgs.hello"; description = "The hello package to use."; type = package; }

    mkPackageOption pkgs "GHC" {
      default = [ "ghc" ];
      example = "pkgs.haskell.packages.ghc92.ghc.withPackages (hkgs: [ hkgs.primes ])";
    }
    => { ...; default = pkgs.ghc; defaultText = literalExpression "pkgs.ghc"; description = "The GHC package to use."; example = literalExpression "pkgs.haskell.packages.ghc92.ghc.withPackages (hkgs: [ hkgs.primes ])"; type = package; }

    mkPackageOption pkgs [ "python3Packages" "pytorch" ] {
      extraDescription = "This is an example and doesn't actually do anything.";
    }
    => { ...; default = pkgs.python3Packages.pytorch; defaultText = literalExpression "pkgs.python3Packages.pytorch"; description = "The pytorch package to use. This is an example and doesn't actually do anything."; type = package; }

    mkPackageOption pkgs "nushell" {
      nullable = true;
    }
    => { ...; default = pkgs.nushell; defaultText = literalExpression "pkgs.nushell"; description = "The nushell package to use."; type = nullOr package; }

    mkPackageOption pkgs "coreutils" {
      default = null;
    }
    => { ...; description = "The coreutils package to use."; type = package; }

    mkPackageOption pkgs "dbus" {
      nullable = true;
      default = null;
    }
    => { ...; default = null; description = "The dbus package to use."; type = nullOr package; }

    mkPackageOption pkgs.javaPackages "OpenJFX" {
      default = "openjfx20";
      pkgsText = "pkgs.javaPackages";
    }
    => { ...; default = pkgs.javaPackages.openjfx20; defaultText = literalExpression "pkgs.javaPackages.openjfx20"; description = "The OpenJFX package to use."; type = package; }
    ```

    :::
  */
  mkPackageOption =
    pkgs: name:
    {
      nullable ? false,
      default ? name,
      example ? null,
      extraDescription ? "",
      pkgsText ? "pkgs",
    }:
    let
      name' = if isList name then last name else name;
      default' = toList default;
      defaultText = showAttrPath default';
      defaultValue = attrByPath default' (throw "${defaultText} cannot be found in ${pkgsText}") pkgs;
      defaults =
        if default != null then
          {
            default = defaultValue;
            defaultText = literalExpression "${pkgsText}.${defaultText}";
          }
        else
          optionalAttrs nullable {
            default = null;
          };
    in
    mkOption (
      defaults
      // {
        description =
          "The ${name'} package to use." + (if extraDescription == "" then "" else " ") + extraDescription;
        type = with lib.types; (if nullable then nullOr else lib.id) package;
      }
      // optionalAttrs (example != null) {
        example = literalExpression (
          if isList example then "${pkgsText}.${showAttrPath example}" else example
        );
      }
    );

  /**
    Deprecated alias of mkPackageOption, to be removed in 25.05.

    Previously used to create options with markdown documentation, which is no longer required.
  */
  mkPackageOptionMD = lib.warn "mkPackageOptionMD is deprecated and will be removed in 25.05; please use mkPackageOption." mkPackageOption;

  /**
    This option accepts arbitrary definitions, but it does not produce an option value.

    This is useful for sharing a module across different module sets
    without having to implement similar features as long as the
    values of the options are not accessed.

    # Inputs

    `attrs`

    : Attribute set whose attributes override the argument to `mkOption`.
  */
  mkSinkUndeclaredOptions =
    attrs:
    mkOption (
      {
        internal = true;
        visible = false;
        default = false;
        description = "Sink for option definitions.";
        type = mkOptionType {
          name = "sink";
          check = x: true;
          merge = loc: defs: false;
        };
        apply = x: throw "Option value is not readable because the option is not declared.";
      }
      // attrs
    );

  /**
    A merge function that merges multiple definitions of an option into a single value

    :::{.caution}
    This function is used as the default merge operation in `lib.types.mkOptionType`. In most cases, explicit usage of this function is unnecessary.
    :::

    # Inputs

    `loc`
    : location of the option in the configuration as a list of strings.

      e.g. `["boot" "loader "grub" "enable"]`

    `defs`
    : list of definition values and locations.

      e.g. `[ { file = "/foo.nix"; value = 1; } { file = "/bar.nix"; value = 2 } ]`

    # Example
    :::{.example}
    ## `lib.options.mergeDefaultOption` usage example

    ```nix
    myType = mkOptionType {
      name = "myType";
      merge = mergeDefaultOption; # <- This line is redundant. It is the default already.
    };
    ```

    :::

    # Merge behavior

    Merging requires all definition values to have the same type.

    - If all definitions are booleans, the result of a `foldl'` with the `or` operation is returned.
    - If all definitions are strings, they are concatenated. (`lib.concatStrings`)
    - If all definitions are integers and all are equal, the first one is returned.
    - If all definitions are lists, they are concatenated. (`++`)
    - If all definitions are attribute sets, they are merged. (`lib.mergeAttrs`)
    - If all definitions are functions, the first function is applied to the result of the second function. (`f -> x: f x`)
    - Otherwise, an error is thrown.
  */
  mergeDefaultOption =
    loc: defs:
    let
      list = getValues defs;
    in
    if length list == 1 then
      head list
    else if all isFunction list then
      x: mergeDefaultOption loc (map (f: f x) list)
    else if all isList list then
      concatLists list
    else if all isAttrs list then
      foldl' lib.mergeAttrs { } list
    else if all isBool list then
      foldl' lib.or false list
    else if all isString list then
      lib.concatStrings list
    else if all isInt list && all (x: x == head list) list then
      head list
    else
      throw "Cannot merge definitions of `${showOption loc}'. Definition values:${showDefs defs}";

  /**
    Require a single definition.

    WARNING: Does not perform nested checks, as this does not run the merge function!
  */
  mergeOneOption = mergeUniqueOption { message = ""; };

  /**
    Require a single definition.

    NOTE: When the type is not checked completely by check, pass a merge function for further checking (of sub-attributes, etc).

    # Inputs

    `loc`

    : 2\. Function argument

    `defs`

    : 3\. Function argument
  */
  mergeUniqueOption =
    args@{
      message,
      # WARNING: the default merge function assumes that the definition is a valid (option) value. You MUST pass a merge function if the return value needs to be
      #   - type checked beyond what .check does (which should be very little; only on the value head; not attribute values, etc)
      #   - if you want attribute values to be checked, or list items
      #   - if you want coercedTo-like behavior to work
      merge ? loc: defs: (head defs).value,
    }:
    loc: defs:
    if length defs == 1 then
      merge loc defs
    else
      assert length defs > 1;
      throw "The option `${showOption loc}' is defined multiple times while it's expected to be unique.\n${message}\nDefinition values:${showDefs defs}\n${prioritySuggestion}";

  /**
    "Merge" option definitions by checking that they all have the same value.

    # Inputs

    `loc`

    : 1\. Function argument

    `defs`

    : 2\. Function argument
  */
  mergeEqualOption =
    loc: defs:
    if defs == [ ] then
      abort "This case should never happen."
    # Return early if we only have one element
    # This also makes it work for functions, because the foldl' below would try
    # to compare the first element with itself, which is false for functions
    else if length defs == 1 then
      (head defs).value
    else
      (foldl' (
        first: def:
        if def.value != first.value then
          throw "The option `${showOption loc}' has conflicting definition values:${
            showDefs [
              first
              def
            ]
          }\n${prioritySuggestion}"
        else
          first
      ) (head defs) (tail defs)).value;

  /**
    Extracts values of all "value" keys of the given list.

    # Type

    ```
    getValues :: [ { value :: a; } ] -> [a]
    ```

    # Examples
    :::{.example}
    ## `getValues` usage example

    ```nix
    getValues [ { value = 1; } { value = 2; } ] // => [ 1 2 ]
    getValues [ ]                               // => [ ]
    ```

    :::
  */
  getValues = map (x: x.value);

  /**
    Extracts values of all "file" keys of the given list

    # Type

    ```
    getFiles :: [ { file :: a; } ] -> [a]
    ```

    # Examples
    :::{.example}
    ## `getFiles` usage example

    ```nix
    getFiles [ { file = "file1"; } { file = "file2"; } ] // => [ "file1" "file2" ]
    getFiles [ ]                                         // => [ ]
    ```

    :::
  */
  getFiles = map (x: x.file);

  # Generate documentation template from the list of option declaration like
  # the set generated with filterOptionSets.
  optionAttrSetToDocList = optionAttrSetToDocList' [ ];

  optionAttrSetToDocList' =
    _: options:
    concatMap (
      opt:
      let
        name = showOption opt.loc;
        docOption = {
          loc = opt.loc;
          inherit name;
          description = opt.description or null;
          declarations = filter (x: x != unknownModule) opt.declarations;
          internal = opt.internal or false;
          visible = if (opt ? visible && opt.visible == "shallow") then true else opt.visible or true;
          readOnly = opt.readOnly or false;
          type = opt.type.description or "unspecified";
        }
        // optionalAttrs (opt ? example) {
          example = builtins.addErrorContext "while evaluating the example of option `${name}`" (
            renderOptionValue opt.example
          );
        }
        // optionalAttrs (opt ? defaultText || opt ? default) {
          default = builtins.addErrorContext "while evaluating the ${
            if opt ? defaultText then "defaultText" else "default value"
          } of option `${name}`" (renderOptionValue (opt.defaultText or opt.default));
        }
        // optionalAttrs (opt ? relatedPackages && opt.relatedPackages != null) {
          inherit (opt) relatedPackages;
        };

        subOptions =
          let
            ss = opt.type.getSubOptions opt.loc;
          in
          if ss != { } then optionAttrSetToDocList' opt.loc ss else [ ];
        subOptionsVisible = docOption.visible && opt.visible or null != "shallow";
      in
      # To find infinite recursion in NixOS option docs:
      # builtins.trace opt.loc
      [ docOption ] ++ optionals subOptionsVisible subOptions
    ) (collect isOption options);

  /**
    This function recursively removes all derivation attributes from
    `x` except for the `name` attribute.

    This is to make the generation of `options.xml` much more
    efficient: the XML representation of derivations is very large
    (on the order of megabytes) and is not actually used by the
    manual generator.

    This function was made obsolete by renderOptionValue and is kept for
    compatibility with out-of-tree code.

    # Inputs

    `x`

    : 1\. Function argument
  */
  scrubOptionValue =
    x:
    if isDerivation x then
      {
        type = "derivation";
        drvPath = x.name;
        outPath = x.name;
        name = x.name;
      }
    else if isList x then
      map scrubOptionValue x
    else if isAttrs x then
      mapAttrs (n: v: scrubOptionValue v) (removeAttrs x [ "_args" ])
    else
      x;

  /**
    Ensures that the given option value (default or example) is a `_type`d string
    by rendering Nix values to `literalExpression`s.

    # Inputs

    `v`

    : 1\. Function argument
  */
  renderOptionValue =
    v:
    if v ? _type && v ? text then
      v
    else
      literalExpression (
        lib.generators.toPretty {
          multiline = true;
          allowPrettyValues = true;
        } v
      );

  /**
    For use in the `defaultText` and `example` option attributes. Causes the
    given string to be rendered verbatim in the documentation as Nix code. This
    is necessary for complex values, e.g. functions, or values that depend on
    other values or packages.

    # Inputs

    `text`

    : 1\. Function argument
  */
  literalExpression =
    text:
    if !isString text then
      throw "literalExpression expects a string."
    else
      {
        _type = "literalExpression";
        inherit text;
      };

  literalExample = lib.warn "lib.literalExample is deprecated, use lib.literalExpression instead, or use lib.literalMD for a non-Nix description." literalExpression;

  /**
    For use in the `defaultText` and `example` option attributes. Causes the
    given MD text to be inserted verbatim in the documentation, for when
    a `literalExpression` would be too hard to read.

    # Inputs

    `text`

    : 1\. Function argument
  */
  literalMD =
    text:
    if !isString text then
      throw "literalMD expects a string."
    else
      {
        _type = "literalMD";
        inherit text;
      };

  # Helper functions.

  /**
    Convert an option, described as a list of the option parts to a
    human-readable version.

    # Inputs

    `parts`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `showOption` usage example

    ```nix
    (showOption ["foo" "bar" "baz"]) == "foo.bar.baz"
      (showOption ["foo" "bar.baz" "tux"]) == "foo.\"bar.baz\".tux"
      (showOption ["windowManager" "2bwm" "enable"]) == "windowManager.\"2bwm\".enable"

    Placeholders will not be quoted as they are not actual values:
      (showOption ["foo" "*" "bar"]) == "foo.*.bar"
      (showOption ["foo" "<name>" "bar"]) == "foo.<name>.bar"
      (showOption ["foo" "<myPlaceholder>" "bar"]) == "foo.<myPlaceholder>.bar"
    ```

    :::
  */
  showOption =
    parts:
    let
      # If the part is a named placeholder of the form "<...>" don't escape it.
      # It may cause misleading escaping if somebody uses literally "<...>" in their option names.
      # This is the trade-off to allow for placeholders in option names.
      isNamedPlaceholder = builtins.match "<(.*)>";
      escapeOptionPart =
        part:
        if part == "*" || isNamedPlaceholder part != null then
          part
        else
          lib.strings.escapeNixIdentifier part;
    in
    (concatStringsSep ".") (map escapeOptionPart parts);
  showFiles = files: concatStringsSep " and " (map (f: "`${f}'") files);

  showDefs =
    defs:
    concatMapStrings (
      def:
      let
        # Pretty print the value for display, if successful
        prettyEval = builtins.tryEval (
          lib.generators.toPretty { } (
            lib.generators.withRecursion {
              depthLimit = 10;
              throwOnDepthLimit = false;
            } def.value
          )
        );
        # Split it into its lines
        lines = filter (v: !isList v) (builtins.split "\n" prettyEval.value);
        # Only display the first 5 lines, and indent them for better visibility
        value = concatStringsSep "\n    " (take 5 lines ++ optional (length lines > 5) "...");
        result =
          # Don't print any value if evaluating the value strictly fails
          if !prettyEval.success then
            ""
          # Put it on a new line if it consists of multiple
          else if length lines > 1 then
            ":\n    " + value
          else
            ": " + value;
      in
      "\n- In `${def.file}'${result}"
    ) defs;

  /**
    Pretty prints all option definition locations

    # Inputs

    `option`
    : The option to pretty print

    # Examples
    :::{.example}
    ## `lib.options.showOptionWithDefLocs` usage example

    ```nix
    showOptionWithDefLocs { loc = ["x" "y" ]; files = [ "foo.nix" "bar.nix" ];  }
    "x.y, with values defined in:\n  - foo.nix\n  - bar.nix\n"
    ```

    ```nix
    nix-repl> eval = lib.evalModules {
        modules = [
          {
            options = {
              foo = lib.mkEnableOption "foo";
            };
          }
        ];
      }

    nix-repl> lib.options.showOptionWithDefLocs eval.options.foo
    "foo, with values defined in:\n  - <unknown-file>\n"
    ```

    :::

    # Type

    ```
    showDefsSep :: { files :: [ String ]; loc :: [ String ]; ... } -> string
    ```
  */
  showOptionWithDefLocs = opt: ''
    ${showOption opt.loc}, with values defined in:
    ${concatMapStringsSep "\n" (defFile: "  - ${defFile}") opt.files}
  '';

  unknownModule = "<unknown-file>";

}
</file>

<file path="lib/README.md">
# Nixpkgs lib

This directory contains the implementation, documentation and tests for the Nixpkgs `lib` library.

## Overview

The evaluation entry point for `lib` is [`default.nix`](default.nix).
This file evaluates to an attribute set containing two separate kinds of attributes:
- Sub-libraries:
  Attribute sets grouping together similar functionality.
  Each sub-library is defined in a separate file usually matching its attribute name.

  Example: `lib.lists` is a sub-library containing list-related functionality such as `lib.lists.take` and `lib.lists.imap0`.
  These are defined in the file [`lists.nix`](lists.nix).

- Aliases:
  Attributes that point to an attribute of the same name in some sub-library.

  Example: `lib.take` is an alias for `lib.lists.take`.

Most files in this directory are definitions of sub-libraries, but there are a few others:
- [`minver.nix`](minver.nix): A string of the minimum version of Nix that is required to evaluate Nixpkgs.
- [`tests`](tests): Tests, see [Running tests](#running-tests)
  - [`release.nix`](tests/release.nix): A derivation aggregating all tests
  - [`misc.nix`](tests/misc.nix): Evaluation unit tests for most sub-libraries
  - `*.sh`: Bash scripts that run tests for specific sub-libraries
  - All other files in this directory exist to support the tests
- [`systems`](systems): The `lib.systems` sub-library, structured into a directory instead of a file due to its complexity
- [`path`](path): The `lib.path` sub-library, which includes tests as well as a document describing the design goals of `lib.path`
- All other files in this directory are sub-libraries

### Module system

The [module system](https://nixos.org/manual/nixpkgs/#module-system) spans multiple sub-libraries:
- [`modules.nix`](modules.nix): `lib.modules` for the core functions and anything not relating to option definitions
- [`options.nix`](options.nix): `lib.options` for anything relating to option definitions
- [`types.nix`](types.nix): `lib.types` for module system types

## PR Guidelines

Follow these guidelines for proposing a change to the interface of `lib`.

### Provide a Motivation

Clearly describe why the change is necessary and its use cases.

Make sure that the change benefits the user more than the added mental effort of looking it up and keeping track of its definition.
If the same can reasonably be done with the existing interface,
consider just updating the documentation with more examples and links.
This is also known as the [Fairbairn Threshold](https://wiki.haskell.org/Fairbairn_threshold).

Through this principle we avoid the human cost of duplicated functionality in an overly large library.

### Make one PR for each change

Don't have multiple changes in one PR, instead split it up into multiple ones.

This keeps the conversation focused and has a higher chance of getting merged.

### Name the interface appropriately

When introducing new names to the interface, such as new function, or new function attributes,
make sure to name it appropriately.

Names should be self-explanatory and consistent with the rest of `lib`.
If there's no obvious best name, include the alternatives you considered.

### Write documentation

Update the [reference documentation](#reference-documentation) to reflect the change.

Be generous with links to related functionality.

### Write tests

Add good test coverage for the change, including:

- Tests for edge cases, such as empty values or lists.
- Tests for tricky inputs, such as a string with string context or a path that doesn't exist.
- Test all code paths, such as `if-then-else` branches and returned attributes.
- If the tests for the sub-library are written in bash,
  test messages of custom errors, such as `throw` or `abortMsg`,

  At the time this is only not necessary for sub-libraries tested with [`tests/misc.nix`](./tests/misc.nix).

See [running tests](#running-tests) for more details on the test suites.

### Write tidy code

Name variables well, even if they're internal.
The code should be as self-explanatory as possible.
Be generous with code comments when appropriate.

As a baseline, follow the [Nixpkgs code conventions](https://github.com/NixOS/nixpkgs/blob/master/CONTRIBUTING.md#code-conventions).

### Write efficient code

Nix generally does not have free abstractions.
Be aware that seemingly straightforward changes can cause more allocations and a decrease in performance.
That said, don't optimise prematurely, especially in new code.

## Reference documentation

Reference documentation for library functions is written above each function as a multi-line comment.
These comments are processed using [nixdoc](https://github.com/nix-community/nixdoc) and [rendered in the Nixpkgs manual](https://nixos.org/manual/nixpkgs/stable/#chap-functions).
The nixdoc README describes the [comment format](https://github.com/nix-community/nixdoc#comment-format).

See [doc/README.md](../doc/README.md) for how to build the manual.

## Running tests

All library tests can be run by building the derivation in [`tests/release.nix`](tests/release.nix):

```bash
nix-build tests/release.nix
```

Some commands for quicker iteration over parts of the test suite are also available:

```bash
# Run all evaluation unit tests in tests/misc.nix
# if the resulting list is empty, all tests passed
nix-instantiate --eval --strict tests/misc.nix

# Run the module system tests
tests/modules.sh

# Run the lib.sources tests
tests/sources.sh

# Run the lib.filesystem tests
tests/filesystem.sh

# Run the lib.path property tests
path/tests/prop.sh

# Run the lib.fileset tests
fileset/tests.sh
```

## Commit conventions

- Make sure you read about the [commit conventions](../CONTRIBUTING.md#commit-conventions) common to Nixpkgs as a whole.

- Format the commit messages in the following way:

  ```
  lib.(section): (init | add additional argument | refactor | etc)

  (Motivation for change. Additional information.)
  ```

  Examples:

  * lib.getExe': check arguments
  * lib.fileset: Add an additional argument in the design docs

    Closes #264537
</file>

<file path="lib/source-types.nix">
{ lib }:

let
  defaultSourceType = tname: {
    shortName = tname;
    isSource = false;
  };
in
lib.mapAttrs (tname: tset: defaultSourceType tname // tset) {

  fromSource = {
    isSource = true;
  };

  binaryNativeCode = { };

  binaryBytecode = { };

  binaryFirmware = { };
}
</file>

<file path="lib/sources.nix">
# Functions for copying sources to the Nix store.
{ lib }:

# Tested in lib/tests/sources.sh
let
  inherit (lib.strings)
    match
    split
    storeDir
    ;
  inherit (lib)
    boolToString
    filter
    isString
    readFile
    ;
  inherit (lib.filesystem)
    pathIsRegularFile
    ;

  /**
    A basic filter for `cleanSourceWith` that removes
    directories of version control system, backup files (*~)
    and some generated files.

    # Inputs

    `name`

    : 1\. Function argument

    `type`

    : 2\. Function argument
  */
  cleanSourceFilter =
    name: type:
    let
      baseName = baseNameOf (toString name);
    in
    !(
      # Filter out version control software files/directories
      (
        baseName == ".git"
        ||
          type == "directory"
          && (baseName == ".svn" || baseName == "CVS" || baseName == ".hg" || baseName == ".jj")
      )
      ||
        # Filter out editor backup / swap files.
        lib.hasSuffix "~" baseName
      || match "^\\.sw[a-z]$" baseName != null
      || match "^\\..*\\.sw[a-z]$" baseName != null
      ||

        # Filter out generates files.
        lib.hasSuffix ".o" baseName
      || lib.hasSuffix ".so" baseName
      ||
        # Filter out nix-build result symlinks
        (type == "symlink" && lib.hasPrefix "result" baseName)
      ||
        # Filter out sockets and other types of files we can't have in the store.
        (type == "unknown")
    );

  /**
    Filters a source tree removing version control files and directories using cleanSourceFilter.

    # Inputs

    `src`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `cleanSource` usage example

    ```nix
    cleanSource ./.
    ```

    :::
  */
  cleanSource =
    src:
    cleanSourceWith {
      filter = cleanSourceFilter;
      inherit src;
    };

  /**
    Like `builtins.filterSource`, except it will compose with itself,
    allowing you to chain multiple calls together without any
    intermediate copies being put in the nix store.

    # Examples
    :::{.example}
    ## `cleanSourceWith` usage example

    ```nix
    lib.cleanSourceWith {
      filter = f;
      src = lib.cleanSourceWith {
        filter = g;
        src = ./.;
      };
    }
    # Succeeds!

    builtins.filterSource f (builtins.filterSource g ./.)
    # Fails!
    ```

    :::
  */
  cleanSourceWith =
    {
      # A path or cleanSourceWith result to filter and/or rename.
      src,
      # Optional with default value: constant true (include everything)
      # The function will be combined with the && operator such
      # that src.filter is called lazily.
      # For implementing a filter, see
      # https://nixos.org/nix/manual/#builtin-filterSource
      # Type: A function (path -> type -> bool)
      filter ? _path: _type: true,
      # Optional name to use as part of the store path.
      # This defaults to `src.name` or otherwise `"source"`.
      name ? null,
    }:
    let
      orig = toSourceAttributes src;
    in
    fromSourceAttributes {
      inherit (orig) origSrc;
      filter = path: type: filter path type && orig.filter path type;
      name = if name != null then name else orig.name;
    };

  /**
    Add logging to a source, for troubleshooting the filtering behavior.

    # Inputs

    `src`

    : Source to debug. The returned source will behave like this source, but also log its filter invocations.

    # Type

    ```
    sources.trace :: sourceLike -> Source
    ```
  */
  trace =
    # Source to debug. The returned source will behave like this source, but also log its filter invocations.
    src:
    let
      attrs = toSourceAttributes src;
    in
    fromSourceAttributes (
      attrs
      // {
        filter =
          path: type:
          let
            r = attrs.filter path type;
          in
          builtins.trace "${attrs.name}.filter ${path} = ${boolToString r}" r;
      }
    )
    // {
      satisfiesSubpathInvariant = src ? satisfiesSubpathInvariant && src.satisfiesSubpathInvariant;
    };

  /**
    Filter sources by a list of regular expressions.

    # Inputs

    `src`

    : 1\. Function argument

    `regexes`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `sourceByRegex` usage example

    ```nix
    src = sourceByRegex ./my-subproject [".*\.py$" "^database.sql$"]
    ```

    :::
  */
  sourceByRegex =
    src: regexes:
    let
      isFiltered = src ? _isLibCleanSourceWith;
      origSrc = if isFiltered then src.origSrc else src;
    in
    lib.cleanSourceWith {
      filter = (
        path: type:
        let
          relPath = lib.removePrefix (toString origSrc + "/") (toString path);
        in
        lib.any (re: match re relPath != null) regexes
      );
      inherit src;
    };

  /**
    Get all files ending with the specified suffices from the given
    source directory or its descendants, omitting files that do not match
    any suffix. The result of the example below will include files like
    `./dir/module.c` and `./dir/subdir/doc.xml` if present.

    # Inputs

    `src`

    : Path or source containing the files to be returned

    `exts`

    : A list of file suffix strings

    # Type

    ```
    sourceLike -> [String] -> Source
    ```

    # Examples
    :::{.example}
    ## `sourceFilesBySuffices` usage example

    ```nix
    sourceFilesBySuffices ./. [ ".xml" ".c" ]
    ```

    :::
  */
  sourceFilesBySuffices =
    # Path or source containing the files to be returned
    src:
    # A list of file suffix strings
    exts:
    let
      filter =
        name: type:
        let
          base = baseNameOf (toString name);
        in
        type == "directory" || lib.any (ext: lib.hasSuffix ext base) exts;
    in
    cleanSourceWith { inherit filter src; };

  pathIsGitRepo = path: (_commitIdFromGitRepoOrError path) ? value;

  /**
    Get the commit id of a git repo.

    # Inputs

    `path`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `commitIdFromGitRepo` usage example

    ```nix
    commitIdFromGitRepo <nixpkgs/.git>
    ```

    :::
  */
  commitIdFromGitRepo =
    path:
    let
      commitIdOrError = _commitIdFromGitRepoOrError path;
    in
    commitIdOrError.value or (throw commitIdOrError.error);

  # Get the commit id of a git repo.

  # Returns `{ value = commitHash }` or `{ error = "... message ..." }`.

  # Example: commitIdFromGitRepo <nixpkgs/.git>
  # not exported, used for commitIdFromGitRepo
  _commitIdFromGitRepoOrError =
    let
      readCommitFromFile =
        file: path:
        let
          fileName = path + "/${file}";
          packedRefsName = path + "/packed-refs";
          absolutePath =
            base: path: if lib.hasPrefix "/" path then path else toString (/. + "${base}/${path}");
        in
        if
          pathIsRegularFile path
        # Resolve git worktrees. See gitrepository-layout(5)
        then
          let
            m = match "^gitdir: (.*)$" (lib.fileContents path);
          in
          if m == null then
            { error = "File contains no gitdir reference: " + path; }
          else
            let
              gitDir = absolutePath (dirOf path) (lib.head m);
              commonDir'' =
                if pathIsRegularFile "${gitDir}/commondir" then lib.fileContents "${gitDir}/commondir" else gitDir;
              commonDir' = lib.removeSuffix "/" commonDir'';
              commonDir = absolutePath gitDir commonDir';
              refFile = lib.removePrefix "${commonDir}/" "${gitDir}/${file}";
            in
            readCommitFromFile refFile commonDir

        else if
          pathIsRegularFile fileName
        # Sometimes git stores the commitId directly in the file but
        # sometimes it stores something like: «ref: refs/heads/branch-name»
        then
          let
            fileContent = lib.fileContents fileName;
            matchRef = match "^ref: (.*)$" fileContent;
          in
          if matchRef == null then { value = fileContent; } else readCommitFromFile (lib.head matchRef) path

        else if
          pathIsRegularFile packedRefsName
        # Sometimes, the file isn't there at all and has been packed away in the
        # packed-refs file, so we have to grep through it:
        then
          let
            fileContent = readFile packedRefsName;
            matchRef = match "([a-z0-9]+) ${file}";
            isRef = s: isString s && (matchRef s) != null;
            # there is a bug in libstdc++ leading to stackoverflow for long strings:
            # https://github.com/NixOS/nix/issues/2147#issuecomment-659868795
            refs = filter isRef (split "\n" fileContent);
          in
          if refs == [ ] then
            { error = "Could not find " + file + " in " + packedRefsName; }
          else
            { value = lib.head (matchRef (lib.head refs)); }

        else
          { error = "Not a .git directory: " + toString path; };
    in
    readCommitFromFile "HEAD";

  pathHasContext = builtins.hasContext or (lib.hasPrefix storeDir);

  canCleanSource = src: src ? _isLibCleanSourceWith || !(pathHasContext (toString src));

  # -------------------------------------------------------------------------- #
  # Internal functions
  #

  # toSourceAttributes : sourceLike -> SourceAttrs
  #
  # Convert any source-like object into a simple, singular representation.
  # We don't expose this representation in order to avoid having a fifth path-
  # like class of objects in the wild.
  # (Existing ones being: paths, strings, sources and x//{outPath})
  # So instead of exposing internals, we build a library of combinator functions.
  toSourceAttributes =
    src:
    let
      isFiltered = src ? _isLibCleanSourceWith;
    in
    {
      # The original path
      origSrc = if isFiltered then src.origSrc else src;
      filter = if isFiltered then src.filter else _: _: true;
      name = if isFiltered then src.name else "source";
    };

  # fromSourceAttributes : SourceAttrs -> Source
  #
  # Inverse of toSourceAttributes for Source objects.
  fromSourceAttributes =
    {
      origSrc,
      filter,
      name,
    }:
    {
      _isLibCleanSourceWith = true;
      inherit origSrc filter name;
      outPath = builtins.path {
        inherit filter name;
        path = origSrc;
      };
    };

  # urlToName : (URL | Path | String) -> String
  #
  # Transform a URL (or path, or string) into a clean package name.
  urlToName =
    url:
    let
      inherit (lib.strings) stringLength;
      base = baseNameOf (lib.removeSuffix "/" (lib.last (lib.splitString ":" (toString url))));
      # chop away one git or archive-related extension
      removeExt =
        name:
        let
          matchExt = match "(.*)\\.(git|tar|zip|gz|tgz|bz|tbz|bz2|tbz2|lzma|txz|xz|zstd)$" name;
        in
        if matchExt != null then lib.head matchExt else name;
      # apply function f to string x while the result shrinks
      shrink =
        f: x:
        let
          v = f x;
        in
        if stringLength v < stringLength x then shrink f v else x;
    in
    shrink removeExt base;

  # shortRev : (String | Integer) -> String
  #
  # Given a package revision (like "refs/tags/v12.0"), produce a short revision ("12.0").
  shortRev =
    rev:
    let
      baseRev = baseNameOf (toString rev);
      matchHash = match "[a-f0-9]+" baseRev;
      matchVer = match "([A-Za-z]+[-_. ]?)*(v)?([0-9.]+.*)" baseRev;
    in
    if matchHash != null then
      builtins.substring 0 7 baseRev
    else if matchVer != null then
      lib.last matchVer
    else
      baseRev;

  # revOrTag : String -> String -> String
  #
  # Turn git `rev` and `tag` pair into a revision usable in `repoRevToName*`.
  revOrTag =
    rev: tag:
    if tag != null then
      tag
    else if rev != null then
      rev
    else
      "HEAD";

  # repoRevToNameFull : (URL | Path | String) -> (String | Integer | null) -> (String | null) -> String
  #
  # See `repoRevToName` below.
  repoRevToNameFull =
    repo_: rev_: suffix_:
    let
      repo = urlToName repo_;
      rev = if rev_ != null then "-${shortRev rev_}" else "";
      suffix = if suffix_ != null then "-${suffix_}" else "";
    in
    "${repo}${rev}${suffix}-source";

  # repoRevToName : String -> (URL | Path | String) -> (String | Integer | null) -> String -> String
  #
  # Produce derivation.name attribute for a given repository URL/path/name and (optionally) its revision/version tag.
  #
  # This is used by fetch(zip|git|FromGitHub|hg|svn|etc) to generate discoverable
  # /nix/store paths.
  #
  # This uses a different implementation depending on the `pretty` argument:
  #  "source" -> name everything as "source"
  #  "versioned" -> name everything as "${repo}-${rev}-source"
  #  "full" -> name everything as "${repo}-${rev}-${fetcher}-source"
  repoRevToName =
    kind:
    # match on `kind` first to minimize the thunk
    if kind == "source" then
      (
        repo: rev: suffix:
        "source"
      )
    else if kind == "versioned" then
      (
        repo: rev: suffix:
        repoRevToNameFull repo rev null
      )
    else if kind == "full" then
      repoRevToNameFull
    else
      throw "repoRevToName: invalid kind";

in
{

  pathType =
    lib.warnIf (lib.oldestSupportedReleaseIsAtLeast 2305)
      "lib.sources.pathType has been moved to lib.filesystem.pathType."
      lib.filesystem.pathType;

  pathIsDirectory =
    lib.warnIf (lib.oldestSupportedReleaseIsAtLeast 2305)
      "lib.sources.pathIsDirectory has been moved to lib.filesystem.pathIsDirectory."
      lib.filesystem.pathIsDirectory;

  pathIsRegularFile =
    lib.warnIf (lib.oldestSupportedReleaseIsAtLeast 2305)
      "lib.sources.pathIsRegularFile has been moved to lib.filesystem.pathIsRegularFile."
      lib.filesystem.pathIsRegularFile;

  inherit
    pathIsGitRepo
    commitIdFromGitRepo

    cleanSource
    cleanSourceWith
    cleanSourceFilter
    pathHasContext
    canCleanSource

    urlToName
    shortRev
    revOrTag
    repoRevToName

    sourceByRegex
    sourceFilesBySuffices

    trace
    ;
}
</file>

<file path="lib/strings-with-deps.nix">
{ lib }:
/**
  Usage:

    You define you custom builder script by adding all build steps to a list.
    for example:
         builder = writeScript "fsg-4.4-builder"
                 (textClosure [doUnpack addInputs preBuild doMake installPhase doForceShare]);

    a step is defined by noDepEntry, fullDepEntry or packEntry.
    To ensure that prerequisite are met those are added before the task itself by
    textClosureDupList. Duplicated items are removed again.

    See trace/nixpkgs/trunk/pkgs/top-level/builder-defs.nix for some predefined build steps

    Attention:

    let
      pkgs = (import <nixpkgs>) {};
    in let
      inherit (pkgs.stringsWithDeps) fullDepEntry packEntry noDepEntry textClosureMap;
      inherit (pkgs.lib) id;

      nameA = noDepEntry "Text a";
      nameB = fullDepEntry "Text b" ["nameA"];
      nameC = fullDepEntry "Text c" ["nameA"];

      stages = {
        nameHeader = noDepEntry "#! /bin/sh \n";
        inherit nameA nameB nameC;
      };
    in
      textClosureMap id stages
      [ "nameHeader" "nameA" "nameB" "nameC"
        nameC # <- added twice. add a dep entry if you know that it will be added once only [1]
        "nameB" # <- this will not be added again because the attr name (reference) is used
      ]

    # result: Str("#! /bin/sh \n\nText a\nText b\nText c\nText c",[])

    [1] maybe this behaviour should be removed to keep things simple (?)
*/

let
  inherit (lib)
    concatStringsSep
    head
    isAttrs
    listToAttrs
    tail
    ;
in
rec {

  /**
    Topologically sort a collection of dependent strings.
    Only the values to keys listed in `arg` and their dependencies will be included in the result.

    ::: {.note}
    This function doesn't formally fulfill the definition of topological sorting, but it's good enough for our purposes in Nixpkgs.
    :::

    # Inputs

    `predefined` (attribute set)

    : strings with annotated dependencies (strings or attribute set)
      A value can be a simple string if it has no dependencies.
      Otherwise, is can be an attribute set with the following attributes:
      - `deps` (list of strings)
      - `text` (Any

    `arg` (list of strings)

    : Keys for which the values in the dependency closure will be included in the result

    # Type

    ```
    textClosureList :: { ${phase} :: { deps :: [String]; text :: String; } | String; } -> [String] -> [String]
    ```

    # Examples
    :::{.example}
    ## `lib.stringsWithDeps.textClosureList` usage example

    ```nix
    textClosureList {
      a = {
        deps = [ "b" "c" "e" ];
        text = "a: depends on b, c and e";
      };
      b = {
        deps = [ ];
        text = "b: no dependencies";
      };
      c = {
        deps = [ "b" ];
        text = "c: depends on b";
      };
      d = {
        deps = [ "c" ];
        text = "d: not being depended on by anything in `arg`";
      };
      e = {
        deps = [ "c" ];
        text = "e: depends on c, depended on by a, not in `arg`";
      };
    } [
      "a"
      "b"
      "c"
    ]
    => [
      "b: no dependencies"
      "c: depends on b"
      "e: depends on c, depended on by a, not in `arg`"
      "a: depends on b, c and e"
    ]
    ```
    :::

    Common real world usages are:
    - Ordering the dependent phases of `system.activationScripts`
    - Ordering the dependent phases of `system.userActivationScripts`

    For further examples see: [NixOS activation script](https://nixos.org/manual/nixos/stable/#sec-activation-script)
  */
  textClosureList =
    predefined: arg:
    let
      f =
        done: todo:
        if todo == [ ] then
          {
            result = [ ];
            inherit done;
          }
        else
          let
            entry = head todo;
          in
          if isAttrs entry then
            let
              x = f done entry.deps;
              y = f x.done (tail todo);
            in
            {
              result = x.result ++ [ entry.text ] ++ y.result;
              done = y.done;
            }
          else if done ? ${entry} then
            f done (tail todo)
          else
            f (
              done
              // listToAttrs [
                {
                  name = entry;
                  value = 1;
                }
              ]
            ) ([ predefined.${entry} ] ++ tail todo);
    in
    (f { } arg).result;

  textClosureMap =
    f: predefined: names:
    concatStringsSep "\n" (map f (textClosureList predefined names));

  noDepEntry = text: {
    inherit text;
    deps = [ ];
  };
  fullDepEntry = text: deps: { inherit text deps; };
  packEntry = deps: {
    inherit deps;
    text = "";
  };

  stringAfter = deps: text: { inherit text deps; };

}
</file>

<file path="lib/types.nix">
# Definitions related to run-time type checking.  Used in particular
# to type-check NixOS configurations.
{ lib }:

let
  inherit (lib)
    elem
    flip
    isAttrs
    isBool
    isDerivation
    isFloat
    isFunction
    isInt
    isList
    isString
    isStorePath
    throwIf
    toDerivation
    toList
    ;
  inherit (lib.lists)
    all
    concatLists
    count
    elemAt
    filter
    foldl'
    head
    imap1
    last
    length
    tail
    ;
  inherit (lib.attrsets)
    attrNames
    filterAttrs
    hasAttr
    mapAttrs
    optionalAttrs
    zipAttrsWith
    ;
  inherit (lib.options)
    getFiles
    getValues
    mergeDefaultOption
    mergeEqualOption
    mergeOneOption
    mergeUniqueOption
    showFiles
    showOption
    ;
  inherit (lib.strings)
    concatMapStringsSep
    concatStringsSep
    escapeNixString
    hasInfix
    isStringLike
    ;
  inherit (lib.trivial)
    boolToString
    ;

  inherit (lib.modules)
    mergeDefinitions
    fixupOptionType
    mergeOptionDecls
    ;

  inAttrPosSuffix =
    v: name:
    let
      pos = builtins.unsafeGetAttrPos name v;
    in
    if pos == null then "" else " at ${pos.file}:${toString pos.line}:${toString pos.column}";

  # Internal functor to help for migrating functor.wrapped to functor.payload.elemType
  # Note that individual attributes can be overridden if needed.
  elemTypeFunctor =
    name:
    { elemType, ... }@payload:
    {
      inherit name payload;
      wrappedDeprecationMessage = makeWrappedDeprecationMessage payload;
      type = outer_types.types.${name};
      binOp =
        a: b:
        let
          merged = a.elemType.typeMerge b.elemType.functor;
        in
        if merged == null then null else { elemType = merged; };
    };
  makeWrappedDeprecationMessage =
    payload:
    { loc }:
    lib.warn ''
      The deprecated `${lib.optionalString (loc != null) "type."}functor.wrapped` attribute ${
        lib.optionalString (loc != null) "of the option `${showOption loc}` "
      }is accessed, use `${lib.optionalString (loc != null) "type."}nestedTypes.elemType` instead.
    '' payload.elemType;

  outer_types = rec {
    isType = type: x: (x._type or "") == type;

    setType =
      typeName: value:
      value
      // {
        _type = typeName;
      };

    # Default type merging function
    # takes two type functors and return the merged type
    defaultTypeMerge =
      f: f':
      let
        mergedWrapped = f.wrapped.typeMerge f'.wrapped.functor;
        mergedPayload = f.binOp f.payload f'.payload;

        hasPayload =
          assert (f'.payload != null) == (f.payload != null);
          f.payload != null;
        hasWrapped =
          assert (f'.wrapped != null) == (f.wrapped != null);
          f.wrapped != null;

        typeFromPayload = if mergedPayload == null then null else f.type mergedPayload;
        typeFromWrapped = if mergedWrapped == null then null else f.type mergedWrapped;
      in
      # Abort early: cannot merge different types
      if f.name != f'.name then
        null
      else

      if hasPayload then
        # Just return the payload if returning wrapped is deprecated
        if f ? wrappedDeprecationMessage then
          typeFromPayload
        else if hasWrapped then
          # Has both wrapped and payload
          throw ''
            Type ${f.name} defines both `functor.payload` and `functor.wrapped` at the same time, which is not supported.

            Use either `functor.payload` or `functor.wrapped` but not both.

            If your code worked before remove either `functor.wrapped` or `functor.payload` from the type definition.
          ''
        else
          typeFromPayload
      else if hasWrapped then
        typeFromWrapped
      else
        f.type;

    # Default type functor
    defaultFunctor = name: {
      inherit name;
      type = types.${name} or null;
      wrapped = null;
      payload = null;
      binOp = a: b: null;
    };

    isOptionType = isType "option-type";
    mkOptionType =
      {
        # Human-readable representation of the type, should be equivalent to
        # the type function name.
        name,
        # Description of the type, defined recursively by embedding the wrapped type if any.
        description ? null,
        # A hint for whether or not this description needs parentheses. Possible values:
        #  - "noun": a noun phrase
        #    Example description: "positive integer",
        #  - "conjunction": a phrase with a potentially ambiguous "or" connective
        #    Example description: "int or string"
        #  - "composite": a phrase with an "of" connective
        #    Example description: "list of string"
        #  - "nonRestrictiveClause": a noun followed by a comma and a clause
        #    Example description: "positive integer, meaning >0"
        # See the `optionDescriptionPhrase` function.
        descriptionClass ? null,
        # DO NOT USE WITHOUT KNOWING WHAT YOU ARE DOING!
        # Function applied to each definition that must return false when a definition
        # does not match the type. It should not check more than the root of the value,
        # because checking nested values reduces laziness, leading to unnecessary
        # infinite recursions in the module system.
        # Further checks of nested values should be performed by throwing in
        # the merge function.
        # Strict and deep type checking can be performed by calling lib.deepSeq on
        # the merged value.
        #
        # See https://github.com/NixOS/nixpkgs/pull/6794 that introduced this change,
        # https://github.com/NixOS/nixpkgs/pull/173568 and
        # https://github.com/NixOS/nixpkgs/pull/168295 that attempted to revert this,
        # https://github.com/NixOS/nixpkgs/issues/191124 and
        # https://github.com/NixOS/nixos-search/issues/391 for what happens if you ignore
        # this disclaimer.
        check ? (x: true),
        # Merge a list of definitions together into a single value.
        # This function is called with two arguments: the location of
        # the option in the configuration as a list of strings
        # (e.g. ["boot" "loader "grub" "enable"]), and a list of
        # definition values and locations (e.g. [ { file = "/foo.nix";
        # value = 1; } { file = "/bar.nix"; value = 2 } ]).
        merge ? mergeDefaultOption,
        # Whether this type has a value representing nothingness. If it does,
        # this should be a value of the form { value = <the nothing value>; }
        # If it doesn't, this should be {}
        # This may be used when a value is required for `mkIf false`. This allows the extra laziness in e.g. `lazyAttrsOf`.
        emptyValue ? { },
        # Return a flat attrset of sub-options.  Used to generate
        # documentation.
        getSubOptions ? prefix: { },
        # List of modules if any, or null if none.
        getSubModules ? null,
        # Function for building the same option type with a different list of
        # modules.
        substSubModules ? m: null,
        # Function that merge type declarations.
        # internal, takes a functor as argument and returns the merged type.
        # returning null means the type is not mergeable
        typeMerge ? defaultTypeMerge functor,
        # The type functor.
        # internal, representation of the type as an attribute set.
        #   name: name of the type
        #   type: type function.
        #   wrapped: the type wrapped in case of compound types.
        #   payload: values of the type, two payloads of the same type must be
        #            combinable with the binOp binary operation.
        #   binOp: binary operation that merge two payloads of the same type.
        functor ? defaultFunctor name,
        # The deprecation message to display when this type is used by an option
        # If null, the type isn't deprecated
        deprecationMessage ? null,
        # The types that occur in the definition of this type. This is used to
        # issue deprecation warnings recursively. Can also be used to reuse
        # nested types
        nestedTypes ? { },
      }:
      {
        _type = "option-type";
        inherit
          name
          check
          merge
          emptyValue
          getSubOptions
          getSubModules
          substSubModules
          typeMerge
          deprecationMessage
          nestedTypes
          descriptionClass
          ;
        functor =
          if functor ? wrappedDeprecationMessage then
            functor
            // {
              wrapped = functor.wrappedDeprecationMessage {
                loc = null;
              };
            }
          else
            functor;
        description = if description == null then name else description;
      };

    # optionDescriptionPhrase :: (str -> bool) -> optionType -> str
    #
    # Helper function for producing unambiguous but readable natural language
    # descriptions of types.
    #
    # Parameters
    #
    #     optionDescriptionPhase unparenthesize optionType
    #
    # `unparenthesize`: A function from descriptionClass string to boolean.
    #   It must return true when the class of phrase will fit unambiguously into
    #   the description of the caller.
    #
    # `optionType`: The option type to parenthesize or not.
    #   The option whose description we're returning.
    #
    # Return value
    #
    # The description of the `optionType`, with parentheses if there may be an
    # ambiguity.
    optionDescriptionPhrase =
      unparenthesize: t:
      if unparenthesize (t.descriptionClass or null) then t.description else "(${t.description})";

    noCheckForDocsModule = {
      # When generating documentation, our goal isn't to check anything.
      # Quite the opposite in fact. Generating docs is somewhat of a
      # challenge, evaluating modules in a *lacking* context. Anything
      # that makes the docs avoid an error is a win.
      config._module.check = lib.mkForce false;
      _file = "<built-in module that disables checks for the purpose of documentation generation>";
    };

    # When adding new types don't forget to document them in
    # nixos/doc/manual/development/option-types.section.md!
    types = rec {

      raw = mkOptionType {
        name = "raw";
        description = "raw value";
        descriptionClass = "noun";
        check = value: true;
        merge = mergeOneOption;
      };

      anything = mkOptionType {
        name = "anything";
        description = "anything";
        descriptionClass = "noun";
        check = value: true;
        merge =
          loc: defs:
          let
            getType =
              value: if isAttrs value && isStringLike value then "stringCoercibleSet" else builtins.typeOf value;

            # Returns the common type of all definitions, throws an error if they
            # don't have the same type
            commonType = foldl' (
              type: def:
              if getType def.value == type then
                type
              else
                throw "The option `${showOption loc}' has conflicting option types in ${showFiles (getFiles defs)}"
            ) (getType (head defs).value) defs;

            mergeFunction =
              {
                # Recursively merge attribute sets
                set = (attrsOf anything).merge;
                # This is the type of packages, only accept a single definition
                stringCoercibleSet = mergeOneOption;
                lambda =
                  loc: defs: arg:
                  anything.merge (loc ++ [ "<function body>" ]) (
                    map (def: {
                      file = def.file;
                      value = def.value arg;
                    }) defs
                  );
                # Otherwise fall back to only allowing all equal definitions
              }
              .${commonType} or mergeEqualOption;
          in
          mergeFunction loc defs;
      };

      unspecified = mkOptionType {
        name = "unspecified";
        description = "unspecified value";
        descriptionClass = "noun";
      };

      bool = mkOptionType {
        name = "bool";
        description = "boolean";
        descriptionClass = "noun";
        check = isBool;
        merge = mergeEqualOption;
      };

      boolByOr = mkOptionType {
        name = "boolByOr";
        description = "boolean (merged using or)";
        descriptionClass = "noun";
        check = isBool;
        merge =
          loc: defs:
          foldl' (
            result: def:
            # Under the assumption that .check always runs before merge, we can assume that all defs.*.value
            # have been forced, and therefore we assume we don't introduce order-dependent strictness here
            result || def.value
          ) false defs;
      };

      int = mkOptionType {
        name = "int";
        description = "signed integer";
        descriptionClass = "noun";
        check = isInt;
        merge = mergeEqualOption;
      };

      # Specialized subdomains of int
      ints =
        let
          betweenDesc = lowest: highest: "${toString lowest} and ${toString highest} (both inclusive)";
          between =
            lowest: highest:
            assert lib.assertMsg (lowest <= highest) "ints.between: lowest must be smaller than highest";
            addCheck int (x: x >= lowest && x <= highest)
            // {
              name = "intBetween";
              description = "integer between ${betweenDesc lowest highest}";
            };
          ign =
            lowest: highest: name: docStart:
            between lowest highest
            // {
              inherit name;
              description = docStart + "; between ${betweenDesc lowest highest}";
            };
          unsign =
            bit: range: ign 0 (range - 1) "unsignedInt${toString bit}" "${toString bit} bit unsigned integer";
          sign =
            bit: range:
            ign (0 - (range / 2)) (
              range / 2 - 1
            ) "signedInt${toString bit}" "${toString bit} bit signed integer";

        in
        {
          # TODO: Deduplicate with docs in nixos/doc/manual/development/option-types.section.md
          /**
            An int with a fixed range.

            # Example
            :::{.example}
            ## `lib.types.ints.between` usage example

            ```nix
            (ints.between 0 100).check (-1)
            => false
            (ints.between 0 100).check (101)
            => false
            (ints.between 0 0).check 0
            => true
            ```

            :::
          */
          inherit between;

          unsigned = addCheck types.int (x: x >= 0) // {
            name = "unsignedInt";
            description = "unsigned integer, meaning >=0";
            descriptionClass = "nonRestrictiveClause";
          };
          positive = addCheck types.int (x: x > 0) // {
            name = "positiveInt";
            description = "positive integer, meaning >0";
            descriptionClass = "nonRestrictiveClause";
          };
          u8 = unsign 8 256;
          u16 = unsign 16 65536;
          # the biggest int Nix accepts is 2^63 - 1 (9223372036854775808)
          # the smallest int Nix accepts is -2^63 (-9223372036854775807)
          u32 = unsign 32 4294967296;
          # u64 = unsign 64 18446744073709551616;

          s8 = sign 8 256;
          s16 = sign 16 65536;
          s32 = sign 32 4294967296;
        };

      # Alias of u16 for a port number
      port = ints.u16;

      float = mkOptionType {
        name = "float";
        description = "floating point number";
        descriptionClass = "noun";
        check = isFloat;
        merge = mergeEqualOption;
      };

      number = either int float;

      numbers =
        let
          betweenDesc =
            lowest: highest: "${builtins.toJSON lowest} and ${builtins.toJSON highest} (both inclusive)";
        in
        {
          between =
            lowest: highest:
            assert lib.assertMsg (lowest <= highest) "numbers.between: lowest must be smaller than highest";
            addCheck number (x: x >= lowest && x <= highest)
            // {
              name = "numberBetween";
              description = "integer or floating point number between ${betweenDesc lowest highest}";
            };

          nonnegative = addCheck number (x: x >= 0) // {
            name = "numberNonnegative";
            description = "nonnegative integer or floating point number, meaning >=0";
            descriptionClass = "nonRestrictiveClause";
          };
          positive = addCheck number (x: x > 0) // {
            name = "numberPositive";
            description = "positive integer or floating point number, meaning >0";
            descriptionClass = "nonRestrictiveClause";
          };
        };

      str = mkOptionType {
        name = "str";
        description = "string";
        descriptionClass = "noun";
        check = isString;
        merge = mergeEqualOption;
      };

      nonEmptyStr = mkOptionType {
        name = "nonEmptyStr";
        description = "non-empty string";
        descriptionClass = "noun";
        check = x: str.check x && builtins.match "[ \t\n]*" x == null;
        inherit (str) merge;
      };

      # Allow a newline character at the end and trim it in the merge function.
      singleLineStr =
        let
          inherit (strMatching "[^\n\r]*\n?") check merge;
        in
        mkOptionType {
          name = "singleLineStr";
          description = "(optionally newline-terminated) single-line string";
          descriptionClass = "noun";
          inherit check;
          merge = loc: defs: lib.removeSuffix "\n" (merge loc defs);
        };

      strMatching =
        pattern:
        mkOptionType {
          name = "strMatching ${escapeNixString pattern}";
          description = "string matching the pattern ${pattern}";
          descriptionClass = "noun";
          check = x: str.check x && builtins.match pattern x != null;
          inherit (str) merge;
          functor = defaultFunctor "strMatching" // {
            type = payload: strMatching payload.pattern;
            payload = { inherit pattern; };
            binOp = lhs: rhs: if lhs == rhs then lhs else null;
          };
        };

      # Merge multiple definitions by concatenating them (with the given
      # separator between the values).
      separatedString =
        sep:
        mkOptionType rec {
          name = "separatedString";
          description =
            if sep == "" then
              "Concatenated string" # for types.string.
            else
              "strings concatenated with ${builtins.toJSON sep}";
          descriptionClass = "noun";
          check = isString;
          merge = loc: defs: concatStringsSep sep (getValues defs);
          functor = (defaultFunctor name) // {
            payload = { inherit sep; };
            type = payload: types.separatedString payload.sep;
            binOp = lhs: rhs: if lhs.sep == rhs.sep then { inherit (lhs) sep; } else null;
          };
        };

      lines = separatedString "\n";
      commas = separatedString ",";
      envVar = separatedString ":";

      # Deprecated; should not be used because it quietly concatenates
      # strings, which is usually not what you want.
      # We use a lib.warn because `deprecationMessage` doesn't trigger in nested types such as `attrsOf string`
      string =
        lib.warn
          "The type `types.string` is deprecated. See https://github.com/NixOS/nixpkgs/pull/66346 for better alternative types."
          (
            separatedString ""
            // {
              name = "string";
            }
          );

      passwdEntry =
        entryType:
        addCheck entryType (str: !(hasInfix ":" str || hasInfix "\n" str))
        // {
          name = "passwdEntry ${entryType.name}";
          description = "${
            optionDescriptionPhrase (class: class == "noun") entryType
          }, not containing newlines or colons";
          descriptionClass = "nonRestrictiveClause";
        };

      attrs = mkOptionType {
        name = "attrs";
        description = "attribute set";
        check = isAttrs;
        merge = loc: foldl' (res: def: res // def.value) { };
        emptyValue = {
          value = { };
        };
      };

      # A package is a top-level store path (/nix/store/hash-name). This includes:
      # - derivations
      # - more generally, attribute sets with an `outPath` or `__toString` attribute
      #   pointing to a store path, e.g. flake inputs
      # - strings with context, e.g. "${pkgs.foo}" or (toString pkgs.foo)
      # - hardcoded store path literals (/nix/store/hash-foo) or strings without context
      #   ("/nix/store/hash-foo"). These get a context added to them using builtins.storePath.
      # If you don't need a *top-level* store path, consider using pathInStore instead.
      package = mkOptionType {
        name = "package";
        descriptionClass = "noun";
        check = x: isDerivation x || isStorePath x;
        merge =
          loc: defs:
          let
            res = mergeOneOption loc defs;
          in
          if builtins.isPath res || (builtins.isString res && !builtins.hasContext res) then
            toDerivation res
          else
            res;
      };

      shellPackage = package // {
        check = x: isDerivation x && hasAttr "shellPath" x;
      };

      pkgs = addCheck (
        unique { message = "A Nixpkgs pkgs set can not be merged with another pkgs set."; } attrs
        // {
          name = "pkgs";
          descriptionClass = "noun";
          description = "Nixpkgs package set";
        }
      ) (x: (x._type or null) == "pkgs");

      path = pathWith {
        absolute = true;
      };

      pathInStore = pathWith {
        inStore = true;
      };

      pathWith =
        {
          inStore ? null,
          absolute ? null,
        }:
        throwIf (inStore != null && absolute != null && inStore && !absolute)
          "In pathWith, inStore means the path must be absolute"
          mkOptionType
          {
            name = "path";
            description = (
              (if absolute == null then "" else (if absolute then "absolute " else "relative "))
              + "path"
              + (
                if inStore == null then "" else (if inStore then " in the Nix store" else " not in the Nix store")
              )
            );
            descriptionClass = "noun";

            merge = mergeEqualOption;
            functor = defaultFunctor "path" // {
              type = pathWith;
              payload = { inherit inStore absolute; };
              binOp = lhs: rhs: if lhs == rhs then lhs else null;
            };

            check =
              x:
              let
                isInStore = lib.path.hasStorePathPrefix (
                  if builtins.isPath x then
                    x
                  # Discarding string context is necessary to convert the value to
                  # a path and safe as the result is never used in any derivation.
                  else
                    /. + builtins.unsafeDiscardStringContext x
                );
                isAbsolute = builtins.substring 0 1 (toString x) == "/";
                isExpectedType = (
                  if inStore == null || inStore then isStringLike x else isString x # Do not allow a true path, which could be copied to the store later on.
                );
              in
              isExpectedType
              && (inStore == null || inStore == isInStore)
              && (absolute == null || absolute == isAbsolute);
          };

      listOf =
        elemType:
        mkOptionType rec {
          name = "listOf";
          description = "list of ${
            optionDescriptionPhrase (class: class == "noun" || class == "composite") elemType
          }";
          descriptionClass = "composite";
          check = isList;
          merge =
            loc: defs:
            map (x: x.value) (
              filter (x: x ? value) (
                concatLists (
                  imap1 (
                    n: def:
                    imap1 (
                      m: def':
                      (mergeDefinitions (loc ++ [ "[definition ${toString n}-entry ${toString m}]" ]) elemType [
                        {
                          inherit (def) file;
                          value = def';
                        }
                      ]).optionalValue
                    ) def.value
                  ) defs
                )
              )
            );
          emptyValue = {
            value = [ ];
          };
          getSubOptions = prefix: elemType.getSubOptions (prefix ++ [ "*" ]);
          getSubModules = elemType.getSubModules;
          substSubModules = m: listOf (elemType.substSubModules m);
          functor = (elemTypeFunctor name { inherit elemType; }) // {
            type = payload: types.listOf payload.elemType;
          };
          nestedTypes.elemType = elemType;
        };

      nonEmptyListOf =
        elemType:
        let
          list = addCheck (types.listOf elemType) (l: l != [ ]);
        in
        list
        // {
          description = "non-empty ${optionDescriptionPhrase (class: class == "noun") list}";
          emptyValue = { }; # no .value attr, meaning unset
          substSubModules = m: nonEmptyListOf (elemType.substSubModules m);
        };

      attrsOf = elemType: attrsWith { inherit elemType; };

      # A version of attrsOf that's lazy in its values at the expense of
      # conditional definitions not working properly. E.g. defining a value with
      # `foo.attr = mkIf false 10`, then `foo ? attr == true`, whereas with
      # attrsOf it would correctly be `false`. Accessing `foo.attr` would throw an
      # error that it's not defined. Use only if conditional definitions don't make sense.
      lazyAttrsOf =
        elemType:
        attrsWith {
          inherit elemType;
          lazy = true;
        };

      # base type for lazyAttrsOf and attrsOf
      attrsWith =
        let
          # Push down position info.
          pushPositions = map (
            def:
            mapAttrs (n: v: {
              inherit (def) file;
              value = v;
            }) def.value
          );
          binOp =
            lhs: rhs:
            let
              elemType = lhs.elemType.typeMerge rhs.elemType.functor;
              lazy = if lhs.lazy == rhs.lazy then lhs.lazy else null;
              placeholder =
                if lhs.placeholder == rhs.placeholder then
                  lhs.placeholder
                else if lhs.placeholder == "name" then
                  rhs.placeholder
                else if rhs.placeholder == "name" then
                  lhs.placeholder
                else
                  null;
            in
            if elemType == null || lazy == null || placeholder == null then
              null
            else
              {
                inherit elemType lazy placeholder;
              };
        in
        {
          elemType,
          lazy ? false,
          placeholder ? "name",
        }:
        mkOptionType {
          name = if lazy then "lazyAttrsOf" else "attrsOf";
          description =
            (if lazy then "lazy attribute set" else "attribute set")
            + " of ${optionDescriptionPhrase (class: class == "noun" || class == "composite") elemType}";
          descriptionClass = "composite";
          check = isAttrs;
          merge =
            if lazy then
              (
                # Lazy merge Function
                loc: defs:
                zipAttrsWith
                  (
                    name: defs:
                    let
                      merged = mergeDefinitions (loc ++ [ name ]) elemType defs;
                      # mergedValue will trigger an appropriate error when accessed
                    in
                    merged.optionalValue.value or elemType.emptyValue.value or merged.mergedValue
                  )
                  # Push down position info.
                  (pushPositions defs)
              )
            else
              (
                # Non-lazy merge Function
                loc: defs:
                mapAttrs (n: v: v.value) (
                  filterAttrs (n: v: v ? value) (
                    zipAttrsWith (name: defs: (mergeDefinitions (loc ++ [ name ]) elemType (defs)).optionalValue)
                      # Push down position info.
                      (pushPositions defs)
                  )
                )
              );
          emptyValue = {
            value = { };
          };
          getSubOptions = prefix: elemType.getSubOptions (prefix ++ [ "<${placeholder}>" ]);
          getSubModules = elemType.getSubModules;
          substSubModules =
            m:
            attrsWith {
              elemType = elemType.substSubModules m;
              inherit lazy placeholder;
            };
          functor =
            (elemTypeFunctor "attrsWith" {
              inherit elemType lazy placeholder;
            })
            // {
              # Custom type merging required because of the "placeholder" attribute
              inherit binOp;
            };
          nestedTypes.elemType = elemType;
        };

      # TODO: deprecate this in the future:
      loaOf =
        elemType:
        types.attrsOf elemType
        // {
          name = "loaOf";
          deprecationMessage =
            "Mixing lists with attribute values is no longer"
            + " possible; please use `types.attrsOf` instead. See"
            + " https://github.com/NixOS/nixpkgs/issues/1800 for the motivation.";
          nestedTypes.elemType = elemType;
        };

      attrTag =
        tags:
        let
          tags_ = tags;
        in
        let
          tags = mapAttrs (
            n: opt:
            builtins.addErrorContext
              "while checking that attrTag tag ${lib.strings.escapeNixIdentifier n} is an option with a type${inAttrPosSuffix tags_ n}"
              (
                throwIf (opt._type or null != "option")
                  "In attrTag, each tag value must be an option, but tag ${lib.strings.escapeNixIdentifier n} ${
                    if opt ? _type then
                      if opt._type == "option-type" then
                        "was a bare type, not wrapped in mkOption."
                      else
                        "was of type ${lib.strings.escapeNixString opt._type}."
                    else
                      "was not."
                  }"
                  opt
                // {
                  declarations =
                    opt.declarations or (
                      let
                        pos = builtins.unsafeGetAttrPos n tags_;
                      in
                      if pos == null then [ ] else [ pos.file ]
                    );
                  declarationPositions =
                    opt.declarationPositions or (
                      let
                        pos = builtins.unsafeGetAttrPos n tags_;
                      in
                      if pos == null then [ ] else [ pos ]
                    );
                }
              )
          ) tags_;
          choicesStr = concatMapStringsSep ", " lib.strings.escapeNixIdentifier (attrNames tags);
        in
        mkOptionType {
          name = "attrTag";
          description = "attribute-tagged union";
          descriptionClass = "noun";
          getSubOptions =
            prefix: mapAttrs (tagName: tagOption: tagOption // { loc = prefix ++ [ tagName ]; }) tags;
          check = v: isAttrs v && length (attrNames v) == 1 && tags ? ${head (attrNames v)};
          merge =
            loc: defs:
            let
              choice = head (attrNames (head defs).value);
              checkedValueDefs = map (
                def:
                assert (length (attrNames def.value)) == 1;
                if (head (attrNames def.value)) != choice then
                  throw "The option `${showOption loc}` is defined both as `${choice}` and `${head (attrNames def.value)}`, in ${showFiles (getFiles defs)}."
                else
                  {
                    inherit (def) file;
                    value = def.value.${choice};
                  }
              ) defs;
            in
            if tags ? ${choice} then
              {
                ${choice} = (lib.modules.evalOptionValue (loc ++ [ choice ]) tags.${choice} checkedValueDefs).value;
              }
            else
              throw "The option `${showOption loc}` is defined as ${lib.strings.escapeNixIdentifier choice}, but ${lib.strings.escapeNixIdentifier choice} is not among the valid choices (${choicesStr}). Value ${choice} was defined in ${showFiles (getFiles defs)}.";
          nestedTypes = tags;
          functor = defaultFunctor "attrTag" // {
            type = { tags, ... }: types.attrTag tags;
            payload = { inherit tags; };
            binOp =
              let
                # Add metadata in the format that submodules work with
                wrapOptionDecl = option: {
                  options = option;
                  _file = "<attrTag {...}>";
                  pos = null;
                };
              in
              a: b: {
                tags =
                  a.tags
                  // b.tags
                  // mapAttrs (
                    tagName: bOpt:
                    lib.mergeOptionDecls
                      # FIXME: loc is not accurate; should include prefix
                      #        Fortunately, it's only used for error messages, where a "relative" location is kinda ok.
                      #        It is also returned though, but use of the attribute seems rare?
                      [ tagName ]
                      [
                        (wrapOptionDecl a.tags.${tagName})
                        (wrapOptionDecl bOpt)
                      ]
                    // {
                      # mergeOptionDecls is not idempotent in these attrs:
                      declarations = a.tags.${tagName}.declarations ++ bOpt.declarations;
                      declarationPositions = a.tags.${tagName}.declarationPositions ++ bOpt.declarationPositions;
                    }
                  ) (builtins.intersectAttrs a.tags b.tags);
              };
          };
        };

      # A value produced by `lib.mkLuaInline`
      luaInline = mkOptionType {
        name = "luaInline";
        description = "inline lua";
        descriptionClass = "noun";
        check = x: x._type or null == "lua-inline";
        merge = mergeEqualOption;
      };

      uniq = unique { message = ""; };

      unique =
        { message }:
        type:
        mkOptionType rec {
          name = "unique";
          inherit (type) description descriptionClass check;
          merge = mergeUniqueOption {
            inherit message;
            inherit (type) merge;
          };
          emptyValue = type.emptyValue;
          getSubOptions = type.getSubOptions;
          getSubModules = type.getSubModules;
          substSubModules = m: uniq (type.substSubModules m);
          functor = elemTypeFunctor name { elemType = type; } // {
            type = payload: types.unique { inherit message; } payload.elemType;
          };
          nestedTypes.elemType = type;
        };

      # Null or value of ...
      nullOr =
        elemType:
        mkOptionType rec {
          name = "nullOr";
          description = "null or ${
            optionDescriptionPhrase (class: class == "noun" || class == "conjunction") elemType
          }";
          descriptionClass = "conjunction";
          check = x: x == null || elemType.check x;
          merge =
            loc: defs:
            let
              nrNulls = count (def: def.value == null) defs;
            in
            if nrNulls == length defs then
              null
            else if nrNulls != 0 then
              throw "The option `${showOption loc}` is defined both null and not null, in ${showFiles (getFiles defs)}."
            else
              elemType.merge loc defs;
          emptyValue = {
            value = null;
          };
          getSubOptions = elemType.getSubOptions;
          getSubModules = elemType.getSubModules;
          substSubModules = m: nullOr (elemType.substSubModules m);
          functor = (elemTypeFunctor name { inherit elemType; }) // {
            type = payload: types.nullOr payload.elemType;
          };
          nestedTypes.elemType = elemType;
        };

      functionTo =
        elemType:
        mkOptionType {
          name = "functionTo";
          description = "function that evaluates to a(n) ${
            optionDescriptionPhrase (class: class == "noun" || class == "composite") elemType
          }";
          descriptionClass = "composite";
          check = isFunction;
          merge = loc: defs: {
            # An argument attribute has a default when it has a default in all definitions
            __functionArgs = lib.zipAttrsWith (_: lib.all (x: x)) (
              lib.map (fn: lib.functionArgs fn.value) defs
            );
            __functor =
              _: callerArgs:
              (mergeDefinitions (loc ++ [ "<function body>" ]) elemType (
                map (fn: {
                  inherit (fn) file;
                  value = fn.value callerArgs;
                }) defs
              )).mergedValue;
          };
          getSubOptions = prefix: elemType.getSubOptions (prefix ++ [ "<function body>" ]);
          getSubModules = elemType.getSubModules;
          substSubModules = m: functionTo (elemType.substSubModules m);
          functor = (elemTypeFunctor "functionTo" { inherit elemType; }) // {
            type = payload: types.functionTo payload.elemType;
          };
          nestedTypes.elemType = elemType;
        };

      # A submodule (like typed attribute set). See NixOS manual.
      submodule =
        modules:
        submoduleWith {
          shorthandOnlyDefinesConfig = true;
          modules = toList modules;
        };

      # A module to be imported in some other part of the configuration.
      deferredModule = deferredModuleWith { };

      # A module to be imported in some other part of the configuration.
      # `staticModules`' options will be added to the documentation, unlike
      # options declared via `config`.
      deferredModuleWith =
        attrs@{
          staticModules ? [ ],
        }:
        mkOptionType {
          name = "deferredModule";
          description = "module";
          descriptionClass = "noun";
          check = x: isAttrs x || isFunction x || path.check x;
          merge = loc: defs: {
            imports =
              staticModules
              ++ map (
                def: lib.setDefaultModuleLocation "${def.file}, via option ${showOption loc}" def.value
              ) defs;
          };
          inherit (submoduleWith { modules = staticModules; })
            getSubOptions
            getSubModules
            ;
          substSubModules =
            m:
            deferredModuleWith (
              attrs
              // {
                staticModules = m;
              }
            );
          functor = defaultFunctor "deferredModuleWith" // {
            type = types.deferredModuleWith;
            payload = {
              inherit staticModules;
            };
            binOp = lhs: rhs: {
              staticModules = lhs.staticModules ++ rhs.staticModules;
            };
          };
        };

      # The type of a type!
      optionType = mkOptionType {
        name = "optionType";
        description = "optionType";
        descriptionClass = "noun";
        check = value: value._type or null == "option-type";
        merge =
          loc: defs:
          if length defs == 1 then
            (head defs).value
          else
            let
              # Prepares the type definitions for mergeOptionDecls, which
              # annotates submodules types with file locations
              optionModules = map (
                { value, file }:
                {
                  _file = file;
                  # There's no way to merge types directly from the module system,
                  # but we can cheat a bit by just declaring an option with the type
                  options = lib.mkOption {
                    type = value;
                  };
                }
              ) defs;
              # Merges all the types into a single one, including submodule merging.
              # This also propagates file information to all submodules
              mergedOption = fixupOptionType loc (mergeOptionDecls loc optionModules);
            in
            mergedOption.type;
      };

      submoduleWith =
        {
          modules,
          specialArgs ? { },
          shorthandOnlyDefinesConfig ? false,
          description ? null,
          class ? null,
        }@attrs:
        let
          inherit (lib.modules) evalModules;

          allModules =
            defs:
            map (
              { value, file }:
              if isAttrs value && shorthandOnlyDefinesConfig then
                {
                  _file = file;
                  config = value;
                }
              else
                {
                  _file = file;
                  imports = [ value ];
                }
            ) defs;

          base = evalModules {
            inherit class specialArgs;
            modules = [
              {
                # This is a work-around for the fact that some sub-modules,
                # such as the one included in an attribute set, expects an "args"
                # attribute to be given to the sub-module. As the option
                # evaluation does not have any specific attribute name yet, we
                # provide a default for the documentation and the freeform type.
                #
                # This is necessary as some option declaration might use the
                # "name" attribute given as argument of the submodule and use it
                # as the default of option declarations.
                #
                # We use lookalike unicode single angle quotation marks because
                # of the docbook transformation the options receive. In all uses
                # &gt; and &lt; wouldn't be encoded correctly so the encoded values
                # would be used, and use of `<` and `>` would break the XML document.
                # It shouldn't cause an issue since this is cosmetic for the manual.
                _module.args.name = lib.mkOptionDefault "‹name›";
              }
            ]
            ++ modules;
          };

          freeformType = base._module.freeformType;

          name = "submodule";

        in
        mkOptionType {
          inherit name;
          description =
            if description != null then
              description
            else
              let
                docsEval = base.extendModules { modules = [ noCheckForDocsModule ]; };
              in
              docsEval._module.freeformType.description or name;
          check = x: isAttrs x || isFunction x || path.check x;
          merge =
            loc: defs:
            (base.extendModules {
              modules = [ { _module.args.name = last loc; } ] ++ allModules defs;
              prefix = loc;
            }).config;
          emptyValue = {
            value = { };
          };
          getSubOptions =
            prefix:
            let
              docsEval = (
                base.extendModules {
                  inherit prefix;
                  modules = [ noCheckForDocsModule ];
                }
              );
              # Intentionally shadow the freeformType from the possibly *checked*
              # configuration. See `noCheckForDocsModule` comment.
              inherit (docsEval._module) freeformType;
            in
            docsEval.options
            // optionalAttrs (freeformType != null) {
              # Expose the sub options of the freeform type. Note that the option
              # discovery doesn't care about the attribute name used here, so this
              # is just to avoid conflicts with potential options from the submodule
              _freeformOptions = freeformType.getSubOptions prefix;
            };
          getSubModules = modules;
          substSubModules =
            m:
            submoduleWith (
              attrs
              // {
                modules = m;
              }
            );
          nestedTypes = lib.optionalAttrs (freeformType != null) {
            freeformType = freeformType;
          };
          functor = defaultFunctor name // {
            type = types.submoduleWith;
            payload = {
              inherit
                modules
                class
                specialArgs
                shorthandOnlyDefinesConfig
                description
                ;
            };
            binOp = lhs: rhs: {
              class =
                # `or null` was added for backwards compatibility only. `class` is
                # always set in the current version of the module system.
                if lhs.class or null == null then
                  rhs.class or null
                else if rhs.class or null == null then
                  lhs.class or null
                else if lhs.class or null == rhs.class then
                  lhs.class or null
                else
                  throw "A submoduleWith option is declared multiple times with conflicting class values \"${toString lhs.class}\" and \"${toString rhs.class}\".";
              modules = lhs.modules ++ rhs.modules;
              specialArgs =
                let
                  intersecting = builtins.intersectAttrs lhs.specialArgs rhs.specialArgs;
                in
                if intersecting == { } then
                  lhs.specialArgs // rhs.specialArgs
                else
                  throw "A submoduleWith option is declared multiple times with the same specialArgs \"${toString (attrNames intersecting)}\"";
              shorthandOnlyDefinesConfig =
                if lhs.shorthandOnlyDefinesConfig == null then
                  rhs.shorthandOnlyDefinesConfig
                else if rhs.shorthandOnlyDefinesConfig == null then
                  lhs.shorthandOnlyDefinesConfig
                else if lhs.shorthandOnlyDefinesConfig == rhs.shorthandOnlyDefinesConfig then
                  lhs.shorthandOnlyDefinesConfig
                else
                  throw "A submoduleWith option is declared multiple times with conflicting shorthandOnlyDefinesConfig values";
              description =
                if lhs.description == null then
                  rhs.description
                else if rhs.description == null then
                  lhs.description
                else if lhs.description == rhs.description then
                  lhs.description
                else
                  throw "A submoduleWith option is declared multiple times with conflicting descriptions";
            };
          };
        };

      # A value from a set of allowed ones.
      enum =
        values:
        let
          inherit (lib.lists) unique;
          show =
            v:
            if builtins.isString v then
              ''"${v}"''
            else if builtins.isInt v then
              builtins.toString v
            else if builtins.isBool v then
              boolToString v
            else
              ''<${builtins.typeOf v}>'';
        in
        mkOptionType rec {
          name = "enum";
          description =
            # Length 0 or 1 enums may occur in a design pattern with type merging
            # where an "interface" module declares an empty enum and other modules
            # provide implementations, each extending the enum with their own
            # identifier.
            if values == [ ] then
              "impossible (empty enum)"
            else if builtins.length values == 1 then
              "value ${show (builtins.head values)} (singular enum)"
            else
              "one of ${concatMapStringsSep ", " show values}";
          descriptionClass = if builtins.length values < 2 then "noun" else "conjunction";
          check = flip elem values;
          merge = mergeEqualOption;
          functor = (defaultFunctor name) // {
            payload = { inherit values; };
            type = payload: types.enum payload.values;
            binOp = a: b: { values = unique (a.values ++ b.values); };
          };
        };

      # Either value of type `t1` or `t2`.
      either =
        t1: t2:
        mkOptionType rec {
          name = "either";
          description =
            if t1.descriptionClass or null == "nonRestrictiveClause" then
              # Plain, but add comma
              "${t1.description}, or ${
                optionDescriptionPhrase (class: class == "noun" || class == "conjunction") t2
              }"
            else
              "${optionDescriptionPhrase (class: class == "noun" || class == "conjunction") t1} or ${
                optionDescriptionPhrase (
                  class: class == "noun" || class == "conjunction" || class == "composite"
                ) t2
              }";
          descriptionClass = "conjunction";
          check = x: t1.check x || t2.check x;
          merge =
            loc: defs:
            let
              defList = map (d: d.value) defs;
            in
            if all (x: t1.check x) defList then
              t1.merge loc defs
            else if all (x: t2.check x) defList then
              t2.merge loc defs
            else
              mergeOneOption loc defs;
          typeMerge =
            f':
            let
              mt1 = t1.typeMerge (elemAt f'.payload.elemType 0).functor;
              mt2 = t2.typeMerge (elemAt f'.payload.elemType 1).functor;
            in
            if (name == f'.name) && (mt1 != null) && (mt2 != null) then functor.type mt1 mt2 else null;
          functor = elemTypeFunctor name {
            elemType = [
              t1
              t2
            ];
          };
          nestedTypes.left = t1;
          nestedTypes.right = t2;
        };

      # Any of the types in the given list
      oneOf =
        ts:
        let
          head' =
            if ts == [ ] then throw "types.oneOf needs to get at least one type in its argument" else head ts;
          tail' = tail ts;
        in
        foldl' either head' tail';

      # Either value of type `coercedType` or `finalType`, the former is
      # converted to `finalType` using `coerceFunc`.
      coercedTo =
        coercedType: coerceFunc: finalType:
        assert lib.assertMsg (
          coercedType.getSubModules == null
        ) "coercedTo: coercedType must not have submodules (it’s a ${coercedType.description})";
        mkOptionType rec {
          name = "coercedTo";
          description = "${optionDescriptionPhrase (class: class == "noun") finalType} or ${
            optionDescriptionPhrase (class: class == "noun") coercedType
          } convertible to it";
          check = x: (coercedType.check x && finalType.check (coerceFunc x)) || finalType.check x;
          merge =
            loc: defs:
            let
              coerceVal = val: if coercedType.check val then coerceFunc val else val;
            in
            finalType.merge loc (map (def: def // { value = coerceVal def.value; }) defs);
          emptyValue = finalType.emptyValue;
          getSubOptions = finalType.getSubOptions;
          getSubModules = finalType.getSubModules;
          substSubModules = m: coercedTo coercedType coerceFunc (finalType.substSubModules m);
          typeMerge = t: null;
          functor = (defaultFunctor name) // {
            wrappedDeprecationMessage = makeWrappedDeprecationMessage { elemType = finalType; };
          };
          nestedTypes.coercedType = coercedType;
          nestedTypes.finalType = finalType;
        };
      /**
        Augment the given type with an additional type check function.

        :::{.warning}
        This function has some broken behavior see: [#396021](https://github.com/NixOS/nixpkgs/issues/396021)
        Fixing is not trivial, we appreciate any help!
        :::
      */
      addCheck = elemType: check: elemType // { check = x: elemType.check x && check x; };

    };

    /**
      Merges two option types together.

      :::{.note}
      Uses the type merge function of the first type, to merge it with the second type.

      Usually types can only be merged if they are of the same type
      :::

      # Inputs

      : `a` (option type): The first option type.
      : `b` (option type): The second option type.

      # Returns

      - The merged option type.
      - `{ _type = "merge-error"; error = "Cannot merge types"; }` if the types can't be merged.

      # Examples
      :::{.example}
      ## `lib.types.mergeTypes` usage example
      ```nix
      let
        enumAB = lib.types.enum ["A" "B"];
        enumXY = lib.types.enum ["X" "Y"];
        # This operation could be notated as: [ A ] | [ B ] -> [ A B ]
        merged = lib.types.mergeTypes enumAB enumXY; # -> enum [ "A" "B" "X" "Y" ]
      in
        assert merged.check "A"; # true
        assert merged.check "B"; # true
        assert merged.check "X"; # true
        assert merged.check "Y"; # true
        merged.check "C" # false
      ```
      :::
    */
    mergeTypes =
      a: b:
      assert isOptionType a && isOptionType b;
      let
        merged = a.typeMerge b.functor;
      in
      if merged == null then setType "merge-error" { error = "Cannot merge types"; } else merged;
  };

in
outer_types // outer_types.types
</file>

<file path="lib/versions.nix">
# Version string functions.
{ lib }:

rec {

  /**
    Break a version string into its component parts.

    # Examples
    :::{.example}
    ## `splitVersion` usage example

    ```nix
    splitVersion "1.2.3"
    => ["1" "2" "3"]
    ```

    :::
  */
  splitVersion = builtins.splitVersion;

  /**
    Get the major version string from a string.

    # Inputs

    `v`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `major` usage example

    ```nix
    major "1.2.3"
    => "1"
    ```

    :::
  */
  major = v: builtins.elemAt (splitVersion v) 0;

  /**
    Get the minor version string from a string.

    # Inputs

    `v`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `minor` usage example

    ```nix
    minor "1.2.3"
    => "2"
    ```

    :::
  */
  minor = v: builtins.elemAt (splitVersion v) 1;

  /**
    Get the patch version string from a string.

    # Inputs

    `v`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `patch` usage example

    ```nix
    patch "1.2.3"
    => "3"
    ```

    :::
  */
  patch = v: builtins.elemAt (splitVersion v) 2;

  /**
    Get string of the first two parts (major and minor)
    of a version string.

    # Inputs

    `v`

    : 1\. Function argument

    # Examples
    :::{.example}
    ## `majorMinor` usage example

    ```nix
    majorMinor "1.2.3"
    => "1.2"
    ```

    :::
  */
  majorMinor = v: builtins.concatStringsSep "." (lib.take 2 (splitVersion v));

  /**
    Pad a version string with zeros to match the given number of components.

    # Inputs

    `n`

    : 1\. Function argument

    `version`

    : 2\. Function argument

    # Examples
    :::{.example}
    ## `pad` usage example

    ```nix
    pad 3 "1.2"
    => "1.2.0"
    pad 3 "1.3-rc1"
    => "1.3.0-rc1"
    pad 3 "1.2.3.4"
    => "1.2.3"
    ```

    :::
  */
  pad =
    n: version:
    let
      numericVersion = lib.head (lib.splitString "-" version);
      versionSuffix = lib.removePrefix numericVersion version;
    in
    lib.concatStringsSep "." (lib.take n (lib.splitVersion numericVersion ++ lib.genList (_: "0") n))
    + versionSuffix;

}
</file>

<file path="lib/zip-int-bits.nix">
/* Helper function to implement a fallback for the bit operators
   `bitAnd`, `bitOr` and `bitXor` on older nix version.
   See ./trivial.nix
*/
f: x: y:
  let
    # (intToBits 6) -> [ 0 1 1 ]
    intToBits = x:
      if x == 0 || x == -1 then
        []
      else
        let
          headbit  = if (x / 2) * 2 != x then 1 else 0;          # x & 1
          tailbits = if x < 0 then ((x + 1) / 2) - 1 else x / 2; # x >> 1
        in
          [headbit] ++ (intToBits tailbits);

    # (bitsToInt [ 0 1 1 ] 0) -> 6
    # (bitsToInt [ 0 1 0 ] 1) -> -6
    bitsToInt = l: signum:
      if l == [] then
        (if signum == 0 then 0 else -1)
      else
        (builtins.head l) + (2 * (bitsToInt (builtins.tail l) signum));

    xsignum = if x < 0 then 1 else 0;
    ysignum = if y < 0 then 1 else 0;
    zipListsWith' = fst: snd:
      if fst==[] && snd==[] then
        []
      else if fst==[] then
        [(f xsignum             (builtins.head snd))] ++ (zipListsWith' []                  (builtins.tail snd))
      else if snd==[] then
        [(f (builtins.head fst) ysignum            )] ++ (zipListsWith' (builtins.tail fst) []                 )
      else
        [(f (builtins.head fst) (builtins.head snd))] ++ (zipListsWith' (builtins.tail fst) (builtins.tail snd));
  in
    assert (builtins.isInt x) && (builtins.isInt y);
    bitsToInt (zipListsWith' (intToBits x) (intToBits y)) (f xsignum ysignum)
</file>

<file path="flake.nix">
{
  description = "A cheap & continously rebased fork of nixpkgs.lib";

  outputs = { self }: { lib = import ./lib; };
}
</file>

</files>
